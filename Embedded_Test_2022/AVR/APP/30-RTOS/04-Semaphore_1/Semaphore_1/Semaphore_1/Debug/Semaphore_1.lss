
Semaphore_1.elf:     file format elf32-avr

Sections:
Idx Name          Size      VMA       LMA       File off  Algn
  0 .text         00002868  00000000  00000000  00000094  2**1
                  CONTENTS, ALLOC, LOAD, READONLY, CODE
  1 .data         00000014  00800060  00002868  000028fc  2**0
                  CONTENTS, ALLOC, LOAD, DATA
  2 .bss          000003ba  00800074  00800074  00002910  2**0
                  ALLOC
  3 .stab         00000750  00000000  00000000  00002910  2**2
                  CONTENTS, READONLY, DEBUGGING
  4 .stabstr      000000e7  00000000  00000000  00003060  2**0
                  CONTENTS, READONLY, DEBUGGING
  5 .debug_aranges 00000160  00000000  00000000  00003148  2**3
                  CONTENTS, READONLY, DEBUGGING
  6 .debug_info   0000368c  00000000  00000000  000032a8  2**0
                  CONTENTS, READONLY, DEBUGGING
  7 .debug_abbrev 00000c78  00000000  00000000  00006934  2**0
                  CONTENTS, READONLY, DEBUGGING
  8 .debug_line   000013bc  00000000  00000000  000075ac  2**0
                  CONTENTS, READONLY, DEBUGGING
  9 .debug_frame  00000c24  00000000  00000000  00008968  2**2
                  CONTENTS, READONLY, DEBUGGING
 10 .debug_str    000015bd  00000000  00000000  0000958c  2**0
                  CONTENTS, READONLY, DEBUGGING
 11 .debug_loc    00004121  00000000  00000000  0000ab49  2**0
                  CONTENTS, READONLY, DEBUGGING
 12 .debug_ranges 00000130  00000000  00000000  0000ec6a  2**0
                  CONTENTS, READONLY, DEBUGGING

Disassembly of section .text:

00000000 <__vectors>:
       0:	0c 94 2a 00 	jmp	0x54	; 0x54 <__ctors_end>
       4:	0c 94 09 0a 	jmp	0x1412	; 0x1412 <__vector_1>
       8:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
       c:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      10:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      14:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      18:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      1c:	0c 94 72 05 	jmp	0xae4	; 0xae4 <__vector_7>
      20:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      24:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      28:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      2c:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      30:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      34:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      38:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      3c:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      40:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      44:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      48:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      4c:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      50:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>

00000054 <__ctors_end>:
      54:	11 24       	eor	r1, r1
      56:	1f be       	out	0x3f, r1	; 63
      58:	cf e5       	ldi	r28, 0x5F	; 95
      5a:	d8 e0       	ldi	r29, 0x08	; 8
      5c:	de bf       	out	0x3e, r29	; 62
      5e:	cd bf       	out	0x3d, r28	; 61

00000060 <__do_copy_data>:
      60:	10 e0       	ldi	r17, 0x00	; 0
      62:	a0 e6       	ldi	r26, 0x60	; 96
      64:	b0 e0       	ldi	r27, 0x00	; 0
      66:	e8 e6       	ldi	r30, 0x68	; 104
      68:	f8 e2       	ldi	r31, 0x28	; 40
      6a:	02 c0       	rjmp	.+4      	; 0x70 <__do_copy_data+0x10>
      6c:	05 90       	lpm	r0, Z+
      6e:	0d 92       	st	X+, r0
      70:	a4 37       	cpi	r26, 0x74	; 116
      72:	b1 07       	cpc	r27, r17
      74:	d9 f7       	brne	.-10     	; 0x6c <__do_copy_data+0xc>

00000076 <__do_clear_bss>:
      76:	14 e0       	ldi	r17, 0x04	; 4
      78:	a4 e7       	ldi	r26, 0x74	; 116
      7a:	b0 e0       	ldi	r27, 0x00	; 0
      7c:	01 c0       	rjmp	.+2      	; 0x80 <.do_clear_bss_start>

0000007e <.do_clear_bss_loop>:
      7e:	1d 92       	st	X+, r1

00000080 <.do_clear_bss_start>:
      80:	ae 32       	cpi	r26, 0x2E	; 46
      82:	b1 07       	cpc	r27, r17
      84:	e1 f7       	brne	.-8      	; 0x7e <.do_clear_bss_loop>
      86:	0e 94 de 09 	call	0x13bc	; 0x13bc <main>
      8a:	0c 94 32 14 	jmp	0x2864	; 0x2864 <_exit>

0000008e <__bad_interrupt>:
      8e:	0c 94 00 00 	jmp	0	; 0x0 <__vectors>

00000092 <prvTestWaitCondition>:

static BaseType_t prvTestWaitCondition( const EventBits_t uxCurrentEventBits, const EventBits_t uxBitsToWaitFor, const BaseType_t xWaitForAllBits )
{
BaseType_t xWaitConditionMet = pdFALSE;

	if( xWaitForAllBits == pdFALSE )
      92:	44 23       	and	r20, r20
      94:	41 f4       	brne	.+16     	; 0xa6 <prvTestWaitCondition+0x14>
	{
		/* Task only has to wait for one bit within uxBitsToWaitFor to be
		set.  Is one already set? */
		if( ( uxCurrentEventBits & uxBitsToWaitFor ) != ( EventBits_t ) 0 )
      96:	68 23       	and	r22, r24
      98:	79 23       	and	r23, r25
		{
			xWaitConditionMet = pdTRUE;
      9a:	81 e0       	ldi	r24, 0x01	; 1
      9c:	61 15       	cp	r22, r1
      9e:	71 05       	cpc	r23, r1
      a0:	51 f4       	brne	.+20     	; 0xb6 <prvTestWaitCondition+0x24>
      a2:	80 e0       	ldi	r24, 0x00	; 0
      a4:	08 95       	ret
	}
	else
	{
		/* Task has to wait for all the bits in uxBitsToWaitFor to be set.
		Are they set already? */
		if( ( uxCurrentEventBits & uxBitsToWaitFor ) == uxBitsToWaitFor )
      a6:	9b 01       	movw	r18, r22
      a8:	28 23       	and	r18, r24
      aa:	39 23       	and	r19, r25
	{
		/* Task only has to wait for one bit within uxBitsToWaitFor to be
		set.  Is one already set? */
		if( ( uxCurrentEventBits & uxBitsToWaitFor ) != ( EventBits_t ) 0 )
		{
			xWaitConditionMet = pdTRUE;
      ac:	81 e0       	ldi	r24, 0x01	; 1
      ae:	62 17       	cp	r22, r18
      b0:	73 07       	cpc	r23, r19
      b2:	09 f0       	breq	.+2      	; 0xb6 <prvTestWaitCondition+0x24>
      b4:	80 e0       	ldi	r24, 0x00	; 0
			mtCOVERAGE_TEST_MARKER();
		}
	}

	return xWaitConditionMet;
}
      b6:	08 95       	ret

000000b8 <xEventGroupCreate>:
/*-----------------------------------------------------------*/

#if( configSUPPORT_DYNAMIC_ALLOCATION == 1 )

	EventGroupHandle_t xEventGroupCreate( void )
	{
      b8:	cf 93       	push	r28
      ba:	df 93       	push	r29
	EventGroup_t *pxEventBits;

		/* Allocate the event group. */
		pxEventBits = ( EventGroup_t * ) pvPortMalloc( sizeof( EventGroup_t ) );
      bc:	8b e0       	ldi	r24, 0x0B	; 11
      be:	90 e0       	ldi	r25, 0x00	; 0
      c0:	0e 94 92 02 	call	0x524	; 0x524 <pvPortMalloc>
      c4:	ec 01       	movw	r28, r24

		if( pxEventBits != NULL )
      c6:	00 97       	sbiw	r24, 0x00	; 0
      c8:	31 f0       	breq	.+12     	; 0xd6 <xEventGroupCreate+0x1e>
		{
			pxEventBits->uxEventBits = 0;
      ca:	fc 01       	movw	r30, r24
      cc:	11 92       	st	Z+, r1
      ce:	11 92       	st	Z+, r1
      d0:	cf 01       	movw	r24, r30
			vListInitialise( &( pxEventBits->xTasksWaitingForBits ) );
      d2:	0e 94 6b 03 	call	0x6d6	; 0x6d6 <vListInitialise>
		{
			traceEVENT_GROUP_CREATE_FAILED();
		}

		return ( EventGroupHandle_t ) pxEventBits;
	}
      d6:	8c 2f       	mov	r24, r28
      d8:	9d 2f       	mov	r25, r29
      da:	df 91       	pop	r29
      dc:	cf 91       	pop	r28
      de:	08 95       	ret

000000e0 <xEventGroupWaitBits>:
	return uxReturn;
}
/*-----------------------------------------------------------*/

EventBits_t xEventGroupWaitBits( EventGroupHandle_t xEventGroup, const EventBits_t uxBitsToWaitFor, const BaseType_t xClearOnExit, const BaseType_t xWaitForAllBits, TickType_t xTicksToWait )
{
      e0:	af 92       	push	r10
      e2:	bf 92       	push	r11
      e4:	cf 92       	push	r12
      e6:	df 92       	push	r13
      e8:	ef 92       	push	r14
      ea:	ff 92       	push	r15
      ec:	0f 93       	push	r16
      ee:	1f 93       	push	r17
      f0:	cf 93       	push	r28
      f2:	df 93       	push	r29
      f4:	5c 01       	movw	r10, r24
      f6:	6b 01       	movw	r12, r22
      f8:	e4 2e       	mov	r14, r20
      fa:	f2 2e       	mov	r15, r18
	{
		configASSERT( !( ( xTaskGetSchedulerState() == taskSCHEDULER_SUSPENDED ) && ( xTicksToWait != 0 ) ) );
	}
	#endif

	vTaskSuspendAll();
      fc:	0e 94 97 0d 	call	0x1b2e	; 0x1b2e <vTaskSuspendAll>
	{
		const EventBits_t uxCurrentEventBits = pxEventBits->uxEventBits;
     100:	f5 01       	movw	r30, r10
     102:	c0 81       	ld	r28, Z
     104:	d1 81       	ldd	r29, Z+1	; 0x01

		/* Check to see if the wait condition is already met or not. */
		xWaitConditionMet = prvTestWaitCondition( uxCurrentEventBits, uxBitsToWaitFor, xWaitForAllBits );
     106:	ce 01       	movw	r24, r28
     108:	b6 01       	movw	r22, r12
     10a:	4f 2d       	mov	r20, r15
     10c:	0e 94 49 00 	call	0x92	; 0x92 <prvTestWaitCondition>

		if( xWaitConditionMet != pdFALSE )
     110:	88 23       	and	r24, r24
     112:	51 f0       	breq	.+20     	; 0x128 <xEventGroupWaitBits+0x48>
			block. */
			uxReturn = uxCurrentEventBits;
			xTicksToWait = ( TickType_t ) 0;

			/* Clear the wait bits if requested to do so. */
			if( xClearOnExit != pdFALSE )
     114:	ee 20       	and	r14, r14
     116:	01 f1       	breq	.+64     	; 0x158 <xEventGroupWaitBits+0x78>
			{
				pxEventBits->uxEventBits &= ~uxBitsToWaitFor;
     118:	c0 94       	com	r12
     11a:	d0 94       	com	r13
     11c:	cc 22       	and	r12, r28
     11e:	dd 22       	and	r13, r29
     120:	f5 01       	movw	r30, r10
     122:	d1 82       	std	Z+1, r13	; 0x01
     124:	c0 82       	st	Z, r12
     126:	18 c0       	rjmp	.+48     	; 0x158 <xEventGroupWaitBits+0x78>
			else
			{
				mtCOVERAGE_TEST_MARKER();
			}
		}
		else if( xTicksToWait == ( TickType_t ) 0 )
     128:	01 15       	cp	r16, r1
     12a:	11 05       	cpc	r17, r1
     12c:	a9 f0       	breq	.+42     	; 0x158 <xEventGroupWaitBits+0x78>
		{
			/* The task is going to block to wait for its required bits to be
			set.  uxControlBits are used to remember the specified behaviour of
			this call to xEventGroupWaitBits() - for use when the event bits
			unblock the task. */
			if( xClearOnExit != pdFALSE )
     12e:	ee 20       	and	r14, r14
     130:	19 f4       	brne	.+6      	; 0x138 <xEventGroupWaitBits+0x58>
/*-----------------------------------------------------------*/

EventBits_t xEventGroupWaitBits( EventGroupHandle_t xEventGroup, const EventBits_t uxBitsToWaitFor, const BaseType_t xClearOnExit, const BaseType_t xWaitForAllBits, TickType_t xTicksToWait )
{
EventGroup_t *pxEventBits = ( EventGroup_t * ) xEventGroup;
EventBits_t uxReturn, uxControlBits = 0;
     132:	60 e0       	ldi	r22, 0x00	; 0
     134:	70 e0       	ldi	r23, 0x00	; 0
     136:	02 c0       	rjmp	.+4      	; 0x13c <xEventGroupWaitBits+0x5c>
			set.  uxControlBits are used to remember the specified behaviour of
			this call to xEventGroupWaitBits() - for use when the event bits
			unblock the task. */
			if( xClearOnExit != pdFALSE )
			{
				uxControlBits |= eventCLEAR_EVENTS_ON_EXIT_BIT;
     138:	60 e0       	ldi	r22, 0x00	; 0
     13a:	71 e0       	ldi	r23, 0x01	; 1
			else
			{
				mtCOVERAGE_TEST_MARKER();
			}

			if( xWaitForAllBits != pdFALSE )
     13c:	f1 10       	cpse	r15, r1
			{
				uxControlBits |= eventWAIT_FOR_ALL_BITS;
     13e:	74 60       	ori	r23, 0x04	; 4
			}

			/* Store the bits that the calling task is waiting for in the
			task's event list item so the kernel knows when a match is
			found.  Then enter the blocked state. */
			vTaskPlaceOnUnorderedEventList( &( pxEventBits->xTasksWaitingForBits ), ( uxBitsToWaitFor | uxControlBits ), xTicksToWait );
     140:	6c 29       	or	r22, r12
     142:	7d 29       	or	r23, r13
     144:	c5 01       	movw	r24, r10
     146:	02 96       	adiw	r24, 0x02	; 2
     148:	a8 01       	movw	r20, r16
     14a:	0e 94 24 10 	call	0x2048	; 0x2048 <vTaskPlaceOnUnorderedEventList>
			uxReturn = 0;

			traceEVENT_GROUP_WAIT_BITS_BLOCK( xEventGroup, uxBitsToWaitFor );
		}
	}
	xAlreadyYielded = xTaskResumeAll();
     14e:	0e 94 5c 0e 	call	0x1cb8	; 0x1cb8 <xTaskResumeAll>

	if( xTicksToWait != ( TickType_t ) 0 )
	{
		if( xAlreadyYielded == pdFALSE )
     152:	88 23       	and	r24, r24
     154:	39 f4       	brne	.+14     	; 0x164 <xEventGroupWaitBits+0x84>
     156:	04 c0       	rjmp	.+8      	; 0x160 <xEventGroupWaitBits+0x80>
			uxReturn = 0;

			traceEVENT_GROUP_WAIT_BITS_BLOCK( xEventGroup, uxBitsToWaitFor );
		}
	}
	xAlreadyYielded = xTaskResumeAll();
     158:	0e 94 5c 0e 	call	0x1cb8	; 0x1cb8 <xTaskResumeAll>
     15c:	ce 01       	movw	r24, r28
     15e:	21 c0       	rjmp	.+66     	; 0x1a2 <xEventGroupWaitBits+0xc2>

	if( xTicksToWait != ( TickType_t ) 0 )
	{
		if( xAlreadyYielded == pdFALSE )
		{
			portYIELD_WITHIN_API();
     160:	0e 94 bc 04 	call	0x978	; 0x978 <vPortYield>

		/* The task blocked to wait for its required bits to be set - at this
		point either the required bits were set or the block time expired.  If
		the required bits were set they will have been stored in the task's
		event list item, and they should now be retrieved then cleared. */
		uxReturn = uxTaskResetEventItemValue();
     164:	0e 94 aa 11 	call	0x2354	; 0x2354 <uxTaskResetEventItemValue>
     168:	ec 01       	movw	r28, r24

		if( ( uxReturn & eventUNBLOCKED_DUE_TO_BIT_SET ) == ( EventBits_t ) 0 )
     16a:	91 fd       	sbrc	r25, 1
     16c:	18 c0       	rjmp	.+48     	; 0x19e <xEventGroupWaitBits+0xbe>
		{
			taskENTER_CRITICAL();
     16e:	0f b6       	in	r0, 0x3f	; 63
     170:	f8 94       	cli
     172:	0f 92       	push	r0
			{
				/* The task timed out, just return the current event bit value. */
				uxReturn = pxEventBits->uxEventBits;
     174:	f5 01       	movw	r30, r10
     176:	c0 81       	ld	r28, Z
     178:	d1 81       	ldd	r29, Z+1	; 0x01

				/* It is possible that the event bits were updated between this
				task leaving the Blocked state and running again. */
				if( prvTestWaitCondition( uxReturn, uxBitsToWaitFor, xWaitForAllBits ) != pdFALSE )
     17a:	ce 01       	movw	r24, r28
     17c:	b6 01       	movw	r22, r12
     17e:	4f 2d       	mov	r20, r15
     180:	0e 94 49 00 	call	0x92	; 0x92 <prvTestWaitCondition>
     184:	88 23       	and	r24, r24
     186:	49 f0       	breq	.+18     	; 0x19a <xEventGroupWaitBits+0xba>
				{
					if( xClearOnExit != pdFALSE )
     188:	ee 20       	and	r14, r14
     18a:	39 f0       	breq	.+14     	; 0x19a <xEventGroupWaitBits+0xba>
					{
						pxEventBits->uxEventBits &= ~uxBitsToWaitFor;
     18c:	c0 94       	com	r12
     18e:	d0 94       	com	r13
     190:	cc 22       	and	r12, r28
     192:	dd 22       	and	r13, r29
     194:	f5 01       	movw	r30, r10
     196:	d1 82       	std	Z+1, r13	; 0x01
     198:	c0 82       	st	Z, r12
				else
				{
					mtCOVERAGE_TEST_MARKER();
				}
			}
			taskEXIT_CRITICAL();
     19a:	0f 90       	pop	r0
     19c:	0f be       	out	0x3f, r0	; 63
		{
			/* The task unblocked because the bits were set. */
		}

		/* The task blocked so control bits may have been set. */
		uxReturn &= ~eventEVENT_BITS_CONTROL_BYTES;
     19e:	ce 01       	movw	r24, r28
     1a0:	90 70       	andi	r25, 0x00	; 0
	}
	traceEVENT_GROUP_WAIT_BITS_END( xEventGroup, uxBitsToWaitFor, xTimeoutOccurred );

	return uxReturn;
}
     1a2:	df 91       	pop	r29
     1a4:	cf 91       	pop	r28
     1a6:	1f 91       	pop	r17
     1a8:	0f 91       	pop	r16
     1aa:	ff 90       	pop	r15
     1ac:	ef 90       	pop	r14
     1ae:	df 90       	pop	r13
     1b0:	cf 90       	pop	r12
     1b2:	bf 90       	pop	r11
     1b4:	af 90       	pop	r10
     1b6:	08 95       	ret

000001b8 <xEventGroupClearBits>:
/*-----------------------------------------------------------*/

EventBits_t xEventGroupClearBits( EventGroupHandle_t xEventGroup, const EventBits_t uxBitsToClear )
{
     1b8:	fc 01       	movw	r30, r24
	/* Check the user is not attempting to clear the bits used by the kernel
	itself. */
	configASSERT( xEventGroup );
	configASSERT( ( uxBitsToClear & eventEVENT_BITS_CONTROL_BYTES ) == 0 );

	taskENTER_CRITICAL();
     1ba:	0f b6       	in	r0, 0x3f	; 63
     1bc:	f8 94       	cli
     1be:	0f 92       	push	r0
	{
		traceEVENT_GROUP_CLEAR_BITS( xEventGroup, uxBitsToClear );

		/* The value returned is the event group value prior to the bits being
		cleared. */
		uxReturn = pxEventBits->uxEventBits;
     1c0:	80 81       	ld	r24, Z
     1c2:	91 81       	ldd	r25, Z+1	; 0x01

		/* Clear the bits. */
		pxEventBits->uxEventBits &= ~uxBitsToClear;
     1c4:	60 95       	com	r22
     1c6:	70 95       	com	r23
     1c8:	68 23       	and	r22, r24
     1ca:	79 23       	and	r23, r25
     1cc:	71 83       	std	Z+1, r23	; 0x01
     1ce:	60 83       	st	Z, r22
	}
	taskEXIT_CRITICAL();
     1d0:	0f 90       	pop	r0
     1d2:	0f be       	out	0x3f, r0	; 63

	return uxReturn;
}
     1d4:	08 95       	ret

000001d6 <xEventGroupGetBitsFromISR>:

#endif
/*-----------------------------------------------------------*/

EventBits_t xEventGroupGetBitsFromISR( EventGroupHandle_t xEventGroup )
{
     1d6:	fc 01       	movw	r30, r24
		uxReturn = pxEventBits->uxEventBits;
	}
	portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );

	return uxReturn;
}
     1d8:	80 81       	ld	r24, Z
     1da:	91 81       	ldd	r25, Z+1	; 0x01
     1dc:	08 95       	ret

000001de <xEventGroupSetBits>:
/*-----------------------------------------------------------*/

EventBits_t xEventGroupSetBits( EventGroupHandle_t xEventGroup, const EventBits_t uxBitsToSet )
{
     1de:	af 92       	push	r10
     1e0:	bf 92       	push	r11
     1e2:	cf 92       	push	r12
     1e4:	df 92       	push	r13
     1e6:	ef 92       	push	r14
     1e8:	ff 92       	push	r15
     1ea:	0f 93       	push	r16
     1ec:	1f 93       	push	r17
     1ee:	cf 93       	push	r28
     1f0:	df 93       	push	r29
     1f2:	8c 01       	movw	r16, r24
     1f4:	eb 01       	movw	r28, r22
	itself. */
	configASSERT( xEventGroup );
	configASSERT( ( uxBitsToSet & eventEVENT_BITS_CONTROL_BYTES ) == 0 );

	pxList = &( pxEventBits->xTasksWaitingForBits );
	pxListEnd = listGET_END_MARKER( pxList ); /*lint !e826 !e740 The mini list structure is used as the list end to save RAM.  This is checked and valid. */
     1f6:	0f 2e       	mov	r0, r31
     1f8:	f5 e0       	ldi	r31, 0x05	; 5
     1fa:	cf 2e       	mov	r12, r31
     1fc:	dd 24       	eor	r13, r13
     1fe:	f0 2d       	mov	r31, r0
     200:	c8 0e       	add	r12, r24
     202:	d9 1e       	adc	r13, r25
	vTaskSuspendAll();
     204:	0e 94 97 0d 	call	0x1b2e	; 0x1b2e <vTaskSuspendAll>
	{
		traceEVENT_GROUP_SET_BITS( xEventGroup, uxBitsToSet );

		pxListItem = listGET_HEAD_ENTRY( pxList );
     208:	d8 01       	movw	r26, r16
     20a:	17 96       	adiw	r26, 0x07	; 7
     20c:	ed 91       	ld	r30, X+
     20e:	fc 91       	ld	r31, X
     210:	18 97       	sbiw	r26, 0x08	; 8

		/* Set the bits. */
		pxEventBits->uxEventBits |= uxBitsToSet;
     212:	8d 91       	ld	r24, X+
     214:	9c 91       	ld	r25, X
     216:	11 97       	sbiw	r26, 0x01	; 1
     218:	8c 2b       	or	r24, r28
     21a:	9d 2b       	or	r25, r29
     21c:	11 96       	adiw	r26, 0x01	; 1
     21e:	9c 93       	st	X, r25
     220:	8e 93       	st	-X, r24

		/* See if the new bit value should unblock any tasks. */
		while( pxListItem != pxListEnd )
     222:	ce 16       	cp	r12, r30
     224:	df 06       	cpc	r13, r31
     226:	c1 f1       	breq	.+112    	; 0x298 <xEventGroupSetBits+0xba>
EventBits_t xEventGroupSetBits( EventGroupHandle_t xEventGroup, const EventBits_t uxBitsToSet )
{
ListItem_t *pxListItem, *pxNext;
ListItem_t const *pxListEnd;
List_t *pxList;
EventBits_t uxBitsToClear = 0, uxBitsWaitedFor, uxControlBits;
     228:	aa 24       	eor	r10, r10
     22a:	bb 24       	eor	r11, r11
			if( ( uxControlBits & eventWAIT_FOR_ALL_BITS ) == ( EventBits_t ) 0 )
			{
				/* Just looking for single bit being set. */
				if( ( uxBitsWaitedFor & pxEventBits->uxEventBits ) != ( EventBits_t ) 0 )
				{
					xMatchFound = pdTRUE;
     22c:	ff 24       	eor	r15, r15
     22e:	f3 94       	inc	r15
     230:	ee 24       	eor	r14, r14
     232:	01 c0       	rjmp	.+2      	; 0x236 <xEventGroupSetBits+0x58>

		/* Set the bits. */
		pxEventBits->uxEventBits |= uxBitsToSet;

		/* See if the new bit value should unblock any tasks. */
		while( pxListItem != pxListEnd )
     234:	fe 01       	movw	r30, r28
		{
			pxNext = listGET_NEXT( pxListItem );
     236:	c2 81       	ldd	r28, Z+2	; 0x02
     238:	d3 81       	ldd	r29, Z+3	; 0x03
			uxBitsWaitedFor = listGET_LIST_ITEM_VALUE( pxListItem );
     23a:	80 81       	ld	r24, Z
     23c:	91 81       	ldd	r25, Z+1	; 0x01
			xMatchFound = pdFALSE;

			/* Split the bits waited for from the control bits. */
			uxControlBits = uxBitsWaitedFor & eventEVENT_BITS_CONTROL_BYTES;
     23e:	bc 01       	movw	r22, r24
     240:	60 70       	andi	r22, 0x00	; 0
			uxBitsWaitedFor &= ~eventEVENT_BITS_CONTROL_BYTES;
     242:	9c 01       	movw	r18, r24
     244:	30 70       	andi	r19, 0x00	; 0

			if( ( uxControlBits & eventWAIT_FOR_ALL_BITS ) == ( EventBits_t ) 0 )
     246:	92 fd       	sbrc	r25, 2
     248:	0b c0       	rjmp	.+22     	; 0x260 <xEventGroupSetBits+0x82>
			{
				/* Just looking for single bit being set. */
				if( ( uxBitsWaitedFor & pxEventBits->uxEventBits ) != ( EventBits_t ) 0 )
     24a:	d8 01       	movw	r26, r16
     24c:	8d 91       	ld	r24, X+
     24e:	9c 91       	ld	r25, X
     250:	11 97       	sbiw	r26, 0x01	; 1
     252:	82 23       	and	r24, r18
     254:	93 23       	and	r25, r19
				{
					xMatchFound = pdTRUE;
     256:	4f 2d       	mov	r20, r15
     258:	00 97       	sbiw	r24, 0x00	; 0
     25a:	69 f4       	brne	.+26     	; 0x276 <xEventGroupSetBits+0x98>
     25c:	4e 2d       	mov	r20, r14
     25e:	0b c0       	rjmp	.+22     	; 0x276 <xEventGroupSetBits+0x98>
				else
				{
					mtCOVERAGE_TEST_MARKER();
				}
			}
			else if( ( uxBitsWaitedFor & pxEventBits->uxEventBits ) == uxBitsWaitedFor )
     260:	d8 01       	movw	r26, r16
     262:	8d 91       	ld	r24, X+
     264:	9c 91       	ld	r25, X
     266:	11 97       	sbiw	r26, 0x01	; 1
     268:	82 23       	and	r24, r18
     26a:	93 23       	and	r25, r19
			if( ( uxControlBits & eventWAIT_FOR_ALL_BITS ) == ( EventBits_t ) 0 )
			{
				/* Just looking for single bit being set. */
				if( ( uxBitsWaitedFor & pxEventBits->uxEventBits ) != ( EventBits_t ) 0 )
				{
					xMatchFound = pdTRUE;
     26c:	4f 2d       	mov	r20, r15
     26e:	28 17       	cp	r18, r24
     270:	39 07       	cpc	r19, r25
     272:	09 f0       	breq	.+2      	; 0x276 <xEventGroupSetBits+0x98>
     274:	4e 2d       	mov	r20, r14
			else
			{
				/* Need all bits to be set, but not all the bits were set. */
			}

			if( xMatchFound != pdFALSE )
     276:	44 23       	and	r20, r20
     278:	59 f0       	breq	.+22     	; 0x290 <xEventGroupSetBits+0xb2>
			{
				/* The bits match.  Should the bits be cleared on exit? */
				if( ( uxControlBits & eventCLEAR_EVENTS_ON_EXIT_BIT ) != ( EventBits_t ) 0 )
     27a:	70 ff       	sbrs	r23, 0
     27c:	02 c0       	rjmp	.+4      	; 0x282 <xEventGroupSetBits+0xa4>
				{
					uxBitsToClear |= uxBitsWaitedFor;
     27e:	a2 2a       	or	r10, r18
     280:	b3 2a       	or	r11, r19
				/* Store the actual event flag value in the task's event list
				item before removing the task from the event list.  The
				eventUNBLOCKED_DUE_TO_BIT_SET bit is set so the task knows
				that is was unblocked due to its required bits matching, rather
				than because it timed out. */
				( void ) xTaskRemoveFromUnorderedEventList( pxListItem, pxEventBits->uxEventBits | eventUNBLOCKED_DUE_TO_BIT_SET );
     282:	d8 01       	movw	r26, r16
     284:	6d 91       	ld	r22, X+
     286:	7c 91       	ld	r23, X
     288:	72 60       	ori	r23, 0x02	; 2
     28a:	cf 01       	movw	r24, r30
     28c:	0e 94 88 10 	call	0x2110	; 0x2110 <xTaskRemoveFromUnorderedEventList>

		/* Set the bits. */
		pxEventBits->uxEventBits |= uxBitsToSet;

		/* See if the new bit value should unblock any tasks. */
		while( pxListItem != pxListEnd )
     290:	cc 16       	cp	r12, r28
     292:	dd 06       	cpc	r13, r29
     294:	79 f6       	brne	.-98     	; 0x234 <xEventGroupSetBits+0x56>
     296:	02 c0       	rjmp	.+4      	; 0x29c <xEventGroupSetBits+0xbe>
EventBits_t xEventGroupSetBits( EventGroupHandle_t xEventGroup, const EventBits_t uxBitsToSet )
{
ListItem_t *pxListItem, *pxNext;
ListItem_t const *pxListEnd;
List_t *pxList;
EventBits_t uxBitsToClear = 0, uxBitsWaitedFor, uxControlBits;
     298:	aa 24       	eor	r10, r10
     29a:	bb 24       	eor	r11, r11
			pxListItem = pxNext;
		}

		/* Clear any bits that matched when the eventCLEAR_EVENTS_ON_EXIT_BIT
		bit was set in the control word. */
		pxEventBits->uxEventBits &= ~uxBitsToClear;
     29c:	c5 01       	movw	r24, r10
     29e:	80 95       	com	r24
     2a0:	90 95       	com	r25
     2a2:	f8 01       	movw	r30, r16
     2a4:	a0 80       	ld	r10, Z
     2a6:	b1 80       	ldd	r11, Z+1	; 0x01
     2a8:	a8 22       	and	r10, r24
     2aa:	b9 22       	and	r11, r25
     2ac:	b1 82       	std	Z+1, r11	; 0x01
     2ae:	a0 82       	st	Z, r10
	}
	( void ) xTaskResumeAll();
     2b0:	0e 94 5c 0e 	call	0x1cb8	; 0x1cb8 <xTaskResumeAll>

	return pxEventBits->uxEventBits;
}
     2b4:	d8 01       	movw	r26, r16
     2b6:	8c 91       	ld	r24, X
     2b8:	11 96       	adiw	r26, 0x01	; 1
     2ba:	9c 91       	ld	r25, X
     2bc:	11 97       	sbiw	r26, 0x01	; 1
     2be:	df 91       	pop	r29
     2c0:	cf 91       	pop	r28
     2c2:	1f 91       	pop	r17
     2c4:	0f 91       	pop	r16
     2c6:	ff 90       	pop	r15
     2c8:	ef 90       	pop	r14
     2ca:	df 90       	pop	r13
     2cc:	cf 90       	pop	r12
     2ce:	bf 90       	pop	r11
     2d0:	af 90       	pop	r10
     2d2:	08 95       	ret

000002d4 <xEventGroupSync>:

#endif /* configSUPPORT_DYNAMIC_ALLOCATION */
/*-----------------------------------------------------------*/

EventBits_t xEventGroupSync( EventGroupHandle_t xEventGroup, const EventBits_t uxBitsToSet, const EventBits_t uxBitsToWaitFor, TickType_t xTicksToWait )
{
     2d4:	af 92       	push	r10
     2d6:	bf 92       	push	r11
     2d8:	cf 92       	push	r12
     2da:	df 92       	push	r13
     2dc:	ef 92       	push	r14
     2de:	ff 92       	push	r15
     2e0:	0f 93       	push	r16
     2e2:	1f 93       	push	r17
     2e4:	cf 93       	push	r28
     2e6:	df 93       	push	r29
     2e8:	6c 01       	movw	r12, r24
     2ea:	eb 01       	movw	r28, r22
     2ec:	7a 01       	movw	r14, r20
     2ee:	59 01       	movw	r10, r18
	{
		configASSERT( !( ( xTaskGetSchedulerState() == taskSCHEDULER_SUSPENDED ) && ( xTicksToWait != 0 ) ) );
	}
	#endif

	vTaskSuspendAll();
     2f0:	0e 94 97 0d 	call	0x1b2e	; 0x1b2e <vTaskSuspendAll>
	{
		uxOriginalBitValue = pxEventBits->uxEventBits;
     2f4:	f6 01       	movw	r30, r12
     2f6:	00 81       	ld	r16, Z
     2f8:	11 81       	ldd	r17, Z+1	; 0x01

		( void ) xEventGroupSetBits( xEventGroup, uxBitsToSet );
     2fa:	c6 01       	movw	r24, r12
     2fc:	be 01       	movw	r22, r28
     2fe:	0e 94 ef 00 	call	0x1de	; 0x1de <xEventGroupSetBits>

		if( ( ( uxOriginalBitValue | uxBitsToSet ) & uxBitsToWaitFor ) == uxBitsToWaitFor )
     302:	c0 2b       	or	r28, r16
     304:	d1 2b       	or	r29, r17
     306:	c7 01       	movw	r24, r14
     308:	8c 23       	and	r24, r28
     30a:	9d 23       	and	r25, r29
     30c:	8e 15       	cp	r24, r14
     30e:	9f 05       	cpc	r25, r15
     310:	51 f4       	brne	.+20     	; 0x326 <xEventGroupSync+0x52>
			/* All the rendezvous bits are now set - no need to block. */
			uxReturn = ( uxOriginalBitValue | uxBitsToSet );

			/* Rendezvous always clear the bits.  They will have been cleared
			already unless this is the only task in the rendezvous. */
			pxEventBits->uxEventBits &= ~uxBitsToWaitFor;
     312:	80 95       	com	r24
     314:	90 95       	com	r25
     316:	f6 01       	movw	r30, r12
     318:	20 81       	ld	r18, Z
     31a:	31 81       	ldd	r19, Z+1	; 0x01
     31c:	82 23       	and	r24, r18
     31e:	93 23       	and	r25, r19
     320:	91 83       	std	Z+1, r25	; 0x01
     322:	80 83       	st	Z, r24
     324:	12 c0       	rjmp	.+36     	; 0x34a <xEventGroupSync+0x76>

			xTicksToWait = 0;
		}
		else
		{
			if( xTicksToWait != ( TickType_t ) 0 )
     326:	a1 14       	cp	r10, r1
     328:	b1 04       	cpc	r11, r1
     32a:	61 f0       	breq	.+24     	; 0x344 <xEventGroupSync+0x70>
				traceEVENT_GROUP_SYNC_BLOCK( xEventGroup, uxBitsToSet, uxBitsToWaitFor );

				/* Store the bits that the calling task is waiting for in the
				task's event list item so the kernel knows when a match is
				found.  Then enter the blocked state. */
				vTaskPlaceOnUnorderedEventList( &( pxEventBits->xTasksWaitingForBits ), ( uxBitsToWaitFor | eventCLEAR_EVENTS_ON_EXIT_BIT | eventWAIT_FOR_ALL_BITS ), xTicksToWait );
     32c:	b7 01       	movw	r22, r14
     32e:	75 60       	ori	r23, 0x05	; 5
     330:	c6 01       	movw	r24, r12
     332:	02 96       	adiw	r24, 0x02	; 2
     334:	a5 01       	movw	r20, r10
     336:	0e 94 24 10 	call	0x2048	; 0x2048 <vTaskPlaceOnUnorderedEventList>
				specified - just return the current event bit value. */
				uxReturn = pxEventBits->uxEventBits;
			}
		}
	}
	xAlreadyYielded = xTaskResumeAll();
     33a:	0e 94 5c 0e 	call	0x1cb8	; 0x1cb8 <xTaskResumeAll>

	if( xTicksToWait != ( TickType_t ) 0 )
	{
		if( xAlreadyYielded == pdFALSE )
     33e:	88 23       	and	r24, r24
     340:	49 f4       	brne	.+18     	; 0x354 <xEventGroupSync+0x80>
     342:	06 c0       	rjmp	.+12     	; 0x350 <xEventGroupSync+0x7c>
			}
			else
			{
				/* The rendezvous bits were not set, but no block time was
				specified - just return the current event bit value. */
				uxReturn = pxEventBits->uxEventBits;
     344:	f6 01       	movw	r30, r12
     346:	c0 81       	ld	r28, Z
     348:	d1 81       	ldd	r29, Z+1	; 0x01
			}
		}
	}
	xAlreadyYielded = xTaskResumeAll();
     34a:	0e 94 5c 0e 	call	0x1cb8	; 0x1cb8 <xTaskResumeAll>
     34e:	1c c0       	rjmp	.+56     	; 0x388 <xEventGroupSync+0xb4>

	if( xTicksToWait != ( TickType_t ) 0 )
	{
		if( xAlreadyYielded == pdFALSE )
		{
			portYIELD_WITHIN_API();
     350:	0e 94 bc 04 	call	0x978	; 0x978 <vPortYield>

		/* The task blocked to wait for its required bits to be set - at this
		point either the required bits were set or the block time expired.  If
		the required bits were set they will have been stored in the task's
		event list item, and they should now be retrieved then cleared. */
		uxReturn = uxTaskResetEventItemValue();
     354:	0e 94 aa 11 	call	0x2354	; 0x2354 <uxTaskResetEventItemValue>

		if( ( uxReturn & eventUNBLOCKED_DUE_TO_BIT_SET ) == ( EventBits_t ) 0 )
     358:	91 fd       	sbrc	r25, 1
     35a:	14 c0       	rjmp	.+40     	; 0x384 <xEventGroupSync+0xb0>
		{
			/* The task timed out, just return the current event bit value. */
			taskENTER_CRITICAL();
     35c:	0f b6       	in	r0, 0x3f	; 63
     35e:	f8 94       	cli
     360:	0f 92       	push	r0
			{
				uxReturn = pxEventBits->uxEventBits;
     362:	f6 01       	movw	r30, r12
     364:	80 81       	ld	r24, Z
     366:	91 81       	ldd	r25, Z+1	; 0x01

				/* Although the task got here because it timed out before the
				bits it was waiting for were set, it is possible that since it
				unblocked another task has set the bits.  If this is the case
				then it needs to clear the bits before exiting. */
				if( ( uxReturn & uxBitsToWaitFor ) == uxBitsToWaitFor )
     368:	97 01       	movw	r18, r14
     36a:	28 23       	and	r18, r24
     36c:	39 23       	and	r19, r25
     36e:	2e 15       	cp	r18, r14
     370:	3f 05       	cpc	r19, r15
     372:	31 f4       	brne	.+12     	; 0x380 <xEventGroupSync+0xac>
				{
					pxEventBits->uxEventBits &= ~uxBitsToWaitFor;
     374:	20 95       	com	r18
     376:	30 95       	com	r19
     378:	28 23       	and	r18, r24
     37a:	39 23       	and	r19, r25
     37c:	31 83       	std	Z+1, r19	; 0x01
     37e:	20 83       	st	Z, r18
				else
				{
					mtCOVERAGE_TEST_MARKER();
				}
			}
			taskEXIT_CRITICAL();
     380:	0f 90       	pop	r0
     382:	0f be       	out	0x3f, r0	; 63
			/* The task unblocked because the bits were set. */
		}

		/* Control bits might be set as the task had blocked should not be
		returned. */
		uxReturn &= ~eventEVENT_BITS_CONTROL_BYTES;
     384:	ec 01       	movw	r28, r24
     386:	d0 70       	andi	r29, 0x00	; 0
	}

	traceEVENT_GROUP_SYNC_END( xEventGroup, uxBitsToSet, uxBitsToWaitFor, xTimeoutOccurred );

	return uxReturn;
}
     388:	8c 2f       	mov	r24, r28
     38a:	9d 2f       	mov	r25, r29
     38c:	df 91       	pop	r29
     38e:	cf 91       	pop	r28
     390:	1f 91       	pop	r17
     392:	0f 91       	pop	r16
     394:	ff 90       	pop	r15
     396:	ef 90       	pop	r14
     398:	df 90       	pop	r13
     39a:	cf 90       	pop	r12
     39c:	bf 90       	pop	r11
     39e:	af 90       	pop	r10
     3a0:	08 95       	ret

000003a2 <vEventGroupDelete>:
	return pxEventBits->uxEventBits;
}
/*-----------------------------------------------------------*/

void vEventGroupDelete( EventGroupHandle_t xEventGroup )
{
     3a2:	cf 93       	push	r28
     3a4:	df 93       	push	r29
     3a6:	ec 01       	movw	r28, r24
EventGroup_t *pxEventBits = ( EventGroup_t * ) xEventGroup;
const List_t *pxTasksWaitingForBits = &( pxEventBits->xTasksWaitingForBits );

	vTaskSuspendAll();
     3a8:	0e 94 97 0d 	call	0x1b2e	; 0x1b2e <vTaskSuspendAll>
	{
		traceEVENT_GROUP_DELETE( xEventGroup );

		while( listCURRENT_LIST_LENGTH( pxTasksWaitingForBits ) > ( UBaseType_t ) 0 )
     3ac:	8a 81       	ldd	r24, Y+2	; 0x02
     3ae:	88 23       	and	r24, r24
     3b0:	49 f0       	breq	.+18     	; 0x3c4 <vEventGroupDelete+0x22>
		{
			/* Unblock the task, returning 0 as the event list is being deleted
			and	cannot therefore have any bits set. */
			configASSERT( pxTasksWaitingForBits->xListEnd.pxNext != ( ListItem_t * ) &( pxTasksWaitingForBits->xListEnd ) );
			( void ) xTaskRemoveFromUnorderedEventList( pxTasksWaitingForBits->xListEnd.pxNext, eventUNBLOCKED_DUE_TO_BIT_SET );
     3b2:	8f 81       	ldd	r24, Y+7	; 0x07
     3b4:	98 85       	ldd	r25, Y+8	; 0x08
     3b6:	60 e0       	ldi	r22, 0x00	; 0
     3b8:	72 e0       	ldi	r23, 0x02	; 2
     3ba:	0e 94 88 10 	call	0x2110	; 0x2110 <xTaskRemoveFromUnorderedEventList>

	vTaskSuspendAll();
	{
		traceEVENT_GROUP_DELETE( xEventGroup );

		while( listCURRENT_LIST_LENGTH( pxTasksWaitingForBits ) > ( UBaseType_t ) 0 )
     3be:	8a 81       	ldd	r24, Y+2	; 0x02
     3c0:	88 23       	and	r24, r24
     3c2:	b9 f7       	brne	.-18     	; 0x3b2 <vEventGroupDelete+0x10>

		#if( ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) && ( configSUPPORT_STATIC_ALLOCATION == 0 ) )
		{
			/* The event group can only have been allocated dynamically - free
			it again. */
			vPortFree( pxEventBits );
     3c4:	ce 01       	movw	r24, r28
     3c6:	0e 94 32 03 	call	0x664	; 0x664 <vPortFree>
				mtCOVERAGE_TEST_MARKER();
			}
		}
		#endif /* configSUPPORT_DYNAMIC_ALLOCATION */
	}
	( void ) xTaskResumeAll();
     3ca:	0e 94 5c 0e 	call	0x1cb8	; 0x1cb8 <xTaskResumeAll>
}
     3ce:	df 91       	pop	r29
     3d0:	cf 91       	pop	r28
     3d2:	08 95       	ret

000003d4 <vEventGroupSetBitsCallback>:

/* For internal use only - execute a 'set bits' command that was pended from
an interrupt. */
void vEventGroupSetBitsCallback( void *pvEventGroup, const uint32_t ulBitsToSet )
{
	( void ) xEventGroupSetBits( pvEventGroup, ( EventBits_t ) ulBitsToSet );
     3d4:	ba 01       	movw	r22, r20
     3d6:	0e 94 ef 00 	call	0x1de	; 0x1de <xEventGroupSetBits>
}
     3da:	08 95       	ret

000003dc <vEventGroupClearBitsCallback>:

/* For internal use only - execute a 'clear bits' command that was pended from
an interrupt. */
void vEventGroupClearBitsCallback( void *pvEventGroup, const uint32_t ulBitsToClear )
{
	( void ) xEventGroupClearBits( pvEventGroup, ( EventBits_t ) ulBitsToClear );
     3dc:	ba 01       	movw	r22, r20
     3de:	0e 94 dc 00 	call	0x1b8	; 0x1b8 <xEventGroupClearBits>
}
     3e2:	08 95       	ret

000003e4 <DIO_Set_Port_Direction>:


/*        SET Direction         */ 
void DIO_Set_Port_Direction(u8 Base, u8 Direction)
{
	if((Direction == OUTPUT)||(Direction==1))
     3e4:	61 30       	cpi	r22, 0x01	; 1
     3e6:	29 f4       	brne	.+10     	; 0x3f2 <DIO_Set_Port_Direction+0xe>
	{
		(*(volatile u8*)(Base+1)) = 0xFF;
     3e8:	e8 2f       	mov	r30, r24
     3ea:	f0 e0       	ldi	r31, 0x00	; 0
     3ec:	8f ef       	ldi	r24, 0xFF	; 255
     3ee:	81 83       	std	Z+1, r24	; 0x01
     3f0:	08 95       	ret
	}
	else if((Direction == INPUT)||(Direction==0))
     3f2:	66 23       	and	r22, r22
     3f4:	19 f4       	brne	.+6      	; 0x3fc <DIO_Set_Port_Direction+0x18>
	{
		(*(volatile u8*)(Base+1)) = 0x00;
     3f6:	e8 2f       	mov	r30, r24
     3f8:	f0 e0       	ldi	r31, 0x00	; 0
     3fa:	11 82       	std	Z+1, r1	; 0x01
     3fc:	08 95       	ret

000003fe <DIO_Set_Pin_Direction>:


void DIO_Set_Pin_Direction(u8 Base, u8 PIN, u8 Direction)
{

	if((Direction == OUTPUT) || (Direction == 1))
     3fe:	41 30       	cpi	r20, 0x01	; 1
     400:	79 f4       	brne	.+30     	; 0x420 <DIO_Set_Pin_Direction+0x22>
	{
		//SET_BIT((*(volatile u8*)(Base+1)),PIN);  // OUTPUT = 1
		(*(volatile u8*)(Base+1))|=(1<<PIN);
     402:	e8 2f       	mov	r30, r24
     404:	f0 e0       	ldi	r31, 0x00	; 0
     406:	21 81       	ldd	r18, Z+1	; 0x01
     408:	81 e0       	ldi	r24, 0x01	; 1
     40a:	90 e0       	ldi	r25, 0x00	; 0
     40c:	ac 01       	movw	r20, r24
     40e:	02 c0       	rjmp	.+4      	; 0x414 <DIO_Set_Pin_Direction+0x16>
     410:	44 0f       	add	r20, r20
     412:	55 1f       	adc	r21, r21
     414:	6a 95       	dec	r22
     416:	e2 f7       	brpl	.-8      	; 0x410 <DIO_Set_Pin_Direction+0x12>
     418:	ba 01       	movw	r22, r20
     41a:	62 2b       	or	r22, r18
     41c:	61 83       	std	Z+1, r22	; 0x01
     41e:	08 95       	ret
	}
	else if((Direction == INPUT) || (Direction == 0))
     420:	44 23       	and	r20, r20
     422:	79 f4       	brne	.+30     	; 0x442 <DIO_Set_Pin_Direction+0x44>
	{
		//CLR_BIT((*(volatile u8*)(Base+1)),PIN); // INPUT = 0;
		(*(volatile u8*)(Base+1))&=(~(1<<PIN)); 
     424:	e8 2f       	mov	r30, r24
     426:	f0 e0       	ldi	r31, 0x00	; 0
     428:	21 81       	ldd	r18, Z+1	; 0x01
     42a:	81 e0       	ldi	r24, 0x01	; 1
     42c:	90 e0       	ldi	r25, 0x00	; 0
     42e:	ac 01       	movw	r20, r24
     430:	02 c0       	rjmp	.+4      	; 0x436 <DIO_Set_Pin_Direction+0x38>
     432:	44 0f       	add	r20, r20
     434:	55 1f       	adc	r21, r21
     436:	6a 95       	dec	r22
     438:	e2 f7       	brpl	.-8      	; 0x432 <DIO_Set_Pin_Direction+0x34>
     43a:	ba 01       	movw	r22, r20
     43c:	60 95       	com	r22
     43e:	62 23       	and	r22, r18
     440:	61 83       	std	Z+1, r22	; 0x01
     442:	08 95       	ret

00000444 <DIO_Set_Port_Value>:


/*        SET Value         */ 
void DIO_Set_Port_Value(u8 Base, u8 Value)
{
	(*(volatile u8*)(Base+2)) = Value;
     444:	e8 2f       	mov	r30, r24
     446:	f0 e0       	ldi	r31, 0x00	; 0
     448:	62 83       	std	Z+2, r22	; 0x02
}
     44a:	08 95       	ret

0000044c <DIO_Set_Pin_Value>:

void DIO_Set_Pin_Value(u8 Base,u8 PIN, u8 Value)
{
	if((Value == HIGH) || (Value == 1))
     44c:	41 30       	cpi	r20, 0x01	; 1
     44e:	79 f4       	brne	.+30     	; 0x46e <DIO_Set_Pin_Value+0x22>
	{	//SET_BIT((*(volatile u8*)(Base+2)),PIN);
		(*(volatile u8*)(Base+2))|=(1<<PIN);
     450:	e8 2f       	mov	r30, r24
     452:	f0 e0       	ldi	r31, 0x00	; 0
     454:	22 81       	ldd	r18, Z+2	; 0x02
     456:	81 e0       	ldi	r24, 0x01	; 1
     458:	90 e0       	ldi	r25, 0x00	; 0
     45a:	ac 01       	movw	r20, r24
     45c:	02 c0       	rjmp	.+4      	; 0x462 <DIO_Set_Pin_Value+0x16>
     45e:	44 0f       	add	r20, r20
     460:	55 1f       	adc	r21, r21
     462:	6a 95       	dec	r22
     464:	e2 f7       	brpl	.-8      	; 0x45e <DIO_Set_Pin_Value+0x12>
     466:	ba 01       	movw	r22, r20
     468:	62 2b       	or	r22, r18
     46a:	62 83       	std	Z+2, r22	; 0x02
     46c:	08 95       	ret
	}
	else if((Value == LOW) || (Value == 0))
     46e:	44 23       	and	r20, r20
     470:	79 f4       	brne	.+30     	; 0x490 <DIO_Set_Pin_Value+0x44>
	{
		(*(volatile u8*)(Base+2))&=(~(1<<PIN));
     472:	e8 2f       	mov	r30, r24
     474:	f0 e0       	ldi	r31, 0x00	; 0
     476:	22 81       	ldd	r18, Z+2	; 0x02
     478:	81 e0       	ldi	r24, 0x01	; 1
     47a:	90 e0       	ldi	r25, 0x00	; 0
     47c:	ac 01       	movw	r20, r24
     47e:	02 c0       	rjmp	.+4      	; 0x484 <DIO_Set_Pin_Value+0x38>
     480:	44 0f       	add	r20, r20
     482:	55 1f       	adc	r21, r21
     484:	6a 95       	dec	r22
     486:	e2 f7       	brpl	.-8      	; 0x480 <DIO_Set_Pin_Value+0x34>
     488:	ba 01       	movw	r22, r20
     48a:	60 95       	com	r22
     48c:	62 23       	and	r22, r18
     48e:	62 83       	std	Z+2, r22	; 0x02
     490:	08 95       	ret

00000492 <DIO_Get_Port_value>:
	}
}

/*        Get Value         */ 
u8 DIO_Get_Port_value(u8 Base)
{
     492:	cf 93       	push	r28
     494:	df 93       	push	r29
     496:	0f 92       	push	r0
     498:	cd b7       	in	r28, 0x3d	; 61
     49a:	de b7       	in	r29, 0x3e	; 62
	 volatile u8 Value;
	Value = (*(volatile u8*)(Base));
     49c:	e8 2f       	mov	r30, r24
     49e:	f0 e0       	ldi	r31, 0x00	; 0
     4a0:	80 81       	ld	r24, Z
     4a2:	89 83       	std	Y+1, r24	; 0x01
	return Value;
     4a4:	89 81       	ldd	r24, Y+1	; 0x01
}
     4a6:	0f 90       	pop	r0
     4a8:	df 91       	pop	r29
     4aa:	cf 91       	pop	r28
     4ac:	08 95       	ret

000004ae <DIO_Get_Pin_value>:


u8 DIO_Get_Pin_value (u8 Base, u8 PIN)
{
     4ae:	cf 93       	push	r28
     4b0:	df 93       	push	r29
     4b2:	0f 92       	push	r0
     4b4:	cd b7       	in	r28, 0x3d	; 61
     4b6:	de b7       	in	r29, 0x3e	; 62
	volatile u8 Value;
	Value = ((*(volatile u8*)(Base))>>PIN)&1;	
     4b8:	e8 2f       	mov	r30, r24
     4ba:	f0 e0       	ldi	r31, 0x00	; 0
     4bc:	80 81       	ld	r24, Z
     4be:	90 e0       	ldi	r25, 0x00	; 0
     4c0:	9c 01       	movw	r18, r24
     4c2:	02 c0       	rjmp	.+4      	; 0x4c8 <DIO_Get_Pin_value+0x1a>
     4c4:	35 95       	asr	r19
     4c6:	27 95       	ror	r18
     4c8:	6a 95       	dec	r22
     4ca:	e2 f7       	brpl	.-8      	; 0x4c4 <DIO_Get_Pin_value+0x16>
     4cc:	b9 01       	movw	r22, r18
     4ce:	61 70       	andi	r22, 0x01	; 1
     4d0:	69 83       	std	Y+1, r22	; 0x01
	return Value;
     4d2:	89 81       	ldd	r24, Y+1	; 0x01
}
     4d4:	0f 90       	pop	r0
     4d6:	df 91       	pop	r29
     4d8:	cf 91       	pop	r28
     4da:	08 95       	ret

000004dc <DIO_Toggle_Pin>:

void DIO_Toggle_Pin(u8 Base, u8 PIN)
{
	*((volatile u8*)(Base+2))^=(1<<PIN);
     4dc:	e8 2f       	mov	r30, r24
     4de:	f0 e0       	ldi	r31, 0x00	; 0
     4e0:	22 81       	ldd	r18, Z+2	; 0x02
     4e2:	81 e0       	ldi	r24, 0x01	; 1
     4e4:	90 e0       	ldi	r25, 0x00	; 0
     4e6:	ac 01       	movw	r20, r24
     4e8:	02 c0       	rjmp	.+4      	; 0x4ee <DIO_Toggle_Pin+0x12>
     4ea:	44 0f       	add	r20, r20
     4ec:	55 1f       	adc	r21, r21
     4ee:	6a 95       	dec	r22
     4f0:	e2 f7       	brpl	.-8      	; 0x4ea <DIO_Toggle_Pin+0xe>
     4f2:	ba 01       	movw	r22, r20
     4f4:	62 27       	eor	r22, r18
     4f6:	62 83       	std	Z+2, r22	; 0x02
}
     4f8:	08 95       	ret

000004fa <DIO_SET_HIGH_Nipple_Value>:
/* Set HIGH NIPPLE */

void DIO_SET_HIGH_Nipple_Value(u8 Base, u8 Data)
{
	Data<<=4;
	(*(volatile u8*)(Base+2)) &=0x0f;  //to CLR HIGH NIPPLE Pins before write 
     4fa:	e8 2f       	mov	r30, r24
     4fc:	f0 e0       	ldi	r31, 0x00	; 0
     4fe:	82 81       	ldd	r24, Z+2	; 0x02
     500:	8f 70       	andi	r24, 0x0F	; 15
     502:	82 83       	std	Z+2, r24	; 0x02
	(*(volatile u8*)(Base+2)) ^=Data;
     504:	82 81       	ldd	r24, Z+2	; 0x02

/* Set HIGH NIPPLE */

void DIO_SET_HIGH_Nipple_Value(u8 Base, u8 Data)
{
	Data<<=4;
     506:	62 95       	swap	r22
     508:	60 7f       	andi	r22, 0xF0	; 240
	(*(volatile u8*)(Base+2)) &=0x0f;  //to CLR HIGH NIPPLE Pins before write 
	(*(volatile u8*)(Base+2)) ^=Data;
     50a:	68 27       	eor	r22, r24
     50c:	62 83       	std	Z+2, r22	; 0x02
	
} 
     50e:	08 95       	ret

00000510 <DIO_SET_LOW_Nipple_Value>:

/* Set LOW NIPPLE */

void DIO_SET_LOW_Nipple_Value(u8 Base, u8 Data)
{
	(*(volatile u8*)(Base+2)) &=0xf0;  //to CLR LOW NIPPLE before write
     510:	e8 2f       	mov	r30, r24
     512:	f0 e0       	ldi	r31, 0x00	; 0
     514:	82 81       	ldd	r24, Z+2	; 0x02
     516:	80 7f       	andi	r24, 0xF0	; 240
     518:	82 83       	std	Z+2, r24	; 0x02
	(*(volatile u8*)(Base+2)) ^=(Data & 0x0F) ;
     51a:	82 81       	ldd	r24, Z+2	; 0x02
     51c:	6f 70       	andi	r22, 0x0F	; 15
     51e:	68 27       	eor	r22, r24
     520:	62 83       	std	Z+2, r22	; 0x02
	
}
     522:	08 95       	ret

00000524 <pvPortMalloc>:
	pxIterator->pxNextFreeBlock = pxBlockToInsert;									\
}
/*-----------------------------------------------------------*/

void *pvPortMalloc( size_t xWantedSize )
{
     524:	0f 93       	push	r16
     526:	1f 93       	push	r17
     528:	cf 93       	push	r28
     52a:	df 93       	push	r29
     52c:	ec 01       	movw	r28, r24
BlockLink_t *pxBlock, *pxPreviousBlock, *pxNewBlockLink;
static BaseType_t xHeapHasBeenInitialised = pdFALSE;
void *pvReturn = NULL;

	vTaskSuspendAll();
     52e:	0e 94 97 0d 	call	0x1b2e	; 0x1b2e <vTaskSuspendAll>
	{
		/* If this is the first call to malloc then the heap will require
		initialisation to setup the list of free blocks. */
		if( xHeapHasBeenInitialised == pdFALSE )
     532:	80 91 74 00 	lds	r24, 0x0074
     536:	88 23       	and	r24, r24
     538:	f9 f4       	brne	.+62     	; 0x578 <pvPortMalloc+0x54>
	/* Ensure the heap starts on a correctly aligned boundary. */
	pucAlignedHeap = ( uint8_t * ) ( ( ( portPOINTER_SIZE_TYPE ) &ucHeap[ portBYTE_ALIGNMENT ] ) & ( ~( ( portPOINTER_SIZE_TYPE ) portBYTE_ALIGNMENT_MASK ) ) );

	/* xStart is used to hold a pointer to the first item in the list of free
	blocks.  The void cast is used to prevent compiler warnings. */
	xStart.pxNextFreeBlock = ( void * ) pucAlignedHeap;
     53a:	8e e7       	ldi	r24, 0x7E	; 126
     53c:	90 e0       	ldi	r25, 0x00	; 0
     53e:	90 93 76 00 	sts	0x0076, r25
     542:	80 93 75 00 	sts	0x0075, r24
	xStart.xBlockSize = ( size_t ) 0;
     546:	10 92 78 00 	sts	0x0078, r1
     54a:	10 92 77 00 	sts	0x0077, r1

	/* xEnd is used to mark the end of the list of free blocks. */
	xEnd.xBlockSize = configADJUSTED_HEAP_SIZE;
     54e:	8f e1       	ldi	r24, 0x1F	; 31
     550:	93 e0       	ldi	r25, 0x03	; 3
     552:	90 93 7c 00 	sts	0x007C, r25
     556:	80 93 7b 00 	sts	0x007B, r24
	xEnd.pxNextFreeBlock = NULL;
     55a:	eb e7       	ldi	r30, 0x7B	; 123
     55c:	f0 e0       	ldi	r31, 0x00	; 0
     55e:	12 92       	st	-Z, r1
     560:	12 92       	st	-Z, r1

	/* To start with there is a single free block that is sized to take up the
	entire heap space. */
	pxFirstFreeBlock = ( void * ) pucAlignedHeap;
	pxFirstFreeBlock->xBlockSize = configADJUSTED_HEAP_SIZE;
     562:	90 93 81 00 	sts	0x0081, r25
     566:	80 93 80 00 	sts	0x0080, r24
	pxFirstFreeBlock->pxNextFreeBlock = &xEnd;
     56a:	f0 93 7f 00 	sts	0x007F, r31
     56e:	e0 93 7e 00 	sts	0x007E, r30
		/* If this is the first call to malloc then the heap will require
		initialisation to setup the list of free blocks. */
		if( xHeapHasBeenInitialised == pdFALSE )
		{
			prvHeapInit();
			xHeapHasBeenInitialised = pdTRUE;
     572:	81 e0       	ldi	r24, 0x01	; 1
     574:	80 93 74 00 	sts	0x0074, r24
		}

		/* The wanted size is increased so it can contain a BlockLink_t
		structure in addition to the requested amount of bytes. */
		if( xWantedSize > 0 )
     578:	20 97       	sbiw	r28, 0x00	; 0
     57a:	09 f4       	brne	.+2      	; 0x57e <pvPortMalloc+0x5a>
     57c:	62 c0       	rjmp	.+196    	; 0x642 <pvPortMalloc+0x11e>
		{
			xWantedSize += heapSTRUCT_SIZE;
     57e:	9e 01       	movw	r18, r28
     580:	2c 5f       	subi	r18, 0xFC	; 252
     582:	3f 4f       	sbci	r19, 0xFF	; 255
				/* Byte alignment required. */
				xWantedSize += ( portBYTE_ALIGNMENT - ( xWantedSize & portBYTE_ALIGNMENT_MASK ) );
			}
		}

		if( ( xWantedSize > 0 ) && ( xWantedSize < configADJUSTED_HEAP_SIZE ) )
     584:	23 96       	adiw	r28, 0x03	; 3
     586:	83 e0       	ldi	r24, 0x03	; 3
     588:	ce 31       	cpi	r28, 0x1E	; 30
     58a:	d8 07       	cpc	r29, r24
     58c:	08 f0       	brcs	.+2      	; 0x590 <pvPortMalloc+0x6c>
     58e:	5c c0       	rjmp	.+184    	; 0x648 <pvPortMalloc+0x124>
		{
			/* Blocks are stored in byte order - traverse the list from the start
			(smallest) block until one of adequate size is found. */
			pxPreviousBlock = &xStart;
			pxBlock = xStart.pxNextFreeBlock;
     590:	e0 91 75 00 	lds	r30, 0x0075
     594:	f0 91 76 00 	lds	r31, 0x0076

		if( ( xWantedSize > 0 ) && ( xWantedSize < configADJUSTED_HEAP_SIZE ) )
		{
			/* Blocks are stored in byte order - traverse the list from the start
			(smallest) block until one of adequate size is found. */
			pxPreviousBlock = &xStart;
     598:	a5 e7       	ldi	r26, 0x75	; 117
     59a:	b0 e0       	ldi	r27, 0x00	; 0
			pxBlock = xStart.pxNextFreeBlock;
			while( ( pxBlock->xBlockSize < xWantedSize ) && ( pxBlock->pxNextFreeBlock != NULL ) )
     59c:	02 c0       	rjmp	.+4      	; 0x5a2 <pvPortMalloc+0x7e>
     59e:	df 01       	movw	r26, r30
			{
				pxPreviousBlock = pxBlock;
				pxBlock = pxBlock->pxNextFreeBlock;
     5a0:	fc 01       	movw	r30, r24
		{
			/* Blocks are stored in byte order - traverse the list from the start
			(smallest) block until one of adequate size is found. */
			pxPreviousBlock = &xStart;
			pxBlock = xStart.pxNextFreeBlock;
			while( ( pxBlock->xBlockSize < xWantedSize ) && ( pxBlock->pxNextFreeBlock != NULL ) )
     5a2:	82 81       	ldd	r24, Z+2	; 0x02
     5a4:	93 81       	ldd	r25, Z+3	; 0x03
     5a6:	82 17       	cp	r24, r18
     5a8:	93 07       	cpc	r25, r19
     5aa:	20 f4       	brcc	.+8      	; 0x5b4 <pvPortMalloc+0x90>
     5ac:	80 81       	ld	r24, Z
     5ae:	91 81       	ldd	r25, Z+1	; 0x01
     5b0:	00 97       	sbiw	r24, 0x00	; 0
     5b2:	a9 f7       	brne	.-22     	; 0x59e <pvPortMalloc+0x7a>
				pxPreviousBlock = pxBlock;
				pxBlock = pxBlock->pxNextFreeBlock;
			}

			/* If we found the end marker then a block of adequate size was not found. */
			if( pxBlock != &xEnd )
     5b4:	c0 e0       	ldi	r28, 0x00	; 0
     5b6:	e9 37       	cpi	r30, 0x79	; 121
     5b8:	fc 07       	cpc	r31, r28
     5ba:	09 f4       	brne	.+2      	; 0x5be <pvPortMalloc+0x9a>
     5bc:	48 c0       	rjmp	.+144    	; 0x64e <pvPortMalloc+0x12a>
			{
				/* Return the memory space - jumping over the BlockLink_t structure
				at its start. */
				pvReturn = ( void * ) ( ( ( uint8_t * ) pxPreviousBlock->pxNextFreeBlock ) + heapSTRUCT_SIZE );
     5be:	8d 91       	ld	r24, X+
     5c0:	9c 91       	ld	r25, X
     5c2:	11 97       	sbiw	r26, 0x01	; 1
     5c4:	8c 01       	movw	r16, r24
     5c6:	0c 5f       	subi	r16, 0xFC	; 252
     5c8:	1f 4f       	sbci	r17, 0xFF	; 255

				/* This block is being returned for use so must be taken out of the
				list of free blocks. */
				pxPreviousBlock->pxNextFreeBlock = pxBlock->pxNextFreeBlock;
     5ca:	80 81       	ld	r24, Z
     5cc:	91 81       	ldd	r25, Z+1	; 0x01
     5ce:	11 96       	adiw	r26, 0x01	; 1
     5d0:	9c 93       	st	X, r25
     5d2:	8e 93       	st	-X, r24

				/* If the block is larger than required it can be split into two. */
				if( ( pxBlock->xBlockSize - xWantedSize ) > heapMINIMUM_BLOCK_SIZE )
     5d4:	82 81       	ldd	r24, Z+2	; 0x02
     5d6:	93 81       	ldd	r25, Z+3	; 0x03
     5d8:	82 1b       	sub	r24, r18
     5da:	93 0b       	sbc	r25, r19
     5dc:	89 30       	cpi	r24, 0x09	; 9
     5de:	91 05       	cpc	r25, r1
     5e0:	18 f1       	brcs	.+70     	; 0x628 <pvPortMalloc+0x104>
				{
					/* This block is to be split into two.  Create a new block
					following the number of bytes requested. The void cast is
					used to prevent byte alignment warnings from the compiler. */
					pxNewBlockLink = ( void * ) ( ( ( uint8_t * ) pxBlock ) + xWantedSize );
     5e2:	af 01       	movw	r20, r30
     5e4:	42 0f       	add	r20, r18
     5e6:	53 1f       	adc	r21, r19

					/* Calculate the sizes of two blocks split from the single
					block. */
					pxNewBlockLink->xBlockSize = pxBlock->xBlockSize - xWantedSize;
     5e8:	da 01       	movw	r26, r20
     5ea:	13 96       	adiw	r26, 0x03	; 3
     5ec:	9c 93       	st	X, r25
     5ee:	8e 93       	st	-X, r24
     5f0:	12 97       	sbiw	r26, 0x02	; 2
					pxBlock->xBlockSize = xWantedSize;
     5f2:	33 83       	std	Z+3, r19	; 0x03
     5f4:	22 83       	std	Z+2, r18	; 0x02

					/* Insert the new block into the list of free blocks. */
					prvInsertBlockIntoFreeList( ( pxNewBlockLink ) );
     5f6:	12 96       	adiw	r26, 0x02	; 2
     5f8:	2d 91       	ld	r18, X+
     5fa:	3c 91       	ld	r19, X
     5fc:	13 97       	sbiw	r26, 0x03	; 3
     5fe:	65 e7       	ldi	r22, 0x75	; 117
     600:	70 e0       	ldi	r23, 0x00	; 0
     602:	01 c0       	rjmp	.+2      	; 0x606 <pvPortMalloc+0xe2>
     604:	bd 01       	movw	r22, r26
     606:	eb 01       	movw	r28, r22
     608:	a8 81       	ld	r26, Y
     60a:	b9 81       	ldd	r27, Y+1	; 0x01
     60c:	12 96       	adiw	r26, 0x02	; 2
     60e:	8d 91       	ld	r24, X+
     610:	9c 91       	ld	r25, X
     612:	13 97       	sbiw	r26, 0x03	; 3
     614:	82 17       	cp	r24, r18
     616:	93 07       	cpc	r25, r19
     618:	a8 f3       	brcs	.-22     	; 0x604 <pvPortMalloc+0xe0>
     61a:	ea 01       	movw	r28, r20
     61c:	b9 83       	std	Y+1, r27	; 0x01
     61e:	a8 83       	st	Y, r26
     620:	db 01       	movw	r26, r22
     622:	11 96       	adiw	r26, 0x01	; 1
     624:	5c 93       	st	X, r21
     626:	4e 93       	st	-X, r20
				}

				xFreeBytesRemaining -= pxBlock->xBlockSize;
     628:	80 91 60 00 	lds	r24, 0x0060
     62c:	90 91 61 00 	lds	r25, 0x0061
     630:	22 81       	ldd	r18, Z+2	; 0x02
     632:	33 81       	ldd	r19, Z+3	; 0x03
     634:	82 1b       	sub	r24, r18
     636:	93 0b       	sbc	r25, r19
     638:	90 93 61 00 	sts	0x0061, r25
     63c:	80 93 60 00 	sts	0x0060, r24
     640:	08 c0       	rjmp	.+16     	; 0x652 <pvPortMalloc+0x12e>

void *pvPortMalloc( size_t xWantedSize )
{
BlockLink_t *pxBlock, *pxPreviousBlock, *pxNewBlockLink;
static BaseType_t xHeapHasBeenInitialised = pdFALSE;
void *pvReturn = NULL;
     642:	00 e0       	ldi	r16, 0x00	; 0
     644:	10 e0       	ldi	r17, 0x00	; 0
     646:	05 c0       	rjmp	.+10     	; 0x652 <pvPortMalloc+0x12e>
     648:	00 e0       	ldi	r16, 0x00	; 0
     64a:	10 e0       	ldi	r17, 0x00	; 0
     64c:	02 c0       	rjmp	.+4      	; 0x652 <pvPortMalloc+0x12e>
     64e:	00 e0       	ldi	r16, 0x00	; 0
     650:	10 e0       	ldi	r17, 0x00	; 0
			}
		}

		traceMALLOC( pvReturn, xWantedSize );
	}
	( void ) xTaskResumeAll();
     652:	0e 94 5c 0e 	call	0x1cb8	; 0x1cb8 <xTaskResumeAll>
		}
	}
	#endif

	return pvReturn;
}
     656:	80 2f       	mov	r24, r16
     658:	91 2f       	mov	r25, r17
     65a:	df 91       	pop	r29
     65c:	cf 91       	pop	r28
     65e:	1f 91       	pop	r17
     660:	0f 91       	pop	r16
     662:	08 95       	ret

00000664 <vPortFree>:
/*-----------------------------------------------------------*/

void vPortFree( void *pv )
{
     664:	0f 93       	push	r16
     666:	1f 93       	push	r17
     668:	cf 93       	push	r28
     66a:	df 93       	push	r29
     66c:	ec 01       	movw	r28, r24
uint8_t *puc = ( uint8_t * ) pv;
BlockLink_t *pxLink;

	if( pv != NULL )
     66e:	00 97       	sbiw	r24, 0x00	; 0
     670:	39 f1       	breq	.+78     	; 0x6c0 <vPortFree+0x5c>
		before it. */
		puc -= heapSTRUCT_SIZE;

		/* This unexpected casting is to keep some compilers from issuing
		byte alignment warnings. */
		pxLink = ( void * ) puc;
     672:	8c 01       	movw	r16, r24
     674:	04 50       	subi	r16, 0x04	; 4
     676:	10 40       	sbci	r17, 0x00	; 0

		vTaskSuspendAll();
     678:	0e 94 97 0d 	call	0x1b2e	; 0x1b2e <vTaskSuspendAll>
		{
			/* Add this block to the list of free blocks. */
			prvInsertBlockIntoFreeList( ( ( BlockLink_t * ) pxLink ) );
     67c:	f8 01       	movw	r30, r16
     67e:	22 81       	ldd	r18, Z+2	; 0x02
     680:	33 81       	ldd	r19, Z+3	; 0x03
     682:	a5 e7       	ldi	r26, 0x75	; 117
     684:	b0 e0       	ldi	r27, 0x00	; 0
     686:	01 c0       	rjmp	.+2      	; 0x68a <vPortFree+0x26>
     688:	df 01       	movw	r26, r30
     68a:	ed 91       	ld	r30, X+
     68c:	fc 91       	ld	r31, X
     68e:	11 97       	sbiw	r26, 0x01	; 1
     690:	82 81       	ldd	r24, Z+2	; 0x02
     692:	93 81       	ldd	r25, Z+3	; 0x03
     694:	82 17       	cp	r24, r18
     696:	93 07       	cpc	r25, r19
     698:	b8 f3       	brcs	.-18     	; 0x688 <vPortFree+0x24>
     69a:	24 97       	sbiw	r28, 0x04	; 4
     69c:	f9 83       	std	Y+1, r31	; 0x01
     69e:	e8 83       	st	Y, r30
     6a0:	0d 93       	st	X+, r16
     6a2:	1c 93       	st	X, r17
			xFreeBytesRemaining += pxLink->xBlockSize;
     6a4:	80 91 60 00 	lds	r24, 0x0060
     6a8:	90 91 61 00 	lds	r25, 0x0061
     6ac:	2a 81       	ldd	r18, Y+2	; 0x02
     6ae:	3b 81       	ldd	r19, Y+3	; 0x03
     6b0:	82 0f       	add	r24, r18
     6b2:	93 1f       	adc	r25, r19
     6b4:	90 93 61 00 	sts	0x0061, r25
     6b8:	80 93 60 00 	sts	0x0060, r24
			traceFREE( pv, pxLink->xBlockSize );
		}
		( void ) xTaskResumeAll();
     6bc:	0e 94 5c 0e 	call	0x1cb8	; 0x1cb8 <xTaskResumeAll>
	}
}
     6c0:	df 91       	pop	r29
     6c2:	cf 91       	pop	r28
     6c4:	1f 91       	pop	r17
     6c6:	0f 91       	pop	r16
     6c8:	08 95       	ret

000006ca <xPortGetFreeHeapSize>:
/*-----------------------------------------------------------*/

size_t xPortGetFreeHeapSize( void )
{
	return xFreeBytesRemaining;
}
     6ca:	80 91 60 00 	lds	r24, 0x0060
     6ce:	90 91 61 00 	lds	r25, 0x0061
     6d2:	08 95       	ret

000006d4 <vPortInitialiseBlocks>:
/*-----------------------------------------------------------*/

void vPortInitialiseBlocks( void )
{
	/* This just exists to keep the linker quiet. */
}
     6d4:	08 95       	ret

000006d6 <vListInitialise>:
/*-----------------------------------------------------------
 * PUBLIC LIST API documented in list.h
 *----------------------------------------------------------*/

void vListInitialise( List_t * const pxList )
{
     6d6:	fc 01       	movw	r30, r24
	/* The list structure contains a list item which is used to mark the
	end of the list.  To initialise the list the list end is inserted
	as the only list entry. */
	pxList->pxIndex = ( ListItem_t * ) &( pxList->xListEnd );			/*lint !e826 !e740 The mini list structure is used as the list end to save RAM.  This is checked and valid. */
     6d8:	03 96       	adiw	r24, 0x03	; 3
     6da:	92 83       	std	Z+2, r25	; 0x02
     6dc:	81 83       	std	Z+1, r24	; 0x01

	/* The list end value is the highest possible value in the list to
	ensure it remains at the end of the list. */
	pxList->xListEnd.xItemValue = portMAX_DELAY;
     6de:	2f ef       	ldi	r18, 0xFF	; 255
     6e0:	3f ef       	ldi	r19, 0xFF	; 255
     6e2:	34 83       	std	Z+4, r19	; 0x04
     6e4:	23 83       	std	Z+3, r18	; 0x03

	/* The list end next and previous pointers point to itself so we know
	when the list is empty. */
	pxList->xListEnd.pxNext = ( ListItem_t * ) &( pxList->xListEnd );	/*lint !e826 !e740 The mini list structure is used as the list end to save RAM.  This is checked and valid. */
     6e6:	96 83       	std	Z+6, r25	; 0x06
     6e8:	85 83       	std	Z+5, r24	; 0x05
	pxList->xListEnd.pxPrevious = ( ListItem_t * ) &( pxList->xListEnd );/*lint !e826 !e740 The mini list structure is used as the list end to save RAM.  This is checked and valid. */
     6ea:	90 87       	std	Z+8, r25	; 0x08
     6ec:	87 83       	std	Z+7, r24	; 0x07

	pxList->uxNumberOfItems = ( UBaseType_t ) 0U;
     6ee:	10 82       	st	Z, r1

	/* Write known values into the list if
	configUSE_LIST_DATA_INTEGRITY_CHECK_BYTES is set to 1. */
	listSET_LIST_INTEGRITY_CHECK_1_VALUE( pxList );
	listSET_LIST_INTEGRITY_CHECK_2_VALUE( pxList );
}
     6f0:	08 95       	ret

000006f2 <vListInitialiseItem>:
/*-----------------------------------------------------------*/

void vListInitialiseItem( ListItem_t * const pxItem )
{
	/* Make sure the list item is not recorded as being on a list. */
	pxItem->pvContainer = NULL;
     6f2:	fc 01       	movw	r30, r24
     6f4:	11 86       	std	Z+9, r1	; 0x09
     6f6:	10 86       	std	Z+8, r1	; 0x08

	/* Write known values into the list item if
	configUSE_LIST_DATA_INTEGRITY_CHECK_BYTES is set to 1. */
	listSET_FIRST_LIST_ITEM_INTEGRITY_CHECK_VALUE( pxItem );
	listSET_SECOND_LIST_ITEM_INTEGRITY_CHECK_VALUE( pxItem );
}
     6f8:	08 95       	ret

000006fa <vListInsertEnd>:
/*-----------------------------------------------------------*/

void vListInsertEnd( List_t * const pxList, ListItem_t * const pxNewListItem )
{
     6fa:	cf 93       	push	r28
     6fc:	df 93       	push	r29
     6fe:	fb 01       	movw	r30, r22
ListItem_t * const pxIndex = pxList->pxIndex;
     700:	dc 01       	movw	r26, r24
     702:	11 96       	adiw	r26, 0x01	; 1
     704:	cd 91       	ld	r28, X+
     706:	dc 91       	ld	r29, X
     708:	12 97       	sbiw	r26, 0x02	; 2
	listTEST_LIST_ITEM_INTEGRITY( pxNewListItem );

	/* Insert a new list item into pxList, but rather than sort the list,
	makes the new list item the last item to be removed by a call to
	listGET_OWNER_OF_NEXT_ENTRY(). */
	pxNewListItem->pxNext = pxIndex;
     70a:	d3 83       	std	Z+3, r29	; 0x03
     70c:	c2 83       	std	Z+2, r28	; 0x02
	pxNewListItem->pxPrevious = pxIndex->pxPrevious;
     70e:	2c 81       	ldd	r18, Y+4	; 0x04
     710:	3d 81       	ldd	r19, Y+5	; 0x05
     712:	35 83       	std	Z+5, r19	; 0x05
     714:	24 83       	std	Z+4, r18	; 0x04

	/* Only used during decision coverage testing. */
	mtCOVERAGE_TEST_DELAY();

	pxIndex->pxPrevious->pxNext = pxNewListItem;
     716:	ac 81       	ldd	r26, Y+4	; 0x04
     718:	bd 81       	ldd	r27, Y+5	; 0x05
     71a:	13 96       	adiw	r26, 0x03	; 3
     71c:	7c 93       	st	X, r23
     71e:	6e 93       	st	-X, r22
     720:	12 97       	sbiw	r26, 0x02	; 2
	pxIndex->pxPrevious = pxNewListItem;
     722:	7d 83       	std	Y+5, r23	; 0x05
     724:	6c 83       	std	Y+4, r22	; 0x04

	/* Remember which list the item is in. */
	pxNewListItem->pvContainer = ( void * ) pxList;
     726:	91 87       	std	Z+9, r25	; 0x09
     728:	80 87       	std	Z+8, r24	; 0x08

	( pxList->uxNumberOfItems )++;
     72a:	fc 01       	movw	r30, r24
     72c:	20 81       	ld	r18, Z
     72e:	2f 5f       	subi	r18, 0xFF	; 255
     730:	20 83       	st	Z, r18
}
     732:	df 91       	pop	r29
     734:	cf 91       	pop	r28
     736:	08 95       	ret

00000738 <vListInsert>:
/*-----------------------------------------------------------*/

void vListInsert( List_t * const pxList, ListItem_t * const pxNewListItem )
{
     738:	cf 93       	push	r28
     73a:	df 93       	push	r29
     73c:	ac 01       	movw	r20, r24
     73e:	eb 01       	movw	r28, r22
ListItem_t *pxIterator;
const TickType_t xValueOfInsertion = pxNewListItem->xItemValue;
     740:	28 81       	ld	r18, Y
     742:	39 81       	ldd	r19, Y+1	; 0x01
	new list item should be placed after it.  This ensures that TCB's which are
	stored in ready lists (all of which have the same xItemValue value) get a
	share of the CPU.  However, if the xItemValue is the same as the back marker
	the iteration loop below will not end.  Therefore the value is checked
	first, and the algorithm slightly modified if necessary. */
	if( xValueOfInsertion == portMAX_DELAY )
     744:	8f ef       	ldi	r24, 0xFF	; 255
     746:	2f 3f       	cpi	r18, 0xFF	; 255
     748:	38 07       	cpc	r19, r24
     74a:	21 f4       	brne	.+8      	; 0x754 <vListInsert+0x1c>
	{
		pxIterator = pxList->xListEnd.pxPrevious;
     74c:	fa 01       	movw	r30, r20
     74e:	a7 81       	ldd	r26, Z+7	; 0x07
     750:	b0 85       	ldd	r27, Z+8	; 0x08
     752:	0d c0       	rjmp	.+26     	; 0x76e <vListInsert+0x36>
			4) Using a queue or semaphore before it has been initialised or
			   before the scheduler has been started (are interrupts firing
			   before vTaskStartScheduler() has been called?).
		**********************************************************************/

		for( pxIterator = ( ListItem_t * ) &( pxList->xListEnd ); pxIterator->pxNext->xItemValue <= xValueOfInsertion; pxIterator = pxIterator->pxNext ) /*lint !e826 !e740 The mini list structure is used as the list end to save RAM.  This is checked and valid. */
     754:	da 01       	movw	r26, r20
     756:	13 96       	adiw	r26, 0x03	; 3
     758:	01 c0       	rjmp	.+2      	; 0x75c <vListInsert+0x24>
     75a:	df 01       	movw	r26, r30
     75c:	12 96       	adiw	r26, 0x02	; 2
     75e:	ed 91       	ld	r30, X+
     760:	fc 91       	ld	r31, X
     762:	13 97       	sbiw	r26, 0x03	; 3
     764:	80 81       	ld	r24, Z
     766:	91 81       	ldd	r25, Z+1	; 0x01
     768:	28 17       	cp	r18, r24
     76a:	39 07       	cpc	r19, r25
     76c:	b0 f7       	brcc	.-20     	; 0x75a <vListInsert+0x22>
			/* There is nothing to do here, just iterating to the wanted
			insertion position. */
		}
	}

	pxNewListItem->pxNext = pxIterator->pxNext;
     76e:	12 96       	adiw	r26, 0x02	; 2
     770:	ed 91       	ld	r30, X+
     772:	fc 91       	ld	r31, X
     774:	13 97       	sbiw	r26, 0x03	; 3
     776:	fb 83       	std	Y+3, r31	; 0x03
     778:	ea 83       	std	Y+2, r30	; 0x02
	pxNewListItem->pxNext->pxPrevious = pxNewListItem;
     77a:	d5 83       	std	Z+5, r29	; 0x05
     77c:	c4 83       	std	Z+4, r28	; 0x04
	pxNewListItem->pxPrevious = pxIterator;
     77e:	bd 83       	std	Y+5, r27	; 0x05
     780:	ac 83       	std	Y+4, r26	; 0x04
	pxIterator->pxNext = pxNewListItem;
     782:	13 96       	adiw	r26, 0x03	; 3
     784:	dc 93       	st	X, r29
     786:	ce 93       	st	-X, r28
     788:	12 97       	sbiw	r26, 0x02	; 2

	/* Remember which list the item is in.  This allows fast removal of the
	item later. */
	pxNewListItem->pvContainer = ( void * ) pxList;
     78a:	59 87       	std	Y+9, r21	; 0x09
     78c:	48 87       	std	Y+8, r20	; 0x08

	( pxList->uxNumberOfItems )++;
     78e:	fa 01       	movw	r30, r20
     790:	80 81       	ld	r24, Z
     792:	8f 5f       	subi	r24, 0xFF	; 255
     794:	80 83       	st	Z, r24
}
     796:	df 91       	pop	r29
     798:	cf 91       	pop	r28
     79a:	08 95       	ret

0000079c <uxListRemove>:
/*-----------------------------------------------------------*/

UBaseType_t uxListRemove( ListItem_t * const pxItemToRemove )
{
     79c:	cf 93       	push	r28
     79e:	df 93       	push	r29
     7a0:	fc 01       	movw	r30, r24
/* The list item knows which list it is in.  Obtain the list from the list
item. */
List_t * const pxList = ( List_t * ) pxItemToRemove->pvContainer;
     7a2:	c0 85       	ldd	r28, Z+8	; 0x08
     7a4:	d1 85       	ldd	r29, Z+9	; 0x09

	pxItemToRemove->pxNext->pxPrevious = pxItemToRemove->pxPrevious;
     7a6:	a2 81       	ldd	r26, Z+2	; 0x02
     7a8:	b3 81       	ldd	r27, Z+3	; 0x03
     7aa:	84 81       	ldd	r24, Z+4	; 0x04
     7ac:	95 81       	ldd	r25, Z+5	; 0x05
     7ae:	15 96       	adiw	r26, 0x05	; 5
     7b0:	9c 93       	st	X, r25
     7b2:	8e 93       	st	-X, r24
     7b4:	14 97       	sbiw	r26, 0x04	; 4
	pxItemToRemove->pxPrevious->pxNext = pxItemToRemove->pxNext;
     7b6:	a4 81       	ldd	r26, Z+4	; 0x04
     7b8:	b5 81       	ldd	r27, Z+5	; 0x05
     7ba:	82 81       	ldd	r24, Z+2	; 0x02
     7bc:	93 81       	ldd	r25, Z+3	; 0x03
     7be:	13 96       	adiw	r26, 0x03	; 3
     7c0:	9c 93       	st	X, r25
     7c2:	8e 93       	st	-X, r24
     7c4:	12 97       	sbiw	r26, 0x02	; 2

	/* Only used during decision coverage testing. */
	mtCOVERAGE_TEST_DELAY();

	/* Make sure the index is left pointing to a valid item. */
	if( pxList->pxIndex == pxItemToRemove )
     7c6:	a9 81       	ldd	r26, Y+1	; 0x01
     7c8:	ba 81       	ldd	r27, Y+2	; 0x02
     7ca:	ae 17       	cp	r26, r30
     7cc:	bf 07       	cpc	r27, r31
     7ce:	31 f4       	brne	.+12     	; 0x7dc <uxListRemove+0x40>
	{
		pxList->pxIndex = pxItemToRemove->pxPrevious;
     7d0:	14 96       	adiw	r26, 0x04	; 4
     7d2:	8d 91       	ld	r24, X+
     7d4:	9c 91       	ld	r25, X
     7d6:	15 97       	sbiw	r26, 0x05	; 5
     7d8:	9a 83       	std	Y+2, r25	; 0x02
     7da:	89 83       	std	Y+1, r24	; 0x01
	else
	{
		mtCOVERAGE_TEST_MARKER();
	}

	pxItemToRemove->pvContainer = NULL;
     7dc:	11 86       	std	Z+9, r1	; 0x09
     7de:	10 86       	std	Z+8, r1	; 0x08
	( pxList->uxNumberOfItems )--;
     7e0:	88 81       	ld	r24, Y
     7e2:	81 50       	subi	r24, 0x01	; 1
     7e4:	88 83       	st	Y, r24

	return pxList->uxNumberOfItems;
}
     7e6:	df 91       	pop	r29
     7e8:	cf 91       	pop	r28
     7ea:	08 95       	ret

000007ec <pxPortInitialiseStack>:
uint16_t usAddress;

	/* Place a few bytes of known values on the bottom of the stack. 
	This is just useful for debugging. */

	*pxTopOfStack = 0x11;
     7ec:	21 e1       	ldi	r18, 0x11	; 17
     7ee:	fc 01       	movw	r30, r24
     7f0:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = 0x22;
     7f2:	31 97       	sbiw	r30, 0x01	; 1
     7f4:	32 e2       	ldi	r19, 0x22	; 34
     7f6:	30 83       	st	Z, r19
	pxTopOfStack--;
	*pxTopOfStack = 0x33;
     7f8:	fc 01       	movw	r30, r24
     7fa:	32 97       	sbiw	r30, 0x02	; 2
     7fc:	a3 e3       	ldi	r26, 0x33	; 51
     7fe:	a0 83       	st	Z, r26
	/*lint -e950 -e611 -e923 Lint doesn't like this much - but nothing I can do about it. */

	/* The start of the task code will be popped off the stack last, so place
	it on first. */
	usAddress = ( uint16_t ) pxCode;
	*pxTopOfStack = ( StackType_t ) ( usAddress & ( uint16_t ) 0x00ff );
     800:	fc 01       	movw	r30, r24
     802:	33 97       	sbiw	r30, 0x03	; 3
     804:	60 83       	st	Z, r22
	pxTopOfStack--;

	usAddress >>= 8;
	*pxTopOfStack = ( StackType_t ) ( usAddress & ( uint16_t ) 0x00ff );
     806:	fc 01       	movw	r30, r24
     808:	34 97       	sbiw	r30, 0x04	; 4
     80a:	70 83       	st	Z, r23

	/* Next simulate the stack as if after a call to portSAVE_CONTEXT().  
	portSAVE_CONTEXT places the flags on the stack immediately after r0
	to ensure the interrupts get disabled as soon as possible, and so ensuring
	the stack use is minimal should a context switch interrupt occur. */
	*pxTopOfStack = ( StackType_t ) 0x00;	/* R0 */
     80c:	fc 01       	movw	r30, r24
     80e:	35 97       	sbiw	r30, 0x05	; 5
     810:	10 82       	st	Z, r1
	pxTopOfStack--;
	*pxTopOfStack = portFLAGS_INT_ENABLED;
     812:	fc 01       	movw	r30, r24
     814:	36 97       	sbiw	r30, 0x06	; 6
     816:	60 e8       	ldi	r22, 0x80	; 128
     818:	60 83       	st	Z, r22
	pxTopOfStack--;


	/* Now the remaining registers.   The compiler expects R1 to be 0. */
	*pxTopOfStack = ( StackType_t ) 0x00;	/* R1 */
     81a:	fc 01       	movw	r30, r24
     81c:	37 97       	sbiw	r30, 0x07	; 7
     81e:	10 82       	st	Z, r1
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x02;	/* R2 */
     820:	fc 01       	movw	r30, r24
     822:	38 97       	sbiw	r30, 0x08	; 8
     824:	62 e0       	ldi	r22, 0x02	; 2
     826:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x03;	/* R3 */
     828:	fc 01       	movw	r30, r24
     82a:	39 97       	sbiw	r30, 0x09	; 9
     82c:	63 e0       	ldi	r22, 0x03	; 3
     82e:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x04;	/* R4 */
     830:	fc 01       	movw	r30, r24
     832:	3a 97       	sbiw	r30, 0x0a	; 10
     834:	64 e0       	ldi	r22, 0x04	; 4
     836:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x05;	/* R5 */
     838:	fc 01       	movw	r30, r24
     83a:	3b 97       	sbiw	r30, 0x0b	; 11
     83c:	65 e0       	ldi	r22, 0x05	; 5
     83e:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x06;	/* R6 */
     840:	fc 01       	movw	r30, r24
     842:	3c 97       	sbiw	r30, 0x0c	; 12
     844:	66 e0       	ldi	r22, 0x06	; 6
     846:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x07;	/* R7 */
     848:	fc 01       	movw	r30, r24
     84a:	3d 97       	sbiw	r30, 0x0d	; 13
     84c:	67 e0       	ldi	r22, 0x07	; 7
     84e:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x08;	/* R8 */
     850:	fc 01       	movw	r30, r24
     852:	3e 97       	sbiw	r30, 0x0e	; 14
     854:	68 e0       	ldi	r22, 0x08	; 8
     856:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x09;	/* R9 */
     858:	fc 01       	movw	r30, r24
     85a:	3f 97       	sbiw	r30, 0x0f	; 15
     85c:	69 e0       	ldi	r22, 0x09	; 9
     85e:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x10;	/* R10 */
     860:	fc 01       	movw	r30, r24
     862:	70 97       	sbiw	r30, 0x10	; 16
     864:	60 e1       	ldi	r22, 0x10	; 16
     866:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x11;	/* R11 */
     868:	fc 01       	movw	r30, r24
     86a:	71 97       	sbiw	r30, 0x11	; 17
     86c:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x12;	/* R12 */
     86e:	fc 01       	movw	r30, r24
     870:	72 97       	sbiw	r30, 0x12	; 18
     872:	22 e1       	ldi	r18, 0x12	; 18
     874:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x13;	/* R13 */
     876:	fc 01       	movw	r30, r24
     878:	73 97       	sbiw	r30, 0x13	; 19
     87a:	23 e1       	ldi	r18, 0x13	; 19
     87c:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x14;	/* R14 */
     87e:	fc 01       	movw	r30, r24
     880:	74 97       	sbiw	r30, 0x14	; 20
     882:	24 e1       	ldi	r18, 0x14	; 20
     884:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x15;	/* R15 */
     886:	fc 01       	movw	r30, r24
     888:	75 97       	sbiw	r30, 0x15	; 21
     88a:	25 e1       	ldi	r18, 0x15	; 21
     88c:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x16;	/* R16 */
     88e:	fc 01       	movw	r30, r24
     890:	76 97       	sbiw	r30, 0x16	; 22
     892:	26 e1       	ldi	r18, 0x16	; 22
     894:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x17;	/* R17 */
     896:	fc 01       	movw	r30, r24
     898:	77 97       	sbiw	r30, 0x17	; 23
     89a:	27 e1       	ldi	r18, 0x17	; 23
     89c:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x18;	/* R18 */
     89e:	fc 01       	movw	r30, r24
     8a0:	78 97       	sbiw	r30, 0x18	; 24
     8a2:	28 e1       	ldi	r18, 0x18	; 24
     8a4:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x19;	/* R19 */
     8a6:	fc 01       	movw	r30, r24
     8a8:	79 97       	sbiw	r30, 0x19	; 25
     8aa:	29 e1       	ldi	r18, 0x19	; 25
     8ac:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x20;	/* R20 */
     8ae:	fc 01       	movw	r30, r24
     8b0:	7a 97       	sbiw	r30, 0x1a	; 26
     8b2:	20 e2       	ldi	r18, 0x20	; 32
     8b4:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x21;	/* R21 */
     8b6:	fc 01       	movw	r30, r24
     8b8:	7b 97       	sbiw	r30, 0x1b	; 27
     8ba:	21 e2       	ldi	r18, 0x21	; 33
     8bc:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x22;	/* R22 */
     8be:	fc 01       	movw	r30, r24
     8c0:	7c 97       	sbiw	r30, 0x1c	; 28
     8c2:	30 83       	st	Z, r19
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x23;	/* R23 */
     8c4:	fc 01       	movw	r30, r24
     8c6:	7d 97       	sbiw	r30, 0x1d	; 29
     8c8:	23 e2       	ldi	r18, 0x23	; 35
     8ca:	20 83       	st	Z, r18
	pxTopOfStack--;

	/* Place the parameter on the stack in the expected location. */
	usAddress = ( uint16_t ) pvParameters;
	*pxTopOfStack = ( StackType_t ) ( usAddress & ( uint16_t ) 0x00ff );
     8cc:	fc 01       	movw	r30, r24
     8ce:	7e 97       	sbiw	r30, 0x1e	; 30
     8d0:	40 83       	st	Z, r20
	pxTopOfStack--;

	usAddress >>= 8;
	*pxTopOfStack = ( StackType_t ) ( usAddress & ( uint16_t ) 0x00ff );
     8d2:	fc 01       	movw	r30, r24
     8d4:	7f 97       	sbiw	r30, 0x1f	; 31
     8d6:	50 83       	st	Z, r21
	pxTopOfStack--;

	*pxTopOfStack = ( StackType_t ) 0x26;	/* R26 X */
     8d8:	fc 01       	movw	r30, r24
     8da:	b0 97       	sbiw	r30, 0x20	; 32
     8dc:	26 e2       	ldi	r18, 0x26	; 38
     8de:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x27;	/* R27 */
     8e0:	fc 01       	movw	r30, r24
     8e2:	b1 97       	sbiw	r30, 0x21	; 33
     8e4:	27 e2       	ldi	r18, 0x27	; 39
     8e6:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x28;	/* R28 Y */
     8e8:	fc 01       	movw	r30, r24
     8ea:	b2 97       	sbiw	r30, 0x22	; 34
     8ec:	28 e2       	ldi	r18, 0x28	; 40
     8ee:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x29;	/* R29 */
     8f0:	fc 01       	movw	r30, r24
     8f2:	b3 97       	sbiw	r30, 0x23	; 35
     8f4:	29 e2       	ldi	r18, 0x29	; 41
     8f6:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x30;	/* R30 Z */
     8f8:	fc 01       	movw	r30, r24
     8fa:	b4 97       	sbiw	r30, 0x24	; 36
     8fc:	20 e3       	ldi	r18, 0x30	; 48
     8fe:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x031;	/* R31 */
     900:	fc 01       	movw	r30, r24
     902:	b5 97       	sbiw	r30, 0x25	; 37
     904:	21 e3       	ldi	r18, 0x31	; 49
     906:	20 83       	st	Z, r18
	pxTopOfStack--;

	/*lint +e950 +e611 +e923 */

	return pxTopOfStack;
     908:	86 97       	sbiw	r24, 0x26	; 38
}
     90a:	08 95       	ret

0000090c <xPortStartScheduler>:
	/* Setup compare match value for compare match A.  Interrupts are disabled 
	before this is called so we need not worry here. */
	ucLowByte = ( uint8_t ) ( ulCompareMatch & ( uint32_t ) 0xff );
	ulCompareMatch >>= 8;
	ucHighByte = ( uint8_t ) ( ulCompareMatch & ( uint32_t ) 0xff );
	OCR1AH = ucHighByte;
     90c:	1b bc       	out	0x2b, r1	; 43
	OCR1AL = ucLowByte;
     90e:	8c e7       	ldi	r24, 0x7C	; 124
     910:	8a bd       	out	0x2a, r24	; 42

	/* Setup clock source and compare match behaviour. */
	ucLowByte = portCLEAR_COUNTER_ON_MATCH | portPRESCALE_64;
	TCCR1B = ucLowByte;
     912:	8b e0       	ldi	r24, 0x0B	; 11
     914:	8e bd       	out	0x2e, r24	; 46

	/* Enable the interrupt - this is okay as interrupt are currently globally
	disabled. */
	ucLowByte = TIMSK;
     916:	89 b7       	in	r24, 0x39	; 57
	ucLowByte |= portCOMPARE_MATCH_A_INTERRUPT_ENABLE;
     918:	80 61       	ori	r24, 0x10	; 16
	TIMSK = ucLowByte;
     91a:	89 bf       	out	0x39, r24	; 57
{
	/* Setup the hardware to generate the tick. */
	prvSetupTimerInterrupt();

	/* Restore the context of the first task that is going to run. */
	portRESTORE_CONTEXT();
     91c:	a0 91 9d 03 	lds	r26, 0x039D
     920:	b0 91 9e 03 	lds	r27, 0x039E
     924:	cd 91       	ld	r28, X+
     926:	cd bf       	out	0x3d, r28	; 61
     928:	dd 91       	ld	r29, X+
     92a:	de bf       	out	0x3e, r29	; 62
     92c:	ff 91       	pop	r31
     92e:	ef 91       	pop	r30
     930:	df 91       	pop	r29
     932:	cf 91       	pop	r28
     934:	bf 91       	pop	r27
     936:	af 91       	pop	r26
     938:	9f 91       	pop	r25
     93a:	8f 91       	pop	r24
     93c:	7f 91       	pop	r23
     93e:	6f 91       	pop	r22
     940:	5f 91       	pop	r21
     942:	4f 91       	pop	r20
     944:	3f 91       	pop	r19
     946:	2f 91       	pop	r18
     948:	1f 91       	pop	r17
     94a:	0f 91       	pop	r16
     94c:	ff 90       	pop	r15
     94e:	ef 90       	pop	r14
     950:	df 90       	pop	r13
     952:	cf 90       	pop	r12
     954:	bf 90       	pop	r11
     956:	af 90       	pop	r10
     958:	9f 90       	pop	r9
     95a:	8f 90       	pop	r8
     95c:	7f 90       	pop	r7
     95e:	6f 90       	pop	r6
     960:	5f 90       	pop	r5
     962:	4f 90       	pop	r4
     964:	3f 90       	pop	r3
     966:	2f 90       	pop	r2
     968:	1f 90       	pop	r1
     96a:	0f 90       	pop	r0
     96c:	0f be       	out	0x3f, r0	; 63
     96e:	0f 90       	pop	r0

	/* Simulate a function call end as generated by the compiler.  We will now
	jump to the start of the task the context of which we have just restored. */
	asm volatile ( "ret" );
     970:	08 95       	ret

	/* Should not get here. */
	return pdTRUE;
}
     972:	81 e0       	ldi	r24, 0x01	; 1
     974:	08 95       	ret

00000976 <vPortEndScheduler>:

void vPortEndScheduler( void )
{
	/* It is unlikely that the AVR port will get stopped.  If required simply
	disable the tick interrupt here. */
}
     976:	08 95       	ret

00000978 <vPortYield>:
 * can use a naked attribute.
 */
void vPortYield( void ) __attribute__ ( ( naked ) );
void vPortYield( void )
{
	portSAVE_CONTEXT();
     978:	0f 92       	push	r0
     97a:	0f b6       	in	r0, 0x3f	; 63
     97c:	f8 94       	cli
     97e:	0f 92       	push	r0
     980:	1f 92       	push	r1
     982:	11 24       	eor	r1, r1
     984:	2f 92       	push	r2
     986:	3f 92       	push	r3
     988:	4f 92       	push	r4
     98a:	5f 92       	push	r5
     98c:	6f 92       	push	r6
     98e:	7f 92       	push	r7
     990:	8f 92       	push	r8
     992:	9f 92       	push	r9
     994:	af 92       	push	r10
     996:	bf 92       	push	r11
     998:	cf 92       	push	r12
     99a:	df 92       	push	r13
     99c:	ef 92       	push	r14
     99e:	ff 92       	push	r15
     9a0:	0f 93       	push	r16
     9a2:	1f 93       	push	r17
     9a4:	2f 93       	push	r18
     9a6:	3f 93       	push	r19
     9a8:	4f 93       	push	r20
     9aa:	5f 93       	push	r21
     9ac:	6f 93       	push	r22
     9ae:	7f 93       	push	r23
     9b0:	8f 93       	push	r24
     9b2:	9f 93       	push	r25
     9b4:	af 93       	push	r26
     9b6:	bf 93       	push	r27
     9b8:	cf 93       	push	r28
     9ba:	df 93       	push	r29
     9bc:	ef 93       	push	r30
     9be:	ff 93       	push	r31
     9c0:	a0 91 9d 03 	lds	r26, 0x039D
     9c4:	b0 91 9e 03 	lds	r27, 0x039E
     9c8:	0d b6       	in	r0, 0x3d	; 61
     9ca:	0d 92       	st	X+, r0
     9cc:	0e b6       	in	r0, 0x3e	; 62
     9ce:	0d 92       	st	X+, r0
	vTaskSwitchContext();
     9d0:	0e 94 67 0f 	call	0x1ece	; 0x1ece <vTaskSwitchContext>
	portRESTORE_CONTEXT();
     9d4:	a0 91 9d 03 	lds	r26, 0x039D
     9d8:	b0 91 9e 03 	lds	r27, 0x039E
     9dc:	cd 91       	ld	r28, X+
     9de:	cd bf       	out	0x3d, r28	; 61
     9e0:	dd 91       	ld	r29, X+
     9e2:	de bf       	out	0x3e, r29	; 62
     9e4:	ff 91       	pop	r31
     9e6:	ef 91       	pop	r30
     9e8:	df 91       	pop	r29
     9ea:	cf 91       	pop	r28
     9ec:	bf 91       	pop	r27
     9ee:	af 91       	pop	r26
     9f0:	9f 91       	pop	r25
     9f2:	8f 91       	pop	r24
     9f4:	7f 91       	pop	r23
     9f6:	6f 91       	pop	r22
     9f8:	5f 91       	pop	r21
     9fa:	4f 91       	pop	r20
     9fc:	3f 91       	pop	r19
     9fe:	2f 91       	pop	r18
     a00:	1f 91       	pop	r17
     a02:	0f 91       	pop	r16
     a04:	ff 90       	pop	r15
     a06:	ef 90       	pop	r14
     a08:	df 90       	pop	r13
     a0a:	cf 90       	pop	r12
     a0c:	bf 90       	pop	r11
     a0e:	af 90       	pop	r10
     a10:	9f 90       	pop	r9
     a12:	8f 90       	pop	r8
     a14:	7f 90       	pop	r7
     a16:	6f 90       	pop	r6
     a18:	5f 90       	pop	r5
     a1a:	4f 90       	pop	r4
     a1c:	3f 90       	pop	r3
     a1e:	2f 90       	pop	r2
     a20:	1f 90       	pop	r1
     a22:	0f 90       	pop	r0
     a24:	0f be       	out	0x3f, r0	; 63
     a26:	0f 90       	pop	r0

	asm volatile ( "ret" );
     a28:	08 95       	ret

00000a2a <vPortYieldFromTick>:
 * call comes from the tick ISR.
 */
void vPortYieldFromTick( void ) __attribute__ ( ( naked ) );
void vPortYieldFromTick( void )
{
	portSAVE_CONTEXT();
     a2a:	0f 92       	push	r0
     a2c:	0f b6       	in	r0, 0x3f	; 63
     a2e:	f8 94       	cli
     a30:	0f 92       	push	r0
     a32:	1f 92       	push	r1
     a34:	11 24       	eor	r1, r1
     a36:	2f 92       	push	r2
     a38:	3f 92       	push	r3
     a3a:	4f 92       	push	r4
     a3c:	5f 92       	push	r5
     a3e:	6f 92       	push	r6
     a40:	7f 92       	push	r7
     a42:	8f 92       	push	r8
     a44:	9f 92       	push	r9
     a46:	af 92       	push	r10
     a48:	bf 92       	push	r11
     a4a:	cf 92       	push	r12
     a4c:	df 92       	push	r13
     a4e:	ef 92       	push	r14
     a50:	ff 92       	push	r15
     a52:	0f 93       	push	r16
     a54:	1f 93       	push	r17
     a56:	2f 93       	push	r18
     a58:	3f 93       	push	r19
     a5a:	4f 93       	push	r20
     a5c:	5f 93       	push	r21
     a5e:	6f 93       	push	r22
     a60:	7f 93       	push	r23
     a62:	8f 93       	push	r24
     a64:	9f 93       	push	r25
     a66:	af 93       	push	r26
     a68:	bf 93       	push	r27
     a6a:	cf 93       	push	r28
     a6c:	df 93       	push	r29
     a6e:	ef 93       	push	r30
     a70:	ff 93       	push	r31
     a72:	a0 91 9d 03 	lds	r26, 0x039D
     a76:	b0 91 9e 03 	lds	r27, 0x039E
     a7a:	0d b6       	in	r0, 0x3d	; 61
     a7c:	0d 92       	st	X+, r0
     a7e:	0e b6       	in	r0, 0x3e	; 62
     a80:	0d 92       	st	X+, r0
	if( xTaskIncrementTick() != pdFALSE )
     a82:	0e 94 b7 0d 	call	0x1b6e	; 0x1b6e <xTaskIncrementTick>
     a86:	88 23       	and	r24, r24
     a88:	11 f0       	breq	.+4      	; 0xa8e <vPortYieldFromTick+0x64>
	{
		vTaskSwitchContext();
     a8a:	0e 94 67 0f 	call	0x1ece	; 0x1ece <vTaskSwitchContext>
	}
	portRESTORE_CONTEXT();
     a8e:	a0 91 9d 03 	lds	r26, 0x039D
     a92:	b0 91 9e 03 	lds	r27, 0x039E
     a96:	cd 91       	ld	r28, X+
     a98:	cd bf       	out	0x3d, r28	; 61
     a9a:	dd 91       	ld	r29, X+
     a9c:	de bf       	out	0x3e, r29	; 62
     a9e:	ff 91       	pop	r31
     aa0:	ef 91       	pop	r30
     aa2:	df 91       	pop	r29
     aa4:	cf 91       	pop	r28
     aa6:	bf 91       	pop	r27
     aa8:	af 91       	pop	r26
     aaa:	9f 91       	pop	r25
     aac:	8f 91       	pop	r24
     aae:	7f 91       	pop	r23
     ab0:	6f 91       	pop	r22
     ab2:	5f 91       	pop	r21
     ab4:	4f 91       	pop	r20
     ab6:	3f 91       	pop	r19
     ab8:	2f 91       	pop	r18
     aba:	1f 91       	pop	r17
     abc:	0f 91       	pop	r16
     abe:	ff 90       	pop	r15
     ac0:	ef 90       	pop	r14
     ac2:	df 90       	pop	r13
     ac4:	cf 90       	pop	r12
     ac6:	bf 90       	pop	r11
     ac8:	af 90       	pop	r10
     aca:	9f 90       	pop	r9
     acc:	8f 90       	pop	r8
     ace:	7f 90       	pop	r7
     ad0:	6f 90       	pop	r6
     ad2:	5f 90       	pop	r5
     ad4:	4f 90       	pop	r4
     ad6:	3f 90       	pop	r3
     ad8:	2f 90       	pop	r2
     ada:	1f 90       	pop	r1
     adc:	0f 90       	pop	r0
     ade:	0f be       	out	0x3f, r0	; 63
     ae0:	0f 90       	pop	r0

	asm volatile ( "ret" );
     ae2:	08 95       	ret

00000ae4 <__vector_7>:
	 * count is incremented after the context is saved.
	 */
	void TIMER1_COMPA_vect( void ) __attribute__ ( ( signal, naked ) );
	void TIMER1_COMPA_vect( void )
	{
		vPortYieldFromTick();
     ae4:	0e 94 15 05 	call	0xa2a	; 0xa2a <vPortYieldFromTick>
		asm volatile ( "reti" );
     ae8:	18 95       	reti

00000aea <prvIsQueueEmpty>:

static BaseType_t prvIsQueueEmpty( const Queue_t *pxQueue )
{
BaseType_t xReturn;

	taskENTER_CRITICAL();
     aea:	0f b6       	in	r0, 0x3f	; 63
     aec:	f8 94       	cli
     aee:	0f 92       	push	r0
	{
		if( pxQueue->uxMessagesWaiting == ( UBaseType_t )  0 )
     af0:	fc 01       	movw	r30, r24
     af2:	92 8d       	ldd	r25, Z+26	; 0x1a
		else
		{
			xReturn = pdFALSE;
		}
	}
	taskEXIT_CRITICAL();
     af4:	0f 90       	pop	r0
     af6:	0f be       	out	0x3f, r0	; 63

	taskENTER_CRITICAL();
	{
		if( pxQueue->uxMessagesWaiting == ( UBaseType_t )  0 )
		{
			xReturn = pdTRUE;
     af8:	81 e0       	ldi	r24, 0x01	; 1
     afa:	91 11       	cpse	r25, r1
     afc:	80 e0       	ldi	r24, 0x00	; 0
		}
	}
	taskEXIT_CRITICAL();

	return xReturn;
}
     afe:	08 95       	ret

00000b00 <prvCopyDataFromQueue>:
	return xReturn;
}
/*-----------------------------------------------------------*/

static void prvCopyDataFromQueue( Queue_t * const pxQueue, void * const pvBuffer )
{
     b00:	fc 01       	movw	r30, r24
	if( pxQueue->uxItemSize != ( UBaseType_t ) 0 )
     b02:	44 8d       	ldd	r20, Z+28	; 0x1c
     b04:	44 23       	and	r20, r20
     b06:	c1 f0       	breq	.+48     	; 0xb38 <prvCopyDataFromQueue+0x38>
	{
		pxQueue->u.pcReadFrom += pxQueue->uxItemSize;
     b08:	26 81       	ldd	r18, Z+6	; 0x06
     b0a:	37 81       	ldd	r19, Z+7	; 0x07
     b0c:	24 0f       	add	r18, r20
     b0e:	31 1d       	adc	r19, r1
     b10:	37 83       	std	Z+7, r19	; 0x07
     b12:	26 83       	std	Z+6, r18	; 0x06
		if( pxQueue->u.pcReadFrom >= pxQueue->pcTail ) /*lint !e946 MISRA exception justified as use of the relational operator is the cleanest solutions. */
     b14:	a2 81       	ldd	r26, Z+2	; 0x02
     b16:	b3 81       	ldd	r27, Z+3	; 0x03
     b18:	2a 17       	cp	r18, r26
     b1a:	3b 07       	cpc	r19, r27
     b1c:	20 f0       	brcs	.+8      	; 0xb26 <prvCopyDataFromQueue+0x26>
		{
			pxQueue->u.pcReadFrom = pxQueue->pcHead;
     b1e:	20 81       	ld	r18, Z
     b20:	31 81       	ldd	r19, Z+1	; 0x01
     b22:	37 83       	std	Z+7, r19	; 0x07
     b24:	26 83       	std	Z+6, r18	; 0x06
		}
		else
		{
			mtCOVERAGE_TEST_MARKER();
		}
		( void ) memcpy( ( void * ) pvBuffer, ( void * ) pxQueue->u.pcReadFrom, ( size_t ) pxQueue->uxItemSize ); /*lint !e961 !e418 MISRA exception as the casts are only redundant for some ports.  Also previous logic ensures a null pointer can only be passed to memcpy() when the count is 0. */
     b26:	36 81       	ldd	r19, Z+6	; 0x06
     b28:	27 81       	ldd	r18, Z+7	; 0x07
     b2a:	86 2f       	mov	r24, r22
     b2c:	97 2f       	mov	r25, r23
     b2e:	63 2f       	mov	r22, r19
     b30:	72 2f       	mov	r23, r18
     b32:	50 e0       	ldi	r21, 0x00	; 0
     b34:	0e 94 29 14 	call	0x2852	; 0x2852 <memcpy>
     b38:	08 95       	ret

00000b3a <prvUnlockQueue>:
	}
}
/*-----------------------------------------------------------*/

static void prvUnlockQueue( Queue_t * const pxQueue )
{
     b3a:	ef 92       	push	r14
     b3c:	ff 92       	push	r15
     b3e:	0f 93       	push	r16
     b40:	1f 93       	push	r17
     b42:	cf 93       	push	r28
     b44:	8c 01       	movw	r16, r24

	/* The lock counts contains the number of extra data items placed or
	removed from the queue while the queue was locked.  When a queue is
	locked items can be added or removed, but the event lists cannot be
	updated. */
	taskENTER_CRITICAL();
     b46:	0f b6       	in	r0, 0x3f	; 63
     b48:	f8 94       	cli
     b4a:	0f 92       	push	r0
	{
		int8_t cTxLock = pxQueue->cTxLock;
     b4c:	fc 01       	movw	r30, r24
     b4e:	c6 8d       	ldd	r28, Z+30	; 0x1e

		/* See if data was added to the queue while it was locked. */
		while( cTxLock > queueLOCKED_UNMODIFIED )
     b50:	1c 16       	cp	r1, r28
     b52:	cc f4       	brge	.+50     	; 0xb86 <prvUnlockQueue+0x4c>
			}
			#else /* configUSE_QUEUE_SETS */
			{
				/* Tasks that are removed from the event list will get added to
				the pending ready list as the scheduler is still suspended. */
				if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
     b54:	81 89       	ldd	r24, Z+17	; 0x11
     b56:	88 23       	and	r24, r24
     b58:	31 f4       	brne	.+12     	; 0xb66 <prvUnlockQueue+0x2c>
     b5a:	15 c0       	rjmp	.+42     	; 0xb86 <prvUnlockQueue+0x4c>
     b5c:	f8 01       	movw	r30, r16
     b5e:	81 89       	ldd	r24, Z+17	; 0x11
     b60:	88 23       	and	r24, r24
     b62:	41 f4       	brne	.+16     	; 0xb74 <prvUnlockQueue+0x3a>
     b64:	10 c0       	rjmp	.+32     	; 0xb86 <prvUnlockQueue+0x4c>
				{
					if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )
     b66:	0f 2e       	mov	r0, r31
     b68:	f1 e1       	ldi	r31, 0x11	; 17
     b6a:	ef 2e       	mov	r14, r31
     b6c:	ff 24       	eor	r15, r15
     b6e:	f0 2d       	mov	r31, r0
     b70:	e0 0e       	add	r14, r16
     b72:	f1 1e       	adc	r15, r17
     b74:	c7 01       	movw	r24, r14
     b76:	0e 94 3d 10 	call	0x207a	; 0x207a <xTaskRemoveFromEventList>
     b7a:	88 23       	and	r24, r24
     b7c:	11 f0       	breq	.+4      	; 0xb82 <prvUnlockQueue+0x48>
					{
						/* The task waiting has a higher priority so record that
						a context switch is required. */
						vTaskMissedYield();
     b7e:	0e 94 02 11 	call	0x2204	; 0x2204 <vTaskMissedYield>
					break;
				}
			}
			#endif /* configUSE_QUEUE_SETS */

			--cTxLock;
     b82:	c1 50       	subi	r28, 0x01	; 1
	taskENTER_CRITICAL();
	{
		int8_t cTxLock = pxQueue->cTxLock;

		/* See if data was added to the queue while it was locked. */
		while( cTxLock > queueLOCKED_UNMODIFIED )
     b84:	59 f7       	brne	.-42     	; 0xb5c <prvUnlockQueue+0x22>
			#endif /* configUSE_QUEUE_SETS */

			--cTxLock;
		}

		pxQueue->cTxLock = queueUNLOCKED;
     b86:	8f ef       	ldi	r24, 0xFF	; 255
     b88:	f8 01       	movw	r30, r16
     b8a:	86 8f       	std	Z+30, r24	; 0x1e
	}
	taskEXIT_CRITICAL();
     b8c:	0f 90       	pop	r0
     b8e:	0f be       	out	0x3f, r0	; 63

	/* Do the same for the Rx lock. */
	taskENTER_CRITICAL();
     b90:	0f b6       	in	r0, 0x3f	; 63
     b92:	f8 94       	cli
     b94:	0f 92       	push	r0
	{
		int8_t cRxLock = pxQueue->cRxLock;
     b96:	f8 01       	movw	r30, r16
     b98:	c5 8d       	ldd	r28, Z+29	; 0x1d

		while( cRxLock > queueLOCKED_UNMODIFIED )
     b9a:	1c 16       	cp	r1, r28
     b9c:	c4 f4       	brge	.+48     	; 0xbce <prvUnlockQueue+0x94>
		{
			if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToSend ) ) == pdFALSE )
     b9e:	80 85       	ldd	r24, Z+8	; 0x08
     ba0:	88 23       	and	r24, r24
     ba2:	31 f4       	brne	.+12     	; 0xbb0 <prvUnlockQueue+0x76>
     ba4:	14 c0       	rjmp	.+40     	; 0xbce <prvUnlockQueue+0x94>
     ba6:	f8 01       	movw	r30, r16
     ba8:	80 85       	ldd	r24, Z+8	; 0x08
     baa:	88 23       	and	r24, r24
     bac:	39 f4       	brne	.+14     	; 0xbbc <prvUnlockQueue+0x82>
     bae:	0f c0       	rjmp	.+30     	; 0xbce <prvUnlockQueue+0x94>
			{
				if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) != pdFALSE )
     bb0:	ee 24       	eor	r14, r14
     bb2:	ff 24       	eor	r15, r15
     bb4:	68 94       	set
     bb6:	e3 f8       	bld	r14, 3
     bb8:	e0 0e       	add	r14, r16
     bba:	f1 1e       	adc	r15, r17
     bbc:	c7 01       	movw	r24, r14
     bbe:	0e 94 3d 10 	call	0x207a	; 0x207a <xTaskRemoveFromEventList>
     bc2:	88 23       	and	r24, r24
     bc4:	11 f0       	breq	.+4      	; 0xbca <prvUnlockQueue+0x90>
				{
					vTaskMissedYield();
     bc6:	0e 94 02 11 	call	0x2204	; 0x2204 <vTaskMissedYield>
				else
				{
					mtCOVERAGE_TEST_MARKER();
				}

				--cRxLock;
     bca:	c1 50       	subi	r28, 0x01	; 1
	/* Do the same for the Rx lock. */
	taskENTER_CRITICAL();
	{
		int8_t cRxLock = pxQueue->cRxLock;

		while( cRxLock > queueLOCKED_UNMODIFIED )
     bcc:	61 f7       	brne	.-40     	; 0xba6 <prvUnlockQueue+0x6c>
			{
				break;
			}
		}

		pxQueue->cRxLock = queueUNLOCKED;
     bce:	8f ef       	ldi	r24, 0xFF	; 255
     bd0:	f8 01       	movw	r30, r16
     bd2:	85 8f       	std	Z+29, r24	; 0x1d
	}
	taskEXIT_CRITICAL();
     bd4:	0f 90       	pop	r0
     bd6:	0f be       	out	0x3f, r0	; 63
}
     bd8:	cf 91       	pop	r28
     bda:	1f 91       	pop	r17
     bdc:	0f 91       	pop	r16
     bde:	ff 90       	pop	r15
     be0:	ef 90       	pop	r14
     be2:	08 95       	ret

00000be4 <prvCopyDataToQueue>:

#endif /* configUSE_TRACE_FACILITY */
/*-----------------------------------------------------------*/

static BaseType_t prvCopyDataToQueue( Queue_t * const pxQueue, const void *pvItemToQueue, const BaseType_t xPosition )
{
     be4:	0f 93       	push	r16
     be6:	1f 93       	push	r17
     be8:	cf 93       	push	r28
     bea:	df 93       	push	r29
     bec:	ec 01       	movw	r28, r24
     bee:	14 2f       	mov	r17, r20
BaseType_t xReturn = pdFALSE;
UBaseType_t uxMessagesWaiting;

	/* This function is called from a critical section. */

	uxMessagesWaiting = pxQueue->uxMessagesWaiting;
     bf0:	0a 8d       	ldd	r16, Y+26	; 0x1a

	if( pxQueue->uxItemSize == ( UBaseType_t ) 0 )
     bf2:	4c 8d       	ldd	r20, Y+28	; 0x1c
     bf4:	44 23       	and	r20, r20
     bf6:	61 f4       	brne	.+24     	; 0xc10 <prvCopyDataToQueue+0x2c>
	{
		#if ( configUSE_MUTEXES == 1 )
		{
			if( pxQueue->uxQueueType == queueQUEUE_IS_MUTEX )
     bf8:	88 81       	ld	r24, Y
     bfa:	99 81       	ldd	r25, Y+1	; 0x01
     bfc:	00 97       	sbiw	r24, 0x00	; 0
     bfe:	09 f0       	breq	.+2      	; 0xc02 <prvCopyDataToQueue+0x1e>
     c00:	42 c0       	rjmp	.+132    	; 0xc86 <prvCopyDataToQueue+0xa2>
			{
				/* The mutex is no longer being held. */
				xReturn = xTaskPriorityDisinherit( ( void * ) pxQueue->pxMutexHolder );
     c02:	8a 81       	ldd	r24, Y+2	; 0x02
     c04:	9b 81       	ldd	r25, Y+3	; 0x03
     c06:	0e 94 69 11 	call	0x22d2	; 0x22d2 <xTaskPriorityDisinherit>
				pxQueue->pxMutexHolder = NULL;
     c0a:	1b 82       	std	Y+3, r1	; 0x03
     c0c:	1a 82       	std	Y+2, r1	; 0x02
     c0e:	42 c0       	rjmp	.+132    	; 0xc94 <prvCopyDataToQueue+0xb0>
				mtCOVERAGE_TEST_MARKER();
			}
		}
		#endif /* configUSE_MUTEXES */
	}
	else if( xPosition == queueSEND_TO_BACK )
     c10:	11 23       	and	r17, r17
     c12:	b9 f4       	brne	.+46     	; 0xc42 <prvCopyDataToQueue+0x5e>
	{
		( void ) memcpy( ( void * ) pxQueue->pcWriteTo, pvItemToQueue, ( size_t ) pxQueue->uxItemSize ); /*lint !e961 !e418 MISRA exception as the casts are only redundant for some ports, plus previous logic ensures a null pointer can only be passed to memcpy() if the copy size is 0. */
     c14:	8c 81       	ldd	r24, Y+4	; 0x04
     c16:	9d 81       	ldd	r25, Y+5	; 0x05
     c18:	50 e0       	ldi	r21, 0x00	; 0
     c1a:	0e 94 29 14 	call	0x2852	; 0x2852 <memcpy>
		pxQueue->pcWriteTo += pxQueue->uxItemSize;
     c1e:	2c 8d       	ldd	r18, Y+28	; 0x1c
     c20:	8c 81       	ldd	r24, Y+4	; 0x04
     c22:	9d 81       	ldd	r25, Y+5	; 0x05
     c24:	82 0f       	add	r24, r18
     c26:	91 1d       	adc	r25, r1
     c28:	9d 83       	std	Y+5, r25	; 0x05
     c2a:	8c 83       	std	Y+4, r24	; 0x04
		if( pxQueue->pcWriteTo >= pxQueue->pcTail ) /*lint !e946 MISRA exception justified as comparison of pointers is the cleanest solution. */
     c2c:	2a 81       	ldd	r18, Y+2	; 0x02
     c2e:	3b 81       	ldd	r19, Y+3	; 0x03
     c30:	82 17       	cp	r24, r18
     c32:	93 07       	cpc	r25, r19
     c34:	50 f1       	brcs	.+84     	; 0xc8a <prvCopyDataToQueue+0xa6>
		{
			pxQueue->pcWriteTo = pxQueue->pcHead;
     c36:	88 81       	ld	r24, Y
     c38:	99 81       	ldd	r25, Y+1	; 0x01
     c3a:	9d 83       	std	Y+5, r25	; 0x05
     c3c:	8c 83       	std	Y+4, r24	; 0x04
#endif /* configUSE_TRACE_FACILITY */
/*-----------------------------------------------------------*/

static BaseType_t prvCopyDataToQueue( Queue_t * const pxQueue, const void *pvItemToQueue, const BaseType_t xPosition )
{
BaseType_t xReturn = pdFALSE;
     c3e:	80 e0       	ldi	r24, 0x00	; 0
     c40:	29 c0       	rjmp	.+82     	; 0xc94 <prvCopyDataToQueue+0xb0>
			mtCOVERAGE_TEST_MARKER();
		}
	}
	else
	{
		( void ) memcpy( ( void * ) pxQueue->u.pcReadFrom, pvItemToQueue, ( size_t ) pxQueue->uxItemSize ); /*lint !e961 MISRA exception as the casts are only redundant for some ports. */
     c42:	8e 81       	ldd	r24, Y+6	; 0x06
     c44:	9f 81       	ldd	r25, Y+7	; 0x07
     c46:	50 e0       	ldi	r21, 0x00	; 0
     c48:	0e 94 29 14 	call	0x2852	; 0x2852 <memcpy>
		pxQueue->u.pcReadFrom -= pxQueue->uxItemSize;
     c4c:	4c 8d       	ldd	r20, Y+28	; 0x1c
     c4e:	50 e0       	ldi	r21, 0x00	; 0
     c50:	50 95       	com	r21
     c52:	41 95       	neg	r20
     c54:	5f 4f       	sbci	r21, 0xFF	; 255
     c56:	8e 81       	ldd	r24, Y+6	; 0x06
     c58:	9f 81       	ldd	r25, Y+7	; 0x07
     c5a:	84 0f       	add	r24, r20
     c5c:	95 1f       	adc	r25, r21
     c5e:	9f 83       	std	Y+7, r25	; 0x07
     c60:	8e 83       	std	Y+6, r24	; 0x06
		if( pxQueue->u.pcReadFrom < pxQueue->pcHead ) /*lint !e946 MISRA exception justified as comparison of pointers is the cleanest solution. */
     c62:	28 81       	ld	r18, Y
     c64:	39 81       	ldd	r19, Y+1	; 0x01
     c66:	82 17       	cp	r24, r18
     c68:	93 07       	cpc	r25, r19
     c6a:	30 f4       	brcc	.+12     	; 0xc78 <prvCopyDataToQueue+0x94>
		{
			pxQueue->u.pcReadFrom = ( pxQueue->pcTail - pxQueue->uxItemSize );
     c6c:	8a 81       	ldd	r24, Y+2	; 0x02
     c6e:	9b 81       	ldd	r25, Y+3	; 0x03
     c70:	84 0f       	add	r24, r20
     c72:	95 1f       	adc	r25, r21
     c74:	9f 83       	std	Y+7, r25	; 0x07
     c76:	8e 83       	std	Y+6, r24	; 0x06
		else
		{
			mtCOVERAGE_TEST_MARKER();
		}

		if( xPosition == queueOVERWRITE )
     c78:	12 30       	cpi	r17, 0x02	; 2
     c7a:	49 f4       	brne	.+18     	; 0xc8e <prvCopyDataToQueue+0xaa>
		{
			if( uxMessagesWaiting > ( UBaseType_t ) 0 )
     c7c:	00 23       	and	r16, r16
     c7e:	49 f0       	breq	.+18     	; 0xc92 <prvCopyDataToQueue+0xae>
			{
				/* An item is not being added but overwritten, so subtract
				one from the recorded number of items in the queue so when
				one is added again below the number of recorded items remains
				correct. */
				--uxMessagesWaiting;
     c80:	01 50       	subi	r16, 0x01	; 1
#endif /* configUSE_TRACE_FACILITY */
/*-----------------------------------------------------------*/

static BaseType_t prvCopyDataToQueue( Queue_t * const pxQueue, const void *pvItemToQueue, const BaseType_t xPosition )
{
BaseType_t xReturn = pdFALSE;
     c82:	80 e0       	ldi	r24, 0x00	; 0
     c84:	07 c0       	rjmp	.+14     	; 0xc94 <prvCopyDataToQueue+0xb0>
     c86:	80 e0       	ldi	r24, 0x00	; 0
     c88:	05 c0       	rjmp	.+10     	; 0xc94 <prvCopyDataToQueue+0xb0>
     c8a:	80 e0       	ldi	r24, 0x00	; 0
     c8c:	03 c0       	rjmp	.+6      	; 0xc94 <prvCopyDataToQueue+0xb0>
     c8e:	80 e0       	ldi	r24, 0x00	; 0
     c90:	01 c0       	rjmp	.+2      	; 0xc94 <prvCopyDataToQueue+0xb0>
     c92:	80 e0       	ldi	r24, 0x00	; 0
		{
			mtCOVERAGE_TEST_MARKER();
		}
	}

	pxQueue->uxMessagesWaiting = uxMessagesWaiting + 1;
     c94:	0f 5f       	subi	r16, 0xFF	; 255
     c96:	0a 8f       	std	Y+26, r16	; 0x1a

	return xReturn;
}
     c98:	df 91       	pop	r29
     c9a:	cf 91       	pop	r28
     c9c:	1f 91       	pop	r17
     c9e:	0f 91       	pop	r16
     ca0:	08 95       	ret

00000ca2 <xQueueGenericReset>:
	}														\
	taskEXIT_CRITICAL()
/*-----------------------------------------------------------*/

BaseType_t xQueueGenericReset( QueueHandle_t xQueue, BaseType_t xNewQueue )
{
     ca2:	cf 93       	push	r28
     ca4:	df 93       	push	r29
     ca6:	ec 01       	movw	r28, r24
Queue_t * const pxQueue = ( Queue_t * ) xQueue;

	configASSERT( pxQueue );

	taskENTER_CRITICAL();
     ca8:	0f b6       	in	r0, 0x3f	; 63
     caa:	f8 94       	cli
     cac:	0f 92       	push	r0
	{
		pxQueue->pcTail = pxQueue->pcHead + ( pxQueue->uxLength * pxQueue->uxItemSize );
     cae:	48 81       	ld	r20, Y
     cb0:	59 81       	ldd	r21, Y+1	; 0x01
     cb2:	2b 8d       	ldd	r18, Y+27	; 0x1b
     cb4:	30 e0       	ldi	r19, 0x00	; 0
     cb6:	ec 8d       	ldd	r30, Y+28	; 0x1c
     cb8:	f0 e0       	ldi	r31, 0x00	; 0
     cba:	2e 9f       	mul	r18, r30
     cbc:	c0 01       	movw	r24, r0
     cbe:	2f 9f       	mul	r18, r31
     cc0:	90 0d       	add	r25, r0
     cc2:	3e 9f       	mul	r19, r30
     cc4:	90 0d       	add	r25, r0
     cc6:	11 24       	eor	r1, r1
     cc8:	84 0f       	add	r24, r20
     cca:	95 1f       	adc	r25, r21
     ccc:	9b 83       	std	Y+3, r25	; 0x03
     cce:	8a 83       	std	Y+2, r24	; 0x02
		pxQueue->uxMessagesWaiting = ( UBaseType_t ) 0U;
     cd0:	1a 8e       	std	Y+26, r1	; 0x1a
		pxQueue->pcWriteTo = pxQueue->pcHead;
     cd2:	5d 83       	std	Y+5, r21	; 0x05
     cd4:	4c 83       	std	Y+4, r20	; 0x04
		pxQueue->u.pcReadFrom = pxQueue->pcHead + ( ( pxQueue->uxLength - ( UBaseType_t ) 1U ) * pxQueue->uxItemSize );
     cd6:	c9 01       	movw	r24, r18
     cd8:	01 97       	sbiw	r24, 0x01	; 1
     cda:	e8 9f       	mul	r30, r24
     cdc:	90 01       	movw	r18, r0
     cde:	e9 9f       	mul	r30, r25
     ce0:	30 0d       	add	r19, r0
     ce2:	f8 9f       	mul	r31, r24
     ce4:	30 0d       	add	r19, r0
     ce6:	11 24       	eor	r1, r1
     ce8:	24 0f       	add	r18, r20
     cea:	35 1f       	adc	r19, r21
     cec:	3f 83       	std	Y+7, r19	; 0x07
     cee:	2e 83       	std	Y+6, r18	; 0x06
		pxQueue->cRxLock = queueUNLOCKED;
     cf0:	8f ef       	ldi	r24, 0xFF	; 255
     cf2:	8d 8f       	std	Y+29, r24	; 0x1d
		pxQueue->cTxLock = queueUNLOCKED;
     cf4:	8e 8f       	std	Y+30, r24	; 0x1e

		if( xNewQueue == pdFALSE )
     cf6:	66 23       	and	r22, r22
     cf8:	61 f4       	brne	.+24     	; 0xd12 <xQueueGenericReset+0x70>
			/* If there are tasks blocked waiting to read from the queue, then
			the tasks will remain blocked as after this function exits the queue
			will still be empty.  If there are tasks blocked waiting to write to
			the queue, then one should be unblocked as after this function exits
			it will be possible to write to it. */
			if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToSend ) ) == pdFALSE )
     cfa:	88 85       	ldd	r24, Y+8	; 0x08
     cfc:	88 23       	and	r24, r24
     cfe:	89 f0       	breq	.+34     	; 0xd22 <xQueueGenericReset+0x80>
			{
				if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) != pdFALSE )
     d00:	ce 01       	movw	r24, r28
     d02:	08 96       	adiw	r24, 0x08	; 8
     d04:	0e 94 3d 10 	call	0x207a	; 0x207a <xTaskRemoveFromEventList>
     d08:	88 23       	and	r24, r24
     d0a:	59 f0       	breq	.+22     	; 0xd22 <xQueueGenericReset+0x80>
				{
					queueYIELD_IF_USING_PREEMPTION();
     d0c:	0e 94 bc 04 	call	0x978	; 0x978 <vPortYield>
     d10:	08 c0       	rjmp	.+16     	; 0xd22 <xQueueGenericReset+0x80>
			}
		}
		else
		{
			/* Ensure the event queues start in the correct state. */
			vListInitialise( &( pxQueue->xTasksWaitingToSend ) );
     d12:	ce 01       	movw	r24, r28
     d14:	08 96       	adiw	r24, 0x08	; 8
     d16:	0e 94 6b 03 	call	0x6d6	; 0x6d6 <vListInitialise>
			vListInitialise( &( pxQueue->xTasksWaitingToReceive ) );
     d1a:	ce 01       	movw	r24, r28
     d1c:	41 96       	adiw	r24, 0x11	; 17
     d1e:	0e 94 6b 03 	call	0x6d6	; 0x6d6 <vListInitialise>
		}
	}
	taskEXIT_CRITICAL();
     d22:	0f 90       	pop	r0
     d24:	0f be       	out	0x3f, r0	; 63

	/* A value is returned for calling semantic consistency with previous
	versions. */
	return pdPASS;
}
     d26:	81 e0       	ldi	r24, 0x01	; 1
     d28:	df 91       	pop	r29
     d2a:	cf 91       	pop	r28
     d2c:	08 95       	ret

00000d2e <xQueueGenericCreate>:
/*-----------------------------------------------------------*/

#if( configSUPPORT_DYNAMIC_ALLOCATION == 1 )

	QueueHandle_t xQueueGenericCreate( const UBaseType_t uxQueueLength, const UBaseType_t uxItemSize, const uint8_t ucQueueType )
	{
     d2e:	0f 93       	push	r16
     d30:	1f 93       	push	r17
     d32:	cf 93       	push	r28
     d34:	df 93       	push	r29
     d36:	08 2f       	mov	r16, r24
     d38:	16 2f       	mov	r17, r22
	size_t xQueueSizeInBytes;
	uint8_t *pucQueueStorage;

		configASSERT( uxQueueLength > ( UBaseType_t ) 0 );

		if( uxItemSize == ( UBaseType_t ) 0 )
     d3a:	66 23       	and	r22, r22
     d3c:	21 f0       	breq	.+8      	; 0xd46 <xQueueGenericCreate+0x18>
		}
		else
		{
			/* Allocate enough space to hold the maximum number of items that
			can be in the queue at any time. */
			xQueueSizeInBytes = ( size_t ) ( uxQueueLength * uxItemSize ); /*lint !e961 MISRA exception as the casts are only redundant for some ports. */
     d3e:	68 9f       	mul	r22, r24
     d40:	c0 01       	movw	r24, r0
     d42:	11 24       	eor	r1, r1
     d44:	02 c0       	rjmp	.+4      	; 0xd4a <xQueueGenericCreate+0x1c>
		configASSERT( uxQueueLength > ( UBaseType_t ) 0 );

		if( uxItemSize == ( UBaseType_t ) 0 )
		{
			/* There is not going to be a queue storage area. */
			xQueueSizeInBytes = ( size_t ) 0;
     d46:	80 e0       	ldi	r24, 0x00	; 0
     d48:	90 e0       	ldi	r25, 0x00	; 0
			/* Allocate enough space to hold the maximum number of items that
			can be in the queue at any time. */
			xQueueSizeInBytes = ( size_t ) ( uxQueueLength * uxItemSize ); /*lint !e961 MISRA exception as the casts are only redundant for some ports. */
		}

		pxNewQueue = ( Queue_t * ) pvPortMalloc( sizeof( Queue_t ) + xQueueSizeInBytes );
     d4a:	4f 96       	adiw	r24, 0x1f	; 31
     d4c:	0e 94 92 02 	call	0x524	; 0x524 <pvPortMalloc>
     d50:	ec 01       	movw	r28, r24

		if( pxNewQueue != NULL )
     d52:	00 97       	sbiw	r24, 0x00	; 0
     d54:	71 f0       	breq	.+28     	; 0xd72 <xQueueGenericCreate+0x44>
{
	/* Remove compiler warnings about unused parameters should
	configUSE_TRACE_FACILITY not be set to 1. */
	( void ) ucQueueType;

	if( uxItemSize == ( UBaseType_t ) 0 )
     d56:	11 23       	and	r17, r17
     d58:	19 f4       	brne	.+6      	; 0xd60 <xQueueGenericCreate+0x32>
	{
		/* No RAM was allocated for the queue storage area, but PC head cannot
		be set to NULL because NULL is used as a key to say the queue is used as
		a mutex.  Therefore just set pcHead to point to the queue as a benign
		value that is known to be within the memory map. */
		pxNewQueue->pcHead = ( int8_t * ) pxNewQueue;
     d5a:	99 83       	std	Y+1, r25	; 0x01
     d5c:	88 83       	st	Y, r24
     d5e:	03 c0       	rjmp	.+6      	; 0xd66 <xQueueGenericCreate+0x38>

		if( pxNewQueue != NULL )
		{
			/* Jump past the queue structure to find the location of the queue
			storage area. */
			pucQueueStorage = ( ( uint8_t * ) pxNewQueue ) + sizeof( Queue_t );
     d60:	4f 96       	adiw	r24, 0x1f	; 31
		pxNewQueue->pcHead = ( int8_t * ) pxNewQueue;
	}
	else
	{
		/* Set the head to the start of the queue storage area. */
		pxNewQueue->pcHead = ( int8_t * ) pucQueueStorage;
     d62:	99 83       	std	Y+1, r25	; 0x01
     d64:	88 83       	st	Y, r24
	}

	/* Initialise the queue members as described where the queue type is
	defined. */
	pxNewQueue->uxLength = uxQueueLength;
     d66:	0b 8f       	std	Y+27, r16	; 0x1b
	pxNewQueue->uxItemSize = uxItemSize;
     d68:	1c 8f       	std	Y+28, r17	; 0x1c
	( void ) xQueueGenericReset( pxNewQueue, pdTRUE );
     d6a:	ce 01       	movw	r24, r28
     d6c:	61 e0       	ldi	r22, 0x01	; 1
     d6e:	0e 94 51 06 	call	0xca2	; 0xca2 <xQueueGenericReset>

			prvInitialiseNewQueue( uxQueueLength, uxItemSize, pucQueueStorage, ucQueueType, pxNewQueue );
		}

		return pxNewQueue;
	}
     d72:	8c 2f       	mov	r24, r28
     d74:	9d 2f       	mov	r25, r29
     d76:	df 91       	pop	r29
     d78:	cf 91       	pop	r28
     d7a:	1f 91       	pop	r17
     d7c:	0f 91       	pop	r16
     d7e:	08 95       	ret

00000d80 <xQueueGenericSend>:

#endif /* ( ( configUSE_COUNTING_SEMAPHORES == 1 ) && ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) ) */
/*-----------------------------------------------------------*/

BaseType_t xQueueGenericSend( QueueHandle_t xQueue, const void * const pvItemToQueue, TickType_t xTicksToWait, const BaseType_t xCopyPosition )
{
     d80:	8f 92       	push	r8
     d82:	9f 92       	push	r9
     d84:	bf 92       	push	r11
     d86:	cf 92       	push	r12
     d88:	df 92       	push	r13
     d8a:	ef 92       	push	r14
     d8c:	ff 92       	push	r15
     d8e:	0f 93       	push	r16
     d90:	1f 93       	push	r17
     d92:	cf 93       	push	r28
     d94:	df 93       	push	r29
     d96:	00 d0       	rcall	.+0      	; 0xd98 <xQueueGenericSend+0x18>
     d98:	00 d0       	rcall	.+0      	; 0xd9a <xQueueGenericSend+0x1a>
     d9a:	0f 92       	push	r0
     d9c:	cd b7       	in	r28, 0x3d	; 61
     d9e:	de b7       	in	r29, 0x3e	; 62
     da0:	8c 01       	movw	r16, r24
     da2:	4b 01       	movw	r8, r22
     da4:	5d 83       	std	Y+5, r21	; 0x05
     da6:	4c 83       	std	Y+4, r20	; 0x04
     da8:	e2 2e       	mov	r14, r18
BaseType_t xEntryTimeSet = pdFALSE, xYieldRequired;
     daa:	ff 24       	eor	r15, r15
				else if( xEntryTimeSet == pdFALSE )
				{
					/* The queue was full and a block time was specified so
					configure the timeout structure. */
					vTaskSetTimeOutState( &xTimeOut );
					xEntryTimeSet = pdTRUE;
     dac:	bb 24       	eor	r11, r11
     dae:	b3 94       	inc	r11
		if( xTaskCheckForTimeOut( &xTimeOut, &xTicksToWait ) == pdFALSE )
		{
			if( prvIsQueueFull( pxQueue ) != pdFALSE )
			{
				traceBLOCKING_ON_QUEUE_SEND( pxQueue );
				vTaskPlaceOnEventList( &( pxQueue->xTasksWaitingToSend ), xTicksToWait );
     db0:	cc 24       	eor	r12, r12
     db2:	dd 24       	eor	r13, r13
     db4:	68 94       	set
     db6:	c3 f8       	bld	r12, 3
     db8:	c8 0e       	add	r12, r24
     dba:	d9 1e       	adc	r13, r25
	/* This function relaxes the coding standard somewhat to allow return
	statements within the function itself.  This is done in the interest
	of execution time efficiency. */
	for( ;; )
	{
		taskENTER_CRITICAL();
     dbc:	0f b6       	in	r0, 0x3f	; 63
     dbe:	f8 94       	cli
     dc0:	0f 92       	push	r0
		{
			/* Is there room on the queue now?  The running task must be the
			highest priority task wanting to access the queue.  If the head item
			in the queue is to be overwritten then it does not matter if the
			queue is full. */
			if( ( pxQueue->uxMessagesWaiting < pxQueue->uxLength ) || ( xCopyPosition == queueOVERWRITE ) )
     dc2:	f8 01       	movw	r30, r16
     dc4:	92 8d       	ldd	r25, Z+26	; 0x1a
     dc6:	83 8d       	ldd	r24, Z+27	; 0x1b
     dc8:	98 17       	cp	r25, r24
     dca:	18 f0       	brcs	.+6      	; 0xdd2 <xQueueGenericSend+0x52>
     dcc:	f2 e0       	ldi	r31, 0x02	; 2
     dce:	ef 16       	cp	r14, r31
     dd0:	d1 f4       	brne	.+52     	; 0xe06 <xQueueGenericSend+0x86>
			{
				traceQUEUE_SEND( pxQueue );
				xYieldRequired = prvCopyDataToQueue( pxQueue, pvItemToQueue, xCopyPosition );
     dd2:	c8 01       	movw	r24, r16
     dd4:	b4 01       	movw	r22, r8
     dd6:	4e 2d       	mov	r20, r14
     dd8:	0e 94 f2 05 	call	0xbe4	; 0xbe4 <prvCopyDataToQueue>
				}
				#else /* configUSE_QUEUE_SETS */
				{
					/* If there was a task waiting for data to arrive on the
					queue then unblock it now. */
					if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
     ddc:	f8 01       	movw	r30, r16
     dde:	91 89       	ldd	r25, Z+17	; 0x11
     de0:	99 23       	and	r25, r25
     de2:	49 f0       	breq	.+18     	; 0xdf6 <xQueueGenericSend+0x76>
					{
						if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )
     de4:	c8 01       	movw	r24, r16
     de6:	41 96       	adiw	r24, 0x11	; 17
     de8:	0e 94 3d 10 	call	0x207a	; 0x207a <xTaskRemoveFromEventList>
     dec:	88 23       	and	r24, r24
     dee:	39 f0       	breq	.+14     	; 0xdfe <xQueueGenericSend+0x7e>
						{
							/* The unblocked task has a priority higher than
							our own so yield immediately.  Yes it is ok to do
							this from within the critical section - the kernel
							takes care of that. */
							queueYIELD_IF_USING_PREEMPTION();
     df0:	0e 94 bc 04 	call	0x978	; 0x978 <vPortYield>
     df4:	04 c0       	rjmp	.+8      	; 0xdfe <xQueueGenericSend+0x7e>
						else
						{
							mtCOVERAGE_TEST_MARKER();
						}
					}
					else if( xYieldRequired != pdFALSE )
     df6:	88 23       	and	r24, r24
     df8:	11 f0       	breq	.+4      	; 0xdfe <xQueueGenericSend+0x7e>
					{
						/* This path is a special case that will only get
						executed if the task was holding multiple mutexes and
						the mutexes were given back in an order that is
						different to that in which they were taken. */
						queueYIELD_IF_USING_PREEMPTION();
     dfa:	0e 94 bc 04 	call	0x978	; 0x978 <vPortYield>
						mtCOVERAGE_TEST_MARKER();
					}
				}
				#endif /* configUSE_QUEUE_SETS */

				taskEXIT_CRITICAL();
     dfe:	0f 90       	pop	r0
     e00:	0f be       	out	0x3f, r0	; 63
				return pdPASS;
     e02:	81 e0       	ldi	r24, 0x01	; 1
     e04:	52 c0       	rjmp	.+164    	; 0xeaa <xQueueGenericSend+0x12a>
			}
			else
			{
				if( xTicksToWait == ( TickType_t ) 0 )
     e06:	8c 81       	ldd	r24, Y+4	; 0x04
     e08:	9d 81       	ldd	r25, Y+5	; 0x05
     e0a:	00 97       	sbiw	r24, 0x00	; 0
     e0c:	21 f4       	brne	.+8      	; 0xe16 <xQueueGenericSend+0x96>
				{
					/* The queue was full and no block time is specified (or
					the block time has expired) so leave now. */
					taskEXIT_CRITICAL();
     e0e:	0f 90       	pop	r0
     e10:	0f be       	out	0x3f, r0	; 63

					/* Return to the original privilege level before exiting
					the function. */
					traceQUEUE_SEND_FAILED( pxQueue );
					return errQUEUE_FULL;
     e12:	80 e0       	ldi	r24, 0x00	; 0
     e14:	4a c0       	rjmp	.+148    	; 0xeaa <xQueueGenericSend+0x12a>
				}
				else if( xEntryTimeSet == pdFALSE )
     e16:	ff 20       	and	r15, r15
     e18:	29 f4       	brne	.+10     	; 0xe24 <xQueueGenericSend+0xa4>
				{
					/* The queue was full and a block time was specified so
					configure the timeout structure. */
					vTaskSetTimeOutState( &xTimeOut );
     e1a:	ce 01       	movw	r24, r28
     e1c:	01 96       	adiw	r24, 0x01	; 1
     e1e:	0e 94 c2 10 	call	0x2184	; 0x2184 <vTaskSetTimeOutState>
					xEntryTimeSet = pdTRUE;
     e22:	fb 2c       	mov	r15, r11
					/* Entry time was already set. */
					mtCOVERAGE_TEST_MARKER();
				}
			}
		}
		taskEXIT_CRITICAL();
     e24:	0f 90       	pop	r0
     e26:	0f be       	out	0x3f, r0	; 63

		/* Interrupts and other tasks can send to and receive from the queue
		now the critical section has been exited. */

		vTaskSuspendAll();
     e28:	0e 94 97 0d 	call	0x1b2e	; 0x1b2e <vTaskSuspendAll>
		prvLockQueue( pxQueue );
     e2c:	0f b6       	in	r0, 0x3f	; 63
     e2e:	f8 94       	cli
     e30:	0f 92       	push	r0
     e32:	f8 01       	movw	r30, r16
     e34:	85 8d       	ldd	r24, Z+29	; 0x1d
     e36:	8f 3f       	cpi	r24, 0xFF	; 255
     e38:	09 f4       	brne	.+2      	; 0xe3c <xQueueGenericSend+0xbc>
     e3a:	15 8e       	std	Z+29, r1	; 0x1d
     e3c:	f8 01       	movw	r30, r16
     e3e:	86 8d       	ldd	r24, Z+30	; 0x1e
     e40:	8f 3f       	cpi	r24, 0xFF	; 255
     e42:	09 f4       	brne	.+2      	; 0xe46 <xQueueGenericSend+0xc6>
     e44:	16 8e       	std	Z+30, r1	; 0x1e
     e46:	0f 90       	pop	r0
     e48:	0f be       	out	0x3f, r0	; 63

		/* Update the timeout state to see if it has expired yet. */
		if( xTaskCheckForTimeOut( &xTimeOut, &xTicksToWait ) == pdFALSE )
     e4a:	ce 01       	movw	r24, r28
     e4c:	01 96       	adiw	r24, 0x01	; 1
     e4e:	be 01       	movw	r22, r28
     e50:	6c 5f       	subi	r22, 0xFC	; 252
     e52:	7f 4f       	sbci	r23, 0xFF	; 255
     e54:	0e 94 cd 10 	call	0x219a	; 0x219a <xTaskCheckForTimeOut>
     e58:	88 23       	and	r24, r24
     e5a:	09 f5       	brne	.+66     	; 0xe9e <xQueueGenericSend+0x11e>

static BaseType_t prvIsQueueFull( const Queue_t *pxQueue )
{
BaseType_t xReturn;

	taskENTER_CRITICAL();
     e5c:	0f b6       	in	r0, 0x3f	; 63
     e5e:	f8 94       	cli
     e60:	0f 92       	push	r0
	{
		if( pxQueue->uxMessagesWaiting == pxQueue->uxLength )
     e62:	f8 01       	movw	r30, r16
     e64:	92 8d       	ldd	r25, Z+26	; 0x1a
		else
		{
			xReturn = pdFALSE;
		}
	}
	taskEXIT_CRITICAL();
     e66:	0f 90       	pop	r0
     e68:	0f be       	out	0x3f, r0	; 63
		prvLockQueue( pxQueue );

		/* Update the timeout state to see if it has expired yet. */
		if( xTaskCheckForTimeOut( &xTimeOut, &xTicksToWait ) == pdFALSE )
		{
			if( prvIsQueueFull( pxQueue ) != pdFALSE )
     e6a:	f8 01       	movw	r30, r16
     e6c:	83 8d       	ldd	r24, Z+27	; 0x1b
     e6e:	98 17       	cp	r25, r24
     e70:	81 f4       	brne	.+32     	; 0xe92 <xQueueGenericSend+0x112>
			{
				traceBLOCKING_ON_QUEUE_SEND( pxQueue );
				vTaskPlaceOnEventList( &( pxQueue->xTasksWaitingToSend ), xTicksToWait );
     e72:	6c 81       	ldd	r22, Y+4	; 0x04
     e74:	7d 81       	ldd	r23, Y+5	; 0x05
     e76:	c6 01       	movw	r24, r12
     e78:	0e 94 12 10 	call	0x2024	; 0x2024 <vTaskPlaceOnEventList>
				/* Unlocking the queue means queue events can effect the
				event list.  It is possible	that interrupts occurring now
				remove this task from the event	list again - but as the
				scheduler is suspended the task will go onto the pending
				ready last instead of the actual ready list. */
				prvUnlockQueue( pxQueue );
     e7c:	c8 01       	movw	r24, r16
     e7e:	0e 94 9d 05 	call	0xb3a	; 0xb3a <prvUnlockQueue>
				/* Resuming the scheduler will move tasks from the pending
				ready list into the ready list - so it is feasible that this
				task is already in a ready list before it yields - in which
				case the yield will not cause a context switch unless there
				is also a higher priority task in the pending ready list. */
				if( xTaskResumeAll() == pdFALSE )
     e82:	0e 94 5c 0e 	call	0x1cb8	; 0x1cb8 <xTaskResumeAll>
     e86:	88 23       	and	r24, r24
     e88:	09 f0       	breq	.+2      	; 0xe8c <xQueueGenericSend+0x10c>
     e8a:	98 cf       	rjmp	.-208    	; 0xdbc <xQueueGenericSend+0x3c>
				{
					portYIELD_WITHIN_API();
     e8c:	0e 94 bc 04 	call	0x978	; 0x978 <vPortYield>
     e90:	95 cf       	rjmp	.-214    	; 0xdbc <xQueueGenericSend+0x3c>
				}
			}
			else
			{
				/* Try again. */
				prvUnlockQueue( pxQueue );
     e92:	c8 01       	movw	r24, r16
     e94:	0e 94 9d 05 	call	0xb3a	; 0xb3a <prvUnlockQueue>
				( void ) xTaskResumeAll();
     e98:	0e 94 5c 0e 	call	0x1cb8	; 0x1cb8 <xTaskResumeAll>
     e9c:	8f cf       	rjmp	.-226    	; 0xdbc <xQueueGenericSend+0x3c>
			}
		}
		else
		{
			/* The timeout has expired. */
			prvUnlockQueue( pxQueue );
     e9e:	c8 01       	movw	r24, r16
     ea0:	0e 94 9d 05 	call	0xb3a	; 0xb3a <prvUnlockQueue>
			( void ) xTaskResumeAll();
     ea4:	0e 94 5c 0e 	call	0x1cb8	; 0x1cb8 <xTaskResumeAll>

			traceQUEUE_SEND_FAILED( pxQueue );
			return errQUEUE_FULL;
     ea8:	80 e0       	ldi	r24, 0x00	; 0
		}
	}
}
     eaa:	0f 90       	pop	r0
     eac:	0f 90       	pop	r0
     eae:	0f 90       	pop	r0
     eb0:	0f 90       	pop	r0
     eb2:	0f 90       	pop	r0
     eb4:	df 91       	pop	r29
     eb6:	cf 91       	pop	r28
     eb8:	1f 91       	pop	r17
     eba:	0f 91       	pop	r16
     ebc:	ff 90       	pop	r15
     ebe:	ef 90       	pop	r14
     ec0:	df 90       	pop	r13
     ec2:	cf 90       	pop	r12
     ec4:	bf 90       	pop	r11
     ec6:	9f 90       	pop	r9
     ec8:	8f 90       	pop	r8
     eca:	08 95       	ret

00000ecc <xQueueCreateMutex>:
/*-----------------------------------------------------------*/

#if( ( configUSE_MUTEXES == 1 ) && ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) )

	QueueHandle_t xQueueCreateMutex( const uint8_t ucQueueType )
	{
     ecc:	cf 93       	push	r28
     ece:	df 93       	push	r29
     ed0:	48 2f       	mov	r20, r24
	Queue_t *pxNewQueue;
	const UBaseType_t uxMutexLength = ( UBaseType_t ) 1, uxMutexSize = ( UBaseType_t ) 0;

		pxNewQueue = ( Queue_t * ) xQueueGenericCreate( uxMutexLength, uxMutexSize, ucQueueType );
     ed2:	81 e0       	ldi	r24, 0x01	; 1
     ed4:	60 e0       	ldi	r22, 0x00	; 0
     ed6:	0e 94 97 06 	call	0xd2e	; 0xd2e <xQueueGenericCreate>
     eda:	ec 01       	movw	r28, r24

#if( configUSE_MUTEXES == 1 )

	static void prvInitialiseMutex( Queue_t *pxNewQueue )
	{
		if( pxNewQueue != NULL )
     edc:	00 97       	sbiw	r24, 0x00	; 0
     ede:	61 f0       	breq	.+24     	; 0xef8 <xQueueCreateMutex+0x2c>
		{
			/* The queue create function will set all the queue structure members
			correctly for a generic queue, but this function is creating a
			mutex.  Overwrite those members that need to be set differently -
			in particular the information required for priority inheritance. */
			pxNewQueue->pxMutexHolder = NULL;
     ee0:	1b 82       	std	Y+3, r1	; 0x03
     ee2:	1a 82       	std	Y+2, r1	; 0x02
			pxNewQueue->uxQueueType = queueQUEUE_IS_MUTEX;
     ee4:	19 82       	std	Y+1, r1	; 0x01
     ee6:	18 82       	st	Y, r1

			/* In case this is a recursive mutex. */
			pxNewQueue->u.uxRecursiveCallCount = 0;
     ee8:	1e 82       	std	Y+6, r1	; 0x06

			traceCREATE_MUTEX( pxNewQueue );

			/* Start with the semaphore in the expected state. */
			( void ) xQueueGenericSend( pxNewQueue, NULL, ( TickType_t ) 0U, queueSEND_TO_BACK );
     eea:	60 e0       	ldi	r22, 0x00	; 0
     eec:	70 e0       	ldi	r23, 0x00	; 0
     eee:	40 e0       	ldi	r20, 0x00	; 0
     ef0:	50 e0       	ldi	r21, 0x00	; 0
     ef2:	20 e0       	ldi	r18, 0x00	; 0
     ef4:	0e 94 c0 06 	call	0xd80	; 0xd80 <xQueueGenericSend>

		pxNewQueue = ( Queue_t * ) xQueueGenericCreate( uxMutexLength, uxMutexSize, ucQueueType );
		prvInitialiseMutex( pxNewQueue );

		return pxNewQueue;
	}
     ef8:	8c 2f       	mov	r24, r28
     efa:	9d 2f       	mov	r25, r29
     efc:	df 91       	pop	r29
     efe:	cf 91       	pop	r28
     f00:	08 95       	ret

00000f02 <xQueueGenericSendFromISR>:
	}
}
/*-----------------------------------------------------------*/

BaseType_t xQueueGenericSendFromISR( QueueHandle_t xQueue, const void * const pvItemToQueue, BaseType_t * const pxHigherPriorityTaskWoken, const BaseType_t xCopyPosition )
{
     f02:	ef 92       	push	r14
     f04:	ff 92       	push	r15
     f06:	0f 93       	push	r16
     f08:	1f 93       	push	r17
     f0a:	cf 93       	push	r28
     f0c:	8c 01       	movw	r16, r24
     f0e:	7a 01       	movw	r14, r20
	read, instead return a flag to say whether a context switch is required or
	not (i.e. has a task with a higher priority than us been woken by this
	post). */
	uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
	{
		if( ( pxQueue->uxMessagesWaiting < pxQueue->uxLength ) || ( xCopyPosition == queueOVERWRITE ) )
     f10:	fc 01       	movw	r30, r24
     f12:	92 8d       	ldd	r25, Z+26	; 0x1a
     f14:	83 8d       	ldd	r24, Z+27	; 0x1b
     f16:	98 17       	cp	r25, r24
     f18:	10 f0       	brcs	.+4      	; 0xf1e <xQueueGenericSendFromISR+0x1c>
     f1a:	22 30       	cpi	r18, 0x02	; 2
     f1c:	f1 f4       	brne	.+60     	; 0xf5a <xQueueGenericSendFromISR+0x58>
		{
			const int8_t cTxLock = pxQueue->cTxLock;
     f1e:	f8 01       	movw	r30, r16
     f20:	c6 8d       	ldd	r28, Z+30	; 0x1e
			/* Semaphores use xQueueGiveFromISR(), so pxQueue will not be a
			semaphore or mutex.  That means prvCopyDataToQueue() cannot result
			in a task disinheriting a priority and prvCopyDataToQueue() can be
			called here even though the disinherit function does not check if
			the scheduler is suspended before accessing the ready lists. */
			( void ) prvCopyDataToQueue( pxQueue, pvItemToQueue, xCopyPosition );
     f22:	c8 01       	movw	r24, r16
     f24:	42 2f       	mov	r20, r18
     f26:	0e 94 f2 05 	call	0xbe4	; 0xbe4 <prvCopyDataToQueue>

			/* The event list is not altered if the queue is locked.  This will
			be done when the queue is unlocked later. */
			if( cTxLock == queueUNLOCKED )
     f2a:	cf 3f       	cpi	r28, 0xFF	; 255
     f2c:	89 f4       	brne	.+34     	; 0xf50 <xQueueGenericSendFromISR+0x4e>
						}
					}
				}
				#else /* configUSE_QUEUE_SETS */
				{
					if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
     f2e:	f8 01       	movw	r30, r16
     f30:	81 89       	ldd	r24, Z+17	; 0x11
     f32:	88 23       	and	r24, r24
     f34:	a1 f0       	breq	.+40     	; 0xf5e <xQueueGenericSendFromISR+0x5c>
					{
						if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )
     f36:	c8 01       	movw	r24, r16
     f38:	41 96       	adiw	r24, 0x11	; 17
     f3a:	0e 94 3d 10 	call	0x207a	; 0x207a <xTaskRemoveFromEventList>
     f3e:	88 23       	and	r24, r24
     f40:	81 f0       	breq	.+32     	; 0xf62 <xQueueGenericSendFromISR+0x60>
						{
							/* The task waiting has a higher priority so record that a
							context	switch is required. */
							if( pxHigherPriorityTaskWoken != NULL )
     f42:	e1 14       	cp	r14, r1
     f44:	f1 04       	cpc	r15, r1
     f46:	79 f0       	breq	.+30     	; 0xf66 <xQueueGenericSendFromISR+0x64>
							{
								*pxHigherPriorityTaskWoken = pdTRUE;
     f48:	81 e0       	ldi	r24, 0x01	; 1
     f4a:	f7 01       	movw	r30, r14
     f4c:	80 83       	st	Z, r24
     f4e:	0c c0       	rjmp	.+24     	; 0xf68 <xQueueGenericSendFromISR+0x66>
			}
			else
			{
				/* Increment the lock count so the task that unlocks the queue
				knows that data was posted while it was locked. */
				pxQueue->cTxLock = ( int8_t ) ( cTxLock + 1 );
     f50:	cf 5f       	subi	r28, 0xFF	; 255
     f52:	f8 01       	movw	r30, r16
     f54:	c6 8f       	std	Z+30, r28	; 0x1e
			}

			xReturn = pdPASS;
     f56:	81 e0       	ldi	r24, 0x01	; 1
     f58:	07 c0       	rjmp	.+14     	; 0xf68 <xQueueGenericSendFromISR+0x66>
		}
		else
		{
			traceQUEUE_SEND_FROM_ISR_FAILED( pxQueue );
			xReturn = errQUEUE_FULL;
     f5a:	80 e0       	ldi	r24, 0x00	; 0
     f5c:	05 c0       	rjmp	.+10     	; 0xf68 <xQueueGenericSendFromISR+0x66>
				/* Increment the lock count so the task that unlocks the queue
				knows that data was posted while it was locked. */
				pxQueue->cTxLock = ( int8_t ) ( cTxLock + 1 );
			}

			xReturn = pdPASS;
     f5e:	81 e0       	ldi	r24, 0x01	; 1
     f60:	03 c0       	rjmp	.+6      	; 0xf68 <xQueueGenericSendFromISR+0x66>
     f62:	81 e0       	ldi	r24, 0x01	; 1
     f64:	01 c0       	rjmp	.+2      	; 0xf68 <xQueueGenericSendFromISR+0x66>
     f66:	81 e0       	ldi	r24, 0x01	; 1
		}
	}
	portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );

	return xReturn;
}
     f68:	cf 91       	pop	r28
     f6a:	1f 91       	pop	r17
     f6c:	0f 91       	pop	r16
     f6e:	ff 90       	pop	r15
     f70:	ef 90       	pop	r14
     f72:	08 95       	ret

00000f74 <xQueueGiveFromISR>:
/*-----------------------------------------------------------*/

BaseType_t xQueueGiveFromISR( QueueHandle_t xQueue, BaseType_t * const pxHigherPriorityTaskWoken )
{
     f74:	cf 93       	push	r28
     f76:	df 93       	push	r29
     f78:	fc 01       	movw	r30, r24
     f7a:	eb 01       	movw	r28, r22
	link: http://www.freertos.org/RTOS-Cortex-M3-M4.html */
	portASSERT_IF_INTERRUPT_PRIORITY_INVALID();

	uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
	{
		const UBaseType_t uxMessagesWaiting = pxQueue->uxMessagesWaiting;
     f7c:	82 8d       	ldd	r24, Z+26	; 0x1a

		/* When the queue is used to implement a semaphore no data is ever
		moved through the queue but it is still valid to see if the queue 'has
		space'. */
		if( uxMessagesWaiting < pxQueue->uxLength )
     f7e:	93 8d       	ldd	r25, Z+27	; 0x1b
     f80:	89 17       	cp	r24, r25
     f82:	b8 f4       	brcc	.+46     	; 0xfb2 <xQueueGiveFromISR+0x3e>
		{
			const int8_t cTxLock = pxQueue->cTxLock;
     f84:	96 8d       	ldd	r25, Z+30	; 0x1e
			holder - and if there is a mutex holder then the mutex cannot be
			given from an ISR.  As this is the ISR version of the function it
			can be assumed there is no mutex holder and no need to determine if
			priority disinheritance is needed.  Simply increase the count of
			messages (semaphores) available. */
			pxQueue->uxMessagesWaiting = uxMessagesWaiting + 1;
     f86:	8f 5f       	subi	r24, 0xFF	; 255
     f88:	82 8f       	std	Z+26, r24	; 0x1a

			/* The event list is not altered if the queue is locked.  This will
			be done when the queue is unlocked later. */
			if( cTxLock == queueUNLOCKED )
     f8a:	9f 3f       	cpi	r25, 0xFF	; 255
     f8c:	71 f4       	brne	.+28     	; 0xfaa <xQueueGiveFromISR+0x36>
						}
					}
				}
				#else /* configUSE_QUEUE_SETS */
				{
					if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
     f8e:	81 89       	ldd	r24, Z+17	; 0x11
     f90:	88 23       	and	r24, r24
     f92:	89 f0       	breq	.+34     	; 0xfb6 <xQueueGiveFromISR+0x42>
					{
						if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )
     f94:	cf 01       	movw	r24, r30
     f96:	41 96       	adiw	r24, 0x11	; 17
     f98:	0e 94 3d 10 	call	0x207a	; 0x207a <xTaskRemoveFromEventList>
     f9c:	88 23       	and	r24, r24
     f9e:	69 f0       	breq	.+26     	; 0xfba <xQueueGiveFromISR+0x46>
						{
							/* The task waiting has a higher priority so record that a
							context	switch is required. */
							if( pxHigherPriorityTaskWoken != NULL )
     fa0:	20 97       	sbiw	r28, 0x00	; 0
     fa2:	69 f0       	breq	.+26     	; 0xfbe <xQueueGiveFromISR+0x4a>
							{
								*pxHigherPriorityTaskWoken = pdTRUE;
     fa4:	81 e0       	ldi	r24, 0x01	; 1
     fa6:	88 83       	st	Y, r24
     fa8:	0b c0       	rjmp	.+22     	; 0xfc0 <xQueueGiveFromISR+0x4c>
			}
			else
			{
				/* Increment the lock count so the task that unlocks the queue
				knows that data was posted while it was locked. */
				pxQueue->cTxLock = ( int8_t ) ( cTxLock + 1 );
     faa:	9f 5f       	subi	r25, 0xFF	; 255
     fac:	96 8f       	std	Z+30, r25	; 0x1e
			}

			xReturn = pdPASS;
     fae:	81 e0       	ldi	r24, 0x01	; 1
     fb0:	07 c0       	rjmp	.+14     	; 0xfc0 <xQueueGiveFromISR+0x4c>
		}
		else
		{
			traceQUEUE_SEND_FROM_ISR_FAILED( pxQueue );
			xReturn = errQUEUE_FULL;
     fb2:	80 e0       	ldi	r24, 0x00	; 0
     fb4:	05 c0       	rjmp	.+10     	; 0xfc0 <xQueueGiveFromISR+0x4c>
				/* Increment the lock count so the task that unlocks the queue
				knows that data was posted while it was locked. */
				pxQueue->cTxLock = ( int8_t ) ( cTxLock + 1 );
			}

			xReturn = pdPASS;
     fb6:	81 e0       	ldi	r24, 0x01	; 1
     fb8:	03 c0       	rjmp	.+6      	; 0xfc0 <xQueueGiveFromISR+0x4c>
     fba:	81 e0       	ldi	r24, 0x01	; 1
     fbc:	01 c0       	rjmp	.+2      	; 0xfc0 <xQueueGiveFromISR+0x4c>
     fbe:	81 e0       	ldi	r24, 0x01	; 1
		}
	}
	portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );

	return xReturn;
}
     fc0:	df 91       	pop	r29
     fc2:	cf 91       	pop	r28
     fc4:	08 95       	ret

00000fc6 <xQueueGenericReceive>:
/*-----------------------------------------------------------*/

BaseType_t xQueueGenericReceive( QueueHandle_t xQueue, void * const pvBuffer, TickType_t xTicksToWait, const BaseType_t xJustPeeking )
{
     fc6:	8f 92       	push	r8
     fc8:	9f 92       	push	r9
     fca:	af 92       	push	r10
     fcc:	bf 92       	push	r11
     fce:	cf 92       	push	r12
     fd0:	df 92       	push	r13
     fd2:	ef 92       	push	r14
     fd4:	ff 92       	push	r15
     fd6:	0f 93       	push	r16
     fd8:	1f 93       	push	r17
     fda:	cf 93       	push	r28
     fdc:	df 93       	push	r29
     fde:	00 d0       	rcall	.+0      	; 0xfe0 <xQueueGenericReceive+0x1a>
     fe0:	00 d0       	rcall	.+0      	; 0xfe2 <xQueueGenericReceive+0x1c>
     fe2:	0f 92       	push	r0
     fe4:	cd b7       	in	r28, 0x3d	; 61
     fe6:	de b7       	in	r29, 0x3e	; 62
     fe8:	7c 01       	movw	r14, r24
     fea:	4b 01       	movw	r8, r22
     fec:	5d 83       	std	Y+5, r21	; 0x05
     fee:	4c 83       	std	Y+4, r20	; 0x04
     ff0:	c2 2e       	mov	r12, r18
BaseType_t xEntryTimeSet = pdFALSE;
     ff2:	00 e0       	ldi	r16, 0x00	; 0
				else if( xEntryTimeSet == pdFALSE )
				{
					/* The queue was empty and a block time was specified so
					configure the timeout structure. */
					vTaskSetTimeOutState( &xTimeOut );
					xEntryTimeSet = pdTRUE;
     ff4:	dd 24       	eor	r13, r13
     ff6:	d3 94       	inc	r13
						mtCOVERAGE_TEST_MARKER();
					}
				}
				#endif

				vTaskPlaceOnEventList( &( pxQueue->xTasksWaitingToReceive ), xTicksToWait );
     ff8:	0f 2e       	mov	r0, r31
     ffa:	f1 e1       	ldi	r31, 0x11	; 17
     ffc:	af 2e       	mov	r10, r31
     ffe:	bb 24       	eor	r11, r11
    1000:	f0 2d       	mov	r31, r0
    1002:	a8 0e       	add	r10, r24
    1004:	b9 1e       	adc	r11, r25
	statements within the function itself.  This is done in the interest
	of execution time efficiency. */

	for( ;; )
	{
		taskENTER_CRITICAL();
    1006:	0f b6       	in	r0, 0x3f	; 63
    1008:	f8 94       	cli
    100a:	0f 92       	push	r0
		{
			const UBaseType_t uxMessagesWaiting = pxQueue->uxMessagesWaiting;
    100c:	f7 01       	movw	r30, r14
    100e:	12 8d       	ldd	r17, Z+26	; 0x1a

			/* Is there data in the queue now?  To be running the calling task
			must be the highest priority task wanting to access the queue. */
			if( uxMessagesWaiting > ( UBaseType_t ) 0 )
    1010:	11 23       	and	r17, r17
    1012:	99 f1       	breq	.+102    	; 0x107a <xQueueGenericReceive+0xb4>
			{
				/* Remember the read position in case the queue is only being
				peeked. */
				pcOriginalReadPosition = pxQueue->u.pcReadFrom;
    1014:	a6 80       	ldd	r10, Z+6	; 0x06
    1016:	b7 80       	ldd	r11, Z+7	; 0x07

				prvCopyDataFromQueue( pxQueue, pvBuffer );
    1018:	c7 01       	movw	r24, r14
    101a:	b4 01       	movw	r22, r8
    101c:	0e 94 80 05 	call	0xb00	; 0xb00 <prvCopyDataFromQueue>

				if( xJustPeeking == pdFALSE )
    1020:	cc 20       	and	r12, r12
    1022:	c9 f4       	brne	.+50     	; 0x1056 <xQueueGenericReceive+0x90>
				{
					traceQUEUE_RECEIVE( pxQueue );

					/* Actually removing data, not just peeking. */
					pxQueue->uxMessagesWaiting = uxMessagesWaiting - 1;
    1024:	11 50       	subi	r17, 0x01	; 1
    1026:	f7 01       	movw	r30, r14
    1028:	12 8f       	std	Z+26, r17	; 0x1a

					#if ( configUSE_MUTEXES == 1 )
					{
						if( pxQueue->uxQueueType == queueQUEUE_IS_MUTEX )
    102a:	80 81       	ld	r24, Z
    102c:	91 81       	ldd	r25, Z+1	; 0x01
    102e:	00 97       	sbiw	r24, 0x00	; 0
    1030:	29 f4       	brne	.+10     	; 0x103c <xQueueGenericReceive+0x76>
						{
							/* Record the information required to implement
							priority inheritance should it become necessary. */
							pxQueue->pxMutexHolder = ( int8_t * ) pvTaskIncrementMutexHeldCount(); /*lint !e961 Cast is not redundant as TaskHandle_t is a typedef. */
    1032:	0e 94 c2 11 	call	0x2384	; 0x2384 <pvTaskIncrementMutexHeldCount>
    1036:	f7 01       	movw	r30, r14
    1038:	93 83       	std	Z+3, r25	; 0x03
    103a:	82 83       	std	Z+2, r24	; 0x02
							mtCOVERAGE_TEST_MARKER();
						}
					}
					#endif /* configUSE_MUTEXES */

					if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToSend ) ) == pdFALSE )
    103c:	f7 01       	movw	r30, r14
    103e:	80 85       	ldd	r24, Z+8	; 0x08
    1040:	88 23       	and	r24, r24
    1042:	b9 f0       	breq	.+46     	; 0x1072 <xQueueGenericReceive+0xac>
					{
						if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) != pdFALSE )
    1044:	c7 01       	movw	r24, r14
    1046:	08 96       	adiw	r24, 0x08	; 8
    1048:	0e 94 3d 10 	call	0x207a	; 0x207a <xTaskRemoveFromEventList>
    104c:	88 23       	and	r24, r24
    104e:	89 f0       	breq	.+34     	; 0x1072 <xQueueGenericReceive+0xac>
						{
							queueYIELD_IF_USING_PREEMPTION();
    1050:	0e 94 bc 04 	call	0x978	; 0x978 <vPortYield>
    1054:	0e c0       	rjmp	.+28     	; 0x1072 <xQueueGenericReceive+0xac>
				{
					traceQUEUE_PEEK( pxQueue );

					/* The data is not being removed, so reset the read
					pointer. */
					pxQueue->u.pcReadFrom = pcOriginalReadPosition;
    1056:	f7 01       	movw	r30, r14
    1058:	b7 82       	std	Z+7, r11	; 0x07
    105a:	a6 82       	std	Z+6, r10	; 0x06

					/* The data is being left in the queue, so see if there are
					any other tasks waiting for the data. */
					if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
    105c:	81 89       	ldd	r24, Z+17	; 0x11
    105e:	88 23       	and	r24, r24
    1060:	41 f0       	breq	.+16     	; 0x1072 <xQueueGenericReceive+0xac>
					{
						if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )
    1062:	c7 01       	movw	r24, r14
    1064:	41 96       	adiw	r24, 0x11	; 17
    1066:	0e 94 3d 10 	call	0x207a	; 0x207a <xTaskRemoveFromEventList>
    106a:	88 23       	and	r24, r24
    106c:	11 f0       	breq	.+4      	; 0x1072 <xQueueGenericReceive+0xac>
						{
							/* The task waiting has a higher priority than this task. */
							queueYIELD_IF_USING_PREEMPTION();
    106e:	0e 94 bc 04 	call	0x978	; 0x978 <vPortYield>
					{
						mtCOVERAGE_TEST_MARKER();
					}
				}

				taskEXIT_CRITICAL();
    1072:	0f 90       	pop	r0
    1074:	0f be       	out	0x3f, r0	; 63
				return pdPASS;
    1076:	81 e0       	ldi	r24, 0x01	; 1
    1078:	61 c0       	rjmp	.+194    	; 0x113c <xQueueGenericReceive+0x176>
			}
			else
			{
				if( xTicksToWait == ( TickType_t ) 0 )
    107a:	8c 81       	ldd	r24, Y+4	; 0x04
    107c:	9d 81       	ldd	r25, Y+5	; 0x05
    107e:	00 97       	sbiw	r24, 0x00	; 0
    1080:	21 f4       	brne	.+8      	; 0x108a <xQueueGenericReceive+0xc4>
				{
					/* The queue was empty and no block time is specified (or
					the block time has expired) so leave now. */
					taskEXIT_CRITICAL();
    1082:	0f 90       	pop	r0
    1084:	0f be       	out	0x3f, r0	; 63
					traceQUEUE_RECEIVE_FAILED( pxQueue );
					return errQUEUE_EMPTY;
    1086:	80 e0       	ldi	r24, 0x00	; 0
    1088:	59 c0       	rjmp	.+178    	; 0x113c <xQueueGenericReceive+0x176>
				}
				else if( xEntryTimeSet == pdFALSE )
    108a:	00 23       	and	r16, r16
    108c:	29 f4       	brne	.+10     	; 0x1098 <xQueueGenericReceive+0xd2>
				{
					/* The queue was empty and a block time was specified so
					configure the timeout structure. */
					vTaskSetTimeOutState( &xTimeOut );
    108e:	ce 01       	movw	r24, r28
    1090:	01 96       	adiw	r24, 0x01	; 1
    1092:	0e 94 c2 10 	call	0x2184	; 0x2184 <vTaskSetTimeOutState>
					xEntryTimeSet = pdTRUE;
    1096:	0d 2d       	mov	r16, r13
					/* Entry time was already set. */
					mtCOVERAGE_TEST_MARKER();
				}
			}
		}
		taskEXIT_CRITICAL();
    1098:	0f 90       	pop	r0
    109a:	0f be       	out	0x3f, r0	; 63

		/* Interrupts and other tasks can send to and receive from the queue
		now the critical section has been exited. */

		vTaskSuspendAll();
    109c:	0e 94 97 0d 	call	0x1b2e	; 0x1b2e <vTaskSuspendAll>
		prvLockQueue( pxQueue );
    10a0:	0f b6       	in	r0, 0x3f	; 63
    10a2:	f8 94       	cli
    10a4:	0f 92       	push	r0
    10a6:	f7 01       	movw	r30, r14
    10a8:	85 8d       	ldd	r24, Z+29	; 0x1d
    10aa:	8f 3f       	cpi	r24, 0xFF	; 255
    10ac:	09 f4       	brne	.+2      	; 0x10b0 <xQueueGenericReceive+0xea>
    10ae:	15 8e       	std	Z+29, r1	; 0x1d
    10b0:	f7 01       	movw	r30, r14
    10b2:	86 8d       	ldd	r24, Z+30	; 0x1e
    10b4:	8f 3f       	cpi	r24, 0xFF	; 255
    10b6:	09 f4       	brne	.+2      	; 0x10ba <xQueueGenericReceive+0xf4>
    10b8:	16 8e       	std	Z+30, r1	; 0x1e
    10ba:	0f 90       	pop	r0
    10bc:	0f be       	out	0x3f, r0	; 63

		/* Update the timeout state to see if it has expired yet. */
		if( xTaskCheckForTimeOut( &xTimeOut, &xTicksToWait ) == pdFALSE )
    10be:	ce 01       	movw	r24, r28
    10c0:	01 96       	adiw	r24, 0x01	; 1
    10c2:	be 01       	movw	r22, r28
    10c4:	6c 5f       	subi	r22, 0xFC	; 252
    10c6:	7f 4f       	sbci	r23, 0xFF	; 255
    10c8:	0e 94 cd 10 	call	0x219a	; 0x219a <xTaskCheckForTimeOut>
    10cc:	88 23       	and	r24, r24
    10ce:	51 f5       	brne	.+84     	; 0x1124 <xQueueGenericReceive+0x15e>
		{
			if( prvIsQueueEmpty( pxQueue ) != pdFALSE )
    10d0:	c7 01       	movw	r24, r14
    10d2:	0e 94 75 05 	call	0xaea	; 0xaea <prvIsQueueEmpty>
    10d6:	88 23       	and	r24, r24
    10d8:	f9 f0       	breq	.+62     	; 0x1118 <xQueueGenericReceive+0x152>
			{
				traceBLOCKING_ON_QUEUE_RECEIVE( pxQueue );

				#if ( configUSE_MUTEXES == 1 )
				{
					if( pxQueue->uxQueueType == queueQUEUE_IS_MUTEX )
    10da:	f7 01       	movw	r30, r14
    10dc:	80 81       	ld	r24, Z
    10de:	91 81       	ldd	r25, Z+1	; 0x01
    10e0:	00 97       	sbiw	r24, 0x00	; 0
    10e2:	51 f4       	brne	.+20     	; 0x10f8 <xQueueGenericReceive+0x132>
					{
						taskENTER_CRITICAL();
    10e4:	0f b6       	in	r0, 0x3f	; 63
    10e6:	f8 94       	cli
    10e8:	0f 92       	push	r0
						{
							vTaskPriorityInherit( ( void * ) pxQueue->pxMutexHolder );
    10ea:	f7 01       	movw	r30, r14
    10ec:	82 81       	ldd	r24, Z+2	; 0x02
    10ee:	93 81       	ldd	r25, Z+3	; 0x03
    10f0:	0e 94 0b 11 	call	0x2216	; 0x2216 <vTaskPriorityInherit>
						}
						taskEXIT_CRITICAL();
    10f4:	0f 90       	pop	r0
    10f6:	0f be       	out	0x3f, r0	; 63
						mtCOVERAGE_TEST_MARKER();
					}
				}
				#endif

				vTaskPlaceOnEventList( &( pxQueue->xTasksWaitingToReceive ), xTicksToWait );
    10f8:	6c 81       	ldd	r22, Y+4	; 0x04
    10fa:	7d 81       	ldd	r23, Y+5	; 0x05
    10fc:	c5 01       	movw	r24, r10
    10fe:	0e 94 12 10 	call	0x2024	; 0x2024 <vTaskPlaceOnEventList>
				prvUnlockQueue( pxQueue );
    1102:	c7 01       	movw	r24, r14
    1104:	0e 94 9d 05 	call	0xb3a	; 0xb3a <prvUnlockQueue>
				if( xTaskResumeAll() == pdFALSE )
    1108:	0e 94 5c 0e 	call	0x1cb8	; 0x1cb8 <xTaskResumeAll>
    110c:	88 23       	and	r24, r24
    110e:	09 f0       	breq	.+2      	; 0x1112 <xQueueGenericReceive+0x14c>
    1110:	7a cf       	rjmp	.-268    	; 0x1006 <xQueueGenericReceive+0x40>
				{
					portYIELD_WITHIN_API();
    1112:	0e 94 bc 04 	call	0x978	; 0x978 <vPortYield>
    1116:	77 cf       	rjmp	.-274    	; 0x1006 <xQueueGenericReceive+0x40>
				}
			}
			else
			{
				/* Try again. */
				prvUnlockQueue( pxQueue );
    1118:	c7 01       	movw	r24, r14
    111a:	0e 94 9d 05 	call	0xb3a	; 0xb3a <prvUnlockQueue>
				( void ) xTaskResumeAll();
    111e:	0e 94 5c 0e 	call	0x1cb8	; 0x1cb8 <xTaskResumeAll>
    1122:	71 cf       	rjmp	.-286    	; 0x1006 <xQueueGenericReceive+0x40>
			}
		}
		else
		{
			prvUnlockQueue( pxQueue );
    1124:	c7 01       	movw	r24, r14
    1126:	0e 94 9d 05 	call	0xb3a	; 0xb3a <prvUnlockQueue>
			( void ) xTaskResumeAll();
    112a:	0e 94 5c 0e 	call	0x1cb8	; 0x1cb8 <xTaskResumeAll>

			if( prvIsQueueEmpty( pxQueue ) != pdFALSE )
    112e:	c7 01       	movw	r24, r14
    1130:	0e 94 75 05 	call	0xaea	; 0xaea <prvIsQueueEmpty>
    1134:	88 23       	and	r24, r24
    1136:	09 f4       	brne	.+2      	; 0x113a <xQueueGenericReceive+0x174>
    1138:	66 cf       	rjmp	.-308    	; 0x1006 <xQueueGenericReceive+0x40>
			{
				traceQUEUE_RECEIVE_FAILED( pxQueue );
				return errQUEUE_EMPTY;
    113a:	80 e0       	ldi	r24, 0x00	; 0
			{
				mtCOVERAGE_TEST_MARKER();
			}
		}
	}
}
    113c:	0f 90       	pop	r0
    113e:	0f 90       	pop	r0
    1140:	0f 90       	pop	r0
    1142:	0f 90       	pop	r0
    1144:	0f 90       	pop	r0
    1146:	df 91       	pop	r29
    1148:	cf 91       	pop	r28
    114a:	1f 91       	pop	r17
    114c:	0f 91       	pop	r16
    114e:	ff 90       	pop	r15
    1150:	ef 90       	pop	r14
    1152:	df 90       	pop	r13
    1154:	cf 90       	pop	r12
    1156:	bf 90       	pop	r11
    1158:	af 90       	pop	r10
    115a:	9f 90       	pop	r9
    115c:	8f 90       	pop	r8
    115e:	08 95       	ret

00001160 <xQueueReceiveFromISR>:
/*-----------------------------------------------------------*/

BaseType_t xQueueReceiveFromISR( QueueHandle_t xQueue, void * const pvBuffer, BaseType_t * const pxHigherPriorityTaskWoken )
{
    1160:	ef 92       	push	r14
    1162:	ff 92       	push	r15
    1164:	0f 93       	push	r16
    1166:	1f 93       	push	r17
    1168:	cf 93       	push	r28
    116a:	df 93       	push	r29
    116c:	8c 01       	movw	r16, r24
    116e:	7a 01       	movw	r14, r20
	link: http://www.freertos.org/RTOS-Cortex-M3-M4.html */
	portASSERT_IF_INTERRUPT_PRIORITY_INVALID();

	uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
	{
		const UBaseType_t uxMessagesWaiting = pxQueue->uxMessagesWaiting;
    1170:	fc 01       	movw	r30, r24
    1172:	c2 8d       	ldd	r28, Z+26	; 0x1a

		/* Cannot block in an ISR, so check there is data available. */
		if( uxMessagesWaiting > ( UBaseType_t ) 0 )
    1174:	cc 23       	and	r28, r28
    1176:	e9 f0       	breq	.+58     	; 0x11b2 <xQueueReceiveFromISR+0x52>
		{
			const int8_t cRxLock = pxQueue->cRxLock;
    1178:	d5 8d       	ldd	r29, Z+29	; 0x1d

			traceQUEUE_RECEIVE_FROM_ISR( pxQueue );

			prvCopyDataFromQueue( pxQueue, pvBuffer );
    117a:	0e 94 80 05 	call	0xb00	; 0xb00 <prvCopyDataFromQueue>
			pxQueue->uxMessagesWaiting = uxMessagesWaiting - 1;
    117e:	c1 50       	subi	r28, 0x01	; 1
    1180:	f8 01       	movw	r30, r16
    1182:	c2 8f       	std	Z+26, r28	; 0x1a

			/* If the queue is locked the event list will not be modified.
			Instead update the lock count so the task that unlocks the queue
			will know that an ISR has removed data while the queue was
			locked. */
			if( cRxLock == queueUNLOCKED )
    1184:	df 3f       	cpi	r29, 0xFF	; 255
    1186:	81 f4       	brne	.+32     	; 0x11a8 <xQueueReceiveFromISR+0x48>
			{
				if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToSend ) ) == pdFALSE )
    1188:	80 85       	ldd	r24, Z+8	; 0x08
    118a:	88 23       	and	r24, r24
    118c:	a1 f0       	breq	.+40     	; 0x11b6 <xQueueReceiveFromISR+0x56>
				{
					if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) != pdFALSE )
    118e:	c8 01       	movw	r24, r16
    1190:	08 96       	adiw	r24, 0x08	; 8
    1192:	0e 94 3d 10 	call	0x207a	; 0x207a <xTaskRemoveFromEventList>
    1196:	88 23       	and	r24, r24
    1198:	81 f0       	breq	.+32     	; 0x11ba <xQueueReceiveFromISR+0x5a>
					{
						/* The task waiting has a higher priority than us so
						force a context switch. */
						if( pxHigherPriorityTaskWoken != NULL )
    119a:	e1 14       	cp	r14, r1
    119c:	f1 04       	cpc	r15, r1
    119e:	79 f0       	breq	.+30     	; 0x11be <xQueueReceiveFromISR+0x5e>
						{
							*pxHigherPriorityTaskWoken = pdTRUE;
    11a0:	81 e0       	ldi	r24, 0x01	; 1
    11a2:	f7 01       	movw	r30, r14
    11a4:	80 83       	st	Z, r24
    11a6:	0c c0       	rjmp	.+24     	; 0x11c0 <xQueueReceiveFromISR+0x60>
			}
			else
			{
				/* Increment the lock count so the task that unlocks the queue
				knows that data was removed while it was locked. */
				pxQueue->cRxLock = ( int8_t ) ( cRxLock + 1 );
    11a8:	df 5f       	subi	r29, 0xFF	; 255
    11aa:	f8 01       	movw	r30, r16
    11ac:	d5 8f       	std	Z+29, r29	; 0x1d
			}

			xReturn = pdPASS;
    11ae:	81 e0       	ldi	r24, 0x01	; 1
    11b0:	07 c0       	rjmp	.+14     	; 0x11c0 <xQueueReceiveFromISR+0x60>
		}
		else
		{
			xReturn = pdFAIL;
    11b2:	80 e0       	ldi	r24, 0x00	; 0
    11b4:	05 c0       	rjmp	.+10     	; 0x11c0 <xQueueReceiveFromISR+0x60>
				/* Increment the lock count so the task that unlocks the queue
				knows that data was removed while it was locked. */
				pxQueue->cRxLock = ( int8_t ) ( cRxLock + 1 );
			}

			xReturn = pdPASS;
    11b6:	81 e0       	ldi	r24, 0x01	; 1
    11b8:	03 c0       	rjmp	.+6      	; 0x11c0 <xQueueReceiveFromISR+0x60>
    11ba:	81 e0       	ldi	r24, 0x01	; 1
    11bc:	01 c0       	rjmp	.+2      	; 0x11c0 <xQueueReceiveFromISR+0x60>
    11be:	81 e0       	ldi	r24, 0x01	; 1
		}
	}
	portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );

	return xReturn;
}
    11c0:	df 91       	pop	r29
    11c2:	cf 91       	pop	r28
    11c4:	1f 91       	pop	r17
    11c6:	0f 91       	pop	r16
    11c8:	ff 90       	pop	r15
    11ca:	ef 90       	pop	r14
    11cc:	08 95       	ret

000011ce <xQueuePeekFromISR>:
/*-----------------------------------------------------------*/

BaseType_t xQueuePeekFromISR( QueueHandle_t xQueue,  void * const pvBuffer )
{
    11ce:	0f 93       	push	r16
    11d0:	1f 93       	push	r17
    11d2:	cf 93       	push	r28
    11d4:	df 93       	push	r29
    11d6:	ec 01       	movw	r28, r24
	portASSERT_IF_INTERRUPT_PRIORITY_INVALID();

	uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
	{
		/* Cannot block in an ISR, so check there is data available. */
		if( pxQueue->uxMessagesWaiting > ( UBaseType_t ) 0 )
    11d8:	8a 8d       	ldd	r24, Y+26	; 0x1a
    11da:	88 23       	and	r24, r24
    11dc:	49 f0       	breq	.+18     	; 0x11f0 <xQueuePeekFromISR+0x22>
		{
			traceQUEUE_PEEK_FROM_ISR( pxQueue );

			/* Remember the read position so it can be reset as nothing is
			actually being removed from the queue. */
			pcOriginalReadPosition = pxQueue->u.pcReadFrom;
    11de:	0e 81       	ldd	r16, Y+6	; 0x06
    11e0:	1f 81       	ldd	r17, Y+7	; 0x07
			prvCopyDataFromQueue( pxQueue, pvBuffer );
    11e2:	ce 01       	movw	r24, r28
    11e4:	0e 94 80 05 	call	0xb00	; 0xb00 <prvCopyDataFromQueue>
			pxQueue->u.pcReadFrom = pcOriginalReadPosition;
    11e8:	1f 83       	std	Y+7, r17	; 0x07
    11ea:	0e 83       	std	Y+6, r16	; 0x06

			xReturn = pdPASS;
    11ec:	81 e0       	ldi	r24, 0x01	; 1
    11ee:	01 c0       	rjmp	.+2      	; 0x11f2 <xQueuePeekFromISR+0x24>
		}
		else
		{
			xReturn = pdFAIL;
    11f0:	80 e0       	ldi	r24, 0x00	; 0
		}
	}
	portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );

	return xReturn;
}
    11f2:	df 91       	pop	r29
    11f4:	cf 91       	pop	r28
    11f6:	1f 91       	pop	r17
    11f8:	0f 91       	pop	r16
    11fa:	08 95       	ret

000011fc <uxQueueMessagesWaiting>:
{
UBaseType_t uxReturn;

	configASSERT( xQueue );

	taskENTER_CRITICAL();
    11fc:	0f b6       	in	r0, 0x3f	; 63
    11fe:	f8 94       	cli
    1200:	0f 92       	push	r0
	{
		uxReturn = ( ( Queue_t * ) xQueue )->uxMessagesWaiting;
    1202:	fc 01       	movw	r30, r24
    1204:	82 8d       	ldd	r24, Z+26	; 0x1a
	}
	taskEXIT_CRITICAL();
    1206:	0f 90       	pop	r0
    1208:	0f be       	out	0x3f, r0	; 63

	return uxReturn;
} /*lint !e818 Pointer cannot be declared const as xQueue is a typedef not pointer. */
    120a:	08 95       	ret

0000120c <uxQueueSpacesAvailable>:
/*-----------------------------------------------------------*/

UBaseType_t uxQueueSpacesAvailable( const QueueHandle_t xQueue )
{
    120c:	fc 01       	movw	r30, r24
Queue_t *pxQueue;

	pxQueue = ( Queue_t * ) xQueue;
	configASSERT( pxQueue );

	taskENTER_CRITICAL();
    120e:	0f b6       	in	r0, 0x3f	; 63
    1210:	f8 94       	cli
    1212:	0f 92       	push	r0
	{
		uxReturn = pxQueue->uxLength - pxQueue->uxMessagesWaiting;
    1214:	92 8d       	ldd	r25, Z+26	; 0x1a
	}
	taskEXIT_CRITICAL();
    1216:	0f 90       	pop	r0
    1218:	0f be       	out	0x3f, r0	; 63
	pxQueue = ( Queue_t * ) xQueue;
	configASSERT( pxQueue );

	taskENTER_CRITICAL();
	{
		uxReturn = pxQueue->uxLength - pxQueue->uxMessagesWaiting;
    121a:	83 8d       	ldd	r24, Z+27	; 0x1b
	}
	taskEXIT_CRITICAL();

	return uxReturn;
} /*lint !e818 Pointer cannot be declared const as xQueue is a typedef not pointer. */
    121c:	89 1b       	sub	r24, r25
    121e:	08 95       	ret

00001220 <uxQueueMessagesWaitingFromISR>:
{
UBaseType_t uxReturn;

	configASSERT( xQueue );

	uxReturn = ( ( Queue_t * ) xQueue )->uxMessagesWaiting;
    1220:	fc 01       	movw	r30, r24
    1222:	82 8d       	ldd	r24, Z+26	; 0x1a

	return uxReturn;
} /*lint !e818 Pointer cannot be declared const as xQueue is a typedef not pointer. */
    1224:	08 95       	ret

00001226 <xQueueIsQueueEmptyFromISR>:
BaseType_t xQueueIsQueueEmptyFromISR( const QueueHandle_t xQueue )
{
BaseType_t xReturn;

	configASSERT( xQueue );
	if( ( ( Queue_t * ) xQueue )->uxMessagesWaiting == ( UBaseType_t ) 0 )
    1226:	fc 01       	movw	r30, r24
    1228:	92 8d       	ldd	r25, Z+26	; 0x1a
	{
		xReturn = pdTRUE;
    122a:	81 e0       	ldi	r24, 0x01	; 1
    122c:	91 11       	cpse	r25, r1
    122e:	80 e0       	ldi	r24, 0x00	; 0
	{
		xReturn = pdFALSE;
	}

	return xReturn;
} /*lint !e818 xQueue could not be pointer to const because it is a typedef. */
    1230:	08 95       	ret

00001232 <xQueueIsQueueFullFromISR>:
	return xReturn;
}
/*-----------------------------------------------------------*/

BaseType_t xQueueIsQueueFullFromISR( const QueueHandle_t xQueue )
{
    1232:	fc 01       	movw	r30, r24
BaseType_t xReturn;

	configASSERT( xQueue );
	if( ( ( Queue_t * ) xQueue )->uxMessagesWaiting == ( ( Queue_t * ) xQueue )->uxLength )
    1234:	22 8d       	ldd	r18, Z+26	; 0x1a
	{
		xReturn = pdTRUE;
    1236:	81 e0       	ldi	r24, 0x01	; 1
    1238:	93 8d       	ldd	r25, Z+27	; 0x1b
    123a:	29 13       	cpse	r18, r25
    123c:	80 e0       	ldi	r24, 0x00	; 0
	{
		xReturn = pdFALSE;
	}

	return xReturn;
} /*lint !e818 xQueue could not be pointer to const because it is a typedef. */
    123e:	08 95       	ret

00001240 <vQueueAddToRegistry>:
/*-----------------------------------------------------------*/

#if ( configQUEUE_REGISTRY_SIZE > 0 )

	void vQueueAddToRegistry( QueueHandle_t xQueue, const char *pcQueueName ) /*lint !e971 Unqualified char types are allowed for strings and single characters only. */
	{
    1240:	dc 01       	movw	r26, r24

		/* See if there is an empty space in the registry.  A NULL name denotes
		a free slot. */
		for( ux = ( UBaseType_t ) 0U; ux < ( UBaseType_t ) configQUEUE_REGISTRY_SIZE; ux++ )
		{
			if( xQueueRegistry[ ux ].pcQueueName == NULL )
    1242:	80 91 0c 04 	lds	r24, 0x040C
    1246:	90 91 0d 04 	lds	r25, 0x040D
    124a:	00 97       	sbiw	r24, 0x00	; 0
    124c:	51 f0       	breq	.+20     	; 0x1262 <vQueueAddToRegistry+0x22>
    124e:	e0 e1       	ldi	r30, 0x10	; 16
    1250:	f4 e0       	ldi	r31, 0x04	; 4
    1252:	21 e0       	ldi	r18, 0x01	; 1
    1254:	30 e0       	ldi	r19, 0x00	; 0
    1256:	a9 01       	movw	r20, r18
    1258:	80 81       	ld	r24, Z
    125a:	91 81       	ldd	r25, Z+1	; 0x01
    125c:	00 97       	sbiw	r24, 0x00	; 0
    125e:	79 f4       	brne	.+30     	; 0x127e <vQueueAddToRegistry+0x3e>
    1260:	02 c0       	rjmp	.+4      	; 0x1266 <vQueueAddToRegistry+0x26>
    1262:	40 e0       	ldi	r20, 0x00	; 0
    1264:	50 e0       	ldi	r21, 0x00	; 0
			{
				/* Store the information on this queue. */
				xQueueRegistry[ ux ].pcQueueName = pcQueueName;
    1266:	fa 01       	movw	r30, r20
    1268:	ee 0f       	add	r30, r30
    126a:	ff 1f       	adc	r31, r31
    126c:	ee 0f       	add	r30, r30
    126e:	ff 1f       	adc	r31, r31
    1270:	e4 5f       	subi	r30, 0xF4	; 244
    1272:	fb 4f       	sbci	r31, 0xFB	; 251
    1274:	71 83       	std	Z+1, r23	; 0x01
    1276:	60 83       	st	Z, r22
				xQueueRegistry[ ux ].xHandle = xQueue;
    1278:	b3 83       	std	Z+3, r27	; 0x03
    127a:	a2 83       	std	Z+2, r26	; 0x02

				traceQUEUE_REGISTRY_ADD( xQueue, pcQueueName );
				break;
    127c:	08 95       	ret
    127e:	2f 5f       	subi	r18, 0xFF	; 255
    1280:	3f 4f       	sbci	r19, 0xFF	; 255
    1282:	34 96       	adiw	r30, 0x04	; 4
	{
	UBaseType_t ux;

		/* See if there is an empty space in the registry.  A NULL name denotes
		a free slot. */
		for( ux = ( UBaseType_t ) 0U; ux < ( UBaseType_t ) configQUEUE_REGISTRY_SIZE; ux++ )
    1284:	28 30       	cpi	r18, 0x08	; 8
    1286:	31 05       	cpc	r19, r1
    1288:	31 f7       	brne	.-52     	; 0x1256 <vQueueAddToRegistry+0x16>
    128a:	08 95       	ret

0000128c <pcQueueGetName>:
/*-----------------------------------------------------------*/

#if ( configQUEUE_REGISTRY_SIZE > 0 )

	const char *pcQueueGetName( QueueHandle_t xQueue ) /*lint !e971 Unqualified char types are allowed for strings and single characters only. */
	{
    128c:	ac 01       	movw	r20, r24

		/* Note there is nothing here to protect against another task adding or
		removing entries from the registry while it is being searched. */
		for( ux = ( UBaseType_t ) 0U; ux < ( UBaseType_t ) configQUEUE_REGISTRY_SIZE; ux++ )
		{
			if( xQueueRegistry[ ux ].xHandle == xQueue )
    128e:	80 91 0e 04 	lds	r24, 0x040E
    1292:	90 91 0f 04 	lds	r25, 0x040F
    1296:	84 17       	cp	r24, r20
    1298:	95 07       	cpc	r25, r21
    129a:	59 f0       	breq	.+22     	; 0x12b2 <pcQueueGetName+0x26>
    129c:	e2 e1       	ldi	r30, 0x12	; 18
    129e:	f4 e0       	ldi	r31, 0x04	; 4
    12a0:	21 e0       	ldi	r18, 0x01	; 1
    12a2:	30 e0       	ldi	r19, 0x00	; 0
    12a4:	b9 01       	movw	r22, r18
    12a6:	80 81       	ld	r24, Z
    12a8:	91 81       	ldd	r25, Z+1	; 0x01
    12aa:	84 17       	cp	r24, r20
    12ac:	95 07       	cpc	r25, r21
    12ae:	69 f4       	brne	.+26     	; 0x12ca <pcQueueGetName+0x3e>
    12b0:	02 c0       	rjmp	.+4      	; 0x12b6 <pcQueueGetName+0x2a>
    12b2:	60 e0       	ldi	r22, 0x00	; 0
    12b4:	70 e0       	ldi	r23, 0x00	; 0
			{
				pcReturn = xQueueRegistry[ ux ].pcQueueName;
    12b6:	fb 01       	movw	r30, r22
    12b8:	ee 0f       	add	r30, r30
    12ba:	ff 1f       	adc	r31, r31
    12bc:	ee 0f       	add	r30, r30
    12be:	ff 1f       	adc	r31, r31
    12c0:	e4 5f       	subi	r30, 0xF4	; 244
    12c2:	fb 4f       	sbci	r31, 0xFB	; 251
    12c4:	80 81       	ld	r24, Z
    12c6:	91 81       	ldd	r25, Z+1	; 0x01
				break;
    12c8:	08 95       	ret
    12ca:	2f 5f       	subi	r18, 0xFF	; 255
    12cc:	3f 4f       	sbci	r19, 0xFF	; 255
    12ce:	34 96       	adiw	r30, 0x04	; 4
	UBaseType_t ux;
	const char *pcReturn = NULL; /*lint !e971 Unqualified char types are allowed for strings and single characters only. */

		/* Note there is nothing here to protect against another task adding or
		removing entries from the registry while it is being searched. */
		for( ux = ( UBaseType_t ) 0U; ux < ( UBaseType_t ) configQUEUE_REGISTRY_SIZE; ux++ )
    12d0:	28 30       	cpi	r18, 0x08	; 8
    12d2:	31 05       	cpc	r19, r1
    12d4:	39 f7       	brne	.-50     	; 0x12a4 <pcQueueGetName+0x18>
#if ( configQUEUE_REGISTRY_SIZE > 0 )

	const char *pcQueueGetName( QueueHandle_t xQueue ) /*lint !e971 Unqualified char types are allowed for strings and single characters only. */
	{
	UBaseType_t ux;
	const char *pcReturn = NULL; /*lint !e971 Unqualified char types are allowed for strings and single characters only. */
    12d6:	80 e0       	ldi	r24, 0x00	; 0
    12d8:	90 e0       	ldi	r25, 0x00	; 0
				mtCOVERAGE_TEST_MARKER();
			}
		}

		return pcReturn;
	}
    12da:	08 95       	ret

000012dc <vQueueUnregisterQueue>:
/*-----------------------------------------------------------*/

#if ( configQUEUE_REGISTRY_SIZE > 0 )

	void vQueueUnregisterQueue( QueueHandle_t xQueue )
	{
    12dc:	ac 01       	movw	r20, r24

		/* See if the handle of the queue being unregistered in actually in the
		registry. */
		for( ux = ( UBaseType_t ) 0U; ux < ( UBaseType_t ) configQUEUE_REGISTRY_SIZE; ux++ )
		{
			if( xQueueRegistry[ ux ].xHandle == xQueue )
    12de:	80 91 0e 04 	lds	r24, 0x040E
    12e2:	90 91 0f 04 	lds	r25, 0x040F
    12e6:	84 17       	cp	r24, r20
    12e8:	95 07       	cpc	r25, r21
    12ea:	59 f0       	breq	.+22     	; 0x1302 <vQueueUnregisterQueue+0x26>
    12ec:	e2 e1       	ldi	r30, 0x12	; 18
    12ee:	f4 e0       	ldi	r31, 0x04	; 4
    12f0:	21 e0       	ldi	r18, 0x01	; 1
    12f2:	30 e0       	ldi	r19, 0x00	; 0
    12f4:	b9 01       	movw	r22, r18
    12f6:	80 81       	ld	r24, Z
    12f8:	91 81       	ldd	r25, Z+1	; 0x01
    12fa:	84 17       	cp	r24, r20
    12fc:	95 07       	cpc	r25, r21
    12fe:	79 f4       	brne	.+30     	; 0x131e <vQueueUnregisterQueue+0x42>
    1300:	02 c0       	rjmp	.+4      	; 0x1306 <vQueueUnregisterQueue+0x2a>
    1302:	60 e0       	ldi	r22, 0x00	; 0
    1304:	70 e0       	ldi	r23, 0x00	; 0
			{
				/* Set the name to NULL to show that this slot if free again. */
				xQueueRegistry[ ux ].pcQueueName = NULL;
    1306:	fb 01       	movw	r30, r22
    1308:	ee 0f       	add	r30, r30
    130a:	ff 1f       	adc	r31, r31
    130c:	ee 0f       	add	r30, r30
    130e:	ff 1f       	adc	r31, r31
    1310:	e4 5f       	subi	r30, 0xF4	; 244
    1312:	fb 4f       	sbci	r31, 0xFB	; 251
    1314:	11 82       	std	Z+1, r1	; 0x01
    1316:	10 82       	st	Z, r1

				/* Set the handle to NULL to ensure the same queue handle cannot
				appear in the registry twice if it is added, removed, then
				added again. */
				xQueueRegistry[ ux ].xHandle = ( QueueHandle_t ) 0;
    1318:	13 82       	std	Z+3, r1	; 0x03
    131a:	12 82       	std	Z+2, r1	; 0x02
				break;
    131c:	08 95       	ret
    131e:	2f 5f       	subi	r18, 0xFF	; 255
    1320:	3f 4f       	sbci	r19, 0xFF	; 255
    1322:	34 96       	adiw	r30, 0x04	; 4
	{
	UBaseType_t ux;

		/* See if the handle of the queue being unregistered in actually in the
		registry. */
		for( ux = ( UBaseType_t ) 0U; ux < ( UBaseType_t ) configQUEUE_REGISTRY_SIZE; ux++ )
    1324:	28 30       	cpi	r18, 0x08	; 8
    1326:	31 05       	cpc	r19, r1
    1328:	29 f7       	brne	.-54     	; 0x12f4 <vQueueUnregisterQueue+0x18>
    132a:	08 95       	ret

0000132c <vQueueDelete>:
	return uxReturn;
} /*lint !e818 Pointer cannot be declared const as xQueue is a typedef not pointer. */
/*-----------------------------------------------------------*/

void vQueueDelete( QueueHandle_t xQueue )
{
    132c:	cf 93       	push	r28
    132e:	df 93       	push	r29
    1330:	ec 01       	movw	r28, r24
	configASSERT( pxQueue );
	traceQUEUE_DELETE( pxQueue );

	#if ( configQUEUE_REGISTRY_SIZE > 0 )
	{
		vQueueUnregisterQueue( pxQueue );
    1332:	0e 94 6e 09 	call	0x12dc	; 0x12dc <vQueueUnregisterQueue>

	#if( ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) && ( configSUPPORT_STATIC_ALLOCATION == 0 ) )
	{
		/* The queue can only have been allocated dynamically - free it
		again. */
		vPortFree( pxQueue );
    1336:	ce 01       	movw	r24, r28
    1338:	0e 94 32 03 	call	0x664	; 0x664 <vPortFree>
		/* The queue must have been statically allocated, so is not going to be
		deleted.  Avoid compiler warnings about the unused parameter. */
		( void ) pxQueue;
	}
	#endif /* configSUPPORT_DYNAMIC_ALLOCATION */
}
    133c:	df 91       	pop	r29
    133e:	cf 91       	pop	r28
    1340:	08 95       	ret

00001342 <Task2>:


void Task2(void* pv)
{
	/* Initialization */
	DIO_Set_Pin_Direction(A,1,OUTPUT);  /* PIN A0 >> OUTPUT */
    1342:	89 e3       	ldi	r24, 0x39	; 57
    1344:	61 e0       	ldi	r22, 0x01	; 1
    1346:	41 e0       	ldi	r20, 0x01	; 1
    1348:	0e 94 ff 01 	call	0x3fe	; 0x3fe <DIO_Set_Pin_Direction>
	while(1)
	{
		DIO_Toggle_Pin(A,1);
    134c:	89 e3       	ldi	r24, 0x39	; 57
    134e:	61 e0       	ldi	r22, 0x01	; 1
    1350:	0e 94 6e 02 	call	0x4dc	; 0x4dc <DIO_Toggle_Pin>
	#else
		//round up by default
		__ticks_dc = (uint32_t)(ceil(fabs(__tmp)));
	#endif

	__builtin_avr_delay_cycles(__ticks_dc);
    1354:	8f ef       	ldi	r24, 0xFF	; 255
    1356:	99 e6       	ldi	r25, 0x69	; 105
    1358:	a8 e1       	ldi	r26, 0x18	; 24
    135a:	81 50       	subi	r24, 0x01	; 1
    135c:	90 40       	sbci	r25, 0x00	; 0
    135e:	a0 40       	sbci	r26, 0x00	; 0
    1360:	e1 f7       	brne	.-8      	; 0x135a <Task2+0x18>
    1362:	00 c0       	rjmp	.+0      	; 0x1364 <Task2+0x22>
    1364:	00 00       	nop
    1366:	f2 cf       	rjmp	.-28     	; 0x134c <Task2+0xa>

00001368 <Task1>:


void Task1(void* pv)
{
	/* Initialization */
	DIO_Set_Pin_Direction(A,0,OUTPUT);  /* PIN A0 >> OUTPUT */
    1368:	89 e3       	ldi	r24, 0x39	; 57
    136a:	60 e0       	ldi	r22, 0x00	; 0
    136c:	41 e0       	ldi	r20, 0x01	; 1
    136e:	0e 94 ff 01 	call	0x3fe	; 0x3fe <DIO_Set_Pin_Direction>
	DIO_Set_Pin_Direction(A,2,OUTPUT);  /* PIN A0 >> OUTPUT */
    1372:	89 e3       	ldi	r24, 0x39	; 57
    1374:	62 e0       	ldi	r22, 0x02	; 2
    1376:	41 e0       	ldi	r20, 0x01	; 1
    1378:	0e 94 ff 01 	call	0x3fe	; 0x3fe <DIO_Set_Pin_Direction>
	u8 sem_state;
	while (1)
	{
		/* Take Semaphore */
		sem_state = xSemaphoreTake(my_sem,10000);  /* time out 2000 tick(2 second) */
    137c:	80 91 2c 04 	lds	r24, 0x042C
    1380:	90 91 2d 04 	lds	r25, 0x042D
    1384:	60 e0       	ldi	r22, 0x00	; 0
    1386:	70 e0       	ldi	r23, 0x00	; 0
    1388:	40 e1       	ldi	r20, 0x10	; 16
    138a:	57 e2       	ldi	r21, 0x27	; 39
    138c:	20 e0       	ldi	r18, 0x00	; 0
    138e:	0e 94 e3 07 	call	0xfc6	; 0xfc6 <xQueueGenericReceive>
		if (sem_state == pdTRUE)
    1392:	81 30       	cpi	r24, 0x01	; 1
    1394:	71 f4       	brne	.+28     	; 0x13b2 <Task1+0x4a>
		{
			DIO_Toggle_Pin(A,0);
    1396:	89 e3       	ldi	r24, 0x39	; 57
    1398:	60 e0       	ldi	r22, 0x00	; 0
    139a:	0e 94 6e 02 	call	0x4dc	; 0x4dc <DIO_Toggle_Pin>
    139e:	8f ef       	ldi	r24, 0xFF	; 255
    13a0:	9d e3       	ldi	r25, 0x3D	; 61
    13a2:	a9 e4       	ldi	r26, 0x49	; 73
    13a4:	81 50       	subi	r24, 0x01	; 1
    13a6:	90 40       	sbci	r25, 0x00	; 0
    13a8:	a0 40       	sbci	r26, 0x00	; 0
    13aa:	e1 f7       	brne	.-8      	; 0x13a4 <Task1+0x3c>
    13ac:	00 c0       	rjmp	.+0      	; 0x13ae <Task1+0x46>
    13ae:	00 00       	nop
    13b0:	e5 cf       	rjmp	.-54     	; 0x137c <Task1+0x14>
			_delay_ms(3000);
		}
		else
		{
			DIO_Toggle_Pin(A,2);
    13b2:	89 e3       	ldi	r24, 0x39	; 57
    13b4:	62 e0       	ldi	r22, 0x02	; 2
    13b6:	0e 94 6e 02 	call	0x4dc	; 0x4dc <DIO_Toggle_Pin>
    13ba:	e0 cf       	rjmp	.-64     	; 0x137c <Task1+0x14>

000013bc <main>:
SemaphoreHandle_t my_sem;  

int main(void)
{
	/*  Enable INT0 for Rising Edge */
	MCUCR |= (1 << ISC00)|(1 << ISC01);
    13bc:	85 b7       	in	r24, 0x35	; 53
    13be:	83 60       	ori	r24, 0x03	; 3
    13c0:	85 bf       	out	0x35, r24	; 53
	GICR  |= (1 << INT0);
    13c2:	8b b7       	in	r24, 0x3b	; 59
    13c4:	80 64       	ori	r24, 0x40	; 64
    13c6:	8b bf       	out	0x3b, r24	; 59
	sei();
    13c8:	78 94       	sei
	
	/* Create Task With Priority 1 */
	xTaskCreate(Task1,"Ali",100,NULL,2,NULL);
    13ca:	84 eb       	ldi	r24, 0xB4	; 180
    13cc:	99 e0       	ldi	r25, 0x09	; 9
    13ce:	62 e6       	ldi	r22, 0x62	; 98
    13d0:	70 e0       	ldi	r23, 0x00	; 0
    13d2:	44 e6       	ldi	r20, 0x64	; 100
    13d4:	50 e0       	ldi	r21, 0x00	; 0
    13d6:	20 e0       	ldi	r18, 0x00	; 0
    13d8:	30 e0       	ldi	r19, 0x00	; 0
    13da:	02 e0       	ldi	r16, 0x02	; 2
    13dc:	ee 24       	eor	r14, r14
    13de:	ff 24       	eor	r15, r15
    13e0:	0e 94 ce 0a 	call	0x159c	; 0x159c <xTaskCreate>
	/* Create Task With Priority 2 */
	xTaskCreate(Task2,"Mahmoud",100,NULL,1,NULL);
    13e4:	81 ea       	ldi	r24, 0xA1	; 161
    13e6:	99 e0       	ldi	r25, 0x09	; 9
    13e8:	66 e6       	ldi	r22, 0x66	; 102
    13ea:	70 e0       	ldi	r23, 0x00	; 0
    13ec:	44 e6       	ldi	r20, 0x64	; 100
    13ee:	50 e0       	ldi	r21, 0x00	; 0
    13f0:	20 e0       	ldi	r18, 0x00	; 0
    13f2:	30 e0       	ldi	r19, 0x00	; 0
    13f4:	01 e0       	ldi	r16, 0x01	; 1
    13f6:	0e 94 ce 0a 	call	0x159c	; 0x159c <xTaskCreate>
	
	my_sem = xSemaphoreCreateBinary();
    13fa:	81 e0       	ldi	r24, 0x01	; 1
    13fc:	60 e0       	ldi	r22, 0x00	; 0
    13fe:	43 e0       	ldi	r20, 0x03	; 3
    1400:	0e 94 97 06 	call	0xd2e	; 0xd2e <xQueueGenericCreate>
    1404:	90 93 2d 04 	sts	0x042D, r25
    1408:	80 93 2c 04 	sts	0x042C, r24
	
	/*  Start Scheduler */
	vTaskStartScheduler();
    140c:	0e 94 67 0d 	call	0x1ace	; 0x1ace <vTaskStartScheduler>
    1410:	ff cf       	rjmp	.-2      	; 0x1410 <main+0x54>

00001412 <__vector_1>:
// }
*/


ISR(INT0_vect)
{
    1412:	1f 92       	push	r1
    1414:	0f 92       	push	r0
    1416:	0f b6       	in	r0, 0x3f	; 63
    1418:	0f 92       	push	r0
    141a:	11 24       	eor	r1, r1
    141c:	2f 93       	push	r18
    141e:	3f 93       	push	r19
    1420:	4f 93       	push	r20
    1422:	5f 93       	push	r21
    1424:	6f 93       	push	r22
    1426:	7f 93       	push	r23
    1428:	8f 93       	push	r24
    142a:	9f 93       	push	r25
    142c:	af 93       	push	r26
    142e:	bf 93       	push	r27
    1430:	ef 93       	push	r30
    1432:	ff 93       	push	r31
	xSemaphoreGiveFromISR(my_sem,NULL);
    1434:	80 91 2c 04 	lds	r24, 0x042C
    1438:	90 91 2d 04 	lds	r25, 0x042D
    143c:	60 e0       	ldi	r22, 0x00	; 0
    143e:	70 e0       	ldi	r23, 0x00	; 0
    1440:	0e 94 ba 07 	call	0xf74	; 0xf74 <xQueueGiveFromISR>
    1444:	ff 91       	pop	r31
    1446:	ef 91       	pop	r30
    1448:	bf 91       	pop	r27
    144a:	af 91       	pop	r26
    144c:	9f 91       	pop	r25
    144e:	8f 91       	pop	r24
    1450:	7f 91       	pop	r23
    1452:	6f 91       	pop	r22
    1454:	5f 91       	pop	r21
    1456:	4f 91       	pop	r20
    1458:	3f 91       	pop	r19
    145a:	2f 91       	pop	r18
    145c:	0f 90       	pop	r0
    145e:	0f be       	out	0x3f, r0	; 63
    1460:	0f 90       	pop	r0
    1462:	1f 90       	pop	r1
    1464:	18 95       	reti

00001466 <prvTaskIsTaskSuspended>:
/*-----------------------------------------------------------*/

#if ( INCLUDE_vTaskSuspend == 1 )

	static BaseType_t prvTaskIsTaskSuspended( const TaskHandle_t xTask )
	{
    1466:	fc 01       	movw	r30, r24

		/* It does not make sense to check if the calling task is suspended. */
		configASSERT( xTask );

		/* Is the task being resumed actually in the suspended list? */
		if( listIS_CONTAINED_WITHIN( &xSuspendedTaskList, &( pxTCB->xStateListItem ) ) != pdFALSE )
    1468:	82 85       	ldd	r24, Z+10	; 0x0a
    146a:	93 85       	ldd	r25, Z+11	; 0x0b
    146c:	24 e0       	ldi	r18, 0x04	; 4
    146e:	81 30       	cpi	r24, 0x01	; 1
    1470:	92 07       	cpc	r25, r18
    1472:	61 f4       	brne	.+24     	; 0x148c <prvTaskIsTaskSuspended+0x26>
		{
			/* Has the task already been resumed from within an ISR? */
			if( listIS_CONTAINED_WITHIN( &xPendingReadyList, &( pxTCB->xEventListItem ) ) == pdFALSE )
    1474:	24 89       	ldd	r18, Z+20	; 0x14
    1476:	35 89       	ldd	r19, Z+21	; 0x15
    1478:	83 e0       	ldi	r24, 0x03	; 3
    147a:	2f 3e       	cpi	r18, 0xEF	; 239
    147c:	38 07       	cpc	r19, r24
    147e:	41 f0       	breq	.+16     	; 0x1490 <prvTaskIsTaskSuspended+0x2a>

#if ( INCLUDE_vTaskSuspend == 1 )

	static BaseType_t prvTaskIsTaskSuspended( const TaskHandle_t xTask )
	{
	BaseType_t xReturn = pdFALSE;
    1480:	81 e0       	ldi	r24, 0x01	; 1
    1482:	21 15       	cp	r18, r1
    1484:	31 05       	cpc	r19, r1
    1486:	29 f0       	breq	.+10     	; 0x1492 <prvTaskIsTaskSuspended+0x2c>
    1488:	80 e0       	ldi	r24, 0x00	; 0
    148a:	08 95       	ret
    148c:	80 e0       	ldi	r24, 0x00	; 0
    148e:	08 95       	ret
    1490:	80 e0       	ldi	r24, 0x00	; 0
		{
			mtCOVERAGE_TEST_MARKER();
		}

		return xReturn;
	} /*lint !e818 xTask cannot be a pointer to const because it is a typedef. */
    1492:	08 95       	ret

00001494 <prvResetNextTaskUnblockTime>:

static void prvResetNextTaskUnblockTime( void )
{
TCB_t *pxTCB;

	if( listLIST_IS_EMPTY( pxDelayedTaskList ) != pdFALSE )
    1494:	e0 91 ad 03 	lds	r30, 0x03AD
    1498:	f0 91 ae 03 	lds	r31, 0x03AE
    149c:	80 81       	ld	r24, Z
    149e:	88 23       	and	r24, r24
    14a0:	39 f4       	brne	.+14     	; 0x14b0 <prvResetNextTaskUnblockTime+0x1c>
	{
		/* The new current delayed list is empty.  Set xNextTaskUnblockTime to
		the maximum possible value so it is	extremely unlikely that the
		if( xTickCount >= xNextTaskUnblockTime ) test will pass until
		there is an item in the delayed list. */
		xNextTaskUnblockTime = portMAX_DELAY;
    14a2:	8f ef       	ldi	r24, 0xFF	; 255
    14a4:	9f ef       	ldi	r25, 0xFF	; 255
    14a6:	90 93 a1 03 	sts	0x03A1, r25
    14aa:	80 93 a0 03 	sts	0x03A0, r24
    14ae:	08 95       	ret
	{
		/* The new current delayed list is not empty, get the value of
		the item at the head of the delayed list.  This is the time at
		which the task at the head of the delayed list should be removed
		from the Blocked state. */
		( pxTCB ) = ( TCB_t * ) listGET_OWNER_OF_HEAD_ENTRY( pxDelayedTaskList );
    14b0:	e0 91 ad 03 	lds	r30, 0x03AD
    14b4:	f0 91 ae 03 	lds	r31, 0x03AE
    14b8:	05 80       	ldd	r0, Z+5	; 0x05
    14ba:	f6 81       	ldd	r31, Z+6	; 0x06
    14bc:	e0 2d       	mov	r30, r0
		xNextTaskUnblockTime = listGET_LIST_ITEM_VALUE( &( ( pxTCB )->xStateListItem ) );
    14be:	06 80       	ldd	r0, Z+6	; 0x06
    14c0:	f7 81       	ldd	r31, Z+7	; 0x07
    14c2:	e0 2d       	mov	r30, r0
    14c4:	82 81       	ldd	r24, Z+2	; 0x02
    14c6:	93 81       	ldd	r25, Z+3	; 0x03
    14c8:	90 93 a1 03 	sts	0x03A1, r25
    14cc:	80 93 a0 03 	sts	0x03A0, r24
    14d0:	08 95       	ret

000014d2 <prvAddCurrentTaskToDelayedList>:
#endif /* configUSE_TASK_NOTIFICATIONS */
/*-----------------------------------------------------------*/


static void prvAddCurrentTaskToDelayedList( TickType_t xTicksToWait, const BaseType_t xCanBlockIndefinitely )
{
    14d2:	ef 92       	push	r14
    14d4:	ff 92       	push	r15
    14d6:	1f 93       	push	r17
    14d8:	cf 93       	push	r28
    14da:	df 93       	push	r29
    14dc:	ec 01       	movw	r28, r24
    14de:	16 2f       	mov	r17, r22
TickType_t xTimeToWake;
const TickType_t xConstTickCount = xTickCount;
    14e0:	e0 90 a7 03 	lds	r14, 0x03A7
    14e4:	f0 90 a8 03 	lds	r15, 0x03A8
	}
	#endif

	/* Remove the task from the ready list before adding it to the blocked list
	as the same list item is used for both lists. */
	if( uxListRemove( &( pxCurrentTCB->xStateListItem ) ) == ( UBaseType_t ) 0 )
    14e8:	80 91 9d 03 	lds	r24, 0x039D
    14ec:	90 91 9e 03 	lds	r25, 0x039E
    14f0:	02 96       	adiw	r24, 0x02	; 2
    14f2:	0e 94 ce 03 	call	0x79c	; 0x79c <uxListRemove>
		mtCOVERAGE_TEST_MARKER();
	}

	#if ( INCLUDE_vTaskSuspend == 1 )
	{
		if( ( xTicksToWait == portMAX_DELAY ) && ( xCanBlockIndefinitely != pdFALSE ) )
    14f6:	8f ef       	ldi	r24, 0xFF	; 255
    14f8:	cf 3f       	cpi	r28, 0xFF	; 255
    14fa:	d8 07       	cpc	r29, r24
    14fc:	69 f4       	brne	.+26     	; 0x1518 <prvAddCurrentTaskToDelayedList+0x46>
    14fe:	11 23       	and	r17, r17
    1500:	59 f0       	breq	.+22     	; 0x1518 <prvAddCurrentTaskToDelayedList+0x46>
		{
			/* Add the task to the suspended task list instead of a delayed task
			list to ensure it is not woken by a timing event.  It will block
			indefinitely. */
			vListInsertEnd( &xSuspendedTaskList, &( pxCurrentTCB->xStateListItem ) );
    1502:	60 91 9d 03 	lds	r22, 0x039D
    1506:	70 91 9e 03 	lds	r23, 0x039E
    150a:	6e 5f       	subi	r22, 0xFE	; 254
    150c:	7f 4f       	sbci	r23, 0xFF	; 255
    150e:	81 e0       	ldi	r24, 0x01	; 1
    1510:	94 e0       	ldi	r25, 0x04	; 4
    1512:	0e 94 7d 03 	call	0x6fa	; 0x6fa <vListInsertEnd>
    1516:	2f c0       	rjmp	.+94     	; 0x1576 <prvAddCurrentTaskToDelayedList+0xa4>
		else
		{
			/* Calculate the time at which the task should be woken if the event
			does not occur.  This may overflow but this doesn't matter, the
			kernel will manage it correctly. */
			xTimeToWake = xConstTickCount + xTicksToWait;
    1518:	ce 0d       	add	r28, r14
    151a:	df 1d       	adc	r29, r15

			/* The list item will be inserted in wake time order. */
			listSET_LIST_ITEM_VALUE( &( pxCurrentTCB->xStateListItem ), xTimeToWake );
    151c:	e0 91 9d 03 	lds	r30, 0x039D
    1520:	f0 91 9e 03 	lds	r31, 0x039E
    1524:	d3 83       	std	Z+3, r29	; 0x03
    1526:	c2 83       	std	Z+2, r28	; 0x02

			if( xTimeToWake < xConstTickCount )
    1528:	ce 15       	cp	r28, r14
    152a:	df 05       	cpc	r29, r15
    152c:	68 f4       	brcc	.+26     	; 0x1548 <prvAddCurrentTaskToDelayedList+0x76>
			{
				/* Wake time has overflowed.  Place this item in the overflow
				list. */
				vListInsert( pxOverflowDelayedTaskList, &( pxCurrentTCB->xStateListItem ) );
    152e:	80 91 ab 03 	lds	r24, 0x03AB
    1532:	90 91 ac 03 	lds	r25, 0x03AC
    1536:	60 91 9d 03 	lds	r22, 0x039D
    153a:	70 91 9e 03 	lds	r23, 0x039E
    153e:	6e 5f       	subi	r22, 0xFE	; 254
    1540:	7f 4f       	sbci	r23, 0xFF	; 255
    1542:	0e 94 9c 03 	call	0x738	; 0x738 <vListInsert>
    1546:	17 c0       	rjmp	.+46     	; 0x1576 <prvAddCurrentTaskToDelayedList+0xa4>
			}
			else
			{
				/* The wake time has not overflowed, so the current block list
				is used. */
				vListInsert( pxDelayedTaskList, &( pxCurrentTCB->xStateListItem ) );
    1548:	80 91 ad 03 	lds	r24, 0x03AD
    154c:	90 91 ae 03 	lds	r25, 0x03AE
    1550:	60 91 9d 03 	lds	r22, 0x039D
    1554:	70 91 9e 03 	lds	r23, 0x039E
    1558:	6e 5f       	subi	r22, 0xFE	; 254
    155a:	7f 4f       	sbci	r23, 0xFF	; 255
    155c:	0e 94 9c 03 	call	0x738	; 0x738 <vListInsert>

				/* If the task entering the blocked state was placed at the
				head of the list of blocked tasks then xNextTaskUnblockTime
				needs to be updated too. */
				if( xTimeToWake < xNextTaskUnblockTime )
    1560:	80 91 a0 03 	lds	r24, 0x03A0
    1564:	90 91 a1 03 	lds	r25, 0x03A1
    1568:	c8 17       	cp	r28, r24
    156a:	d9 07       	cpc	r29, r25
    156c:	20 f4       	brcc	.+8      	; 0x1576 <prvAddCurrentTaskToDelayedList+0xa4>
				{
					xNextTaskUnblockTime = xTimeToWake;
    156e:	d0 93 a1 03 	sts	0x03A1, r29
    1572:	c0 93 a0 03 	sts	0x03A0, r28

		/* Avoid compiler warning when INCLUDE_vTaskSuspend is not 1. */
		( void ) xCanBlockIndefinitely;
	}
	#endif /* INCLUDE_vTaskSuspend */
}
    1576:	df 91       	pop	r29
    1578:	cf 91       	pop	r28
    157a:	1f 91       	pop	r17
    157c:	ff 90       	pop	r15
    157e:	ef 90       	pop	r14
    1580:	08 95       	ret

00001582 <prvDeleteTCB>:
/*-----------------------------------------------------------*/

#if ( INCLUDE_vTaskDelete == 1 )

	static void prvDeleteTCB( TCB_t *pxTCB )
	{
    1582:	cf 93       	push	r28
    1584:	df 93       	push	r29
    1586:	ec 01       	movw	r28, r24

		#if( ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) && ( configSUPPORT_STATIC_ALLOCATION == 0 ) && ( portUSING_MPU_WRAPPERS == 0 ) )
		{
			/* The task can only have been allocated dynamically - free both
			the stack and TCB. */
			vPortFree( pxTCB->pxStack );
    1588:	8f 89       	ldd	r24, Y+23	; 0x17
    158a:	98 8d       	ldd	r25, Y+24	; 0x18
    158c:	0e 94 32 03 	call	0x664	; 0x664 <vPortFree>
			vPortFree( pxTCB );
    1590:	ce 01       	movw	r24, r28
    1592:	0e 94 32 03 	call	0x664	; 0x664 <vPortFree>
				configASSERT( pxTCB->ucStaticallyAllocated == tskSTATICALLY_ALLOCATED_STACK_AND_TCB	)
				mtCOVERAGE_TEST_MARKER();
			}
		}
		#endif /* configSUPPORT_DYNAMIC_ALLOCATION */
	}
    1596:	df 91       	pop	r29
    1598:	cf 91       	pop	r28
    159a:	08 95       	ret

0000159c <xTaskCreate>:
							const char * const pcName,
							const uint16_t usStackDepth,
							void * const pvParameters,
							UBaseType_t uxPriority,
							TaskHandle_t * const pxCreatedTask ) /*lint !e971 Unqualified char types are allowed for strings and single characters only. */
	{
    159c:	2f 92       	push	r2
    159e:	3f 92       	push	r3
    15a0:	4f 92       	push	r4
    15a2:	5f 92       	push	r5
    15a4:	6f 92       	push	r6
    15a6:	7f 92       	push	r7
    15a8:	8f 92       	push	r8
    15aa:	9f 92       	push	r9
    15ac:	af 92       	push	r10
    15ae:	bf 92       	push	r11
    15b0:	df 92       	push	r13
    15b2:	ef 92       	push	r14
    15b4:	ff 92       	push	r15
    15b6:	0f 93       	push	r16
    15b8:	1f 93       	push	r17
    15ba:	cf 93       	push	r28
    15bc:	df 93       	push	r29
    15be:	3c 01       	movw	r6, r24
    15c0:	5b 01       	movw	r10, r22
    15c2:	ea 01       	movw	r28, r20
    15c4:	29 01       	movw	r4, r18
    15c6:	d0 2e       	mov	r13, r16
    15c8:	47 01       	movw	r8, r14
		#else /* portSTACK_GROWTH */
		{
		StackType_t *pxStack;

			/* Allocate space for the stack used by the task being created. */
			pxStack = ( StackType_t * ) pvPortMalloc( ( ( ( size_t ) usStackDepth ) * sizeof( StackType_t ) ) ); /*lint !e961 MISRA exception as the casts are only redundant for some ports. */
    15ca:	ca 01       	movw	r24, r20
    15cc:	0e 94 92 02 	call	0x524	; 0x524 <pvPortMalloc>
    15d0:	7c 01       	movw	r14, r24

			if( pxStack != NULL )
    15d2:	00 97       	sbiw	r24, 0x00	; 0
    15d4:	09 f4       	brne	.+2      	; 0x15d8 <xTaskCreate+0x3c>
    15d6:	ed c0       	rjmp	.+474    	; 0x17b2 <xTaskCreate+0x216>
			{
				/* Allocate space for the TCB. */
				pxNewTCB = ( TCB_t * ) pvPortMalloc( sizeof( TCB_t ) ); /*lint !e961 MISRA exception as the casts are only redundant for some paths. */
    15d8:	8a e2       	ldi	r24, 0x2A	; 42
    15da:	90 e0       	ldi	r25, 0x00	; 0
    15dc:	0e 94 92 02 	call	0x524	; 0x524 <pvPortMalloc>
    15e0:	8c 01       	movw	r16, r24

				if( pxNewTCB != NULL )
    15e2:	00 97       	sbiw	r24, 0x00	; 0
    15e4:	81 f0       	breq	.+32     	; 0x1606 <xTaskCreate+0x6a>
				{
					/* Store the stack location in the TCB. */
					pxNewTCB->pxStack = pxStack;
    15e6:	fc 01       	movw	r30, r24
    15e8:	f0 8e       	std	Z+24, r15	; 0x18
    15ea:	e7 8a       	std	Z+23, r14	; 0x17
	grows from high memory to low (as per the 80x86) or vice versa.
	portSTACK_GROWTH is used to make the result positive or negative as required
	by the port. */
	#if( portSTACK_GROWTH < 0 )
	{
		pxTopOfStack = pxNewTCB->pxStack + ( ulStackDepth - ( uint32_t ) 1 );
    15ec:	21 97       	sbiw	r28, 0x01	; 1
    15ee:	17 01       	movw	r2, r14
    15f0:	2c 0e       	add	r2, r28
    15f2:	3d 1e       	adc	r3, r29
	#endif /* portSTACK_GROWTH */

	/* Store the task name in the TCB. */
	for( x = ( UBaseType_t ) 0; x < ( UBaseType_t ) configMAX_TASK_NAME_LEN; x++ )
	{
		pxNewTCB->pcTaskName[ x ] = pcName[ x ];
    15f4:	f5 01       	movw	r30, r10
    15f6:	80 81       	ld	r24, Z
    15f8:	f8 01       	movw	r30, r16
    15fa:	81 8f       	std	Z+25, r24	; 0x19

		/* Don't copy all configMAX_TASK_NAME_LEN if the string is shorter than
		configMAX_TASK_NAME_LEN characters just in case the memory after the
		string is not accessible (extremely unlikely). */
		if( pcName[ x ] == 0x00 )
    15fc:	f5 01       	movw	r30, r10
    15fe:	80 81       	ld	r24, Z
    1600:	88 23       	and	r24, r24
    1602:	31 f4       	brne	.+12     	; 0x1610 <xTaskCreate+0x74>
    1604:	13 c0       	rjmp	.+38     	; 0x162c <xTaskCreate+0x90>
				}
				else
				{
					/* The stack cannot be used as the TCB was not created.  Free
					it again. */
					vPortFree( pxStack );
    1606:	c7 01       	movw	r24, r14
    1608:	0e 94 32 03 	call	0x664	; 0x664 <vPortFree>
			prvAddNewTaskToReadyList( pxNewTCB );
			xReturn = pdPASS;
		}
		else
		{
			xReturn = errCOULD_NOT_ALLOCATE_REQUIRED_MEMORY;
    160c:	8f ef       	ldi	r24, 0xFF	; 255
    160e:	d6 c0       	rjmp	.+428    	; 0x17bc <xTaskCreate+0x220>
#endif /* portUSING_MPU_WRAPPERS */
/*-----------------------------------------------------------*/

#if( configSUPPORT_DYNAMIC_ALLOCATION == 1 )

	BaseType_t xTaskCreate(	TaskFunction_t pxTaskCode,
    1610:	e8 01       	movw	r28, r16
    1612:	6a 96       	adiw	r28, 0x1a	; 26
    1614:	d5 01       	movw	r26, r10
    1616:	11 96       	adiw	r26, 0x01	; 1
		pxNewTCB->pxEndOfStack = pxNewTCB->pxStack + ( ulStackDepth - ( uint32_t ) 1 );
	}
	#endif /* portSTACK_GROWTH */

	/* Store the task name in the TCB. */
	for( x = ( UBaseType_t ) 0; x < ( UBaseType_t ) configMAX_TASK_NAME_LEN; x++ )
    1618:	81 e0       	ldi	r24, 0x01	; 1
#endif /* portUSING_MPU_WRAPPERS */
/*-----------------------------------------------------------*/

#if( configSUPPORT_DYNAMIC_ALLOCATION == 1 )

	BaseType_t xTaskCreate(	TaskFunction_t pxTaskCode,
    161a:	fd 01       	movw	r30, r26
	#endif /* portSTACK_GROWTH */

	/* Store the task name in the TCB. */
	for( x = ( UBaseType_t ) 0; x < ( UBaseType_t ) configMAX_TASK_NAME_LEN; x++ )
	{
		pxNewTCB->pcTaskName[ x ] = pcName[ x ];
    161c:	9d 91       	ld	r25, X+
    161e:	99 93       	st	Y+, r25

		/* Don't copy all configMAX_TASK_NAME_LEN if the string is shorter than
		configMAX_TASK_NAME_LEN characters just in case the memory after the
		string is not accessible (extremely unlikely). */
		if( pcName[ x ] == 0x00 )
    1620:	90 81       	ld	r25, Z
    1622:	99 23       	and	r25, r25
    1624:	19 f0       	breq	.+6      	; 0x162c <xTaskCreate+0x90>
		pxNewTCB->pxEndOfStack = pxNewTCB->pxStack + ( ulStackDepth - ( uint32_t ) 1 );
	}
	#endif /* portSTACK_GROWTH */

	/* Store the task name in the TCB. */
	for( x = ( UBaseType_t ) 0; x < ( UBaseType_t ) configMAX_TASK_NAME_LEN; x++ )
    1626:	8f 5f       	subi	r24, 0xFF	; 255
    1628:	8a 30       	cpi	r24, 0x0A	; 10
    162a:	b9 f7       	brne	.-18     	; 0x161a <xTaskCreate+0x7e>
		}
	}

	/* Ensure the name string is terminated in the case that the string length
	was greater or equal to configMAX_TASK_NAME_LEN. */
	pxNewTCB->pcTaskName[ configMAX_TASK_NAME_LEN - 1 ] = '\0';
    162c:	f8 01       	movw	r30, r16
    162e:	12 a2       	lds	r17, 0x92
    1630:	cd 2d       	mov	r28, r13
    1632:	c5 30       	cpi	r28, 0x05	; 5
    1634:	08 f0       	brcs	.+2      	; 0x1638 <xTaskCreate+0x9c>
    1636:	c4 e0       	ldi	r28, 0x04	; 4
	else
	{
		mtCOVERAGE_TEST_MARKER();
	}

	pxNewTCB->uxPriority = uxPriority;
    1638:	f8 01       	movw	r30, r16
    163a:	c6 8b       	std	Z+22, r28	; 0x16
	#if ( configUSE_MUTEXES == 1 )
	{
		pxNewTCB->uxBasePriority = uxPriority;
    163c:	c3 a3       	lds	r28, 0x53
		pxNewTCB->uxMutexesHeld = 0;
    163e:	14 a2       	lds	r17, 0x94
	}
	#endif /* configUSE_MUTEXES */

	vListInitialiseItem( &( pxNewTCB->xStateListItem ) );
    1640:	ee 24       	eor	r14, r14
    1642:	ff 24       	eor	r15, r15
    1644:	68 94       	set
    1646:	e1 f8       	bld	r14, 1
    1648:	e0 0e       	add	r14, r16
    164a:	f1 1e       	adc	r15, r17
    164c:	c7 01       	movw	r24, r14
    164e:	0e 94 79 03 	call	0x6f2	; 0x6f2 <vListInitialiseItem>
	vListInitialiseItem( &( pxNewTCB->xEventListItem ) );
    1652:	c8 01       	movw	r24, r16
    1654:	0c 96       	adiw	r24, 0x0c	; 12
    1656:	0e 94 79 03 	call	0x6f2	; 0x6f2 <vListInitialiseItem>

	/* Set the pxNewTCB as a link back from the ListItem_t.  This is so we can get
	back to	the containing TCB from a generic item in a list. */
	listSET_LIST_ITEM_OWNER( &( pxNewTCB->xStateListItem ), pxNewTCB );
    165a:	f8 01       	movw	r30, r16
    165c:	11 87       	std	Z+9, r17	; 0x09
    165e:	00 87       	std	Z+8, r16	; 0x08

	/* Event lists are always in priority order. */
	listSET_LIST_ITEM_VALUE( &( pxNewTCB->xEventListItem ), ( TickType_t ) configMAX_PRIORITIES - ( TickType_t ) uxPriority ); /*lint !e961 MISRA exception as the casts are only redundant for some ports. */
    1660:	85 e0       	ldi	r24, 0x05	; 5
    1662:	90 e0       	ldi	r25, 0x00	; 0
    1664:	8c 1b       	sub	r24, r28
    1666:	91 09       	sbc	r25, r1
    1668:	95 87       	std	Z+13, r25	; 0x0d
    166a:	84 87       	std	Z+12, r24	; 0x0c
	listSET_LIST_ITEM_OWNER( &( pxNewTCB->xEventListItem ), pxNewTCB );
    166c:	13 8b       	std	Z+19, r17	; 0x13
    166e:	02 8b       	std	Z+18, r16	; 0x12
	}
	#endif

	#if ( configUSE_TASK_NOTIFICATIONS == 1 )
	{
		pxNewTCB->ulNotifiedValue = 0;
    1670:	15 a2       	lds	r17, 0x95
    1672:	16 a2       	lds	r17, 0x96
    1674:	17 a2       	lds	r17, 0x97
    1676:	10 a6       	lds	r17, 0xb0
		pxNewTCB->ucNotifyState = taskNOT_WAITING_NOTIFICATION;
    1678:	11 a6       	lds	r17, 0xb1
	{
		pxNewTCB->pxTopOfStack = pxPortInitialiseStack( pxTopOfStack, pxTaskCode, pvParameters, xRunPrivileged );
	}
	#else /* portUSING_MPU_WRAPPERS */
	{
		pxNewTCB->pxTopOfStack = pxPortInitialiseStack( pxTopOfStack, pxTaskCode, pvParameters );
    167a:	c1 01       	movw	r24, r2
    167c:	b3 01       	movw	r22, r6
    167e:	a2 01       	movw	r20, r4
    1680:	0e 94 f6 03 	call	0x7ec	; 0x7ec <pxPortInitialiseStack>
    1684:	f8 01       	movw	r30, r16
    1686:	91 83       	std	Z+1, r25	; 0x01
    1688:	80 83       	st	Z, r24
	}
	#endif /* portUSING_MPU_WRAPPERS */

	if( ( void * ) pxCreatedTask != NULL )
    168a:	81 14       	cp	r8, r1
    168c:	91 04       	cpc	r9, r1
    168e:	19 f0       	breq	.+6      	; 0x1696 <xTaskCreate+0xfa>
	{
		/* Pass the handle out in an anonymous way.  The handle can be used to
		change the created task's priority, delete the created task, etc.*/
		*pxCreatedTask = ( TaskHandle_t ) pxNewTCB;
    1690:	f4 01       	movw	r30, r8
    1692:	11 83       	std	Z+1, r17	; 0x01
    1694:	00 83       	st	Z, r16

static void prvAddNewTaskToReadyList( TCB_t *pxNewTCB )
{
	/* Ensure interrupts don't access the task lists while the lists are being
	updated. */
	taskENTER_CRITICAL();
    1696:	0f b6       	in	r0, 0x3f	; 63
    1698:	f8 94       	cli
    169a:	0f 92       	push	r0
	{
		uxCurrentNumberOfTasks++;
    169c:	80 91 a9 03 	lds	r24, 0x03A9
    16a0:	8f 5f       	subi	r24, 0xFF	; 255
    16a2:	80 93 a9 03 	sts	0x03A9, r24
		if( pxCurrentTCB == NULL )
    16a6:	80 91 9d 03 	lds	r24, 0x039D
    16aa:	90 91 9e 03 	lds	r25, 0x039E
    16ae:	00 97       	sbiw	r24, 0x00	; 0
    16b0:	09 f0       	breq	.+2      	; 0x16b4 <xTaskCreate+0x118>
    16b2:	3f c0       	rjmp	.+126    	; 0x1732 <xTaskCreate+0x196>
		{
			/* There are no other tasks, or all the other tasks are in
			the suspended state - make this the current task. */
			pxCurrentTCB = pxNewTCB;
    16b4:	10 93 9e 03 	sts	0x039E, r17
    16b8:	00 93 9d 03 	sts	0x039D, r16

			if( uxCurrentNumberOfTasks == ( UBaseType_t ) 1 )
    16bc:	80 91 a9 03 	lds	r24, 0x03A9
    16c0:	81 30       	cpi	r24, 0x01	; 1
    16c2:	09 f0       	breq	.+2      	; 0x16c6 <xTaskCreate+0x12a>
    16c4:	47 c0       	rjmp	.+142    	; 0x1754 <xTaskCreate+0x1b8>
    16c6:	c0 e0       	ldi	r28, 0x00	; 0
    16c8:	d0 e0       	ldi	r29, 0x00	; 0
{
UBaseType_t uxPriority;

	for( uxPriority = ( UBaseType_t ) 0U; uxPriority < ( UBaseType_t ) configMAX_PRIORITIES; uxPriority++ )
	{
		vListInitialise( &( pxReadyTasksLists[ uxPriority ] ) );
    16ca:	ce 01       	movw	r24, r28
    16cc:	88 0f       	add	r24, r24
    16ce:	99 1f       	adc	r25, r25
    16d0:	88 0f       	add	r24, r24
    16d2:	99 1f       	adc	r25, r25
    16d4:	88 0f       	add	r24, r24
    16d6:	99 1f       	adc	r25, r25
    16d8:	8c 0f       	add	r24, r28
    16da:	9d 1f       	adc	r25, r29
    16dc:	80 55       	subi	r24, 0x50	; 80
    16de:	9c 4f       	sbci	r25, 0xFC	; 252
    16e0:	0e 94 6b 03 	call	0x6d6	; 0x6d6 <vListInitialise>
    16e4:	21 96       	adiw	r28, 0x01	; 1

static void prvInitialiseTaskLists( void )
{
UBaseType_t uxPriority;

	for( uxPriority = ( UBaseType_t ) 0U; uxPriority < ( UBaseType_t ) configMAX_PRIORITIES; uxPriority++ )
    16e6:	c5 30       	cpi	r28, 0x05	; 5
    16e8:	d1 05       	cpc	r29, r1
    16ea:	79 f7       	brne	.-34     	; 0x16ca <xTaskCreate+0x12e>
	{
		vListInitialise( &( pxReadyTasksLists[ uxPriority ] ) );
	}

	vListInitialise( &xDelayedTaskList1 );
    16ec:	cd ed       	ldi	r28, 0xDD	; 221
    16ee:	d3 e0       	ldi	r29, 0x03	; 3
    16f0:	ce 01       	movw	r24, r28
    16f2:	0e 94 6b 03 	call	0x6d6	; 0x6d6 <vListInitialise>
	vListInitialise( &xDelayedTaskList2 );
    16f6:	0f 2e       	mov	r0, r31
    16f8:	f6 ee       	ldi	r31, 0xE6	; 230
    16fa:	af 2e       	mov	r10, r31
    16fc:	f3 e0       	ldi	r31, 0x03	; 3
    16fe:	bf 2e       	mov	r11, r31
    1700:	f0 2d       	mov	r31, r0
    1702:	c5 01       	movw	r24, r10
    1704:	0e 94 6b 03 	call	0x6d6	; 0x6d6 <vListInitialise>
	vListInitialise( &xPendingReadyList );
    1708:	8f ee       	ldi	r24, 0xEF	; 239
    170a:	93 e0       	ldi	r25, 0x03	; 3
    170c:	0e 94 6b 03 	call	0x6d6	; 0x6d6 <vListInitialise>

	#if ( INCLUDE_vTaskDelete == 1 )
	{
		vListInitialise( &xTasksWaitingTermination );
    1710:	88 ef       	ldi	r24, 0xF8	; 248
    1712:	93 e0       	ldi	r25, 0x03	; 3
    1714:	0e 94 6b 03 	call	0x6d6	; 0x6d6 <vListInitialise>
	}
	#endif /* INCLUDE_vTaskDelete */

	#if ( INCLUDE_vTaskSuspend == 1 )
	{
		vListInitialise( &xSuspendedTaskList );
    1718:	81 e0       	ldi	r24, 0x01	; 1
    171a:	94 e0       	ldi	r25, 0x04	; 4
    171c:	0e 94 6b 03 	call	0x6d6	; 0x6d6 <vListInitialise>
	}
	#endif /* INCLUDE_vTaskSuspend */

	/* Start with pxDelayedTaskList using list1 and the pxOverflowDelayedTaskList
	using list2. */
	pxDelayedTaskList = &xDelayedTaskList1;
    1720:	d0 93 ae 03 	sts	0x03AE, r29
    1724:	c0 93 ad 03 	sts	0x03AD, r28
	pxOverflowDelayedTaskList = &xDelayedTaskList2;
    1728:	b0 92 ac 03 	sts	0x03AC, r11
    172c:	a0 92 ab 03 	sts	0x03AB, r10
    1730:	11 c0       	rjmp	.+34     	; 0x1754 <xTaskCreate+0x1b8>
		else
		{
			/* If the scheduler is not already running, make this task the
			current task if it is the highest priority task to be created
			so far. */
			if( xSchedulerRunning == pdFALSE )
    1732:	80 91 a5 03 	lds	r24, 0x03A5
    1736:	88 23       	and	r24, r24
    1738:	69 f4       	brne	.+26     	; 0x1754 <xTaskCreate+0x1b8>
			{
				if( pxCurrentTCB->uxPriority <= pxNewTCB->uxPriority )
    173a:	e0 91 9d 03 	lds	r30, 0x039D
    173e:	f0 91 9e 03 	lds	r31, 0x039E
    1742:	96 89       	ldd	r25, Z+22	; 0x16
    1744:	f8 01       	movw	r30, r16
    1746:	86 89       	ldd	r24, Z+22	; 0x16
    1748:	89 17       	cp	r24, r25
    174a:	20 f0       	brcs	.+8      	; 0x1754 <xTaskCreate+0x1b8>
				{
					pxCurrentTCB = pxNewTCB;
    174c:	10 93 9e 03 	sts	0x039E, r17
    1750:	00 93 9d 03 	sts	0x039D, r16
			{
				mtCOVERAGE_TEST_MARKER();
			}
		}

		uxTaskNumber++;
    1754:	80 91 af 03 	lds	r24, 0x03AF
    1758:	8f 5f       	subi	r24, 0xFF	; 255
    175a:	80 93 af 03 	sts	0x03AF, r24
			pxNewTCB->uxTCBNumber = uxTaskNumber;
		}
		#endif /* configUSE_TRACE_FACILITY */
		traceTASK_CREATE( pxNewTCB );

		prvAddTaskToReadyList( pxNewTCB );
    175e:	f8 01       	movw	r30, r16
    1760:	86 89       	ldd	r24, Z+22	; 0x16
    1762:	90 91 a6 03 	lds	r25, 0x03A6
    1766:	98 17       	cp	r25, r24
    1768:	10 f4       	brcc	.+4      	; 0x176e <xTaskCreate+0x1d2>
    176a:	80 93 a6 03 	sts	0x03A6, r24
    176e:	90 e0       	ldi	r25, 0x00	; 0
    1770:	9c 01       	movw	r18, r24
    1772:	22 0f       	add	r18, r18
    1774:	33 1f       	adc	r19, r19
    1776:	22 0f       	add	r18, r18
    1778:	33 1f       	adc	r19, r19
    177a:	22 0f       	add	r18, r18
    177c:	33 1f       	adc	r19, r19
    177e:	82 0f       	add	r24, r18
    1780:	93 1f       	adc	r25, r19
    1782:	80 55       	subi	r24, 0x50	; 80
    1784:	9c 4f       	sbci	r25, 0xFC	; 252
    1786:	b7 01       	movw	r22, r14
    1788:	0e 94 7d 03 	call	0x6fa	; 0x6fa <vListInsertEnd>

		portSETUP_TCB( pxNewTCB );
	}
	taskEXIT_CRITICAL();
    178c:	0f 90       	pop	r0
    178e:	0f be       	out	0x3f, r0	; 63

	if( xSchedulerRunning != pdFALSE )
    1790:	80 91 a5 03 	lds	r24, 0x03A5
    1794:	88 23       	and	r24, r24
    1796:	79 f0       	breq	.+30     	; 0x17b6 <xTaskCreate+0x21a>
	{
		/* If the created task is of a higher priority than the current task
		then it should run now. */
		if( pxCurrentTCB->uxPriority < pxNewTCB->uxPriority )
    1798:	e0 91 9d 03 	lds	r30, 0x039D
    179c:	f0 91 9e 03 	lds	r31, 0x039E
    17a0:	96 89       	ldd	r25, Z+22	; 0x16
    17a2:	f8 01       	movw	r30, r16
    17a4:	86 89       	ldd	r24, Z+22	; 0x16
    17a6:	98 17       	cp	r25, r24
    17a8:	40 f4       	brcc	.+16     	; 0x17ba <xTaskCreate+0x21e>
		{
			taskYIELD_IF_USING_PREEMPTION();
    17aa:	0e 94 bc 04 	call	0x978	; 0x978 <vPortYield>
			}
			#endif /* configSUPPORT_STATIC_ALLOCATION */

			prvInitialiseNewTask( pxTaskCode, pcName, ( uint32_t ) usStackDepth, pvParameters, uxPriority, pxCreatedTask, pxNewTCB, NULL );
			prvAddNewTaskToReadyList( pxNewTCB );
			xReturn = pdPASS;
    17ae:	81 e0       	ldi	r24, 0x01	; 1
    17b0:	05 c0       	rjmp	.+10     	; 0x17bc <xTaskCreate+0x220>
		}
		else
		{
			xReturn = errCOULD_NOT_ALLOCATE_REQUIRED_MEMORY;
    17b2:	8f ef       	ldi	r24, 0xFF	; 255
    17b4:	03 c0       	rjmp	.+6      	; 0x17bc <xTaskCreate+0x220>
			}
			#endif /* configSUPPORT_STATIC_ALLOCATION */

			prvInitialiseNewTask( pxTaskCode, pcName, ( uint32_t ) usStackDepth, pvParameters, uxPriority, pxCreatedTask, pxNewTCB, NULL );
			prvAddNewTaskToReadyList( pxNewTCB );
			xReturn = pdPASS;
    17b6:	81 e0       	ldi	r24, 0x01	; 1
    17b8:	01 c0       	rjmp	.+2      	; 0x17bc <xTaskCreate+0x220>
    17ba:	81 e0       	ldi	r24, 0x01	; 1
		{
			xReturn = errCOULD_NOT_ALLOCATE_REQUIRED_MEMORY;
		}

		return xReturn;
	}
    17bc:	df 91       	pop	r29
    17be:	cf 91       	pop	r28
    17c0:	1f 91       	pop	r17
    17c2:	0f 91       	pop	r16
    17c4:	ff 90       	pop	r15
    17c6:	ef 90       	pop	r14
    17c8:	df 90       	pop	r13
    17ca:	bf 90       	pop	r11
    17cc:	af 90       	pop	r10
    17ce:	9f 90       	pop	r9
    17d0:	8f 90       	pop	r8
    17d2:	7f 90       	pop	r7
    17d4:	6f 90       	pop	r6
    17d6:	5f 90       	pop	r5
    17d8:	4f 90       	pop	r4
    17da:	3f 90       	pop	r3
    17dc:	2f 90       	pop	r2
    17de:	08 95       	ret

000017e0 <vTaskDelete>:
/*-----------------------------------------------------------*/

#if ( INCLUDE_vTaskDelete == 1 )

	void vTaskDelete( TaskHandle_t xTaskToDelete )
	{
    17e0:	0f 93       	push	r16
    17e2:	1f 93       	push	r17
    17e4:	cf 93       	push	r28
    17e6:	df 93       	push	r29
	TCB_t *pxTCB;

		taskENTER_CRITICAL();
    17e8:	0f b6       	in	r0, 0x3f	; 63
    17ea:	f8 94       	cli
    17ec:	0f 92       	push	r0
		{
			/* If null is passed in here then it is the calling task that is
			being deleted. */
			pxTCB = prvGetTCBFromHandle( xTaskToDelete );
    17ee:	00 97       	sbiw	r24, 0x00	; 0
    17f0:	29 f4       	brne	.+10     	; 0x17fc <vTaskDelete+0x1c>
    17f2:	c0 91 9d 03 	lds	r28, 0x039D
    17f6:	d0 91 9e 03 	lds	r29, 0x039E
    17fa:	01 c0       	rjmp	.+2      	; 0x17fe <vTaskDelete+0x1e>
    17fc:	ec 01       	movw	r28, r24

			/* Remove task from the ready list. */
			if( uxListRemove( &( pxTCB->xStateListItem ) ) == ( UBaseType_t ) 0 )
    17fe:	8e 01       	movw	r16, r28
    1800:	0e 5f       	subi	r16, 0xFE	; 254
    1802:	1f 4f       	sbci	r17, 0xFF	; 255
    1804:	c8 01       	movw	r24, r16
    1806:	0e 94 ce 03 	call	0x79c	; 0x79c <uxListRemove>
			{
				mtCOVERAGE_TEST_MARKER();
			}

			/* Is the task waiting on an event also? */
			if( listLIST_ITEM_CONTAINER( &( pxTCB->xEventListItem ) ) != NULL )
    180a:	8c 89       	ldd	r24, Y+20	; 0x14
    180c:	9d 89       	ldd	r25, Y+21	; 0x15
    180e:	00 97       	sbiw	r24, 0x00	; 0
    1810:	21 f0       	breq	.+8      	; 0x181a <vTaskDelete+0x3a>
			{
				( void ) uxListRemove( &( pxTCB->xEventListItem ) );
    1812:	ce 01       	movw	r24, r28
    1814:	0c 96       	adiw	r24, 0x0c	; 12
    1816:	0e 94 ce 03 	call	0x79c	; 0x79c <uxListRemove>

			/* Increment the uxTaskNumber also so kernel aware debuggers can
			detect that the task lists need re-generating.  This is done before
			portPRE_TASK_DELETE_HOOK() as in the Windows port that macro will
			not return. */
			uxTaskNumber++;
    181a:	80 91 af 03 	lds	r24, 0x03AF
    181e:	8f 5f       	subi	r24, 0xFF	; 255
    1820:	80 93 af 03 	sts	0x03AF, r24

			if( pxTCB == pxCurrentTCB )
    1824:	80 91 9d 03 	lds	r24, 0x039D
    1828:	90 91 9e 03 	lds	r25, 0x039E
    182c:	c8 17       	cp	r28, r24
    182e:	d9 07       	cpc	r29, r25
    1830:	59 f4       	brne	.+22     	; 0x1848 <vTaskDelete+0x68>
				/* A task is deleting itself.  This cannot complete within the
				task itself, as a context switch to another task is required.
				Place the task in the termination list.  The idle task will
				check the termination list and free up any memory allocated by
				the scheduler for the TCB and stack of the deleted task. */
				vListInsertEnd( &xTasksWaitingTermination, &( pxTCB->xStateListItem ) );
    1832:	88 ef       	ldi	r24, 0xF8	; 248
    1834:	93 e0       	ldi	r25, 0x03	; 3
    1836:	b8 01       	movw	r22, r16
    1838:	0e 94 7d 03 	call	0x6fa	; 0x6fa <vListInsertEnd>

				/* Increment the ucTasksDeleted variable so the idle task knows
				there is a task that has been deleted and that it should therefore
				check the xTasksWaitingTermination list. */
				++uxDeletedTasksWaitingCleanUp;
    183c:	80 91 aa 03 	lds	r24, 0x03AA
    1840:	8f 5f       	subi	r24, 0xFF	; 255
    1842:	80 93 aa 03 	sts	0x03AA, r24
    1846:	0a c0       	rjmp	.+20     	; 0x185c <vTaskDelete+0x7c>
				required. */
				portPRE_TASK_DELETE_HOOK( pxTCB, &xYieldPending );
			}
			else
			{
				--uxCurrentNumberOfTasks;
    1848:	80 91 a9 03 	lds	r24, 0x03A9
    184c:	81 50       	subi	r24, 0x01	; 1
    184e:	80 93 a9 03 	sts	0x03A9, r24
				prvDeleteTCB( pxTCB );
    1852:	ce 01       	movw	r24, r28
    1854:	0e 94 c1 0a 	call	0x1582	; 0x1582 <prvDeleteTCB>

				/* Reset the next expected unblock time in case it referred to
				the task that has just been deleted. */
				prvResetNextTaskUnblockTime();
    1858:	0e 94 4a 0a 	call	0x1494	; 0x1494 <prvResetNextTaskUnblockTime>
			}

			traceTASK_DELETE( pxTCB );
		}
		taskEXIT_CRITICAL();
    185c:	0f 90       	pop	r0
    185e:	0f be       	out	0x3f, r0	; 63

		/* Force a reschedule if it is the currently running task that has just
		been deleted. */
		if( xSchedulerRunning != pdFALSE )
    1860:	80 91 a5 03 	lds	r24, 0x03A5
    1864:	88 23       	and	r24, r24
    1866:	49 f0       	breq	.+18     	; 0x187a <vTaskDelete+0x9a>
		{
			if( pxTCB == pxCurrentTCB )
    1868:	80 91 9d 03 	lds	r24, 0x039D
    186c:	90 91 9e 03 	lds	r25, 0x039E
    1870:	c8 17       	cp	r28, r24
    1872:	d9 07       	cpc	r29, r25
    1874:	11 f4       	brne	.+4      	; 0x187a <vTaskDelete+0x9a>
			{
				configASSERT( uxSchedulerSuspended == 0 );
				portYIELD_WITHIN_API();
    1876:	0e 94 bc 04 	call	0x978	; 0x978 <vPortYield>
			else
			{
				mtCOVERAGE_TEST_MARKER();
			}
		}
	}
    187a:	df 91       	pop	r29
    187c:	cf 91       	pop	r28
    187e:	1f 91       	pop	r17
    1880:	0f 91       	pop	r16
    1882:	08 95       	ret

00001884 <uxTaskPriorityGet>:
	UBaseType_t uxTaskPriorityGet( TaskHandle_t xTask )
	{
	TCB_t *pxTCB;
	UBaseType_t uxReturn;

		taskENTER_CRITICAL();
    1884:	0f b6       	in	r0, 0x3f	; 63
    1886:	f8 94       	cli
    1888:	0f 92       	push	r0
		{
			/* If null is passed in here then it is the priority of the that
			called uxTaskPriorityGet() that is being queried. */
			pxTCB = prvGetTCBFromHandle( xTask );
    188a:	00 97       	sbiw	r24, 0x00	; 0
    188c:	29 f4       	brne	.+10     	; 0x1898 <uxTaskPriorityGet+0x14>
    188e:	e0 91 9d 03 	lds	r30, 0x039D
    1892:	f0 91 9e 03 	lds	r31, 0x039E
    1896:	01 c0       	rjmp	.+2      	; 0x189a <uxTaskPriorityGet+0x16>
    1898:	fc 01       	movw	r30, r24
			uxReturn = pxTCB->uxPriority;
		}
		taskEXIT_CRITICAL();
    189a:	0f 90       	pop	r0
    189c:	0f be       	out	0x3f, r0	; 63

		return uxReturn;
	}
    189e:	86 89       	ldd	r24, Z+22	; 0x16
    18a0:	08 95       	ret

000018a2 <uxTaskPriorityGetFromISR>:

		uxSavedInterruptState = portSET_INTERRUPT_MASK_FROM_ISR();
		{
			/* If null is passed in here then it is the priority of the calling
			task that is being queried. */
			pxTCB = prvGetTCBFromHandle( xTask );
    18a2:	00 97       	sbiw	r24, 0x00	; 0
    18a4:	29 f4       	brne	.+10     	; 0x18b0 <uxTaskPriorityGetFromISR+0xe>
    18a6:	e0 91 9d 03 	lds	r30, 0x039D
    18aa:	f0 91 9e 03 	lds	r31, 0x039E
    18ae:	01 c0       	rjmp	.+2      	; 0x18b2 <uxTaskPriorityGetFromISR+0x10>
    18b0:	fc 01       	movw	r30, r24
			uxReturn = pxTCB->uxPriority;
		}
		portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptState );

		return uxReturn;
	}
    18b2:	86 89       	ldd	r24, Z+22	; 0x16
    18b4:	08 95       	ret

000018b6 <vTaskPrioritySet>:
/*-----------------------------------------------------------*/

#if ( INCLUDE_vTaskPrioritySet == 1 )

	void vTaskPrioritySet( TaskHandle_t xTask, UBaseType_t uxNewPriority )
	{
    18b6:	ef 92       	push	r14
    18b8:	ff 92       	push	r15
    18ba:	1f 93       	push	r17
    18bc:	cf 93       	push	r28
    18be:	df 93       	push	r29
	TCB_t *pxTCB;
	UBaseType_t uxCurrentBasePriority, uxPriorityUsedOnEntry;
	BaseType_t xYieldRequired = pdFALSE;
    18c0:	65 30       	cpi	r22, 0x05	; 5
    18c2:	08 f0       	brcs	.+2      	; 0x18c6 <vTaskPrioritySet+0x10>
    18c4:	64 e0       	ldi	r22, 0x04	; 4
		else
		{
			mtCOVERAGE_TEST_MARKER();
		}

		taskENTER_CRITICAL();
    18c6:	0f b6       	in	r0, 0x3f	; 63
    18c8:	f8 94       	cli
    18ca:	0f 92       	push	r0
		{
			/* If null is passed in here then it is the priority of the calling
			task that is being changed. */
			pxTCB = prvGetTCBFromHandle( xTask );
    18cc:	00 97       	sbiw	r24, 0x00	; 0
    18ce:	29 f4       	brne	.+10     	; 0x18da <vTaskPrioritySet+0x24>
    18d0:	c0 91 9d 03 	lds	r28, 0x039D
    18d4:	d0 91 9e 03 	lds	r29, 0x039E
    18d8:	01 c0       	rjmp	.+2      	; 0x18dc <vTaskPrioritySet+0x26>
    18da:	ec 01       	movw	r28, r24

			traceTASK_PRIORITY_SET( pxTCB, uxNewPriority );

			#if ( configUSE_MUTEXES == 1 )
			{
				uxCurrentBasePriority = pxTCB->uxBasePriority;
    18dc:	2b a1       	lds	r18, 0x4b
			{
				uxCurrentBasePriority = pxTCB->uxPriority;
			}
			#endif

			if( uxCurrentBasePriority != uxNewPriority )
    18de:	26 17       	cp	r18, r22
    18e0:	09 f4       	brne	.+2      	; 0x18e4 <vTaskPrioritySet+0x2e>
    18e2:	61 c0       	rjmp	.+194    	; 0x19a6 <vTaskPrioritySet+0xf0>
			{
				/* The priority change may have readied a task of higher
				priority than the calling task. */
				if( uxNewPriority > uxCurrentBasePriority )
    18e4:	26 17       	cp	r18, r22
    18e6:	88 f4       	brcc	.+34     	; 0x190a <vTaskPrioritySet+0x54>
				{
					if( pxTCB != pxCurrentTCB )
    18e8:	80 91 9d 03 	lds	r24, 0x039D
    18ec:	90 91 9e 03 	lds	r25, 0x039E
    18f0:	c8 17       	cp	r28, r24
    18f2:	d9 07       	cpc	r29, r25
    18f4:	a1 f0       	breq	.+40     	; 0x191e <vTaskPrioritySet+0x68>
					{
						/* The priority of a task other than the currently
						running task is being raised.  Is the priority being
						raised above that of the running task? */
						if( uxNewPriority >= pxCurrentTCB->uxPriority )
    18f6:	e0 91 9d 03 	lds	r30, 0x039D
    18fa:	f0 91 9e 03 	lds	r31, 0x039E
						{
							xYieldRequired = pdTRUE;
    18fe:	11 e0       	ldi	r17, 0x01	; 1
    1900:	86 89       	ldd	r24, Z+22	; 0x16
    1902:	68 17       	cp	r22, r24
    1904:	68 f4       	brcc	.+26     	; 0x1920 <vTaskPrioritySet+0x6a>
    1906:	10 e0       	ldi	r17, 0x00	; 0
    1908:	0b c0       	rjmp	.+22     	; 0x1920 <vTaskPrioritySet+0x6a>
						/* The priority of the running task is being raised,
						but the running task must already be the highest
						priority task able to run so no yield is required. */
					}
				}
				else if( pxTCB == pxCurrentTCB )
    190a:	80 91 9d 03 	lds	r24, 0x039D
    190e:	90 91 9e 03 	lds	r25, 0x039E
						/* The priority of a task other than the currently
						running task is being raised.  Is the priority being
						raised above that of the running task? */
						if( uxNewPriority >= pxCurrentTCB->uxPriority )
						{
							xYieldRequired = pdTRUE;
    1912:	11 e0       	ldi	r17, 0x01	; 1
    1914:	c8 17       	cp	r28, r24
    1916:	d9 07       	cpc	r29, r25
    1918:	19 f0       	breq	.+6      	; 0x1920 <vTaskPrioritySet+0x6a>
    191a:	10 e0       	ldi	r17, 0x00	; 0
    191c:	01 c0       	rjmp	.+2      	; 0x1920 <vTaskPrioritySet+0x6a>

	void vTaskPrioritySet( TaskHandle_t xTask, UBaseType_t uxNewPriority )
	{
	TCB_t *pxTCB;
	UBaseType_t uxCurrentBasePriority, uxPriorityUsedOnEntry;
	BaseType_t xYieldRequired = pdFALSE;
    191e:	10 e0       	ldi	r17, 0x00	; 0
				}

				/* Remember the ready list the task might be referenced from
				before its uxPriority member is changed so the
				taskRESET_READY_PRIORITY() macro can function correctly. */
				uxPriorityUsedOnEntry = pxTCB->uxPriority;
    1920:	8e 89       	ldd	r24, Y+22	; 0x16

				#if ( configUSE_MUTEXES == 1 )
				{
					/* Only change the priority being used if the task is not
					currently using an inherited priority. */
					if( pxTCB->uxBasePriority == pxTCB->uxPriority )
    1922:	28 17       	cp	r18, r24
    1924:	09 f4       	brne	.+2      	; 0x1928 <vTaskPrioritySet+0x72>
					{
						pxTCB->uxPriority = uxNewPriority;
    1926:	6e 8b       	std	Y+22, r22	; 0x16
					{
						mtCOVERAGE_TEST_MARKER();
					}

					/* The base priority gets set whatever. */
					pxTCB->uxBasePriority = uxNewPriority;
    1928:	6b a3       	lds	r22, 0x5b
				}
				#endif

				/* Only reset the event list item value if the value is not
				being used for anything else. */
				if( ( listGET_LIST_ITEM_VALUE( &( pxTCB->xEventListItem ) ) & taskEVENT_LIST_ITEM_VALUE_IN_USE ) == 0UL )
    192a:	2c 85       	ldd	r18, Y+12	; 0x0c
    192c:	3d 85       	ldd	r19, Y+13	; 0x0d
    192e:	33 23       	and	r19, r19
    1930:	34 f0       	brlt	.+12     	; 0x193e <vTaskPrioritySet+0x88>
				{
					listSET_LIST_ITEM_VALUE( &( pxTCB->xEventListItem ), ( ( TickType_t ) configMAX_PRIORITIES - ( TickType_t ) uxNewPriority ) ); /*lint !e961 MISRA exception as the casts are only redundant for some ports. */
    1932:	25 e0       	ldi	r18, 0x05	; 5
    1934:	30 e0       	ldi	r19, 0x00	; 0
    1936:	26 1b       	sub	r18, r22
    1938:	31 09       	sbc	r19, r1
    193a:	3d 87       	std	Y+13, r19	; 0x0d
    193c:	2c 87       	std	Y+12, r18	; 0x0c

				/* If the task is in the blocked or suspended list we need do
				nothing more than change it's priority variable. However, if
				the task is in a ready list it needs to be removed and placed
				in the list appropriate to its new priority. */
				if( listIS_CONTAINED_WITHIN( &( pxReadyTasksLists[ uxPriorityUsedOnEntry ] ), &( pxTCB->xStateListItem ) ) != pdFALSE )
    193e:	90 e0       	ldi	r25, 0x00	; 0
    1940:	9c 01       	movw	r18, r24
    1942:	22 0f       	add	r18, r18
    1944:	33 1f       	adc	r19, r19
    1946:	22 0f       	add	r18, r18
    1948:	33 1f       	adc	r19, r19
    194a:	22 0f       	add	r18, r18
    194c:	33 1f       	adc	r19, r19
    194e:	82 0f       	add	r24, r18
    1950:	93 1f       	adc	r25, r19
    1952:	80 55       	subi	r24, 0x50	; 80
    1954:	9c 4f       	sbci	r25, 0xFC	; 252
    1956:	2a 85       	ldd	r18, Y+10	; 0x0a
    1958:	3b 85       	ldd	r19, Y+11	; 0x0b
    195a:	28 17       	cp	r18, r24
    195c:	39 07       	cpc	r19, r25
    195e:	f9 f4       	brne	.+62     	; 0x199e <vTaskPrioritySet+0xe8>
				{
					/* The task is currently in its ready list - remove before adding
					it to it's new ready list.  As we are in a critical section we
					can do this even if the scheduler is suspended. */
					if( uxListRemove( &( pxTCB->xStateListItem ) ) == ( UBaseType_t ) 0 )
    1960:	ee 24       	eor	r14, r14
    1962:	ff 24       	eor	r15, r15
    1964:	68 94       	set
    1966:	e1 f8       	bld	r14, 1
    1968:	ec 0e       	add	r14, r28
    196a:	fd 1e       	adc	r15, r29
    196c:	c7 01       	movw	r24, r14
    196e:	0e 94 ce 03 	call	0x79c	; 0x79c <uxListRemove>
					}
					else
					{
						mtCOVERAGE_TEST_MARKER();
					}
					prvAddTaskToReadyList( pxTCB );
    1972:	8e 89       	ldd	r24, Y+22	; 0x16
    1974:	90 91 a6 03 	lds	r25, 0x03A6
    1978:	98 17       	cp	r25, r24
    197a:	10 f4       	brcc	.+4      	; 0x1980 <vTaskPrioritySet+0xca>
    197c:	80 93 a6 03 	sts	0x03A6, r24
    1980:	90 e0       	ldi	r25, 0x00	; 0
    1982:	9c 01       	movw	r18, r24
    1984:	22 0f       	add	r18, r18
    1986:	33 1f       	adc	r19, r19
    1988:	22 0f       	add	r18, r18
    198a:	33 1f       	adc	r19, r19
    198c:	22 0f       	add	r18, r18
    198e:	33 1f       	adc	r19, r19
    1990:	82 0f       	add	r24, r18
    1992:	93 1f       	adc	r25, r19
    1994:	80 55       	subi	r24, 0x50	; 80
    1996:	9c 4f       	sbci	r25, 0xFC	; 252
    1998:	b7 01       	movw	r22, r14
    199a:	0e 94 7d 03 	call	0x6fa	; 0x6fa <vListInsertEnd>
				else
				{
					mtCOVERAGE_TEST_MARKER();
				}

				if( xYieldRequired != pdFALSE )
    199e:	11 23       	and	r17, r17
    19a0:	11 f0       	breq	.+4      	; 0x19a6 <vTaskPrioritySet+0xf0>
				{
					taskYIELD_IF_USING_PREEMPTION();
    19a2:	0e 94 bc 04 	call	0x978	; 0x978 <vPortYield>
				/* Remove compiler warning about unused variables when the port
				optimised task selection is not being used. */
				( void ) uxPriorityUsedOnEntry;
			}
		}
		taskEXIT_CRITICAL();
    19a6:	0f 90       	pop	r0
    19a8:	0f be       	out	0x3f, r0	; 63
	}
    19aa:	df 91       	pop	r29
    19ac:	cf 91       	pop	r28
    19ae:	1f 91       	pop	r17
    19b0:	ff 90       	pop	r15
    19b2:	ef 90       	pop	r14
    19b4:	08 95       	ret

000019b6 <vTaskResume>:
/*-----------------------------------------------------------*/

#if ( INCLUDE_vTaskSuspend == 1 )

	void vTaskResume( TaskHandle_t xTaskToResume )
	{
    19b6:	0f 93       	push	r16
    19b8:	1f 93       	push	r17
    19ba:	cf 93       	push	r28
    19bc:	df 93       	push	r29
    19be:	ec 01       	movw	r28, r24
		/* It does not make sense to resume the calling task. */
		configASSERT( xTaskToResume );

		/* The parameter cannot be NULL as it is impossible to resume the
		currently executing task. */
		if( ( pxTCB != NULL ) && ( pxTCB != pxCurrentTCB ) )
    19c0:	00 97       	sbiw	r24, 0x00	; 0
    19c2:	b9 f1       	breq	.+110    	; 0x1a32 <vTaskResume+0x7c>
    19c4:	80 91 9d 03 	lds	r24, 0x039D
    19c8:	90 91 9e 03 	lds	r25, 0x039E
    19cc:	c8 17       	cp	r28, r24
    19ce:	d9 07       	cpc	r29, r25
    19d0:	81 f1       	breq	.+96     	; 0x1a32 <vTaskResume+0x7c>
		{
			taskENTER_CRITICAL();
    19d2:	0f b6       	in	r0, 0x3f	; 63
    19d4:	f8 94       	cli
    19d6:	0f 92       	push	r0
			{
				if( prvTaskIsTaskSuspended( pxTCB ) != pdFALSE )
    19d8:	ce 01       	movw	r24, r28
    19da:	0e 94 33 0a 	call	0x1466	; 0x1466 <prvTaskIsTaskSuspended>
    19de:	88 23       	and	r24, r24
    19e0:	31 f1       	breq	.+76     	; 0x1a2e <vTaskResume+0x78>
				{
					traceTASK_RESUME( pxTCB );

					/* As we are in a critical section we can access the ready
					lists even if the scheduler is suspended. */
					( void ) uxListRemove(  &( pxTCB->xStateListItem ) );
    19e2:	8e 01       	movw	r16, r28
    19e4:	0e 5f       	subi	r16, 0xFE	; 254
    19e6:	1f 4f       	sbci	r17, 0xFF	; 255
    19e8:	c8 01       	movw	r24, r16
    19ea:	0e 94 ce 03 	call	0x79c	; 0x79c <uxListRemove>
					prvAddTaskToReadyList( pxTCB );
    19ee:	8e 89       	ldd	r24, Y+22	; 0x16
    19f0:	90 91 a6 03 	lds	r25, 0x03A6
    19f4:	98 17       	cp	r25, r24
    19f6:	10 f4       	brcc	.+4      	; 0x19fc <vTaskResume+0x46>
    19f8:	80 93 a6 03 	sts	0x03A6, r24
    19fc:	90 e0       	ldi	r25, 0x00	; 0
    19fe:	9c 01       	movw	r18, r24
    1a00:	22 0f       	add	r18, r18
    1a02:	33 1f       	adc	r19, r19
    1a04:	22 0f       	add	r18, r18
    1a06:	33 1f       	adc	r19, r19
    1a08:	22 0f       	add	r18, r18
    1a0a:	33 1f       	adc	r19, r19
    1a0c:	82 0f       	add	r24, r18
    1a0e:	93 1f       	adc	r25, r19
    1a10:	80 55       	subi	r24, 0x50	; 80
    1a12:	9c 4f       	sbci	r25, 0xFC	; 252
    1a14:	b8 01       	movw	r22, r16
    1a16:	0e 94 7d 03 	call	0x6fa	; 0x6fa <vListInsertEnd>

					/* We may have just resumed a higher priority task. */
					if( pxTCB->uxPriority >= pxCurrentTCB->uxPriority )
    1a1a:	e0 91 9d 03 	lds	r30, 0x039D
    1a1e:	f0 91 9e 03 	lds	r31, 0x039E
    1a22:	9e 89       	ldd	r25, Y+22	; 0x16
    1a24:	86 89       	ldd	r24, Z+22	; 0x16
    1a26:	98 17       	cp	r25, r24
    1a28:	10 f0       	brcs	.+4      	; 0x1a2e <vTaskResume+0x78>
					{
						/* This yield may not cause the task just resumed to run,
						but will leave the lists in the correct state for the
						next yield. */
						taskYIELD_IF_USING_PREEMPTION();
    1a2a:	0e 94 bc 04 	call	0x978	; 0x978 <vPortYield>
				else
				{
					mtCOVERAGE_TEST_MARKER();
				}
			}
			taskEXIT_CRITICAL();
    1a2e:	0f 90       	pop	r0
    1a30:	0f be       	out	0x3f, r0	; 63
		}
		else
		{
			mtCOVERAGE_TEST_MARKER();
		}
	}
    1a32:	df 91       	pop	r29
    1a34:	cf 91       	pop	r28
    1a36:	1f 91       	pop	r17
    1a38:	0f 91       	pop	r16
    1a3a:	08 95       	ret

00001a3c <xTaskResumeFromISR>:
/*-----------------------------------------------------------*/

#if ( ( INCLUDE_xTaskResumeFromISR == 1 ) && ( INCLUDE_vTaskSuspend == 1 ) )

	BaseType_t xTaskResumeFromISR( TaskHandle_t xTaskToResume )
	{
    1a3c:	ef 92       	push	r14
    1a3e:	ff 92       	push	r15
    1a40:	1f 93       	push	r17
    1a42:	cf 93       	push	r28
    1a44:	df 93       	push	r29
    1a46:	ec 01       	movw	r28, r24
		http://www.freertos.org/RTOS-Cortex-M3-M4.html */
		portASSERT_IF_INTERRUPT_PRIORITY_INVALID();

		uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
		{
			if( prvTaskIsTaskSuspended( pxTCB ) != pdFALSE )
    1a48:	0e 94 33 0a 	call	0x1466	; 0x1466 <prvTaskIsTaskSuspended>
    1a4c:	88 23       	and	r24, r24
    1a4e:	b9 f1       	breq	.+110    	; 0x1abe <xTaskResumeFromISR+0x82>
			{
				traceTASK_RESUME_FROM_ISR( pxTCB );

				/* Check the ready lists can be accessed. */
				if( uxSchedulerSuspended == ( UBaseType_t ) pdFALSE )
    1a50:	80 91 9f 03 	lds	r24, 0x039F
    1a54:	88 23       	and	r24, r24
    1a56:	51 f5       	brne	.+84     	; 0x1aac <xTaskResumeFromISR+0x70>
				{
					/* Ready lists can be accessed so move the task from the
					suspended list to the ready list directly. */
					if( pxTCB->uxPriority >= pxCurrentTCB->uxPriority )
    1a58:	e0 91 9d 03 	lds	r30, 0x039D
    1a5c:	f0 91 9e 03 	lds	r31, 0x039E

#if ( ( INCLUDE_xTaskResumeFromISR == 1 ) && ( INCLUDE_vTaskSuspend == 1 ) )

	BaseType_t xTaskResumeFromISR( TaskHandle_t xTaskToResume )
	{
	BaseType_t xYieldRequired = pdFALSE;
    1a60:	11 e0       	ldi	r17, 0x01	; 1
    1a62:	9e 89       	ldd	r25, Y+22	; 0x16
    1a64:	86 89       	ldd	r24, Z+22	; 0x16
    1a66:	98 17       	cp	r25, r24
    1a68:	08 f4       	brcc	.+2      	; 0x1a6c <xTaskResumeFromISR+0x30>
    1a6a:	10 e0       	ldi	r17, 0x00	; 0
					else
					{
						mtCOVERAGE_TEST_MARKER();
					}

					( void ) uxListRemove( &( pxTCB->xStateListItem ) );
    1a6c:	ee 24       	eor	r14, r14
    1a6e:	ff 24       	eor	r15, r15
    1a70:	68 94       	set
    1a72:	e1 f8       	bld	r14, 1
    1a74:	ec 0e       	add	r14, r28
    1a76:	fd 1e       	adc	r15, r29
    1a78:	c7 01       	movw	r24, r14
    1a7a:	0e 94 ce 03 	call	0x79c	; 0x79c <uxListRemove>
					prvAddTaskToReadyList( pxTCB );
    1a7e:	8e 89       	ldd	r24, Y+22	; 0x16
    1a80:	90 91 a6 03 	lds	r25, 0x03A6
    1a84:	98 17       	cp	r25, r24
    1a86:	10 f4       	brcc	.+4      	; 0x1a8c <xTaskResumeFromISR+0x50>
    1a88:	80 93 a6 03 	sts	0x03A6, r24
    1a8c:	90 e0       	ldi	r25, 0x00	; 0
    1a8e:	9c 01       	movw	r18, r24
    1a90:	22 0f       	add	r18, r18
    1a92:	33 1f       	adc	r19, r19
    1a94:	22 0f       	add	r18, r18
    1a96:	33 1f       	adc	r19, r19
    1a98:	22 0f       	add	r18, r18
    1a9a:	33 1f       	adc	r19, r19
    1a9c:	82 0f       	add	r24, r18
    1a9e:	93 1f       	adc	r25, r19
    1aa0:	80 55       	subi	r24, 0x50	; 80
    1aa2:	9c 4f       	sbci	r25, 0xFC	; 252
    1aa4:	b7 01       	movw	r22, r14
    1aa6:	0e 94 7d 03 	call	0x6fa	; 0x6fa <vListInsertEnd>
    1aaa:	0a c0       	rjmp	.+20     	; 0x1ac0 <xTaskResumeFromISR+0x84>
				else
				{
					/* The delayed or ready lists cannot be accessed so the task
					is held in the pending ready list until the scheduler is
					unsuspended. */
					vListInsertEnd( &( xPendingReadyList ), &( pxTCB->xEventListItem ) );
    1aac:	be 01       	movw	r22, r28
    1aae:	64 5f       	subi	r22, 0xF4	; 244
    1ab0:	7f 4f       	sbci	r23, 0xFF	; 255
    1ab2:	8f ee       	ldi	r24, 0xEF	; 239
    1ab4:	93 e0       	ldi	r25, 0x03	; 3
    1ab6:	0e 94 7d 03 	call	0x6fa	; 0x6fa <vListInsertEnd>

#if ( ( INCLUDE_xTaskResumeFromISR == 1 ) && ( INCLUDE_vTaskSuspend == 1 ) )

	BaseType_t xTaskResumeFromISR( TaskHandle_t xTaskToResume )
	{
	BaseType_t xYieldRequired = pdFALSE;
    1aba:	10 e0       	ldi	r17, 0x00	; 0
    1abc:	01 c0       	rjmp	.+2      	; 0x1ac0 <xTaskResumeFromISR+0x84>
    1abe:	10 e0       	ldi	r17, 0x00	; 0
			}
		}
		portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );

		return xYieldRequired;
	}
    1ac0:	81 2f       	mov	r24, r17
    1ac2:	df 91       	pop	r29
    1ac4:	cf 91       	pop	r28
    1ac6:	1f 91       	pop	r17
    1ac8:	ff 90       	pop	r15
    1aca:	ef 90       	pop	r14
    1acc:	08 95       	ret

00001ace <vTaskStartScheduler>:

#endif /* ( ( INCLUDE_xTaskResumeFromISR == 1 ) && ( INCLUDE_vTaskSuspend == 1 ) ) */
/*-----------------------------------------------------------*/

void vTaskStartScheduler( void )
{
    1ace:	ef 92       	push	r14
    1ad0:	ff 92       	push	r15
    1ad2:	0f 93       	push	r16
		}
	}
	#else
	{
		/* The Idle task is being created using dynamically allocated RAM. */
		xReturn = xTaskCreate(	prvIdleTask,
    1ad4:	8c ed       	ldi	r24, 0xDC	; 220
    1ad6:	9e e0       	ldi	r25, 0x0E	; 14
    1ad8:	6e e6       	ldi	r22, 0x6E	; 110
    1ada:	70 e0       	ldi	r23, 0x00	; 0
    1adc:	48 ec       	ldi	r20, 0xC8	; 200
    1ade:	50 e0       	ldi	r21, 0x00	; 0
    1ae0:	20 e0       	ldi	r18, 0x00	; 0
    1ae2:	30 e0       	ldi	r19, 0x00	; 0
    1ae4:	00 e0       	ldi	r16, 0x00	; 0
    1ae6:	0f 2e       	mov	r0, r31
    1ae8:	fa e0       	ldi	r31, 0x0A	; 10
    1aea:	ef 2e       	mov	r14, r31
    1aec:	f4 e0       	ldi	r31, 0x04	; 4
    1aee:	ff 2e       	mov	r15, r31
    1af0:	f0 2d       	mov	r31, r0
    1af2:	0e 94 ce 0a 	call	0x159c	; 0x159c <xTaskCreate>
			mtCOVERAGE_TEST_MARKER();
		}
	}
	#endif /* configUSE_TIMERS */

	if( xReturn == pdPASS )
    1af6:	81 30       	cpi	r24, 0x01	; 1
    1af8:	81 f4       	brne	.+32     	; 0x1b1a <vTaskStartScheduler+0x4c>
		/* Interrupts are turned off here, to ensure a tick does not occur
		before or during the call to xPortStartScheduler().  The stacks of
		the created tasks contain a status word with interrupts switched on
		so interrupts will automatically get re-enabled when the first task
		starts to run. */
		portDISABLE_INTERRUPTS();
    1afa:	f8 94       	cli
			structure specific to the task that will run first. */
			_impure_ptr = &( pxCurrentTCB->xNewLib_reent );
		}
		#endif /* configUSE_NEWLIB_REENTRANT */

		xNextTaskUnblockTime = portMAX_DELAY;
    1afc:	8f ef       	ldi	r24, 0xFF	; 255
    1afe:	9f ef       	ldi	r25, 0xFF	; 255
    1b00:	90 93 a1 03 	sts	0x03A1, r25
    1b04:	80 93 a0 03 	sts	0x03A0, r24
		xSchedulerRunning = pdTRUE;
    1b08:	81 e0       	ldi	r24, 0x01	; 1
    1b0a:	80 93 a5 03 	sts	0x03A5, r24
		xTickCount = ( TickType_t ) 0U;
    1b0e:	10 92 a8 03 	sts	0x03A8, r1
    1b12:	10 92 a7 03 	sts	0x03A7, r1
		the run time counter time base. */
		portCONFIGURE_TIMER_FOR_RUN_TIME_STATS();

		/* Setting up the timer tick is hardware specific and thus in the
		portable interface. */
		if( xPortStartScheduler() != pdFALSE )
    1b16:	0e 94 86 04 	call	0x90c	; 0x90c <xPortStartScheduler>
	}

	/* Prevent compiler warnings if INCLUDE_xTaskGetIdleTaskHandle is set to 0,
	meaning xIdleTaskHandle is not used anywhere else. */
	( void ) xIdleTaskHandle;
}
    1b1a:	0f 91       	pop	r16
    1b1c:	ff 90       	pop	r15
    1b1e:	ef 90       	pop	r14
    1b20:	08 95       	ret

00001b22 <vTaskEndScheduler>:
void vTaskEndScheduler( void )
{
	/* Stop the scheduler interrupts and call the portable scheduler end
	routine so the original ISRs can be restored if necessary.  The port
	layer must ensure interrupts enable	bit is left in the correct state. */
	portDISABLE_INTERRUPTS();
    1b22:	f8 94       	cli
	xSchedulerRunning = pdFALSE;
    1b24:	10 92 a5 03 	sts	0x03A5, r1
	vPortEndScheduler();
    1b28:	0e 94 bb 04 	call	0x976	; 0x976 <vPortEndScheduler>
}
    1b2c:	08 95       	ret

00001b2e <vTaskSuspendAll>:
{
	/* A critical section is not required as the variable is of type
	BaseType_t.  Please read Richard Barry's reply in the following link to a
	post in the FreeRTOS support forum before reporting this as a bug! -
	http://goo.gl/wu4acr */
	++uxSchedulerSuspended;
    1b2e:	80 91 9f 03 	lds	r24, 0x039F
    1b32:	8f 5f       	subi	r24, 0xFF	; 255
    1b34:	80 93 9f 03 	sts	0x039F, r24
}
    1b38:	08 95       	ret

00001b3a <xTaskGetTickCount>:
TickType_t xTaskGetTickCount( void )
{
TickType_t xTicks;

	/* Critical section required if running on a 16 bit processor. */
	portTICK_TYPE_ENTER_CRITICAL();
    1b3a:	0f b6       	in	r0, 0x3f	; 63
    1b3c:	f8 94       	cli
    1b3e:	0f 92       	push	r0
	{
		xTicks = xTickCount;
    1b40:	80 91 a7 03 	lds	r24, 0x03A7
    1b44:	90 91 a8 03 	lds	r25, 0x03A8
	}
	portTICK_TYPE_EXIT_CRITICAL();
    1b48:	0f 90       	pop	r0
    1b4a:	0f be       	out	0x3f, r0	; 63

	return xTicks;
}
    1b4c:	08 95       	ret

00001b4e <xTaskGetTickCountFromISR>:
	link: http://www.freertos.org/RTOS-Cortex-M3-M4.html */
	portASSERT_IF_INTERRUPT_PRIORITY_INVALID();

	uxSavedInterruptStatus = portTICK_TYPE_SET_INTERRUPT_MASK_FROM_ISR();
	{
		xReturn = xTickCount;
    1b4e:	80 91 a7 03 	lds	r24, 0x03A7
    1b52:	90 91 a8 03 	lds	r25, 0x03A8
	}
	portTICK_TYPE_CLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );

	return xReturn;
}
    1b56:	08 95       	ret

00001b58 <uxTaskGetNumberOfTasks>:

UBaseType_t uxTaskGetNumberOfTasks( void )
{
	/* A critical section is not required because the variables are of type
	BaseType_t. */
	return uxCurrentNumberOfTasks;
    1b58:	80 91 a9 03 	lds	r24, 0x03A9
}
    1b5c:	08 95       	ret

00001b5e <pcTaskGetName>:
{
TCB_t *pxTCB;

	/* If null is passed in here then the name of the calling task is being
	queried. */
	pxTCB = prvGetTCBFromHandle( xTaskToQuery );
    1b5e:	00 97       	sbiw	r24, 0x00	; 0
    1b60:	21 f4       	brne	.+8      	; 0x1b6a <pcTaskGetName+0xc>
    1b62:	80 91 9d 03 	lds	r24, 0x039D
    1b66:	90 91 9e 03 	lds	r25, 0x039E
	configASSERT( pxTCB );
	return &( pxTCB->pcTaskName[ 0 ] );
    1b6a:	49 96       	adiw	r24, 0x19	; 25
}
    1b6c:	08 95       	ret

00001b6e <xTaskIncrementTick>:

#endif /* INCLUDE_xTaskAbortDelay */
/*----------------------------------------------------------*/

BaseType_t xTaskIncrementTick( void )
{
    1b6e:	cf 92       	push	r12
    1b70:	df 92       	push	r13
    1b72:	ef 92       	push	r14
    1b74:	ff 92       	push	r15
    1b76:	0f 93       	push	r16
    1b78:	1f 93       	push	r17
    1b7a:	cf 93       	push	r28
    1b7c:	df 93       	push	r29

	/* Called by the portable layer each time a tick interrupt occurs.
	Increments the tick then checks to see if the new tick value will cause any
	tasks to be unblocked. */
	traceTASK_INCREMENT_TICK( xTickCount );
	if( uxSchedulerSuspended == ( UBaseType_t ) pdFALSE )
    1b7e:	80 91 9f 03 	lds	r24, 0x039F
    1b82:	88 23       	and	r24, r24
    1b84:	09 f0       	breq	.+2      	; 0x1b88 <xTaskIncrementTick+0x1a>
    1b86:	82 c0       	rjmp	.+260    	; 0x1c8c <xTaskIncrementTick+0x11e>
	{
		/* Minor optimisation.  The tick count cannot change in this
		block. */
		const TickType_t xConstTickCount = xTickCount + 1;
    1b88:	c0 90 a7 03 	lds	r12, 0x03A7
    1b8c:	d0 90 a8 03 	lds	r13, 0x03A8
    1b90:	08 94       	sec
    1b92:	c1 1c       	adc	r12, r1
    1b94:	d1 1c       	adc	r13, r1

		/* Increment the RTOS tick, switching the delayed and overflowed
		delayed lists if it wraps to 0. */
		xTickCount = xConstTickCount;
    1b96:	d0 92 a8 03 	sts	0x03A8, r13
    1b9a:	c0 92 a7 03 	sts	0x03A7, r12

		if( xConstTickCount == ( TickType_t ) 0U )
    1b9e:	c1 14       	cp	r12, r1
    1ba0:	d1 04       	cpc	r13, r1
    1ba2:	b9 f4       	brne	.+46     	; 0x1bd2 <xTaskIncrementTick+0x64>
		{
			taskSWITCH_DELAYED_LISTS();
    1ba4:	80 91 ad 03 	lds	r24, 0x03AD
    1ba8:	90 91 ae 03 	lds	r25, 0x03AE
    1bac:	20 91 ab 03 	lds	r18, 0x03AB
    1bb0:	30 91 ac 03 	lds	r19, 0x03AC
    1bb4:	30 93 ae 03 	sts	0x03AE, r19
    1bb8:	20 93 ad 03 	sts	0x03AD, r18
    1bbc:	90 93 ac 03 	sts	0x03AC, r25
    1bc0:	80 93 ab 03 	sts	0x03AB, r24
    1bc4:	80 91 a2 03 	lds	r24, 0x03A2
    1bc8:	8f 5f       	subi	r24, 0xFF	; 255
    1bca:	80 93 a2 03 	sts	0x03A2, r24
    1bce:	0e 94 4a 0a 	call	0x1494	; 0x1494 <prvResetNextTaskUnblockTime>

		/* See if this tick has made a timeout expire.  Tasks are stored in
		the	queue in the order of their wake time - meaning once one task
		has been found whose block time has not expired there is no need to
		look any further down the list. */
		if( xConstTickCount >= xNextTaskUnblockTime )
    1bd2:	80 91 a0 03 	lds	r24, 0x03A0
    1bd6:	90 91 a1 03 	lds	r25, 0x03A1
    1bda:	c8 16       	cp	r12, r24
    1bdc:	d9 06       	cpc	r13, r25
    1bde:	20 f4       	brcc	.+8      	; 0x1be8 <xTaskIncrementTick+0x7a>

BaseType_t xTaskIncrementTick( void )
{
TCB_t * pxTCB;
TickType_t xItemValue;
BaseType_t xSwitchRequired = pdFALSE;
    1be0:	ff 24       	eor	r15, r15
    1be2:	5a c0       	rjmp	.+180    	; 0x1c98 <xTaskIncrementTick+0x12a>
						only be performed if the unblocked task has a
						priority that is equal to or higher than the
						currently executing task. */
						if( pxTCB->uxPriority >= pxCurrentTCB->uxPriority )
						{
							xSwitchRequired = pdTRUE;
    1be4:	fe 2c       	mov	r15, r14
    1be6:	03 c0       	rjmp	.+6      	; 0x1bee <xTaskIncrementTick+0x80>

		/* See if this tick has made a timeout expire.  Tasks are stored in
		the	queue in the order of their wake time - meaning once one task
		has been found whose block time has not expired there is no need to
		look any further down the list. */
		if( xConstTickCount >= xNextTaskUnblockTime )
    1be8:	ff 24       	eor	r15, r15
						only be performed if the unblocked task has a
						priority that is equal to or higher than the
						currently executing task. */
						if( pxTCB->uxPriority >= pxCurrentTCB->uxPriority )
						{
							xSwitchRequired = pdTRUE;
    1bea:	ee 24       	eor	r14, r14
    1bec:	e3 94       	inc	r14
		look any further down the list. */
		if( xConstTickCount >= xNextTaskUnblockTime )
		{
			for( ;; )
			{
				if( listLIST_IS_EMPTY( pxDelayedTaskList ) != pdFALSE )
    1bee:	e0 91 ad 03 	lds	r30, 0x03AD
    1bf2:	f0 91 ae 03 	lds	r31, 0x03AE
    1bf6:	80 81       	ld	r24, Z
    1bf8:	88 23       	and	r24, r24
    1bfa:	39 f4       	brne	.+14     	; 0x1c0a <xTaskIncrementTick+0x9c>
					/* The delayed list is empty.  Set xNextTaskUnblockTime
					to the maximum possible value so it is extremely
					unlikely that the
					if( xTickCount >= xNextTaskUnblockTime ) test will pass
					next time through. */
					xNextTaskUnblockTime = portMAX_DELAY; /*lint !e961 MISRA exception as the casts are only redundant for some ports. */
    1bfc:	8f ef       	ldi	r24, 0xFF	; 255
    1bfe:	9f ef       	ldi	r25, 0xFF	; 255
    1c00:	90 93 a1 03 	sts	0x03A1, r25
    1c04:	80 93 a0 03 	sts	0x03A0, r24
					break;
    1c08:	47 c0       	rjmp	.+142    	; 0x1c98 <xTaskIncrementTick+0x12a>
				{
					/* The delayed list is not empty, get the value of the
					item at the head of the delayed list.  This is the time
					at which the task at the head of the delayed list must
					be removed from the Blocked state. */
					pxTCB = ( TCB_t * ) listGET_OWNER_OF_HEAD_ENTRY( pxDelayedTaskList );
    1c0a:	e0 91 ad 03 	lds	r30, 0x03AD
    1c0e:	f0 91 ae 03 	lds	r31, 0x03AE
    1c12:	05 80       	ldd	r0, Z+5	; 0x05
    1c14:	f6 81       	ldd	r31, Z+6	; 0x06
    1c16:	e0 2d       	mov	r30, r0
    1c18:	c6 81       	ldd	r28, Z+6	; 0x06
    1c1a:	d7 81       	ldd	r29, Z+7	; 0x07
					xItemValue = listGET_LIST_ITEM_VALUE( &( pxTCB->xStateListItem ) );
    1c1c:	8a 81       	ldd	r24, Y+2	; 0x02
    1c1e:	9b 81       	ldd	r25, Y+3	; 0x03

					if( xConstTickCount < xItemValue )
    1c20:	c8 16       	cp	r12, r24
    1c22:	d9 06       	cpc	r13, r25
    1c24:	28 f4       	brcc	.+10     	; 0x1c30 <xTaskIncrementTick+0xc2>
						/* It is not time to unblock this item yet, but the
						item value is the time at which the task at the head
						of the blocked list must be removed from the Blocked
						state -	so record the item value in
						xNextTaskUnblockTime. */
						xNextTaskUnblockTime = xItemValue;
    1c26:	90 93 a1 03 	sts	0x03A1, r25
    1c2a:	80 93 a0 03 	sts	0x03A0, r24
						break;
    1c2e:	34 c0       	rjmp	.+104    	; 0x1c98 <xTaskIncrementTick+0x12a>
					{
						mtCOVERAGE_TEST_MARKER();
					}

					/* It is time to remove the item from the Blocked state. */
					( void ) uxListRemove( &( pxTCB->xStateListItem ) );
    1c30:	8e 01       	movw	r16, r28
    1c32:	0e 5f       	subi	r16, 0xFE	; 254
    1c34:	1f 4f       	sbci	r17, 0xFF	; 255
    1c36:	c8 01       	movw	r24, r16
    1c38:	0e 94 ce 03 	call	0x79c	; 0x79c <uxListRemove>

					/* Is the task waiting on an event also?  If so remove
					it from the event list. */
					if( listLIST_ITEM_CONTAINER( &( pxTCB->xEventListItem ) ) != NULL )
    1c3c:	8c 89       	ldd	r24, Y+20	; 0x14
    1c3e:	9d 89       	ldd	r25, Y+21	; 0x15
    1c40:	00 97       	sbiw	r24, 0x00	; 0
    1c42:	21 f0       	breq	.+8      	; 0x1c4c <xTaskIncrementTick+0xde>
					{
						( void ) uxListRemove( &( pxTCB->xEventListItem ) );
    1c44:	ce 01       	movw	r24, r28
    1c46:	0c 96       	adiw	r24, 0x0c	; 12
    1c48:	0e 94 ce 03 	call	0x79c	; 0x79c <uxListRemove>
						mtCOVERAGE_TEST_MARKER();
					}

					/* Place the unblocked task into the appropriate ready
					list. */
					prvAddTaskToReadyList( pxTCB );
    1c4c:	8e 89       	ldd	r24, Y+22	; 0x16
    1c4e:	90 91 a6 03 	lds	r25, 0x03A6
    1c52:	98 17       	cp	r25, r24
    1c54:	10 f4       	brcc	.+4      	; 0x1c5a <xTaskIncrementTick+0xec>
    1c56:	80 93 a6 03 	sts	0x03A6, r24
    1c5a:	90 e0       	ldi	r25, 0x00	; 0
    1c5c:	9c 01       	movw	r18, r24
    1c5e:	22 0f       	add	r18, r18
    1c60:	33 1f       	adc	r19, r19
    1c62:	22 0f       	add	r18, r18
    1c64:	33 1f       	adc	r19, r19
    1c66:	22 0f       	add	r18, r18
    1c68:	33 1f       	adc	r19, r19
    1c6a:	82 0f       	add	r24, r18
    1c6c:	93 1f       	adc	r25, r19
    1c6e:	80 55       	subi	r24, 0x50	; 80
    1c70:	9c 4f       	sbci	r25, 0xFC	; 252
    1c72:	b8 01       	movw	r22, r16
    1c74:	0e 94 7d 03 	call	0x6fa	; 0x6fa <vListInsertEnd>
					{
						/* Preemption is on, but a context switch should
						only be performed if the unblocked task has a
						priority that is equal to or higher than the
						currently executing task. */
						if( pxTCB->uxPriority >= pxCurrentTCB->uxPriority )
    1c78:	e0 91 9d 03 	lds	r30, 0x039D
    1c7c:	f0 91 9e 03 	lds	r31, 0x039E
    1c80:	9e 89       	ldd	r25, Y+22	; 0x16
    1c82:	86 89       	ldd	r24, Z+22	; 0x16
    1c84:	98 17       	cp	r25, r24
    1c86:	08 f0       	brcs	.+2      	; 0x1c8a <xTaskIncrementTick+0x11c>
    1c88:	ad cf       	rjmp	.-166    	; 0x1be4 <xTaskIncrementTick+0x76>
    1c8a:	b1 cf       	rjmp	.-158    	; 0x1bee <xTaskIncrementTick+0x80>
		}
		#endif /* configUSE_TICK_HOOK */
	}
	else
	{
		++uxPendedTicks;
    1c8c:	80 91 a4 03 	lds	r24, 0x03A4
    1c90:	8f 5f       	subi	r24, 0xFF	; 255
    1c92:	80 93 a4 03 	sts	0x03A4, r24

BaseType_t xTaskIncrementTick( void )
{
TCB_t * pxTCB;
TickType_t xItemValue;
BaseType_t xSwitchRequired = pdFALSE;
    1c96:	ff 24       	eor	r15, r15
		#endif
	}

	#if ( configUSE_PREEMPTION == 1 )
	{
		if( xYieldPending != pdFALSE )
    1c98:	80 91 a3 03 	lds	r24, 0x03A3
    1c9c:	88 23       	and	r24, r24
    1c9e:	11 f0       	breq	.+4      	; 0x1ca4 <xTaskIncrementTick+0x136>
		{
			xSwitchRequired = pdTRUE;
    1ca0:	ff 24       	eor	r15, r15
    1ca2:	f3 94       	inc	r15
		}
	}
	#endif /* configUSE_PREEMPTION */

	return xSwitchRequired;
}
    1ca4:	8f 2d       	mov	r24, r15
    1ca6:	df 91       	pop	r29
    1ca8:	cf 91       	pop	r28
    1caa:	1f 91       	pop	r17
    1cac:	0f 91       	pop	r16
    1cae:	ff 90       	pop	r15
    1cb0:	ef 90       	pop	r14
    1cb2:	df 90       	pop	r13
    1cb4:	cf 90       	pop	r12
    1cb6:	08 95       	ret

00001cb8 <xTaskResumeAll>:

#endif /* configUSE_TICKLESS_IDLE */
/*----------------------------------------------------------*/

BaseType_t xTaskResumeAll( void )
{
    1cb8:	df 92       	push	r13
    1cba:	ef 92       	push	r14
    1cbc:	ff 92       	push	r15
    1cbe:	0f 93       	push	r16
    1cc0:	1f 93       	push	r17
    1cc2:	cf 93       	push	r28
    1cc4:	df 93       	push	r29
	/* It is possible that an ISR caused a task to be removed from an event
	list while the scheduler was suspended.  If this was the case then the
	removed task will have been added to the xPendingReadyList.  Once the
	scheduler has been resumed it is safe to move all the pending ready
	tasks from this list into their appropriate ready list. */
	taskENTER_CRITICAL();
    1cc6:	0f b6       	in	r0, 0x3f	; 63
    1cc8:	f8 94       	cli
    1cca:	0f 92       	push	r0
	{
		--uxSchedulerSuspended;
    1ccc:	80 91 9f 03 	lds	r24, 0x039F
    1cd0:	81 50       	subi	r24, 0x01	; 1
    1cd2:	80 93 9f 03 	sts	0x039F, r24

		if( uxSchedulerSuspended == ( UBaseType_t ) pdFALSE )
    1cd6:	80 91 9f 03 	lds	r24, 0x039F
    1cda:	88 23       	and	r24, r24
    1cdc:	09 f0       	breq	.+2      	; 0x1ce0 <xTaskResumeAll+0x28>
    1cde:	5f c0       	rjmp	.+190    	; 0x1d9e <xTaskResumeAll+0xe6>
		{
			if( uxCurrentNumberOfTasks > ( UBaseType_t ) 0U )
    1ce0:	80 91 a9 03 	lds	r24, 0x03A9
    1ce4:	88 23       	and	r24, r24
    1ce6:	91 f5       	brne	.+100    	; 0x1d4c <xTaskResumeAll+0x94>
    1ce8:	5d c0       	rjmp	.+186    	; 0x1da4 <xTaskResumeAll+0xec>
			{
				/* Move any readied tasks from the pending list into the
				appropriate ready list. */
				while( listLIST_IS_EMPTY( &xPendingReadyList ) == pdFALSE )
				{
					pxTCB = ( TCB_t * ) listGET_OWNER_OF_HEAD_ENTRY( ( &xPendingReadyList ) );
    1cea:	e0 91 f4 03 	lds	r30, 0x03F4
    1cee:	f0 91 f5 03 	lds	r31, 0x03F5
    1cf2:	c6 81       	ldd	r28, Z+6	; 0x06
    1cf4:	d7 81       	ldd	r29, Z+7	; 0x07
					( void ) uxListRemove( &( pxTCB->xEventListItem ) );
    1cf6:	ce 01       	movw	r24, r28
    1cf8:	0c 96       	adiw	r24, 0x0c	; 12
    1cfa:	0e 94 ce 03 	call	0x79c	; 0x79c <uxListRemove>
					( void ) uxListRemove( &( pxTCB->xStateListItem ) );
    1cfe:	8e 01       	movw	r16, r28
    1d00:	0e 5f       	subi	r16, 0xFE	; 254
    1d02:	1f 4f       	sbci	r17, 0xFF	; 255
    1d04:	c8 01       	movw	r24, r16
    1d06:	0e 94 ce 03 	call	0x79c	; 0x79c <uxListRemove>
					prvAddTaskToReadyList( pxTCB );
    1d0a:	8e 89       	ldd	r24, Y+22	; 0x16
    1d0c:	90 91 a6 03 	lds	r25, 0x03A6
    1d10:	98 17       	cp	r25, r24
    1d12:	10 f4       	brcc	.+4      	; 0x1d18 <xTaskResumeAll+0x60>
    1d14:	80 93 a6 03 	sts	0x03A6, r24
    1d18:	90 e0       	ldi	r25, 0x00	; 0
    1d1a:	9c 01       	movw	r18, r24
    1d1c:	22 0f       	add	r18, r18
    1d1e:	33 1f       	adc	r19, r19
    1d20:	22 0f       	add	r18, r18
    1d22:	33 1f       	adc	r19, r19
    1d24:	22 0f       	add	r18, r18
    1d26:	33 1f       	adc	r19, r19
    1d28:	82 0f       	add	r24, r18
    1d2a:	93 1f       	adc	r25, r19
    1d2c:	80 55       	subi	r24, 0x50	; 80
    1d2e:	9c 4f       	sbci	r25, 0xFC	; 252
    1d30:	b8 01       	movw	r22, r16
    1d32:	0e 94 7d 03 	call	0x6fa	; 0x6fa <vListInsertEnd>

					/* If the moved task has a priority higher than the current
					task then a yield must be performed. */
					if( pxTCB->uxPriority >= pxCurrentTCB->uxPriority )
    1d36:	e0 91 9d 03 	lds	r30, 0x039D
    1d3a:	f0 91 9e 03 	lds	r31, 0x039E
    1d3e:	9e 89       	ldd	r25, Y+22	; 0x16
    1d40:	86 89       	ldd	r24, Z+22	; 0x16
    1d42:	98 17       	cp	r25, r24
    1d44:	68 f0       	brcs	.+26     	; 0x1d60 <xTaskResumeAll+0xa8>
					{
						xYieldPending = pdTRUE;
    1d46:	d0 92 a3 03 	sts	0x03A3, r13
    1d4a:	0a c0       	rjmp	.+20     	; 0x1d60 <xTaskResumeAll+0xa8>
	{
		--uxSchedulerSuspended;

		if( uxSchedulerSuspended == ( UBaseType_t ) pdFALSE )
		{
			if( uxCurrentNumberOfTasks > ( UBaseType_t ) 0U )
    1d4c:	c0 e0       	ldi	r28, 0x00	; 0
    1d4e:	d0 e0       	ldi	r29, 0x00	; 0
			{
				/* Move any readied tasks from the pending list into the
				appropriate ready list. */
				while( listLIST_IS_EMPTY( &xPendingReadyList ) == pdFALSE )
    1d50:	0f 2e       	mov	r0, r31
    1d52:	ff ee       	ldi	r31, 0xEF	; 239
    1d54:	ef 2e       	mov	r14, r31
    1d56:	f3 e0       	ldi	r31, 0x03	; 3
    1d58:	ff 2e       	mov	r15, r31
    1d5a:	f0 2d       	mov	r31, r0

					/* If the moved task has a priority higher than the current
					task then a yield must be performed. */
					if( pxTCB->uxPriority >= pxCurrentTCB->uxPriority )
					{
						xYieldPending = pdTRUE;
    1d5c:	dd 24       	eor	r13, r13
    1d5e:	d3 94       	inc	r13
		{
			if( uxCurrentNumberOfTasks > ( UBaseType_t ) 0U )
			{
				/* Move any readied tasks from the pending list into the
				appropriate ready list. */
				while( listLIST_IS_EMPTY( &xPendingReadyList ) == pdFALSE )
    1d60:	f7 01       	movw	r30, r14
    1d62:	80 81       	ld	r24, Z
    1d64:	88 23       	and	r24, r24
    1d66:	09 f6       	brne	.-126    	; 0x1cea <xTaskResumeAll+0x32>
					{
						mtCOVERAGE_TEST_MARKER();
					}
				}

				if( pxTCB != NULL )
    1d68:	20 97       	sbiw	r28, 0x00	; 0
    1d6a:	11 f0       	breq	.+4      	; 0x1d70 <xTaskResumeAll+0xb8>
					which may have prevented the next unblock time from being
					re-calculated, in which case re-calculate it now.  Mainly
					important for low power tickless implementations, where
					this can prevent an unnecessary exit from low power
					state. */
					prvResetNextTaskUnblockTime();
    1d6c:	0e 94 4a 0a 	call	0x1494	; 0x1494 <prvResetNextTaskUnblockTime>
				/* If any ticks occurred while the scheduler was suspended then
				they should be processed now.  This ensures the tick count does
				not	slip, and that any delayed tasks are resumed at the correct
				time. */
				{
					UBaseType_t uxPendedCounts = uxPendedTicks; /* Non-volatile copy. */
    1d70:	c0 91 a4 03 	lds	r28, 0x03A4

					if( uxPendedCounts > ( UBaseType_t ) 0U )
    1d74:	cc 23       	and	r28, r28
    1d76:	59 f0       	breq	.+22     	; 0x1d8e <xTaskResumeAll+0xd6>
					{
						do
						{
							if( xTaskIncrementTick() != pdFALSE )
							{
								xYieldPending = pdTRUE;
    1d78:	01 e0       	ldi	r16, 0x01	; 1

					if( uxPendedCounts > ( UBaseType_t ) 0U )
					{
						do
						{
							if( xTaskIncrementTick() != pdFALSE )
    1d7a:	0e 94 b7 0d 	call	0x1b6e	; 0x1b6e <xTaskIncrementTick>
    1d7e:	88 23       	and	r24, r24
    1d80:	11 f0       	breq	.+4      	; 0x1d86 <xTaskResumeAll+0xce>
							{
								xYieldPending = pdTRUE;
    1d82:	00 93 a3 03 	sts	0x03A3, r16
							}
							else
							{
								mtCOVERAGE_TEST_MARKER();
							}
							--uxPendedCounts;
    1d86:	c1 50       	subi	r28, 0x01	; 1
						} while( uxPendedCounts > ( UBaseType_t ) 0U );
    1d88:	c1 f7       	brne	.-16     	; 0x1d7a <xTaskResumeAll+0xc2>

						uxPendedTicks = 0;
    1d8a:	10 92 a4 03 	sts	0x03A4, r1
					{
						mtCOVERAGE_TEST_MARKER();
					}
				}

				if( xYieldPending != pdFALSE )
    1d8e:	80 91 a3 03 	lds	r24, 0x03A3
    1d92:	88 23       	and	r24, r24
    1d94:	31 f0       	breq	.+12     	; 0x1da2 <xTaskResumeAll+0xea>
					#if( configUSE_PREEMPTION != 0 )
					{
						xAlreadyYielded = pdTRUE;
					}
					#endif
					taskYIELD_IF_USING_PREEMPTION();
    1d96:	0e 94 bc 04 	call	0x978	; 0x978 <vPortYield>

				if( xYieldPending != pdFALSE )
				{
					#if( configUSE_PREEMPTION != 0 )
					{
						xAlreadyYielded = pdTRUE;
    1d9a:	81 e0       	ldi	r24, 0x01	; 1
    1d9c:	03 c0       	rjmp	.+6      	; 0x1da4 <xTaskResumeAll+0xec>
/*----------------------------------------------------------*/

BaseType_t xTaskResumeAll( void )
{
TCB_t *pxTCB = NULL;
BaseType_t xAlreadyYielded = pdFALSE;
    1d9e:	80 e0       	ldi	r24, 0x00	; 0
    1da0:	01 c0       	rjmp	.+2      	; 0x1da4 <xTaskResumeAll+0xec>
    1da2:	80 e0       	ldi	r24, 0x00	; 0
		else
		{
			mtCOVERAGE_TEST_MARKER();
		}
	}
	taskEXIT_CRITICAL();
    1da4:	0f 90       	pop	r0
    1da6:	0f be       	out	0x3f, r0	; 63

	return xAlreadyYielded;
}
    1da8:	df 91       	pop	r29
    1daa:	cf 91       	pop	r28
    1dac:	1f 91       	pop	r17
    1dae:	0f 91       	pop	r16
    1db0:	ff 90       	pop	r15
    1db2:	ef 90       	pop	r14
    1db4:	df 90       	pop	r13
    1db6:	08 95       	ret

00001db8 <prvIdleTask>:
		too often in the idle task. */
		while( uxDeletedTasksWaitingCleanUp > ( UBaseType_t ) 0U )
		{
			vTaskSuspendAll();
			{
				xListIsEmpty = listLIST_IS_EMPTY( &xTasksWaitingTermination );
    1db8:	08 ef       	ldi	r16, 0xF8	; 248
    1dba:	13 e0       	ldi	r17, 0x03	; 3

			A critical region is not required here as we are just reading from
			the list, and an occasional incorrect value will not matter.  If
			the ready list at the idle priority contains more than one task
			then a task other than the idle task is ready to execute. */
			if( listCURRENT_LIST_LENGTH( &( pxReadyTasksLists[ tskIDLE_PRIORITY ] ) ) > ( UBaseType_t ) 1 )
    1dbc:	0f 2e       	mov	r0, r31
    1dbe:	f0 eb       	ldi	r31, 0xB0	; 176
    1dc0:	ef 2e       	mov	r14, r31
    1dc2:	f3 e0       	ldi	r31, 0x03	; 3
    1dc4:	ff 2e       	mov	r15, r31
    1dc6:	f0 2d       	mov	r31, r0
    1dc8:	24 c0       	rjmp	.+72     	; 0x1e12 <prvIdleTask+0x5a>

		/* ucTasksDeleted is used to prevent vTaskSuspendAll() being called
		too often in the idle task. */
		while( uxDeletedTasksWaitingCleanUp > ( UBaseType_t ) 0U )
		{
			vTaskSuspendAll();
    1dca:	0e 94 97 0d 	call	0x1b2e	; 0x1b2e <vTaskSuspendAll>
			{
				xListIsEmpty = listLIST_IS_EMPTY( &xTasksWaitingTermination );
    1dce:	f8 01       	movw	r30, r16
    1dd0:	c0 81       	ld	r28, Z
			}
			( void ) xTaskResumeAll();
    1dd2:	0e 94 5c 0e 	call	0x1cb8	; 0x1cb8 <xTaskResumeAll>

			if( xListIsEmpty == pdFALSE )
    1dd6:	cc 23       	and	r28, r28
    1dd8:	e1 f0       	breq	.+56     	; 0x1e12 <prvIdleTask+0x5a>
			{
				TCB_t *pxTCB;

				taskENTER_CRITICAL();
    1dda:	0f b6       	in	r0, 0x3f	; 63
    1ddc:	f8 94       	cli
    1dde:	0f 92       	push	r0
				{
					pxTCB = ( TCB_t * ) listGET_OWNER_OF_HEAD_ENTRY( ( &xTasksWaitingTermination ) );
    1de0:	e0 91 fd 03 	lds	r30, 0x03FD
    1de4:	f0 91 fe 03 	lds	r31, 0x03FE
    1de8:	c6 81       	ldd	r28, Z+6	; 0x06
    1dea:	d7 81       	ldd	r29, Z+7	; 0x07
					( void ) uxListRemove( &( pxTCB->xStateListItem ) );
    1dec:	ce 01       	movw	r24, r28
    1dee:	02 96       	adiw	r24, 0x02	; 2
    1df0:	0e 94 ce 03 	call	0x79c	; 0x79c <uxListRemove>
					--uxCurrentNumberOfTasks;
    1df4:	80 91 a9 03 	lds	r24, 0x03A9
    1df8:	81 50       	subi	r24, 0x01	; 1
    1dfa:	80 93 a9 03 	sts	0x03A9, r24
					--uxDeletedTasksWaitingCleanUp;
    1dfe:	80 91 aa 03 	lds	r24, 0x03AA
    1e02:	81 50       	subi	r24, 0x01	; 1
    1e04:	80 93 aa 03 	sts	0x03AA, r24
				}
				taskEXIT_CRITICAL();
    1e08:	0f 90       	pop	r0
    1e0a:	0f be       	out	0x3f, r0	; 63

				prvDeleteTCB( pxTCB );
    1e0c:	ce 01       	movw	r24, r28
    1e0e:	0e 94 c1 0a 	call	0x1582	; 0x1582 <prvDeleteTCB>
	{
		BaseType_t xListIsEmpty;

		/* ucTasksDeleted is used to prevent vTaskSuspendAll() being called
		too often in the idle task. */
		while( uxDeletedTasksWaitingCleanUp > ( UBaseType_t ) 0U )
    1e12:	80 91 aa 03 	lds	r24, 0x03AA
    1e16:	88 23       	and	r24, r24
    1e18:	c1 f6       	brne	.-80     	; 0x1dca <prvIdleTask+0x12>

			A critical region is not required here as we are just reading from
			the list, and an occasional incorrect value will not matter.  If
			the ready list at the idle priority contains more than one task
			then a task other than the idle task is ready to execute. */
			if( listCURRENT_LIST_LENGTH( &( pxReadyTasksLists[ tskIDLE_PRIORITY ] ) ) > ( UBaseType_t ) 1 )
    1e1a:	f7 01       	movw	r30, r14
    1e1c:	80 81       	ld	r24, Z
    1e1e:	82 30       	cpi	r24, 0x02	; 2
    1e20:	c0 f3       	brcs	.-16     	; 0x1e12 <prvIdleTask+0x5a>
			{
				taskYIELD();
    1e22:	0e 94 bc 04 	call	0x978	; 0x978 <vPortYield>
    1e26:	f5 cf       	rjmp	.-22     	; 0x1e12 <prvIdleTask+0x5a>

00001e28 <vTaskDelay>:
/*-----------------------------------------------------------*/

#if ( INCLUDE_vTaskDelay == 1 )

	void vTaskDelay( const TickType_t xTicksToDelay )
	{
    1e28:	cf 93       	push	r28
    1e2a:	df 93       	push	r29
    1e2c:	ec 01       	movw	r28, r24
	BaseType_t xAlreadyYielded = pdFALSE;

		/* A delay time of zero just forces a reschedule. */
		if( xTicksToDelay > ( TickType_t ) 0U )
    1e2e:	00 97       	sbiw	r24, 0x00	; 0
    1e30:	51 f0       	breq	.+20     	; 0x1e46 <vTaskDelay+0x1e>
		{
			configASSERT( uxSchedulerSuspended == 0 );
			vTaskSuspendAll();
    1e32:	0e 94 97 0d 	call	0x1b2e	; 0x1b2e <vTaskSuspendAll>
				list or removed from the blocked list until the scheduler
				is resumed.

				This task cannot be in an event list as it is the currently
				executing task. */
				prvAddCurrentTaskToDelayedList( xTicksToDelay, pdFALSE );
    1e36:	ce 01       	movw	r24, r28
    1e38:	60 e0       	ldi	r22, 0x00	; 0
    1e3a:	0e 94 69 0a 	call	0x14d2	; 0x14d2 <prvAddCurrentTaskToDelayedList>
			}
			xAlreadyYielded = xTaskResumeAll();
    1e3e:	0e 94 5c 0e 	call	0x1cb8	; 0x1cb8 <xTaskResumeAll>
			mtCOVERAGE_TEST_MARKER();
		}

		/* Force a reschedule if xTaskResumeAll has not already done so, we may
		have put ourselves to sleep. */
		if( xAlreadyYielded == pdFALSE )
    1e42:	88 23       	and	r24, r24
    1e44:	11 f4       	brne	.+4      	; 0x1e4a <vTaskDelay+0x22>
		{
			portYIELD_WITHIN_API();
    1e46:	0e 94 bc 04 	call	0x978	; 0x978 <vPortYield>
		}
		else
		{
			mtCOVERAGE_TEST_MARKER();
		}
	}
    1e4a:	df 91       	pop	r29
    1e4c:	cf 91       	pop	r28
    1e4e:	08 95       	ret

00001e50 <vTaskDelayUntil>:
/*-----------------------------------------------------------*/

#if ( INCLUDE_vTaskDelayUntil == 1 )

	void vTaskDelayUntil( TickType_t * const pxPreviousWakeTime, const TickType_t xTimeIncrement )
	{
    1e50:	0f 93       	push	r16
    1e52:	1f 93       	push	r17
    1e54:	cf 93       	push	r28
    1e56:	df 93       	push	r29
    1e58:	8c 01       	movw	r16, r24
    1e5a:	eb 01       	movw	r28, r22

		configASSERT( pxPreviousWakeTime );
		configASSERT( ( xTimeIncrement > 0U ) );
		configASSERT( uxSchedulerSuspended == 0 );

		vTaskSuspendAll();
    1e5c:	0e 94 97 0d 	call	0x1b2e	; 0x1b2e <vTaskSuspendAll>
		{
			/* Minor optimisation.  The tick count cannot change in this
			block. */
			const TickType_t xConstTickCount = xTickCount;
    1e60:	80 91 a7 03 	lds	r24, 0x03A7
    1e64:	90 91 a8 03 	lds	r25, 0x03A8

			/* Generate the tick time at which the task wants to wake. */
			xTimeToWake = *pxPreviousWakeTime + xTimeIncrement;
    1e68:	f8 01       	movw	r30, r16
    1e6a:	20 81       	ld	r18, Z
    1e6c:	31 81       	ldd	r19, Z+1	; 0x01
    1e6e:	c2 0f       	add	r28, r18
    1e70:	d3 1f       	adc	r29, r19

			if( xConstTickCount < *pxPreviousWakeTime )
    1e72:	82 17       	cp	r24, r18
    1e74:	93 07       	cpc	r25, r19
    1e76:	48 f4       	brcc	.+18     	; 0x1e8a <vTaskDelayUntil+0x3a>
				/* The tick count has overflowed since this function was
				lasted called.  In this case the only time we should ever
				actually delay is if the wake time has also	overflowed,
				and the wake time is greater than the tick time.  When this
				is the case it is as if neither time had overflowed. */
				if( ( xTimeToWake < *pxPreviousWakeTime ) && ( xTimeToWake > xConstTickCount ) )
    1e78:	c2 17       	cp	r28, r18
    1e7a:	d3 07       	cpc	r29, r19
    1e7c:	f8 f4       	brcc	.+62     	; 0x1ebc <vTaskDelayUntil+0x6c>
					mtCOVERAGE_TEST_MARKER();
				}
			}

			/* Update the wake time ready for the next call. */
			*pxPreviousWakeTime = xTimeToWake;
    1e7e:	d1 83       	std	Z+1, r29	; 0x01
    1e80:	c0 83       	st	Z, r28

			if( xShouldDelay != pdFALSE )
    1e82:	8c 17       	cp	r24, r28
    1e84:	9d 07       	cpc	r25, r29
    1e86:	78 f4       	brcc	.+30     	; 0x1ea6 <vTaskDelayUntil+0x56>
    1e88:	07 c0       	rjmp	.+14     	; 0x1e98 <vTaskDelayUntil+0x48>
			else
			{
				/* The tick time has not overflowed.  In this case we will
				delay if either the wake time has overflowed, and/or the
				tick time is less than the wake time. */
				if( ( xTimeToWake < *pxPreviousWakeTime ) || ( xTimeToWake > xConstTickCount ) )
    1e8a:	c2 17       	cp	r28, r18
    1e8c:	d3 07       	cpc	r29, r19
    1e8e:	90 f0       	brcs	.+36     	; 0x1eb4 <vTaskDelayUntil+0x64>
    1e90:	8c 17       	cp	r24, r28
    1e92:	9d 07       	cpc	r25, r29
    1e94:	78 f0       	brcs	.+30     	; 0x1eb4 <vTaskDelayUntil+0x64>
    1e96:	12 c0       	rjmp	.+36     	; 0x1ebc <vTaskDelayUntil+0x6c>
			{
				traceTASK_DELAY_UNTIL( xTimeToWake );

				/* prvAddCurrentTaskToDelayedList() needs the block time, not
				the time to wake, so subtract the current tick count. */
				prvAddCurrentTaskToDelayedList( xTimeToWake - xConstTickCount, pdFALSE );
    1e98:	9e 01       	movw	r18, r28
    1e9a:	28 1b       	sub	r18, r24
    1e9c:	39 0b       	sbc	r19, r25
    1e9e:	c9 01       	movw	r24, r18
    1ea0:	60 e0       	ldi	r22, 0x00	; 0
    1ea2:	0e 94 69 0a 	call	0x14d2	; 0x14d2 <prvAddCurrentTaskToDelayedList>
			else
			{
				mtCOVERAGE_TEST_MARKER();
			}
		}
		xAlreadyYielded = xTaskResumeAll();
    1ea6:	0e 94 5c 0e 	call	0x1cb8	; 0x1cb8 <xTaskResumeAll>

		/* Force a reschedule if xTaskResumeAll has not already done so, we may
		have put ourselves to sleep. */
		if( xAlreadyYielded == pdFALSE )
    1eaa:	88 23       	and	r24, r24
    1eac:	59 f4       	brne	.+22     	; 0x1ec4 <vTaskDelayUntil+0x74>
		{
			portYIELD_WITHIN_API();
    1eae:	0e 94 bc 04 	call	0x978	; 0x978 <vPortYield>
    1eb2:	08 c0       	rjmp	.+16     	; 0x1ec4 <vTaskDelayUntil+0x74>
					mtCOVERAGE_TEST_MARKER();
				}
			}

			/* Update the wake time ready for the next call. */
			*pxPreviousWakeTime = xTimeToWake;
    1eb4:	f8 01       	movw	r30, r16
    1eb6:	d1 83       	std	Z+1, r29	; 0x01
    1eb8:	c0 83       	st	Z, r28
    1eba:	ee cf       	rjmp	.-36     	; 0x1e98 <vTaskDelayUntil+0x48>
    1ebc:	f8 01       	movw	r30, r16
    1ebe:	d1 83       	std	Z+1, r29	; 0x01
    1ec0:	c0 83       	st	Z, r28
    1ec2:	f1 cf       	rjmp	.-30     	; 0x1ea6 <vTaskDelayUntil+0x56>
		}
		else
		{
			mtCOVERAGE_TEST_MARKER();
		}
	}
    1ec4:	df 91       	pop	r29
    1ec6:	cf 91       	pop	r28
    1ec8:	1f 91       	pop	r17
    1eca:	0f 91       	pop	r16
    1ecc:	08 95       	ret

00001ece <vTaskSwitchContext>:
#endif /* configUSE_APPLICATION_TASK_TAG */
/*-----------------------------------------------------------*/

void vTaskSwitchContext( void )
{
	if( uxSchedulerSuspended != ( UBaseType_t ) pdFALSE )
    1ece:	80 91 9f 03 	lds	r24, 0x039F
    1ed2:	88 23       	and	r24, r24
    1ed4:	21 f0       	breq	.+8      	; 0x1ede <vTaskSwitchContext+0x10>
	{
		/* The scheduler is currently suspended - do not allow a context
		switch. */
		xYieldPending = pdTRUE;
    1ed6:	81 e0       	ldi	r24, 0x01	; 1
    1ed8:	80 93 a3 03 	sts	0x03A3, r24
    1edc:	08 95       	ret
	}
	else
	{
		xYieldPending = pdFALSE;
    1ede:	10 92 a3 03 	sts	0x03A3, r1
		/* Check for stack overflow, if configured. */
		taskCHECK_FOR_STACK_OVERFLOW();

		/* Select a new task to run using either the generic C or port
		optimised asm code. */
		taskSELECT_HIGHEST_PRIORITY_TASK();
    1ee2:	20 91 a6 03 	lds	r18, 0x03A6
    1ee6:	82 2f       	mov	r24, r18
    1ee8:	90 e0       	ldi	r25, 0x00	; 0
    1eea:	fc 01       	movw	r30, r24
    1eec:	ee 0f       	add	r30, r30
    1eee:	ff 1f       	adc	r31, r31
    1ef0:	ee 0f       	add	r30, r30
    1ef2:	ff 1f       	adc	r31, r31
    1ef4:	ee 0f       	add	r30, r30
    1ef6:	ff 1f       	adc	r31, r31
    1ef8:	e8 0f       	add	r30, r24
    1efa:	f9 1f       	adc	r31, r25
    1efc:	e0 55       	subi	r30, 0x50	; 80
    1efe:	fc 4f       	sbci	r31, 0xFC	; 252
    1f00:	30 81       	ld	r19, Z
    1f02:	33 23       	and	r19, r19
    1f04:	89 f4       	brne	.+34     	; 0x1f28 <vTaskSwitchContext+0x5a>
    1f06:	21 50       	subi	r18, 0x01	; 1
    1f08:	82 2f       	mov	r24, r18
    1f0a:	90 e0       	ldi	r25, 0x00	; 0
    1f0c:	fc 01       	movw	r30, r24
    1f0e:	ee 0f       	add	r30, r30
    1f10:	ff 1f       	adc	r31, r31
    1f12:	ee 0f       	add	r30, r30
    1f14:	ff 1f       	adc	r31, r31
    1f16:	ee 0f       	add	r30, r30
    1f18:	ff 1f       	adc	r31, r31
    1f1a:	e8 0f       	add	r30, r24
    1f1c:	f9 1f       	adc	r31, r25
    1f1e:	e0 55       	subi	r30, 0x50	; 80
    1f20:	fc 4f       	sbci	r31, 0xFC	; 252
    1f22:	30 81       	ld	r19, Z
    1f24:	33 23       	and	r19, r19
    1f26:	79 f3       	breq	.-34     	; 0x1f06 <vTaskSwitchContext+0x38>
    1f28:	dc 01       	movw	r26, r24
    1f2a:	aa 0f       	add	r26, r26
    1f2c:	bb 1f       	adc	r27, r27
    1f2e:	aa 0f       	add	r26, r26
    1f30:	bb 1f       	adc	r27, r27
    1f32:	aa 0f       	add	r26, r26
    1f34:	bb 1f       	adc	r27, r27
    1f36:	8a 0f       	add	r24, r26
    1f38:	9b 1f       	adc	r25, r27
    1f3a:	dc 01       	movw	r26, r24
    1f3c:	a0 55       	subi	r26, 0x50	; 80
    1f3e:	bc 4f       	sbci	r27, 0xFC	; 252
    1f40:	11 96       	adiw	r26, 0x01	; 1
    1f42:	ed 91       	ld	r30, X+
    1f44:	fc 91       	ld	r31, X
    1f46:	12 97       	sbiw	r26, 0x02	; 2
    1f48:	02 80       	ldd	r0, Z+2	; 0x02
    1f4a:	f3 81       	ldd	r31, Z+3	; 0x03
    1f4c:	e0 2d       	mov	r30, r0
    1f4e:	12 96       	adiw	r26, 0x02	; 2
    1f50:	fc 93       	st	X, r31
    1f52:	ee 93       	st	-X, r30
    1f54:	11 97       	sbiw	r26, 0x01	; 1
    1f56:	cd 01       	movw	r24, r26
    1f58:	03 96       	adiw	r24, 0x03	; 3
    1f5a:	e8 17       	cp	r30, r24
    1f5c:	f9 07       	cpc	r31, r25
    1f5e:	31 f4       	brne	.+12     	; 0x1f6c <vTaskSwitchContext+0x9e>
    1f60:	82 81       	ldd	r24, Z+2	; 0x02
    1f62:	93 81       	ldd	r25, Z+3	; 0x03
    1f64:	12 96       	adiw	r26, 0x02	; 2
    1f66:	9c 93       	st	X, r25
    1f68:	8e 93       	st	-X, r24
    1f6a:	11 97       	sbiw	r26, 0x01	; 1
    1f6c:	11 96       	adiw	r26, 0x01	; 1
    1f6e:	ed 91       	ld	r30, X+
    1f70:	fc 91       	ld	r31, X
    1f72:	12 97       	sbiw	r26, 0x02	; 2
    1f74:	86 81       	ldd	r24, Z+6	; 0x06
    1f76:	97 81       	ldd	r25, Z+7	; 0x07
    1f78:	90 93 9e 03 	sts	0x039E, r25
    1f7c:	80 93 9d 03 	sts	0x039D, r24
    1f80:	20 93 a6 03 	sts	0x03A6, r18
    1f84:	08 95       	ret

00001f86 <vTaskSuspend>:
/*-----------------------------------------------------------*/

#if ( INCLUDE_vTaskSuspend == 1 )

	void vTaskSuspend( TaskHandle_t xTaskToSuspend )
	{
    1f86:	0f 93       	push	r16
    1f88:	1f 93       	push	r17
    1f8a:	cf 93       	push	r28
    1f8c:	df 93       	push	r29
	TCB_t *pxTCB;

		taskENTER_CRITICAL();
    1f8e:	0f b6       	in	r0, 0x3f	; 63
    1f90:	f8 94       	cli
    1f92:	0f 92       	push	r0
		{
			/* If null is passed in here then it is the running task that is
			being suspended. */
			pxTCB = prvGetTCBFromHandle( xTaskToSuspend );
    1f94:	00 97       	sbiw	r24, 0x00	; 0
    1f96:	29 f4       	brne	.+10     	; 0x1fa2 <vTaskSuspend+0x1c>
    1f98:	00 91 9d 03 	lds	r16, 0x039D
    1f9c:	10 91 9e 03 	lds	r17, 0x039E
    1fa0:	01 c0       	rjmp	.+2      	; 0x1fa4 <vTaskSuspend+0x1e>
    1fa2:	8c 01       	movw	r16, r24

			traceTASK_SUSPEND( pxTCB );

			/* Remove task from the ready/delayed list and place in the
			suspended list. */
			if( uxListRemove( &( pxTCB->xStateListItem ) ) == ( UBaseType_t ) 0 )
    1fa4:	e8 01       	movw	r28, r16
    1fa6:	22 96       	adiw	r28, 0x02	; 2
    1fa8:	ce 01       	movw	r24, r28
    1faa:	0e 94 ce 03 	call	0x79c	; 0x79c <uxListRemove>
			{
				mtCOVERAGE_TEST_MARKER();
			}

			/* Is the task waiting on an event also? */
			if( listLIST_ITEM_CONTAINER( &( pxTCB->xEventListItem ) ) != NULL )
    1fae:	f8 01       	movw	r30, r16
    1fb0:	84 89       	ldd	r24, Z+20	; 0x14
    1fb2:	95 89       	ldd	r25, Z+21	; 0x15
    1fb4:	00 97       	sbiw	r24, 0x00	; 0
    1fb6:	21 f0       	breq	.+8      	; 0x1fc0 <vTaskSuspend+0x3a>
			{
				( void ) uxListRemove( &( pxTCB->xEventListItem ) );
    1fb8:	c8 01       	movw	r24, r16
    1fba:	0c 96       	adiw	r24, 0x0c	; 12
    1fbc:	0e 94 ce 03 	call	0x79c	; 0x79c <uxListRemove>
			else
			{
				mtCOVERAGE_TEST_MARKER();
			}

			vListInsertEnd( &xSuspendedTaskList, &( pxTCB->xStateListItem ) );
    1fc0:	81 e0       	ldi	r24, 0x01	; 1
    1fc2:	94 e0       	ldi	r25, 0x04	; 4
    1fc4:	be 01       	movw	r22, r28
    1fc6:	0e 94 7d 03 	call	0x6fa	; 0x6fa <vListInsertEnd>
		}
		taskEXIT_CRITICAL();
    1fca:	0f 90       	pop	r0
    1fcc:	0f be       	out	0x3f, r0	; 63

		if( xSchedulerRunning != pdFALSE )
    1fce:	80 91 a5 03 	lds	r24, 0x03A5
    1fd2:	88 23       	and	r24, r24
    1fd4:	39 f0       	breq	.+14     	; 0x1fe4 <vTaskSuspend+0x5e>
		{
			/* Reset the next expected unblock time in case it referred to the
			task that is now in the Suspended state. */
			taskENTER_CRITICAL();
    1fd6:	0f b6       	in	r0, 0x3f	; 63
    1fd8:	f8 94       	cli
    1fda:	0f 92       	push	r0
			{
				prvResetNextTaskUnblockTime();
    1fdc:	0e 94 4a 0a 	call	0x1494	; 0x1494 <prvResetNextTaskUnblockTime>
			}
			taskEXIT_CRITICAL();
    1fe0:	0f 90       	pop	r0
    1fe2:	0f be       	out	0x3f, r0	; 63
		else
		{
			mtCOVERAGE_TEST_MARKER();
		}

		if( pxTCB == pxCurrentTCB )
    1fe4:	80 91 9d 03 	lds	r24, 0x039D
    1fe8:	90 91 9e 03 	lds	r25, 0x039E
    1fec:	08 17       	cp	r16, r24
    1fee:	19 07       	cpc	r17, r25
    1ff0:	a1 f4       	brne	.+40     	; 0x201a <vTaskSuspend+0x94>
		{
			if( xSchedulerRunning != pdFALSE )
    1ff2:	80 91 a5 03 	lds	r24, 0x03A5
    1ff6:	88 23       	and	r24, r24
    1ff8:	19 f0       	breq	.+6      	; 0x2000 <vTaskSuspend+0x7a>
			{
				/* The current task has just been suspended. */
				configASSERT( uxSchedulerSuspended == 0 );
				portYIELD_WITHIN_API();
    1ffa:	0e 94 bc 04 	call	0x978	; 0x978 <vPortYield>
    1ffe:	0d c0       	rjmp	.+26     	; 0x201a <vTaskSuspend+0x94>
			else
			{
				/* The scheduler is not running, but the task that was pointed
				to by pxCurrentTCB has just been suspended and pxCurrentTCB
				must be adjusted to point to a different task. */
				if( listCURRENT_LIST_LENGTH( &xSuspendedTaskList ) == uxCurrentNumberOfTasks )
    2000:	80 91 a9 03 	lds	r24, 0x03A9
    2004:	90 91 01 04 	lds	r25, 0x0401
    2008:	98 17       	cp	r25, r24
    200a:	29 f4       	brne	.+10     	; 0x2016 <vTaskSuspend+0x90>
				{
					/* No other tasks are ready, so set pxCurrentTCB back to
					NULL so when the next task is created pxCurrentTCB will
					be set to point to it no matter what its relative priority
					is. */
					pxCurrentTCB = NULL;
    200c:	10 92 9e 03 	sts	0x039E, r1
    2010:	10 92 9d 03 	sts	0x039D, r1
    2014:	02 c0       	rjmp	.+4      	; 0x201a <vTaskSuspend+0x94>
				}
				else
				{
					vTaskSwitchContext();
    2016:	0e 94 67 0f 	call	0x1ece	; 0x1ece <vTaskSwitchContext>
		}
		else
		{
			mtCOVERAGE_TEST_MARKER();
		}
	}
    201a:	df 91       	pop	r29
    201c:	cf 91       	pop	r28
    201e:	1f 91       	pop	r17
    2020:	0f 91       	pop	r16
    2022:	08 95       	ret

00002024 <vTaskPlaceOnEventList>:
	}
}
/*-----------------------------------------------------------*/

void vTaskPlaceOnEventList( List_t * const pxEventList, const TickType_t xTicksToWait )
{
    2024:	cf 93       	push	r28
    2026:	df 93       	push	r29
    2028:	eb 01       	movw	r28, r22

	/* Place the event list item of the TCB in the appropriate event list.
	This is placed in the list in priority order so the highest priority task
	is the first to be woken by the event.  The queue that contains the event
	list is locked, preventing simultaneous access from interrupts. */
	vListInsert( pxEventList, &( pxCurrentTCB->xEventListItem ) );
    202a:	60 91 9d 03 	lds	r22, 0x039D
    202e:	70 91 9e 03 	lds	r23, 0x039E
    2032:	64 5f       	subi	r22, 0xF4	; 244
    2034:	7f 4f       	sbci	r23, 0xFF	; 255
    2036:	0e 94 9c 03 	call	0x738	; 0x738 <vListInsert>

	prvAddCurrentTaskToDelayedList( xTicksToWait, pdTRUE );
    203a:	ce 01       	movw	r24, r28
    203c:	61 e0       	ldi	r22, 0x01	; 1
    203e:	0e 94 69 0a 	call	0x14d2	; 0x14d2 <prvAddCurrentTaskToDelayedList>
}
    2042:	df 91       	pop	r29
    2044:	cf 91       	pop	r28
    2046:	08 95       	ret

00002048 <vTaskPlaceOnUnorderedEventList>:
/*-----------------------------------------------------------*/

void vTaskPlaceOnUnorderedEventList( List_t * pxEventList, const TickType_t xItemValue, const TickType_t xTicksToWait )
{
    2048:	cf 93       	push	r28
    204a:	df 93       	push	r29
    204c:	ea 01       	movw	r28, r20
	configASSERT( uxSchedulerSuspended != 0 );

	/* Store the item value in the event list item.  It is safe to access the
	event list item here as interrupts won't access the event list item of a
	task that is not in the Blocked state. */
	listSET_LIST_ITEM_VALUE( &( pxCurrentTCB->xEventListItem ), xItemValue | taskEVENT_LIST_ITEM_VALUE_IN_USE );
    204e:	e0 91 9d 03 	lds	r30, 0x039D
    2052:	f0 91 9e 03 	lds	r31, 0x039E
    2056:	70 68       	ori	r23, 0x80	; 128
    2058:	75 87       	std	Z+13, r23	; 0x0d
    205a:	64 87       	std	Z+12, r22	; 0x0c
	/* Place the event list item of the TCB at the end of the appropriate event
	list.  It is safe to access the event list here because it is part of an
	event group implementation - and interrupts don't access event groups
	directly (instead they access them indirectly by pending function calls to
	the task level). */
	vListInsertEnd( pxEventList, &( pxCurrentTCB->xEventListItem ) );
    205c:	60 91 9d 03 	lds	r22, 0x039D
    2060:	70 91 9e 03 	lds	r23, 0x039E
    2064:	64 5f       	subi	r22, 0xF4	; 244
    2066:	7f 4f       	sbci	r23, 0xFF	; 255
    2068:	0e 94 7d 03 	call	0x6fa	; 0x6fa <vListInsertEnd>

	prvAddCurrentTaskToDelayedList( xTicksToWait, pdTRUE );
    206c:	ce 01       	movw	r24, r28
    206e:	61 e0       	ldi	r22, 0x01	; 1
    2070:	0e 94 69 0a 	call	0x14d2	; 0x14d2 <prvAddCurrentTaskToDelayedList>
}
    2074:	df 91       	pop	r29
    2076:	cf 91       	pop	r28
    2078:	08 95       	ret

0000207a <xTaskRemoveFromEventList>:

#endif /* configUSE_TIMERS */
/*-----------------------------------------------------------*/

BaseType_t xTaskRemoveFromEventList( const List_t * const pxEventList )
{
    207a:	0f 93       	push	r16
    207c:	1f 93       	push	r17
    207e:	cf 93       	push	r28
    2080:	df 93       	push	r29
	get called - the lock count on the queue will get modified instead.  This
	means exclusive access to the event list is guaranteed here.

	This function assumes that a check has already been made to ensure that
	pxEventList is not empty. */
	pxUnblockedTCB = ( TCB_t * ) listGET_OWNER_OF_HEAD_ENTRY( pxEventList );
    2082:	dc 01       	movw	r26, r24
    2084:	15 96       	adiw	r26, 0x05	; 5
    2086:	ed 91       	ld	r30, X+
    2088:	fc 91       	ld	r31, X
    208a:	16 97       	sbiw	r26, 0x06	; 6
    208c:	06 81       	ldd	r16, Z+6	; 0x06
    208e:	17 81       	ldd	r17, Z+7	; 0x07
	configASSERT( pxUnblockedTCB );
	( void ) uxListRemove( &( pxUnblockedTCB->xEventListItem ) );
    2090:	e8 01       	movw	r28, r16
    2092:	2c 96       	adiw	r28, 0x0c	; 12
    2094:	ce 01       	movw	r24, r28
    2096:	0e 94 ce 03 	call	0x79c	; 0x79c <uxListRemove>

	if( uxSchedulerSuspended == ( UBaseType_t ) pdFALSE )
    209a:	80 91 9f 03 	lds	r24, 0x039F
    209e:	88 23       	and	r24, r24
    20a0:	e9 f4       	brne	.+58     	; 0x20dc <xTaskRemoveFromEventList+0x62>
	{
		( void ) uxListRemove( &( pxUnblockedTCB->xStateListItem ) );
    20a2:	e8 01       	movw	r28, r16
    20a4:	22 96       	adiw	r28, 0x02	; 2
    20a6:	ce 01       	movw	r24, r28
    20a8:	0e 94 ce 03 	call	0x79c	; 0x79c <uxListRemove>
		prvAddTaskToReadyList( pxUnblockedTCB );
    20ac:	f8 01       	movw	r30, r16
    20ae:	86 89       	ldd	r24, Z+22	; 0x16
    20b0:	90 91 a6 03 	lds	r25, 0x03A6
    20b4:	98 17       	cp	r25, r24
    20b6:	10 f4       	brcc	.+4      	; 0x20bc <xTaskRemoveFromEventList+0x42>
    20b8:	80 93 a6 03 	sts	0x03A6, r24
    20bc:	90 e0       	ldi	r25, 0x00	; 0
    20be:	9c 01       	movw	r18, r24
    20c0:	22 0f       	add	r18, r18
    20c2:	33 1f       	adc	r19, r19
    20c4:	22 0f       	add	r18, r18
    20c6:	33 1f       	adc	r19, r19
    20c8:	22 0f       	add	r18, r18
    20ca:	33 1f       	adc	r19, r19
    20cc:	82 0f       	add	r24, r18
    20ce:	93 1f       	adc	r25, r19
    20d0:	80 55       	subi	r24, 0x50	; 80
    20d2:	9c 4f       	sbci	r25, 0xFC	; 252
    20d4:	be 01       	movw	r22, r28
    20d6:	0e 94 7d 03 	call	0x6fa	; 0x6fa <vListInsertEnd>
    20da:	05 c0       	rjmp	.+10     	; 0x20e6 <xTaskRemoveFromEventList+0x6c>
	}
	else
	{
		/* The delayed and ready lists cannot be accessed, so hold this task
		pending until the scheduler is resumed. */
		vListInsertEnd( &( xPendingReadyList ), &( pxUnblockedTCB->xEventListItem ) );
    20dc:	8f ee       	ldi	r24, 0xEF	; 239
    20de:	93 e0       	ldi	r25, 0x03	; 3
    20e0:	be 01       	movw	r22, r28
    20e2:	0e 94 7d 03 	call	0x6fa	; 0x6fa <vListInsertEnd>
	}

	if( pxUnblockedTCB->uxPriority > pxCurrentTCB->uxPriority )
    20e6:	e0 91 9d 03 	lds	r30, 0x039D
    20ea:	f0 91 9e 03 	lds	r31, 0x039E
    20ee:	d8 01       	movw	r26, r16
    20f0:	56 96       	adiw	r26, 0x16	; 22
    20f2:	9c 91       	ld	r25, X
    20f4:	56 97       	sbiw	r26, 0x16	; 22
    20f6:	86 89       	ldd	r24, Z+22	; 0x16
    20f8:	89 17       	cp	r24, r25
    20fa:	20 f4       	brcc	.+8      	; 0x2104 <xTaskRemoveFromEventList+0x8a>
		it should force a context switch now. */
		xReturn = pdTRUE;

		/* Mark that a yield is pending in case the user is not using the
		"xHigherPriorityTaskWoken" parameter to an ISR safe FreeRTOS function. */
		xYieldPending = pdTRUE;
    20fc:	81 e0       	ldi	r24, 0x01	; 1
    20fe:	80 93 a3 03 	sts	0x03A3, r24
    2102:	01 c0       	rjmp	.+2      	; 0x2106 <xTaskRemoveFromEventList+0x8c>
	}
	else
	{
		xReturn = pdFALSE;
    2104:	80 e0       	ldi	r24, 0x00	; 0
		prvResetNextTaskUnblockTime();
	}
	#endif

	return xReturn;
}
    2106:	df 91       	pop	r29
    2108:	cf 91       	pop	r28
    210a:	1f 91       	pop	r17
    210c:	0f 91       	pop	r16
    210e:	08 95       	ret

00002110 <xTaskRemoveFromUnorderedEventList>:
/*-----------------------------------------------------------*/

BaseType_t xTaskRemoveFromUnorderedEventList( ListItem_t * pxEventListItem, const TickType_t xItemValue )
{
    2110:	0f 93       	push	r16
    2112:	1f 93       	push	r17
    2114:	cf 93       	push	r28
    2116:	df 93       	push	r29
	/* THIS FUNCTION MUST BE CALLED WITH THE SCHEDULER SUSPENDED.  It is used by
	the event flags implementation. */
	configASSERT( uxSchedulerSuspended != pdFALSE );

	/* Store the new item value in the event list. */
	listSET_LIST_ITEM_VALUE( pxEventListItem, xItemValue | taskEVENT_LIST_ITEM_VALUE_IN_USE );
    2118:	70 68       	ori	r23, 0x80	; 128
    211a:	fc 01       	movw	r30, r24
    211c:	71 83       	std	Z+1, r23	; 0x01
    211e:	60 83       	st	Z, r22

	/* Remove the event list form the event flag.  Interrupts do not access
	event flags. */
	pxUnblockedTCB = ( TCB_t * ) listGET_LIST_ITEM_OWNER( pxEventListItem );
    2120:	c6 81       	ldd	r28, Z+6	; 0x06
    2122:	d7 81       	ldd	r29, Z+7	; 0x07
	configASSERT( pxUnblockedTCB );
	( void ) uxListRemove( pxEventListItem );
    2124:	0e 94 ce 03 	call	0x79c	; 0x79c <uxListRemove>

	/* Remove the task from the delayed list and add it to the ready list.  The
	scheduler is suspended so interrupts will not be accessing the ready
	lists. */
	( void ) uxListRemove( &( pxUnblockedTCB->xStateListItem ) );
    2128:	8e 01       	movw	r16, r28
    212a:	0e 5f       	subi	r16, 0xFE	; 254
    212c:	1f 4f       	sbci	r17, 0xFF	; 255
    212e:	c8 01       	movw	r24, r16
    2130:	0e 94 ce 03 	call	0x79c	; 0x79c <uxListRemove>
	prvAddTaskToReadyList( pxUnblockedTCB );
    2134:	8e 89       	ldd	r24, Y+22	; 0x16
    2136:	90 91 a6 03 	lds	r25, 0x03A6
    213a:	98 17       	cp	r25, r24
    213c:	10 f4       	brcc	.+4      	; 0x2142 <xTaskRemoveFromUnorderedEventList+0x32>
    213e:	80 93 a6 03 	sts	0x03A6, r24
    2142:	90 e0       	ldi	r25, 0x00	; 0
    2144:	9c 01       	movw	r18, r24
    2146:	22 0f       	add	r18, r18
    2148:	33 1f       	adc	r19, r19
    214a:	22 0f       	add	r18, r18
    214c:	33 1f       	adc	r19, r19
    214e:	22 0f       	add	r18, r18
    2150:	33 1f       	adc	r19, r19
    2152:	82 0f       	add	r24, r18
    2154:	93 1f       	adc	r25, r19
    2156:	80 55       	subi	r24, 0x50	; 80
    2158:	9c 4f       	sbci	r25, 0xFC	; 252
    215a:	b8 01       	movw	r22, r16
    215c:	0e 94 7d 03 	call	0x6fa	; 0x6fa <vListInsertEnd>

	if( pxUnblockedTCB->uxPriority > pxCurrentTCB->uxPriority )
    2160:	e0 91 9d 03 	lds	r30, 0x039D
    2164:	f0 91 9e 03 	lds	r31, 0x039E
    2168:	9e 89       	ldd	r25, Y+22	; 0x16
    216a:	86 89       	ldd	r24, Z+22	; 0x16
    216c:	89 17       	cp	r24, r25
    216e:	20 f4       	brcc	.+8      	; 0x2178 <xTaskRemoveFromUnorderedEventList+0x68>
		switch now. */
		xReturn = pdTRUE;

		/* Mark that a yield is pending in case the user is not using the
		"xHigherPriorityTaskWoken" parameter to an ISR safe FreeRTOS function. */
		xYieldPending = pdTRUE;
    2170:	81 e0       	ldi	r24, 0x01	; 1
    2172:	80 93 a3 03 	sts	0x03A3, r24
    2176:	01 c0       	rjmp	.+2      	; 0x217a <xTaskRemoveFromUnorderedEventList+0x6a>
	}
	else
	{
		xReturn = pdFALSE;
    2178:	80 e0       	ldi	r24, 0x00	; 0
	}

	return xReturn;
}
    217a:	df 91       	pop	r29
    217c:	cf 91       	pop	r28
    217e:	1f 91       	pop	r17
    2180:	0f 91       	pop	r16
    2182:	08 95       	ret

00002184 <vTaskSetTimeOutState>:
/*-----------------------------------------------------------*/

void vTaskSetTimeOutState( TimeOut_t * const pxTimeOut )
{
    2184:	fc 01       	movw	r30, r24
	configASSERT( pxTimeOut );
	pxTimeOut->xOverflowCount = xNumOfOverflows;
    2186:	80 91 a2 03 	lds	r24, 0x03A2
    218a:	80 83       	st	Z, r24
	pxTimeOut->xTimeOnEntering = xTickCount;
    218c:	80 91 a7 03 	lds	r24, 0x03A7
    2190:	90 91 a8 03 	lds	r25, 0x03A8
    2194:	92 83       	std	Z+2, r25	; 0x02
    2196:	81 83       	std	Z+1, r24	; 0x01
}
    2198:	08 95       	ret

0000219a <xTaskCheckForTimeOut>:
/*-----------------------------------------------------------*/

BaseType_t xTaskCheckForTimeOut( TimeOut_t * const pxTimeOut, TickType_t * const pxTicksToWait )
{
    219a:	fc 01       	movw	r30, r24
    219c:	db 01       	movw	r26, r22
BaseType_t xReturn;

	configASSERT( pxTimeOut );
	configASSERT( pxTicksToWait );

	taskENTER_CRITICAL();
    219e:	0f b6       	in	r0, 0x3f	; 63
    21a0:	f8 94       	cli
    21a2:	0f 92       	push	r0
	{
		/* Minor optimisation.  The tick count cannot change in this block. */
		const TickType_t xConstTickCount = xTickCount;
    21a4:	60 91 a7 03 	lds	r22, 0x03A7
    21a8:	70 91 a8 03 	lds	r23, 0x03A8
			}
			else
		#endif

		#if ( INCLUDE_vTaskSuspend == 1 )
			if( *pxTicksToWait == portMAX_DELAY )
    21ac:	4d 91       	ld	r20, X+
    21ae:	5c 91       	ld	r21, X
    21b0:	11 97       	sbiw	r26, 0x01	; 1
    21b2:	8f ef       	ldi	r24, 0xFF	; 255
    21b4:	4f 3f       	cpi	r20, 0xFF	; 255
    21b6:	58 07       	cpc	r21, r24
    21b8:	e9 f0       	breq	.+58     	; 0x21f4 <xTaskCheckForTimeOut+0x5a>
				xReturn = pdFALSE;
			}
			else
		#endif

		if( ( xNumOfOverflows != pxTimeOut->xOverflowCount ) && ( xConstTickCount >= pxTimeOut->xTimeOnEntering ) ) /*lint !e525 Indentation preferred as is to make code within pre-processor directives clearer. */
    21ba:	80 91 a2 03 	lds	r24, 0x03A2
    21be:	90 81       	ld	r25, Z
    21c0:	98 17       	cp	r25, r24
    21c2:	29 f0       	breq	.+10     	; 0x21ce <xTaskCheckForTimeOut+0x34>
    21c4:	81 81       	ldd	r24, Z+1	; 0x01
    21c6:	92 81       	ldd	r25, Z+2	; 0x02
    21c8:	68 17       	cp	r22, r24
    21ca:	79 07       	cpc	r23, r25
    21cc:	a8 f4       	brcc	.+42     	; 0x21f8 <xTaskCheckForTimeOut+0x5e>
			vTaskSetTimeOut() was called.  It must have wrapped all the way
			around and gone past again. This passed since vTaskSetTimeout()
			was called. */
			xReturn = pdTRUE;
		}
		else if( ( ( TickType_t ) ( xConstTickCount - pxTimeOut->xTimeOnEntering ) ) < *pxTicksToWait ) /*lint !e961 Explicit casting is only redundant with some compilers, whereas others require it to prevent integer conversion errors. */
    21ce:	81 81       	ldd	r24, Z+1	; 0x01
    21d0:	92 81       	ldd	r25, Z+2	; 0x02
    21d2:	9b 01       	movw	r18, r22
    21d4:	28 1b       	sub	r18, r24
    21d6:	39 0b       	sbc	r19, r25
    21d8:	24 17       	cp	r18, r20
    21da:	35 07       	cpc	r19, r21
    21dc:	78 f4       	brcc	.+30     	; 0x21fc <xTaskCheckForTimeOut+0x62>
		{
			/* Not a genuine timeout. Adjust parameters for time remaining. */
			*pxTicksToWait -= ( xConstTickCount - pxTimeOut->xTimeOnEntering );
    21de:	86 1b       	sub	r24, r22
    21e0:	97 0b       	sbc	r25, r23
    21e2:	84 0f       	add	r24, r20
    21e4:	95 1f       	adc	r25, r21
    21e6:	8d 93       	st	X+, r24
    21e8:	9c 93       	st	X, r25
			vTaskSetTimeOutState( pxTimeOut );
    21ea:	cf 01       	movw	r24, r30
    21ec:	0e 94 c2 10 	call	0x2184	; 0x2184 <vTaskSetTimeOutState>
			xReturn = pdFALSE;
    21f0:	80 e0       	ldi	r24, 0x00	; 0
    21f2:	05 c0       	rjmp	.+10     	; 0x21fe <xTaskCheckForTimeOut+0x64>
			if( *pxTicksToWait == portMAX_DELAY )
			{
				/* If INCLUDE_vTaskSuspend is set to 1 and the block time
				specified is the maximum block time then the task should block
				indefinitely, and therefore never time out. */
				xReturn = pdFALSE;
    21f4:	80 e0       	ldi	r24, 0x00	; 0
    21f6:	03 c0       	rjmp	.+6      	; 0x21fe <xTaskCheckForTimeOut+0x64>
			/* The tick count is greater than the time at which
			vTaskSetTimeout() was called, but has also overflowed since
			vTaskSetTimeOut() was called.  It must have wrapped all the way
			around and gone past again. This passed since vTaskSetTimeout()
			was called. */
			xReturn = pdTRUE;
    21f8:	81 e0       	ldi	r24, 0x01	; 1
    21fa:	01 c0       	rjmp	.+2      	; 0x21fe <xTaskCheckForTimeOut+0x64>
			vTaskSetTimeOutState( pxTimeOut );
			xReturn = pdFALSE;
		}
		else
		{
			xReturn = pdTRUE;
    21fc:	81 e0       	ldi	r24, 0x01	; 1
		}
	}
	taskEXIT_CRITICAL();
    21fe:	0f 90       	pop	r0
    2200:	0f be       	out	0x3f, r0	; 63

	return xReturn;
}
    2202:	08 95       	ret

00002204 <vTaskMissedYield>:
/*-----------------------------------------------------------*/

void vTaskMissedYield( void )
{
	xYieldPending = pdTRUE;
    2204:	81 e0       	ldi	r24, 0x01	; 1
    2206:	80 93 a3 03 	sts	0x03A3, r24
}
    220a:	08 95       	ret

0000220c <xTaskGetCurrentTaskHandle>:
	TaskHandle_t xReturn;

		/* A critical section is not required as this is not called from
		an interrupt and the current TCB will always be the same for any
		individual execution thread. */
		xReturn = pxCurrentTCB;
    220c:	80 91 9d 03 	lds	r24, 0x039D
    2210:	90 91 9e 03 	lds	r25, 0x039E

		return xReturn;
	}
    2214:	08 95       	ret

00002216 <vTaskPriorityInherit>:
/*-----------------------------------------------------------*/

#if ( configUSE_MUTEXES == 1 )

	void vTaskPriorityInherit( TaskHandle_t const pxMutexHolder )
	{
    2216:	0f 93       	push	r16
    2218:	1f 93       	push	r17
    221a:	cf 93       	push	r28
    221c:	df 93       	push	r29
    221e:	ec 01       	movw	r28, r24
	TCB_t * const pxTCB = ( TCB_t * ) pxMutexHolder;

		/* If the mutex was given back by an interrupt while the queue was
		locked then the mutex holder might now be NULL. */
		if( pxMutexHolder != NULL )
    2220:	00 97       	sbiw	r24, 0x00	; 0
    2222:	09 f4       	brne	.+2      	; 0x2226 <vTaskPriorityInherit+0x10>
    2224:	51 c0       	rjmp	.+162    	; 0x22c8 <vTaskPriorityInherit+0xb2>
		{
			/* If the holder of the mutex has a priority below the priority of
			the task attempting to obtain the mutex then it will temporarily
			inherit the priority of the task attempting to obtain the mutex. */
			if( pxTCB->uxPriority < pxCurrentTCB->uxPriority )
    2226:	8e 89       	ldd	r24, Y+22	; 0x16
    2228:	e0 91 9d 03 	lds	r30, 0x039D
    222c:	f0 91 9e 03 	lds	r31, 0x039E
    2230:	96 89       	ldd	r25, Z+22	; 0x16
    2232:	89 17       	cp	r24, r25
    2234:	08 f0       	brcs	.+2      	; 0x2238 <vTaskPriorityInherit+0x22>
    2236:	48 c0       	rjmp	.+144    	; 0x22c8 <vTaskPriorityInherit+0xb2>
			{
				/* Adjust the mutex holder state to account for its new
				priority.  Only reset the event list item value if the value is
				not	being used for anything else. */
				if( ( listGET_LIST_ITEM_VALUE( &( pxTCB->xEventListItem ) ) & taskEVENT_LIST_ITEM_VALUE_IN_USE ) == 0UL )
    2238:	2c 85       	ldd	r18, Y+12	; 0x0c
    223a:	3d 85       	ldd	r19, Y+13	; 0x0d
    223c:	33 23       	and	r19, r19
    223e:	5c f0       	brlt	.+22     	; 0x2256 <vTaskPriorityInherit+0x40>
				{
					listSET_LIST_ITEM_VALUE( &( pxTCB->xEventListItem ), ( TickType_t ) configMAX_PRIORITIES - ( TickType_t ) pxCurrentTCB->uxPriority ); /*lint !e961 MISRA exception as the casts are only redundant for some ports. */
    2240:	e0 91 9d 03 	lds	r30, 0x039D
    2244:	f0 91 9e 03 	lds	r31, 0x039E
    2248:	96 89       	ldd	r25, Z+22	; 0x16
    224a:	25 e0       	ldi	r18, 0x05	; 5
    224c:	30 e0       	ldi	r19, 0x00	; 0
    224e:	29 1b       	sub	r18, r25
    2250:	31 09       	sbc	r19, r1
    2252:	3d 87       	std	Y+13, r19	; 0x0d
    2254:	2c 87       	std	Y+12, r18	; 0x0c
					mtCOVERAGE_TEST_MARKER();
				}

				/* If the task being modified is in the ready state it will need
				to be moved into a new list. */
				if( listIS_CONTAINED_WITHIN( &( pxReadyTasksLists[ pxTCB->uxPriority ] ), &( pxTCB->xStateListItem ) ) != pdFALSE )
    2256:	90 e0       	ldi	r25, 0x00	; 0
    2258:	9c 01       	movw	r18, r24
    225a:	22 0f       	add	r18, r18
    225c:	33 1f       	adc	r19, r19
    225e:	22 0f       	add	r18, r18
    2260:	33 1f       	adc	r19, r19
    2262:	22 0f       	add	r18, r18
    2264:	33 1f       	adc	r19, r19
    2266:	82 0f       	add	r24, r18
    2268:	93 1f       	adc	r25, r19
    226a:	80 55       	subi	r24, 0x50	; 80
    226c:	9c 4f       	sbci	r25, 0xFC	; 252
    226e:	2a 85       	ldd	r18, Y+10	; 0x0a
    2270:	3b 85       	ldd	r19, Y+11	; 0x0b
    2272:	28 17       	cp	r18, r24
    2274:	39 07       	cpc	r19, r25
    2276:	11 f5       	brne	.+68     	; 0x22bc <vTaskPriorityInherit+0xa6>
				{
					if( uxListRemove( &( pxTCB->xStateListItem ) ) == ( UBaseType_t ) 0 )
    2278:	8e 01       	movw	r16, r28
    227a:	0e 5f       	subi	r16, 0xFE	; 254
    227c:	1f 4f       	sbci	r17, 0xFF	; 255
    227e:	c8 01       	movw	r24, r16
    2280:	0e 94 ce 03 	call	0x79c	; 0x79c <uxListRemove>
					{
						mtCOVERAGE_TEST_MARKER();
					}

					/* Inherit the priority before being moved into the new list. */
					pxTCB->uxPriority = pxCurrentTCB->uxPriority;
    2284:	e0 91 9d 03 	lds	r30, 0x039D
    2288:	f0 91 9e 03 	lds	r31, 0x039E
    228c:	86 89       	ldd	r24, Z+22	; 0x16
    228e:	8e 8b       	std	Y+22, r24	; 0x16
					prvAddTaskToReadyList( pxTCB );
    2290:	90 91 a6 03 	lds	r25, 0x03A6
    2294:	98 17       	cp	r25, r24
    2296:	10 f4       	brcc	.+4      	; 0x229c <vTaskPriorityInherit+0x86>
    2298:	80 93 a6 03 	sts	0x03A6, r24
    229c:	90 e0       	ldi	r25, 0x00	; 0
    229e:	9c 01       	movw	r18, r24
    22a0:	22 0f       	add	r18, r18
    22a2:	33 1f       	adc	r19, r19
    22a4:	22 0f       	add	r18, r18
    22a6:	33 1f       	adc	r19, r19
    22a8:	22 0f       	add	r18, r18
    22aa:	33 1f       	adc	r19, r19
    22ac:	82 0f       	add	r24, r18
    22ae:	93 1f       	adc	r25, r19
    22b0:	80 55       	subi	r24, 0x50	; 80
    22b2:	9c 4f       	sbci	r25, 0xFC	; 252
    22b4:	b8 01       	movw	r22, r16
    22b6:	0e 94 7d 03 	call	0x6fa	; 0x6fa <vListInsertEnd>
    22ba:	06 c0       	rjmp	.+12     	; 0x22c8 <vTaskPriorityInherit+0xb2>
				}
				else
				{
					/* Just inherit the priority. */
					pxTCB->uxPriority = pxCurrentTCB->uxPriority;
    22bc:	e0 91 9d 03 	lds	r30, 0x039D
    22c0:	f0 91 9e 03 	lds	r31, 0x039E
    22c4:	86 89       	ldd	r24, Z+22	; 0x16
    22c6:	8e 8b       	std	Y+22, r24	; 0x16
		}
		else
		{
			mtCOVERAGE_TEST_MARKER();
		}
	}
    22c8:	df 91       	pop	r29
    22ca:	cf 91       	pop	r28
    22cc:	1f 91       	pop	r17
    22ce:	0f 91       	pop	r16
    22d0:	08 95       	ret

000022d2 <xTaskPriorityDisinherit>:
/*-----------------------------------------------------------*/

#if ( configUSE_MUTEXES == 1 )

	BaseType_t xTaskPriorityDisinherit( TaskHandle_t const pxMutexHolder )
	{
    22d2:	0f 93       	push	r16
    22d4:	1f 93       	push	r17
    22d6:	cf 93       	push	r28
    22d8:	df 93       	push	r29
    22da:	ec 01       	movw	r28, r24
	TCB_t * const pxTCB = ( TCB_t * ) pxMutexHolder;
	BaseType_t xReturn = pdFALSE;

		if( pxMutexHolder != NULL )
    22dc:	00 97       	sbiw	r24, 0x00	; 0
    22de:	81 f1       	breq	.+96     	; 0x2340 <xTaskPriorityDisinherit+0x6e>
			interrupt, and if a mutex is given by the holding task then it must
			be the running state task. */
			configASSERT( pxTCB == pxCurrentTCB );

			configASSERT( pxTCB->uxMutexesHeld );
			( pxTCB->uxMutexesHeld )--;
    22e0:	8c a1       	lds	r24, 0x4c
    22e2:	81 50       	subi	r24, 0x01	; 1
    22e4:	8c a3       	lds	r24, 0x5c

			/* Has the holder of the mutex inherited the priority of another
			task? */
			if( pxTCB->uxPriority != pxTCB->uxBasePriority )
    22e6:	2e 89       	ldd	r18, Y+22	; 0x16
    22e8:	9b a1       	lds	r25, 0x4b
    22ea:	29 17       	cp	r18, r25
    22ec:	59 f1       	breq	.+86     	; 0x2344 <xTaskPriorityDisinherit+0x72>
			{
				/* Only disinherit if no other mutexes are held. */
				if( pxTCB->uxMutexesHeld == ( UBaseType_t ) 0 )
    22ee:	88 23       	and	r24, r24
    22f0:	59 f5       	brne	.+86     	; 0x2348 <xTaskPriorityDisinherit+0x76>
					/* A task can only have an inherited priority if it holds
					the mutex.  If the mutex is held by a task then it cannot be
					given from an interrupt, and if a mutex is given by the
					holding	task then it must be the running state task.  Remove
					the	holding task from the ready	list. */
					if( uxListRemove( &( pxTCB->xStateListItem ) ) == ( UBaseType_t ) 0 )
    22f2:	8e 01       	movw	r16, r28
    22f4:	0e 5f       	subi	r16, 0xFE	; 254
    22f6:	1f 4f       	sbci	r17, 0xFF	; 255
    22f8:	c8 01       	movw	r24, r16
    22fa:	0e 94 ce 03 	call	0x79c	; 0x79c <uxListRemove>
					}

					/* Disinherit the priority before adding the task into the
					new	ready list. */
					traceTASK_PRIORITY_DISINHERIT( pxTCB, pxTCB->uxBasePriority );
					pxTCB->uxPriority = pxTCB->uxBasePriority;
    22fe:	4b a1       	lds	r20, 0x4b
    2300:	4e 8b       	std	Y+22, r20	; 0x16

					/* Reset the event list item value.  It cannot be in use for
					any other purpose if this task is running, and it must be
					running to give back the mutex. */
					listSET_LIST_ITEM_VALUE( &( pxTCB->xEventListItem ), ( TickType_t ) configMAX_PRIORITIES - ( TickType_t ) pxTCB->uxPriority ); /*lint !e961 MISRA exception as the casts are only redundant for some ports. */
    2302:	24 2f       	mov	r18, r20
    2304:	30 e0       	ldi	r19, 0x00	; 0
    2306:	85 e0       	ldi	r24, 0x05	; 5
    2308:	90 e0       	ldi	r25, 0x00	; 0
    230a:	82 1b       	sub	r24, r18
    230c:	93 0b       	sbc	r25, r19
    230e:	9d 87       	std	Y+13, r25	; 0x0d
    2310:	8c 87       	std	Y+12, r24	; 0x0c
					prvAddTaskToReadyList( pxTCB );
    2312:	80 91 a6 03 	lds	r24, 0x03A6
    2316:	84 17       	cp	r24, r20
    2318:	10 f4       	brcc	.+4      	; 0x231e <xTaskPriorityDisinherit+0x4c>
    231a:	40 93 a6 03 	sts	0x03A6, r20
    231e:	c9 01       	movw	r24, r18
    2320:	88 0f       	add	r24, r24
    2322:	99 1f       	adc	r25, r25
    2324:	88 0f       	add	r24, r24
    2326:	99 1f       	adc	r25, r25
    2328:	88 0f       	add	r24, r24
    232a:	99 1f       	adc	r25, r25
    232c:	28 0f       	add	r18, r24
    232e:	39 1f       	adc	r19, r25
    2330:	c9 01       	movw	r24, r18
    2332:	80 55       	subi	r24, 0x50	; 80
    2334:	9c 4f       	sbci	r25, 0xFC	; 252
    2336:	b8 01       	movw	r22, r16
    2338:	0e 94 7d 03 	call	0x6fa	; 0x6fa <vListInsertEnd>
					in an order different to that in which they were taken.
					If a context switch did not occur when the first mutex was
					returned, even if a task was waiting on it, then a context
					switch should occur when the last mutex is returned whether
					a task is waiting on it or not. */
					xReturn = pdTRUE;
    233c:	81 e0       	ldi	r24, 0x01	; 1
    233e:	05 c0       	rjmp	.+10     	; 0x234a <xTaskPriorityDisinherit+0x78>
#if ( configUSE_MUTEXES == 1 )

	BaseType_t xTaskPriorityDisinherit( TaskHandle_t const pxMutexHolder )
	{
	TCB_t * const pxTCB = ( TCB_t * ) pxMutexHolder;
	BaseType_t xReturn = pdFALSE;
    2340:	80 e0       	ldi	r24, 0x00	; 0
    2342:	03 c0       	rjmp	.+6      	; 0x234a <xTaskPriorityDisinherit+0x78>
    2344:	80 e0       	ldi	r24, 0x00	; 0
    2346:	01 c0       	rjmp	.+2      	; 0x234a <xTaskPriorityDisinherit+0x78>
    2348:	80 e0       	ldi	r24, 0x00	; 0
		{
			mtCOVERAGE_TEST_MARKER();
		}

		return xReturn;
	}
    234a:	df 91       	pop	r29
    234c:	cf 91       	pop	r28
    234e:	1f 91       	pop	r17
    2350:	0f 91       	pop	r16
    2352:	08 95       	ret

00002354 <uxTaskResetEventItemValue>:

TickType_t uxTaskResetEventItemValue( void )
{
TickType_t uxReturn;

	uxReturn = listGET_LIST_ITEM_VALUE( &( pxCurrentTCB->xEventListItem ) );
    2354:	e0 91 9d 03 	lds	r30, 0x039D
    2358:	f0 91 9e 03 	lds	r31, 0x039E
    235c:	84 85       	ldd	r24, Z+12	; 0x0c
    235e:	95 85       	ldd	r25, Z+13	; 0x0d

	/* Reset the event list item to its normal value - so it can be used with
	queues and semaphores. */
	listSET_LIST_ITEM_VALUE( &( pxCurrentTCB->xEventListItem ), ( ( TickType_t ) configMAX_PRIORITIES - ( TickType_t ) pxCurrentTCB->uxPriority ) ); /*lint !e961 MISRA exception as the casts are only redundant for some ports. */
    2360:	e0 91 9d 03 	lds	r30, 0x039D
    2364:	f0 91 9e 03 	lds	r31, 0x039E
    2368:	a0 91 9d 03 	lds	r26, 0x039D
    236c:	b0 91 9e 03 	lds	r27, 0x039E
    2370:	56 96       	adiw	r26, 0x16	; 22
    2372:	4c 91       	ld	r20, X
    2374:	56 97       	sbiw	r26, 0x16	; 22
    2376:	25 e0       	ldi	r18, 0x05	; 5
    2378:	30 e0       	ldi	r19, 0x00	; 0
    237a:	24 1b       	sub	r18, r20
    237c:	31 09       	sbc	r19, r1
    237e:	35 87       	std	Z+13, r19	; 0x0d
    2380:	24 87       	std	Z+12, r18	; 0x0c

	return uxReturn;
}
    2382:	08 95       	ret

00002384 <pvTaskIncrementMutexHeldCount>:

	void *pvTaskIncrementMutexHeldCount( void )
	{
		/* If xSemaphoreCreateMutex() is called before any tasks have been created
		then pxCurrentTCB will be NULL. */
		if( pxCurrentTCB != NULL )
    2384:	80 91 9d 03 	lds	r24, 0x039D
    2388:	90 91 9e 03 	lds	r25, 0x039E
    238c:	00 97       	sbiw	r24, 0x00	; 0
    238e:	39 f0       	breq	.+14     	; 0x239e <pvTaskIncrementMutexHeldCount+0x1a>
		{
			( pxCurrentTCB->uxMutexesHeld )++;
    2390:	e0 91 9d 03 	lds	r30, 0x039D
    2394:	f0 91 9e 03 	lds	r31, 0x039E
    2398:	84 a1       	lds	r24, 0x44
    239a:	8f 5f       	subi	r24, 0xFF	; 255
    239c:	84 a3       	lds	r24, 0x54
		}

		return pxCurrentTCB;
    239e:	80 91 9d 03 	lds	r24, 0x039D
    23a2:	90 91 9e 03 	lds	r25, 0x039E
	}
    23a6:	08 95       	ret

000023a8 <ulTaskNotifyTake>:
/*-----------------------------------------------------------*/

#if( configUSE_TASK_NOTIFICATIONS == 1 )

	uint32_t ulTaskNotifyTake( BaseType_t xClearCountOnExit, TickType_t xTicksToWait )
	{
    23a8:	0f 93       	push	r16
    23aa:	1f 93       	push	r17
    23ac:	cf 93       	push	r28
    23ae:	c8 2f       	mov	r28, r24
	uint32_t ulReturn;

		taskENTER_CRITICAL();
    23b0:	0f b6       	in	r0, 0x3f	; 63
    23b2:	f8 94       	cli
    23b4:	0f 92       	push	r0
		{
			/* Only block if the notification count is not already non-zero. */
			if( pxCurrentTCB->ulNotifiedValue == 0UL )
    23b6:	e0 91 9d 03 	lds	r30, 0x039D
    23ba:	f0 91 9e 03 	lds	r31, 0x039E
    23be:	85 a1       	lds	r24, 0x45
    23c0:	96 a1       	lds	r25, 0x46
    23c2:	a7 a1       	lds	r26, 0x47
    23c4:	b0 a5       	lds	r27, 0x60
    23c6:	00 97       	sbiw	r24, 0x00	; 0
    23c8:	a1 05       	cpc	r26, r1
    23ca:	b1 05       	cpc	r27, r1
    23cc:	79 f4       	brne	.+30     	; 0x23ec <ulTaskNotifyTake+0x44>
			{
				/* Mark this task as waiting for a notification. */
				pxCurrentTCB->ucNotifyState = taskWAITING_NOTIFICATION;
    23ce:	e0 91 9d 03 	lds	r30, 0x039D
    23d2:	f0 91 9e 03 	lds	r31, 0x039E
    23d6:	81 e0       	ldi	r24, 0x01	; 1
    23d8:	81 a7       	lds	r24, 0x71

				if( xTicksToWait > ( TickType_t ) 0 )
    23da:	61 15       	cp	r22, r1
    23dc:	71 05       	cpc	r23, r1
    23de:	31 f0       	breq	.+12     	; 0x23ec <ulTaskNotifyTake+0x44>
				{
					prvAddCurrentTaskToDelayedList( xTicksToWait, pdTRUE );
    23e0:	cb 01       	movw	r24, r22
    23e2:	61 e0       	ldi	r22, 0x01	; 1
    23e4:	0e 94 69 0a 	call	0x14d2	; 0x14d2 <prvAddCurrentTaskToDelayedList>

					/* All ports are written to allow a yield in a critical
					section (some will yield immediately, others wait until the
					critical section exits) - but it is not something that
					application code should ever do. */
					portYIELD_WITHIN_API();
    23e8:	0e 94 bc 04 	call	0x978	; 0x978 <vPortYield>
			else
			{
				mtCOVERAGE_TEST_MARKER();
			}
		}
		taskEXIT_CRITICAL();
    23ec:	0f 90       	pop	r0
    23ee:	0f be       	out	0x3f, r0	; 63

		taskENTER_CRITICAL();
    23f0:	0f b6       	in	r0, 0x3f	; 63
    23f2:	f8 94       	cli
    23f4:	0f 92       	push	r0
		{
			traceTASK_NOTIFY_TAKE();
			ulReturn = pxCurrentTCB->ulNotifiedValue;
    23f6:	e0 91 9d 03 	lds	r30, 0x039D
    23fa:	f0 91 9e 03 	lds	r31, 0x039E
    23fe:	05 a1       	lds	r16, 0x45
    2400:	16 a1       	lds	r17, 0x46
    2402:	27 a1       	lds	r18, 0x47
    2404:	30 a5       	lds	r19, 0x60

			if( ulReturn != 0UL )
    2406:	01 15       	cp	r16, r1
    2408:	11 05       	cpc	r17, r1
    240a:	21 05       	cpc	r18, r1
    240c:	31 05       	cpc	r19, r1
    240e:	c1 f0       	breq	.+48     	; 0x2440 <ulTaskNotifyTake+0x98>
			{
				if( xClearCountOnExit != pdFALSE )
    2410:	cc 23       	and	r28, r28
    2412:	49 f0       	breq	.+18     	; 0x2426 <ulTaskNotifyTake+0x7e>
				{
					pxCurrentTCB->ulNotifiedValue = 0UL;
    2414:	e0 91 9d 03 	lds	r30, 0x039D
    2418:	f0 91 9e 03 	lds	r31, 0x039E
    241c:	15 a2       	lds	r17, 0x95
    241e:	16 a2       	lds	r17, 0x96
    2420:	17 a2       	lds	r17, 0x97
    2422:	10 a6       	lds	r17, 0xb0
    2424:	0d c0       	rjmp	.+26     	; 0x2440 <ulTaskNotifyTake+0x98>
				}
				else
				{
					pxCurrentTCB->ulNotifiedValue = ulReturn - 1;
    2426:	e0 91 9d 03 	lds	r30, 0x039D
    242a:	f0 91 9e 03 	lds	r31, 0x039E
    242e:	d9 01       	movw	r26, r18
    2430:	c8 01       	movw	r24, r16
    2432:	01 97       	sbiw	r24, 0x01	; 1
    2434:	a1 09       	sbc	r26, r1
    2436:	b1 09       	sbc	r27, r1
    2438:	85 a3       	lds	r24, 0x55
    243a:	96 a3       	lds	r25, 0x56
    243c:	a7 a3       	lds	r26, 0x57
    243e:	b0 a7       	lds	r27, 0x70
			else
			{
				mtCOVERAGE_TEST_MARKER();
			}

			pxCurrentTCB->ucNotifyState = taskNOT_WAITING_NOTIFICATION;
    2440:	e0 91 9d 03 	lds	r30, 0x039D
    2444:	f0 91 9e 03 	lds	r31, 0x039E
    2448:	11 a6       	lds	r17, 0xb1
		}
		taskEXIT_CRITICAL();
    244a:	0f 90       	pop	r0
    244c:	0f be       	out	0x3f, r0	; 63

		return ulReturn;
	}
    244e:	60 2f       	mov	r22, r16
    2450:	71 2f       	mov	r23, r17
    2452:	82 2f       	mov	r24, r18
    2454:	93 2f       	mov	r25, r19
    2456:	cf 91       	pop	r28
    2458:	1f 91       	pop	r17
    245a:	0f 91       	pop	r16
    245c:	08 95       	ret

0000245e <xTaskNotifyWait>:
/*-----------------------------------------------------------*/

#if( configUSE_TASK_NOTIFICATIONS == 1 )

	BaseType_t xTaskNotifyWait( uint32_t ulBitsToClearOnEntry, uint32_t ulBitsToClearOnExit, uint32_t *pulNotificationValue, TickType_t xTicksToWait )
	{
    245e:	8f 92       	push	r8
    2460:	9f 92       	push	r9
    2462:	af 92       	push	r10
    2464:	bf 92       	push	r11
    2466:	ef 92       	push	r14
    2468:	ff 92       	push	r15
    246a:	0f 93       	push	r16
    246c:	1f 93       	push	r17
    246e:	dc 01       	movw	r26, r24
    2470:	cb 01       	movw	r24, r22
    2472:	49 01       	movw	r8, r18
    2474:	5a 01       	movw	r10, r20
	BaseType_t xReturn;

		taskENTER_CRITICAL();
    2476:	0f b6       	in	r0, 0x3f	; 63
    2478:	f8 94       	cli
    247a:	0f 92       	push	r0
		{
			/* Only block if a notification is not already pending. */
			if( pxCurrentTCB->ucNotifyState != taskNOTIFICATION_RECEIVED )
    247c:	e0 91 9d 03 	lds	r30, 0x039D
    2480:	f0 91 9e 03 	lds	r31, 0x039E
    2484:	21 a5       	lds	r18, 0x61
    2486:	22 30       	cpi	r18, 0x02	; 2
    2488:	19 f1       	breq	.+70     	; 0x24d0 <xTaskNotifyWait+0x72>
			{
				/* Clear bits in the task's notification value as bits may get
				set	by the notifying task or interrupt.  This can be used to
				clear the value to zero. */
				pxCurrentTCB->ulNotifiedValue &= ~ulBitsToClearOnEntry;
    248a:	e0 91 9d 03 	lds	r30, 0x039D
    248e:	f0 91 9e 03 	lds	r31, 0x039E
    2492:	45 a1       	lds	r20, 0x45
    2494:	56 a1       	lds	r21, 0x46
    2496:	67 a1       	lds	r22, 0x47
    2498:	70 a5       	lds	r23, 0x60
    249a:	80 95       	com	r24
    249c:	90 95       	com	r25
    249e:	a0 95       	com	r26
    24a0:	b0 95       	com	r27
    24a2:	84 23       	and	r24, r20
    24a4:	95 23       	and	r25, r21
    24a6:	a6 23       	and	r26, r22
    24a8:	b7 23       	and	r27, r23
    24aa:	85 a3       	lds	r24, 0x55
    24ac:	96 a3       	lds	r25, 0x56
    24ae:	a7 a3       	lds	r26, 0x57
    24b0:	b0 a7       	lds	r27, 0x70

				/* Mark this task as waiting for a notification. */
				pxCurrentTCB->ucNotifyState = taskWAITING_NOTIFICATION;
    24b2:	e0 91 9d 03 	lds	r30, 0x039D
    24b6:	f0 91 9e 03 	lds	r31, 0x039E
    24ba:	81 e0       	ldi	r24, 0x01	; 1
    24bc:	81 a7       	lds	r24, 0x71

				if( xTicksToWait > ( TickType_t ) 0 )
    24be:	e1 14       	cp	r14, r1
    24c0:	f1 04       	cpc	r15, r1
    24c2:	31 f0       	breq	.+12     	; 0x24d0 <xTaskNotifyWait+0x72>
				{
					prvAddCurrentTaskToDelayedList( xTicksToWait, pdTRUE );
    24c4:	c7 01       	movw	r24, r14
    24c6:	61 e0       	ldi	r22, 0x01	; 1
    24c8:	0e 94 69 0a 	call	0x14d2	; 0x14d2 <prvAddCurrentTaskToDelayedList>

					/* All ports are written to allow a yield in a critical
					section (some will yield immediately, others wait until the
					critical section exits) - but it is not something that
					application code should ever do. */
					portYIELD_WITHIN_API();
    24cc:	0e 94 bc 04 	call	0x978	; 0x978 <vPortYield>
			else
			{
				mtCOVERAGE_TEST_MARKER();
			}
		}
		taskEXIT_CRITICAL();
    24d0:	0f 90       	pop	r0
    24d2:	0f be       	out	0x3f, r0	; 63

		taskENTER_CRITICAL();
    24d4:	0f b6       	in	r0, 0x3f	; 63
    24d6:	f8 94       	cli
    24d8:	0f 92       	push	r0
		{
			traceTASK_NOTIFY_WAIT();

			if( pulNotificationValue != NULL )
    24da:	01 15       	cp	r16, r1
    24dc:	11 05       	cpc	r17, r1
    24de:	69 f0       	breq	.+26     	; 0x24fa <xTaskNotifyWait+0x9c>
			{
				/* Output the current notification value, which may or may not
				have changed. */
				*pulNotificationValue = pxCurrentTCB->ulNotifiedValue;
    24e0:	e0 91 9d 03 	lds	r30, 0x039D
    24e4:	f0 91 9e 03 	lds	r31, 0x039E
    24e8:	85 a1       	lds	r24, 0x45
    24ea:	96 a1       	lds	r25, 0x46
    24ec:	a7 a1       	lds	r26, 0x47
    24ee:	b0 a5       	lds	r27, 0x60
    24f0:	f8 01       	movw	r30, r16
    24f2:	80 83       	st	Z, r24
    24f4:	91 83       	std	Z+1, r25	; 0x01
    24f6:	a2 83       	std	Z+2, r26	; 0x02
    24f8:	b3 83       	std	Z+3, r27	; 0x03

			/* If ucNotifyValue is set then either the task never entered the
			blocked state (because a notification was already pending) or the
			task unblocked because of a notification.  Otherwise the task
			unblocked because of a timeout. */
			if( pxCurrentTCB->ucNotifyState == taskWAITING_NOTIFICATION )
    24fa:	e0 91 9d 03 	lds	r30, 0x039D
    24fe:	f0 91 9e 03 	lds	r31, 0x039E
    2502:	81 a5       	lds	r24, 0x61
    2504:	81 30       	cpi	r24, 0x01	; 1
    2506:	b1 f0       	breq	.+44     	; 0x2534 <xTaskNotifyWait+0xd6>
			}
			else
			{
				/* A notification was already pending or a notification was
				received while the task was waiting. */
				pxCurrentTCB->ulNotifiedValue &= ~ulBitsToClearOnExit;
    2508:	e0 91 9d 03 	lds	r30, 0x039D
    250c:	f0 91 9e 03 	lds	r31, 0x039E
    2510:	85 a1       	lds	r24, 0x45
    2512:	96 a1       	lds	r25, 0x46
    2514:	a7 a1       	lds	r26, 0x47
    2516:	b0 a5       	lds	r27, 0x60
    2518:	80 94       	com	r8
    251a:	90 94       	com	r9
    251c:	a0 94       	com	r10
    251e:	b0 94       	com	r11
    2520:	88 22       	and	r8, r24
    2522:	99 22       	and	r9, r25
    2524:	aa 22       	and	r10, r26
    2526:	bb 22       	and	r11, r27
    2528:	85 a2       	lds	r24, 0x95
    252a:	96 a2       	lds	r25, 0x96
    252c:	a7 a2       	lds	r26, 0x97
    252e:	b0 a6       	lds	r27, 0xb0
				xReturn = pdTRUE;
    2530:	81 e0       	ldi	r24, 0x01	; 1
    2532:	01 c0       	rjmp	.+2      	; 0x2536 <xTaskNotifyWait+0xd8>
			task unblocked because of a notification.  Otherwise the task
			unblocked because of a timeout. */
			if( pxCurrentTCB->ucNotifyState == taskWAITING_NOTIFICATION )
			{
				/* A notification was not received. */
				xReturn = pdFALSE;
    2534:	80 e0       	ldi	r24, 0x00	; 0
				received while the task was waiting. */
				pxCurrentTCB->ulNotifiedValue &= ~ulBitsToClearOnExit;
				xReturn = pdTRUE;
			}

			pxCurrentTCB->ucNotifyState = taskNOT_WAITING_NOTIFICATION;
    2536:	e0 91 9d 03 	lds	r30, 0x039D
    253a:	f0 91 9e 03 	lds	r31, 0x039E
    253e:	11 a6       	lds	r17, 0xb1
		}
		taskEXIT_CRITICAL();
    2540:	0f 90       	pop	r0
    2542:	0f be       	out	0x3f, r0	; 63

		return xReturn;
	}
    2544:	1f 91       	pop	r17
    2546:	0f 91       	pop	r16
    2548:	ff 90       	pop	r15
    254a:	ef 90       	pop	r14
    254c:	bf 90       	pop	r11
    254e:	af 90       	pop	r10
    2550:	9f 90       	pop	r9
    2552:	8f 90       	pop	r8
    2554:	08 95       	ret

00002556 <xTaskGenericNotify>:
/*-----------------------------------------------------------*/

#if( configUSE_TASK_NOTIFICATIONS == 1 )

	BaseType_t xTaskGenericNotify( TaskHandle_t xTaskToNotify, uint32_t ulValue, eNotifyAction eAction, uint32_t *pulPreviousNotificationValue )
	{
    2556:	0f 93       	push	r16
    2558:	1f 93       	push	r17
    255a:	cf 93       	push	r28
    255c:	df 93       	push	r29
    255e:	ec 01       	movw	r28, r24
	uint8_t ucOriginalNotifyState;

		configASSERT( xTaskToNotify );
		pxTCB = ( TCB_t * ) xTaskToNotify;

		taskENTER_CRITICAL();
    2560:	0f b6       	in	r0, 0x3f	; 63
    2562:	f8 94       	cli
    2564:	0f 92       	push	r0
		{
			if( pulPreviousNotificationValue != NULL )
    2566:	01 15       	cp	r16, r1
    2568:	11 05       	cpc	r17, r1
    256a:	49 f0       	breq	.+18     	; 0x257e <xTaskGenericNotify+0x28>
			{
				*pulPreviousNotificationValue = pxTCB->ulNotifiedValue;
    256c:	8d a1       	lds	r24, 0x4d
    256e:	9e a1       	lds	r25, 0x4e
    2570:	af a1       	lds	r26, 0x4f
    2572:	b8 a5       	lds	r27, 0x68
    2574:	f8 01       	movw	r30, r16
    2576:	80 83       	st	Z, r24
    2578:	91 83       	std	Z+1, r25	; 0x01
    257a:	a2 83       	std	Z+2, r26	; 0x02
    257c:	b3 83       	std	Z+3, r27	; 0x03
			}

			ucOriginalNotifyState = pxTCB->ucNotifyState;
    257e:	39 a5       	lds	r19, 0x69

			pxTCB->ucNotifyState = taskNOTIFICATION_RECEIVED;
    2580:	82 e0       	ldi	r24, 0x02	; 2
    2582:	89 a7       	lds	r24, 0x79

			switch( eAction )
    2584:	22 30       	cpi	r18, 0x02	; 2
    2586:	b9 f0       	breq	.+46     	; 0x25b6 <xTaskGenericNotify+0x60>
    2588:	23 30       	cpi	r18, 0x03	; 3
    258a:	18 f4       	brcc	.+6      	; 0x2592 <xTaskGenericNotify+0x3c>
    258c:	21 30       	cpi	r18, 0x01	; 1
    258e:	51 f5       	brne	.+84     	; 0x25e4 <xTaskGenericNotify+0x8e>
    2590:	05 c0       	rjmp	.+10     	; 0x259c <xTaskGenericNotify+0x46>
    2592:	23 30       	cpi	r18, 0x03	; 3
    2594:	e1 f0       	breq	.+56     	; 0x25ce <xTaskGenericNotify+0x78>
    2596:	24 30       	cpi	r18, 0x04	; 4
    2598:	29 f5       	brne	.+74     	; 0x25e4 <xTaskGenericNotify+0x8e>
    259a:	1e c0       	rjmp	.+60     	; 0x25d8 <xTaskGenericNotify+0x82>
			{
				case eSetBits	:
					pxTCB->ulNotifiedValue |= ulValue;
    259c:	8d a1       	lds	r24, 0x4d
    259e:	9e a1       	lds	r25, 0x4e
    25a0:	af a1       	lds	r26, 0x4f
    25a2:	b8 a5       	lds	r27, 0x68
    25a4:	48 2b       	or	r20, r24
    25a6:	59 2b       	or	r21, r25
    25a8:	6a 2b       	or	r22, r26
    25aa:	7b 2b       	or	r23, r27
    25ac:	4d a3       	lds	r20, 0x5d
    25ae:	5e a3       	lds	r21, 0x5e
    25b0:	6f a3       	lds	r22, 0x5f
    25b2:	78 a7       	lds	r23, 0x78
					break;
    25b4:	17 c0       	rjmp	.+46     	; 0x25e4 <xTaskGenericNotify+0x8e>

				case eIncrement	:
					( pxTCB->ulNotifiedValue )++;
    25b6:	8d a1       	lds	r24, 0x4d
    25b8:	9e a1       	lds	r25, 0x4e
    25ba:	af a1       	lds	r26, 0x4f
    25bc:	b8 a5       	lds	r27, 0x68
    25be:	01 96       	adiw	r24, 0x01	; 1
    25c0:	a1 1d       	adc	r26, r1
    25c2:	b1 1d       	adc	r27, r1
    25c4:	8d a3       	lds	r24, 0x5d
    25c6:	9e a3       	lds	r25, 0x5e
    25c8:	af a3       	lds	r26, 0x5f
    25ca:	b8 a7       	lds	r27, 0x78
					break;
    25cc:	0b c0       	rjmp	.+22     	; 0x25e4 <xTaskGenericNotify+0x8e>

				case eSetValueWithOverwrite	:
					pxTCB->ulNotifiedValue = ulValue;
    25ce:	4d a3       	lds	r20, 0x5d
    25d0:	5e a3       	lds	r21, 0x5e
    25d2:	6f a3       	lds	r22, 0x5f
    25d4:	78 a7       	lds	r23, 0x78
					break;
    25d6:	06 c0       	rjmp	.+12     	; 0x25e4 <xTaskGenericNotify+0x8e>

				case eSetValueWithoutOverwrite :
					if( ucOriginalNotifyState != taskNOTIFICATION_RECEIVED )
    25d8:	32 30       	cpi	r19, 0x02	; 2
    25da:	71 f1       	breq	.+92     	; 0x2638 <xTaskGenericNotify+0xe2>
					{
						pxTCB->ulNotifiedValue = ulValue;
    25dc:	4d a3       	lds	r20, 0x5d
    25de:	5e a3       	lds	r21, 0x5e
    25e0:	6f a3       	lds	r22, 0x5f
    25e2:	78 a7       	lds	r23, 0x78

			traceTASK_NOTIFY();

			/* If the task is in the blocked state specifically to wait for a
			notification then unblock it now. */
			if( ucOriginalNotifyState == taskWAITING_NOTIFICATION )
    25e4:	31 30       	cpi	r19, 0x01	; 1
    25e6:	51 f5       	brne	.+84     	; 0x263c <xTaskGenericNotify+0xe6>
			{
				( void ) uxListRemove( &( pxTCB->xStateListItem ) );
    25e8:	8e 01       	movw	r16, r28
    25ea:	0e 5f       	subi	r16, 0xFE	; 254
    25ec:	1f 4f       	sbci	r17, 0xFF	; 255
    25ee:	c8 01       	movw	r24, r16
    25f0:	0e 94 ce 03 	call	0x79c	; 0x79c <uxListRemove>
				prvAddTaskToReadyList( pxTCB );
    25f4:	8e 89       	ldd	r24, Y+22	; 0x16
    25f6:	90 91 a6 03 	lds	r25, 0x03A6
    25fa:	98 17       	cp	r25, r24
    25fc:	10 f4       	brcc	.+4      	; 0x2602 <xTaskGenericNotify+0xac>
    25fe:	80 93 a6 03 	sts	0x03A6, r24
    2602:	90 e0       	ldi	r25, 0x00	; 0
    2604:	9c 01       	movw	r18, r24
    2606:	22 0f       	add	r18, r18
    2608:	33 1f       	adc	r19, r19
    260a:	22 0f       	add	r18, r18
    260c:	33 1f       	adc	r19, r19
    260e:	22 0f       	add	r18, r18
    2610:	33 1f       	adc	r19, r19
    2612:	82 0f       	add	r24, r18
    2614:	93 1f       	adc	r25, r19
    2616:	80 55       	subi	r24, 0x50	; 80
    2618:	9c 4f       	sbci	r25, 0xFC	; 252
    261a:	b8 01       	movw	r22, r16
    261c:	0e 94 7d 03 	call	0x6fa	; 0x6fa <vListInsertEnd>
					earliest possible time. */
					prvResetNextTaskUnblockTime();
				}
				#endif

				if( pxTCB->uxPriority > pxCurrentTCB->uxPriority )
    2620:	e0 91 9d 03 	lds	r30, 0x039D
    2624:	f0 91 9e 03 	lds	r31, 0x039E
    2628:	9e 89       	ldd	r25, Y+22	; 0x16
    262a:	86 89       	ldd	r24, Z+22	; 0x16
    262c:	89 17       	cp	r24, r25
    262e:	40 f4       	brcc	.+16     	; 0x2640 <xTaskGenericNotify+0xea>
				{
					/* The notified task has a priority above the currently
					executing task so a yield is required. */
					taskYIELD_IF_USING_PREEMPTION();
    2630:	0e 94 bc 04 	call	0x978	; 0x978 <vPortYield>
    2634:	81 e0       	ldi	r24, 0x01	; 1
    2636:	05 c0       	rjmp	.+10     	; 0x2642 <xTaskGenericNotify+0xec>
						pxTCB->ulNotifiedValue = ulValue;
					}
					else
					{
						/* The value could not be written to the task. */
						xReturn = pdFAIL;
    2638:	80 e0       	ldi	r24, 0x00	; 0
    263a:	03 c0       	rjmp	.+6      	; 0x2642 <xTaskGenericNotify+0xec>

			traceTASK_NOTIFY();

			/* If the task is in the blocked state specifically to wait for a
			notification then unblock it now. */
			if( ucOriginalNotifyState == taskWAITING_NOTIFICATION )
    263c:	81 e0       	ldi	r24, 0x01	; 1
    263e:	01 c0       	rjmp	.+2      	; 0x2642 <xTaskGenericNotify+0xec>
					earliest possible time. */
					prvResetNextTaskUnblockTime();
				}
				#endif

				if( pxTCB->uxPriority > pxCurrentTCB->uxPriority )
    2640:	81 e0       	ldi	r24, 0x01	; 1
			else
			{
				mtCOVERAGE_TEST_MARKER();
			}
		}
		taskEXIT_CRITICAL();
    2642:	0f 90       	pop	r0
    2644:	0f be       	out	0x3f, r0	; 63

		return xReturn;
	}
    2646:	df 91       	pop	r29
    2648:	cf 91       	pop	r28
    264a:	1f 91       	pop	r17
    264c:	0f 91       	pop	r16
    264e:	08 95       	ret

00002650 <xTaskGenericNotifyFromISR>:
/*-----------------------------------------------------------*/

#if( configUSE_TASK_NOTIFICATIONS == 1 )

	BaseType_t xTaskGenericNotifyFromISR( TaskHandle_t xTaskToNotify, uint32_t ulValue, eNotifyAction eAction, uint32_t *pulPreviousNotificationValue, BaseType_t *pxHigherPriorityTaskWoken )
	{
    2650:	ef 92       	push	r14
    2652:	ff 92       	push	r15
    2654:	0f 93       	push	r16
    2656:	1f 93       	push	r17
    2658:	cf 93       	push	r28
    265a:	df 93       	push	r29
    265c:	ec 01       	movw	r28, r24

		pxTCB = ( TCB_t * ) xTaskToNotify;

		uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
		{
			if( pulPreviousNotificationValue != NULL )
    265e:	01 15       	cp	r16, r1
    2660:	11 05       	cpc	r17, r1
    2662:	49 f0       	breq	.+18     	; 0x2676 <xTaskGenericNotifyFromISR+0x26>
			{
				*pulPreviousNotificationValue = pxTCB->ulNotifiedValue;
    2664:	8d a1       	lds	r24, 0x4d
    2666:	9e a1       	lds	r25, 0x4e
    2668:	af a1       	lds	r26, 0x4f
    266a:	b8 a5       	lds	r27, 0x68
    266c:	f8 01       	movw	r30, r16
    266e:	80 83       	st	Z, r24
    2670:	91 83       	std	Z+1, r25	; 0x01
    2672:	a2 83       	std	Z+2, r26	; 0x02
    2674:	b3 83       	std	Z+3, r27	; 0x03
			}

			ucOriginalNotifyState = pxTCB->ucNotifyState;
    2676:	39 a5       	lds	r19, 0x69
			pxTCB->ucNotifyState = taskNOTIFICATION_RECEIVED;
    2678:	82 e0       	ldi	r24, 0x02	; 2
    267a:	89 a7       	lds	r24, 0x79

			switch( eAction )
    267c:	22 30       	cpi	r18, 0x02	; 2
    267e:	b9 f0       	breq	.+46     	; 0x26ae <xTaskGenericNotifyFromISR+0x5e>
    2680:	23 30       	cpi	r18, 0x03	; 3
    2682:	18 f4       	brcc	.+6      	; 0x268a <xTaskGenericNotifyFromISR+0x3a>
    2684:	21 30       	cpi	r18, 0x01	; 1
    2686:	59 f5       	brne	.+86     	; 0x26de <xTaskGenericNotifyFromISR+0x8e>
    2688:	05 c0       	rjmp	.+10     	; 0x2694 <xTaskGenericNotifyFromISR+0x44>
    268a:	23 30       	cpi	r18, 0x03	; 3
    268c:	e1 f0       	breq	.+56     	; 0x26c6 <xTaskGenericNotifyFromISR+0x76>
    268e:	24 30       	cpi	r18, 0x04	; 4
    2690:	31 f5       	brne	.+76     	; 0x26de <xTaskGenericNotifyFromISR+0x8e>
    2692:	1e c0       	rjmp	.+60     	; 0x26d0 <xTaskGenericNotifyFromISR+0x80>
			{
				case eSetBits	:
					pxTCB->ulNotifiedValue |= ulValue;
    2694:	8d a1       	lds	r24, 0x4d
    2696:	9e a1       	lds	r25, 0x4e
    2698:	af a1       	lds	r26, 0x4f
    269a:	b8 a5       	lds	r27, 0x68
    269c:	84 2b       	or	r24, r20
    269e:	95 2b       	or	r25, r21
    26a0:	a6 2b       	or	r26, r22
    26a2:	b7 2b       	or	r27, r23
    26a4:	8d a3       	lds	r24, 0x5d
    26a6:	9e a3       	lds	r25, 0x5e
    26a8:	af a3       	lds	r26, 0x5f
    26aa:	b8 a7       	lds	r27, 0x78
					break;
    26ac:	18 c0       	rjmp	.+48     	; 0x26de <xTaskGenericNotifyFromISR+0x8e>

				case eIncrement	:
					( pxTCB->ulNotifiedValue )++;
    26ae:	8d a1       	lds	r24, 0x4d
    26b0:	9e a1       	lds	r25, 0x4e
    26b2:	af a1       	lds	r26, 0x4f
    26b4:	b8 a5       	lds	r27, 0x68
    26b6:	01 96       	adiw	r24, 0x01	; 1
    26b8:	a1 1d       	adc	r26, r1
    26ba:	b1 1d       	adc	r27, r1
    26bc:	8d a3       	lds	r24, 0x5d
    26be:	9e a3       	lds	r25, 0x5e
    26c0:	af a3       	lds	r26, 0x5f
    26c2:	b8 a7       	lds	r27, 0x78
					break;
    26c4:	0c c0       	rjmp	.+24     	; 0x26de <xTaskGenericNotifyFromISR+0x8e>

				case eSetValueWithOverwrite	:
					pxTCB->ulNotifiedValue = ulValue;
    26c6:	4d a3       	lds	r20, 0x5d
    26c8:	5e a3       	lds	r21, 0x5e
    26ca:	6f a3       	lds	r22, 0x5f
    26cc:	78 a7       	lds	r23, 0x78
					break;
    26ce:	07 c0       	rjmp	.+14     	; 0x26de <xTaskGenericNotifyFromISR+0x8e>

				case eSetValueWithoutOverwrite :
					if( ucOriginalNotifyState != taskNOTIFICATION_RECEIVED )
    26d0:	32 30       	cpi	r19, 0x02	; 2
    26d2:	09 f4       	brne	.+2      	; 0x26d6 <xTaskGenericNotifyFromISR+0x86>
    26d4:	41 c0       	rjmp	.+130    	; 0x2758 <xTaskGenericNotifyFromISR+0x108>
					{
						pxTCB->ulNotifiedValue = ulValue;
    26d6:	4d a3       	lds	r20, 0x5d
    26d8:	5e a3       	lds	r21, 0x5e
    26da:	6f a3       	lds	r22, 0x5f
    26dc:	78 a7       	lds	r23, 0x78

			traceTASK_NOTIFY_FROM_ISR();

			/* If the task is in the blocked state specifically to wait for a
			notification then unblock it now. */
			if( ucOriginalNotifyState == taskWAITING_NOTIFICATION )
    26de:	31 30       	cpi	r19, 0x01	; 1
    26e0:	e9 f5       	brne	.+122    	; 0x275c <xTaskGenericNotifyFromISR+0x10c>
			{
				/* The task should not have been on an event list. */
				configASSERT( listLIST_ITEM_CONTAINER( &( pxTCB->xEventListItem ) ) == NULL );

				if( uxSchedulerSuspended == ( UBaseType_t ) pdFALSE )
    26e2:	80 91 9f 03 	lds	r24, 0x039F
    26e6:	88 23       	and	r24, r24
    26e8:	e9 f4       	brne	.+58     	; 0x2724 <xTaskGenericNotifyFromISR+0xd4>
				{
					( void ) uxListRemove( &( pxTCB->xStateListItem ) );
    26ea:	8e 01       	movw	r16, r28
    26ec:	0e 5f       	subi	r16, 0xFE	; 254
    26ee:	1f 4f       	sbci	r17, 0xFF	; 255
    26f0:	c8 01       	movw	r24, r16
    26f2:	0e 94 ce 03 	call	0x79c	; 0x79c <uxListRemove>
					prvAddTaskToReadyList( pxTCB );
    26f6:	8e 89       	ldd	r24, Y+22	; 0x16
    26f8:	90 91 a6 03 	lds	r25, 0x03A6
    26fc:	98 17       	cp	r25, r24
    26fe:	10 f4       	brcc	.+4      	; 0x2704 <xTaskGenericNotifyFromISR+0xb4>
    2700:	80 93 a6 03 	sts	0x03A6, r24
    2704:	90 e0       	ldi	r25, 0x00	; 0
    2706:	9c 01       	movw	r18, r24
    2708:	22 0f       	add	r18, r18
    270a:	33 1f       	adc	r19, r19
    270c:	22 0f       	add	r18, r18
    270e:	33 1f       	adc	r19, r19
    2710:	22 0f       	add	r18, r18
    2712:	33 1f       	adc	r19, r19
    2714:	82 0f       	add	r24, r18
    2716:	93 1f       	adc	r25, r19
    2718:	80 55       	subi	r24, 0x50	; 80
    271a:	9c 4f       	sbci	r25, 0xFC	; 252
    271c:	b8 01       	movw	r22, r16
    271e:	0e 94 7d 03 	call	0x6fa	; 0x6fa <vListInsertEnd>
    2722:	07 c0       	rjmp	.+14     	; 0x2732 <xTaskGenericNotifyFromISR+0xe2>
				}
				else
				{
					/* The delayed and ready lists cannot be accessed, so hold
					this task pending until the scheduler is resumed. */
					vListInsertEnd( &( xPendingReadyList ), &( pxTCB->xEventListItem ) );
    2724:	be 01       	movw	r22, r28
    2726:	64 5f       	subi	r22, 0xF4	; 244
    2728:	7f 4f       	sbci	r23, 0xFF	; 255
    272a:	8f ee       	ldi	r24, 0xEF	; 239
    272c:	93 e0       	ldi	r25, 0x03	; 3
    272e:	0e 94 7d 03 	call	0x6fa	; 0x6fa <vListInsertEnd>
				}

				if( pxTCB->uxPriority > pxCurrentTCB->uxPriority )
    2732:	e0 91 9d 03 	lds	r30, 0x039D
    2736:	f0 91 9e 03 	lds	r31, 0x039E
    273a:	9e 89       	ldd	r25, Y+22	; 0x16
    273c:	86 89       	ldd	r24, Z+22	; 0x16
    273e:	89 17       	cp	r24, r25
    2740:	78 f4       	brcc	.+30     	; 0x2760 <xTaskGenericNotifyFromISR+0x110>
				{
					/* The notified task has a priority above the currently
					executing task so a yield is required. */
					if( pxHigherPriorityTaskWoken != NULL )
    2742:	e1 14       	cp	r14, r1
    2744:	f1 04       	cpc	r15, r1
    2746:	21 f0       	breq	.+8      	; 0x2750 <xTaskGenericNotifyFromISR+0x100>
					{
						*pxHigherPriorityTaskWoken = pdTRUE;
    2748:	81 e0       	ldi	r24, 0x01	; 1
    274a:	f7 01       	movw	r30, r14
    274c:	80 83       	st	Z, r24
    274e:	09 c0       	rjmp	.+18     	; 0x2762 <xTaskGenericNotifyFromISR+0x112>
					else
					{
						/* Mark that a yield is pending in case the user is not
						using the "xHigherPriorityTaskWoken" parameter to an ISR
						safe FreeRTOS function. */
						xYieldPending = pdTRUE;
    2750:	81 e0       	ldi	r24, 0x01	; 1
    2752:	80 93 a3 03 	sts	0x03A3, r24
    2756:	05 c0       	rjmp	.+10     	; 0x2762 <xTaskGenericNotifyFromISR+0x112>
						pxTCB->ulNotifiedValue = ulValue;
					}
					else
					{
						/* The value could not be written to the task. */
						xReturn = pdFAIL;
    2758:	80 e0       	ldi	r24, 0x00	; 0
    275a:	03 c0       	rjmp	.+6      	; 0x2762 <xTaskGenericNotifyFromISR+0x112>

			traceTASK_NOTIFY_FROM_ISR();

			/* If the task is in the blocked state specifically to wait for a
			notification then unblock it now. */
			if( ucOriginalNotifyState == taskWAITING_NOTIFICATION )
    275c:	81 e0       	ldi	r24, 0x01	; 1
    275e:	01 c0       	rjmp	.+2      	; 0x2762 <xTaskGenericNotifyFromISR+0x112>
					/* The delayed and ready lists cannot be accessed, so hold
					this task pending until the scheduler is resumed. */
					vListInsertEnd( &( xPendingReadyList ), &( pxTCB->xEventListItem ) );
				}

				if( pxTCB->uxPriority > pxCurrentTCB->uxPriority )
    2760:	81 e0       	ldi	r24, 0x01	; 1
			}
		}
		portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );

		return xReturn;
	}
    2762:	df 91       	pop	r29
    2764:	cf 91       	pop	r28
    2766:	1f 91       	pop	r17
    2768:	0f 91       	pop	r16
    276a:	ff 90       	pop	r15
    276c:	ef 90       	pop	r14
    276e:	08 95       	ret

00002770 <vTaskNotifyGiveFromISR>:
/*-----------------------------------------------------------*/

#if( configUSE_TASK_NOTIFICATIONS == 1 )

	void vTaskNotifyGiveFromISR( TaskHandle_t xTaskToNotify, BaseType_t *pxHigherPriorityTaskWoken )
	{
    2770:	ef 92       	push	r14
    2772:	ff 92       	push	r15
    2774:	0f 93       	push	r16
    2776:	1f 93       	push	r17
    2778:	cf 93       	push	r28
    277a:	df 93       	push	r29
    277c:	ec 01       	movw	r28, r24
    277e:	8b 01       	movw	r16, r22

		pxTCB = ( TCB_t * ) xTaskToNotify;

		uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
		{
			ucOriginalNotifyState = pxTCB->ucNotifyState;
    2780:	29 a5       	lds	r18, 0x69
			pxTCB->ucNotifyState = taskNOTIFICATION_RECEIVED;
    2782:	82 e0       	ldi	r24, 0x02	; 2
    2784:	89 a7       	lds	r24, 0x79

			/* 'Giving' is equivalent to incrementing a count in a counting
			semaphore. */
			( pxTCB->ulNotifiedValue )++;
    2786:	8d a1       	lds	r24, 0x4d
    2788:	9e a1       	lds	r25, 0x4e
    278a:	af a1       	lds	r26, 0x4f
    278c:	b8 a5       	lds	r27, 0x68
    278e:	01 96       	adiw	r24, 0x01	; 1
    2790:	a1 1d       	adc	r26, r1
    2792:	b1 1d       	adc	r27, r1
    2794:	8d a3       	lds	r24, 0x5d
    2796:	9e a3       	lds	r25, 0x5e
    2798:	af a3       	lds	r26, 0x5f
    279a:	b8 a7       	lds	r27, 0x78

			traceTASK_NOTIFY_GIVE_FROM_ISR();

			/* If the task is in the blocked state specifically to wait for a
			notification then unblock it now. */
			if( ucOriginalNotifyState == taskWAITING_NOTIFICATION )
    279c:	21 30       	cpi	r18, 0x01	; 1
    279e:	e9 f5       	brne	.+122    	; 0x281a <vTaskNotifyGiveFromISR+0xaa>
			{
				/* The task should not have been on an event list. */
				configASSERT( listLIST_ITEM_CONTAINER( &( pxTCB->xEventListItem ) ) == NULL );

				if( uxSchedulerSuspended == ( UBaseType_t ) pdFALSE )
    27a0:	80 91 9f 03 	lds	r24, 0x039F
    27a4:	88 23       	and	r24, r24
    27a6:	01 f5       	brne	.+64     	; 0x27e8 <vTaskNotifyGiveFromISR+0x78>
				{
					( void ) uxListRemove( &( pxTCB->xStateListItem ) );
    27a8:	ee 24       	eor	r14, r14
    27aa:	ff 24       	eor	r15, r15
    27ac:	68 94       	set
    27ae:	e1 f8       	bld	r14, 1
    27b0:	ec 0e       	add	r14, r28
    27b2:	fd 1e       	adc	r15, r29
    27b4:	c7 01       	movw	r24, r14
    27b6:	0e 94 ce 03 	call	0x79c	; 0x79c <uxListRemove>
					prvAddTaskToReadyList( pxTCB );
    27ba:	8e 89       	ldd	r24, Y+22	; 0x16
    27bc:	90 91 a6 03 	lds	r25, 0x03A6
    27c0:	98 17       	cp	r25, r24
    27c2:	10 f4       	brcc	.+4      	; 0x27c8 <vTaskNotifyGiveFromISR+0x58>
    27c4:	80 93 a6 03 	sts	0x03A6, r24
    27c8:	90 e0       	ldi	r25, 0x00	; 0
    27ca:	9c 01       	movw	r18, r24
    27cc:	22 0f       	add	r18, r18
    27ce:	33 1f       	adc	r19, r19
    27d0:	22 0f       	add	r18, r18
    27d2:	33 1f       	adc	r19, r19
    27d4:	22 0f       	add	r18, r18
    27d6:	33 1f       	adc	r19, r19
    27d8:	82 0f       	add	r24, r18
    27da:	93 1f       	adc	r25, r19
    27dc:	80 55       	subi	r24, 0x50	; 80
    27de:	9c 4f       	sbci	r25, 0xFC	; 252
    27e0:	b7 01       	movw	r22, r14
    27e2:	0e 94 7d 03 	call	0x6fa	; 0x6fa <vListInsertEnd>
    27e6:	07 c0       	rjmp	.+14     	; 0x27f6 <vTaskNotifyGiveFromISR+0x86>
				}
				else
				{
					/* The delayed and ready lists cannot be accessed, so hold
					this task pending until the scheduler is resumed. */
					vListInsertEnd( &( xPendingReadyList ), &( pxTCB->xEventListItem ) );
    27e8:	be 01       	movw	r22, r28
    27ea:	64 5f       	subi	r22, 0xF4	; 244
    27ec:	7f 4f       	sbci	r23, 0xFF	; 255
    27ee:	8f ee       	ldi	r24, 0xEF	; 239
    27f0:	93 e0       	ldi	r25, 0x03	; 3
    27f2:	0e 94 7d 03 	call	0x6fa	; 0x6fa <vListInsertEnd>
				}

				if( pxTCB->uxPriority > pxCurrentTCB->uxPriority )
    27f6:	e0 91 9d 03 	lds	r30, 0x039D
    27fa:	f0 91 9e 03 	lds	r31, 0x039E
    27fe:	9e 89       	ldd	r25, Y+22	; 0x16
    2800:	86 89       	ldd	r24, Z+22	; 0x16
    2802:	89 17       	cp	r24, r25
    2804:	50 f4       	brcc	.+20     	; 0x281a <vTaskNotifyGiveFromISR+0xaa>
				{
					/* The notified task has a priority above the currently
					executing task so a yield is required. */
					if( pxHigherPriorityTaskWoken != NULL )
    2806:	01 15       	cp	r16, r1
    2808:	11 05       	cpc	r17, r1
    280a:	21 f0       	breq	.+8      	; 0x2814 <vTaskNotifyGiveFromISR+0xa4>
					{
						*pxHigherPriorityTaskWoken = pdTRUE;
    280c:	81 e0       	ldi	r24, 0x01	; 1
    280e:	f8 01       	movw	r30, r16
    2810:	80 83       	st	Z, r24
    2812:	03 c0       	rjmp	.+6      	; 0x281a <vTaskNotifyGiveFromISR+0xaa>
					else
					{
						/* Mark that a yield is pending in case the user is not
						using the "xHigherPriorityTaskWoken" parameter in an ISR
						safe FreeRTOS function. */
						xYieldPending = pdTRUE;
    2814:	81 e0       	ldi	r24, 0x01	; 1
    2816:	80 93 a3 03 	sts	0x03A3, r24
					mtCOVERAGE_TEST_MARKER();
				}
			}
		}
		portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );
	}
    281a:	df 91       	pop	r29
    281c:	cf 91       	pop	r28
    281e:	1f 91       	pop	r17
    2820:	0f 91       	pop	r16
    2822:	ff 90       	pop	r15
    2824:	ef 90       	pop	r14
    2826:	08 95       	ret

00002828 <xTaskNotifyStateClear>:
	TCB_t *pxTCB;
	BaseType_t xReturn;

		/* If null is passed in here then it is the calling task that is having
		its notification state cleared. */
		pxTCB = prvGetTCBFromHandle( xTask );
    2828:	00 97       	sbiw	r24, 0x00	; 0
    282a:	29 f4       	brne	.+10     	; 0x2836 <xTaskNotifyStateClear+0xe>
    282c:	e0 91 9d 03 	lds	r30, 0x039D
    2830:	f0 91 9e 03 	lds	r31, 0x039E
    2834:	01 c0       	rjmp	.+2      	; 0x2838 <xTaskNotifyStateClear+0x10>
    2836:	fc 01       	movw	r30, r24

		taskENTER_CRITICAL();
    2838:	0f b6       	in	r0, 0x3f	; 63
    283a:	f8 94       	cli
    283c:	0f 92       	push	r0
		{
			if( pxTCB->ucNotifyState == taskNOTIFICATION_RECEIVED )
    283e:	81 a5       	lds	r24, 0x61
    2840:	82 30       	cpi	r24, 0x02	; 2
    2842:	19 f4       	brne	.+6      	; 0x284a <xTaskNotifyStateClear+0x22>
			{
				pxTCB->ucNotifyState = taskNOT_WAITING_NOTIFICATION;
    2844:	11 a6       	lds	r17, 0xb1
				xReturn = pdPASS;
    2846:	81 e0       	ldi	r24, 0x01	; 1
    2848:	01 c0       	rjmp	.+2      	; 0x284c <xTaskNotifyStateClear+0x24>
			}
			else
			{
				xReturn = pdFAIL;
    284a:	80 e0       	ldi	r24, 0x00	; 0
			}
		}
		taskEXIT_CRITICAL();
    284c:	0f 90       	pop	r0
    284e:	0f be       	out	0x3f, r0	; 63

		return xReturn;
	}
    2850:	08 95       	ret

00002852 <memcpy>:
    2852:	fb 01       	movw	r30, r22
    2854:	dc 01       	movw	r26, r24
    2856:	02 c0       	rjmp	.+4      	; 0x285c <memcpy+0xa>
    2858:	01 90       	ld	r0, Z+
    285a:	0d 92       	st	X+, r0
    285c:	41 50       	subi	r20, 0x01	; 1
    285e:	50 40       	sbci	r21, 0x00	; 0
    2860:	d8 f7       	brcc	.-10     	; 0x2858 <memcpy+0x6>
    2862:	08 95       	ret

00002864 <_exit>:
    2864:	f8 94       	cli

00002866 <__stop_program>:
    2866:	ff cf       	rjmp	.-2      	; 0x2866 <__stop_program>
