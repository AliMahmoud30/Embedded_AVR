
GccApplication1.elf:     file format elf32-avr

Sections:
Idx Name          Size      VMA       LMA       File off  Algn
  0 .text         0000282c  00000000  00000000  00000094  2**1
                  CONTENTS, ALLOC, LOAD, READONLY, CODE
  1 .data         00000012  00800060  0000282c  000028c0  2**0
                  CONTENTS, ALLOC, LOAD, DATA
  2 .bss          000003ba  00800072  00800072  000028d2  2**0
                  ALLOC
  3 .stab         00000750  00000000  00000000  000028d4  2**2
                  CONTENTS, READONLY, DEBUGGING
  4 .stabstr      000000e7  00000000  00000000  00003024  2**0
                  CONTENTS, READONLY, DEBUGGING
  5 .debug_aranges 00000160  00000000  00000000  00003110  2**3
                  CONTENTS, READONLY, DEBUGGING
  6 .debug_info   000035b4  00000000  00000000  00003270  2**0
                  CONTENTS, READONLY, DEBUGGING
  7 .debug_abbrev 00000bd3  00000000  00000000  00006824  2**0
                  CONTENTS, READONLY, DEBUGGING
  8 .debug_line   000012f9  00000000  00000000  000073f7  2**0
                  CONTENTS, READONLY, DEBUGGING
  9 .debug_frame  00000bcc  00000000  00000000  000086f0  2**2
                  CONTENTS, READONLY, DEBUGGING
 10 .debug_str    00001575  00000000  00000000  000092bc  2**0
                  CONTENTS, READONLY, DEBUGGING
 11 .debug_loc    00004016  00000000  00000000  0000a831  2**0
                  CONTENTS, READONLY, DEBUGGING
 12 .debug_ranges 00000130  00000000  00000000  0000e847  2**0
                  CONTENTS, READONLY, DEBUGGING

Disassembly of section .text:

00000000 <__vectors>:
       0:	0c 94 2a 00 	jmp	0x54	; 0x54 <__ctors_end>
       4:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
       8:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
       c:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      10:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      14:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      18:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      1c:	0c 94 e6 05 	jmp	0xbcc	; 0xbcc <__vector_7>
      20:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      24:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      28:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      2c:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      30:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      34:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      38:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      3c:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      40:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      44:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      48:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      4c:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      50:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>

00000054 <__ctors_end>:
      54:	11 24       	eor	r1, r1
      56:	1f be       	out	0x3f, r1	; 63
      58:	cf e5       	ldi	r28, 0x5F	; 95
      5a:	d8 e0       	ldi	r29, 0x08	; 8
      5c:	de bf       	out	0x3e, r29	; 62
      5e:	cd bf       	out	0x3d, r28	; 61

00000060 <__do_copy_data>:
      60:	10 e0       	ldi	r17, 0x00	; 0
      62:	a0 e6       	ldi	r26, 0x60	; 96
      64:	b0 e0       	ldi	r27, 0x00	; 0
      66:	ec e2       	ldi	r30, 0x2C	; 44
      68:	f8 e2       	ldi	r31, 0x28	; 40
      6a:	02 c0       	rjmp	.+4      	; 0x70 <__do_copy_data+0x10>
      6c:	05 90       	lpm	r0, Z+
      6e:	0d 92       	st	X+, r0
      70:	a2 37       	cpi	r26, 0x72	; 114
      72:	b1 07       	cpc	r27, r17
      74:	d9 f7       	brne	.-10     	; 0x6c <__do_copy_data+0xc>

00000076 <__do_clear_bss>:
      76:	14 e0       	ldi	r17, 0x04	; 4
      78:	a2 e7       	ldi	r26, 0x72	; 114
      7a:	b0 e0       	ldi	r27, 0x00	; 0
      7c:	01 c0       	rjmp	.+2      	; 0x80 <.do_clear_bss_start>

0000007e <.do_clear_bss_loop>:
      7e:	1d 92       	st	X+, r1

00000080 <.do_clear_bss_start>:
      80:	ac 32       	cpi	r26, 0x2C	; 44
      82:	b1 07       	cpc	r27, r17
      84:	e1 f7       	brne	.-8      	; 0x7e <.do_clear_bss_loop>
      86:	0e 94 44 02 	call	0x488	; 0x488 <main>
      8a:	0c 94 14 14 	jmp	0x2828	; 0x2828 <_exit>

0000008e <__bad_interrupt>:
      8e:	0c 94 00 00 	jmp	0	; 0x0 <__vectors>

00000092 <prvTestWaitCondition>:

static BaseType_t prvTestWaitCondition( const EventBits_t uxCurrentEventBits, const EventBits_t uxBitsToWaitFor, const BaseType_t xWaitForAllBits )
{
BaseType_t xWaitConditionMet = pdFALSE;

	if( xWaitForAllBits == pdFALSE )
      92:	44 23       	and	r20, r20
      94:	41 f4       	brne	.+16     	; 0xa6 <prvTestWaitCondition+0x14>
	{
		/* Task only has to wait for one bit within uxBitsToWaitFor to be
		set.  Is one already set? */
		if( ( uxCurrentEventBits & uxBitsToWaitFor ) != ( EventBits_t ) 0 )
      96:	68 23       	and	r22, r24
      98:	79 23       	and	r23, r25
		{
			xWaitConditionMet = pdTRUE;
      9a:	81 e0       	ldi	r24, 0x01	; 1
      9c:	61 15       	cp	r22, r1
      9e:	71 05       	cpc	r23, r1
      a0:	51 f4       	brne	.+20     	; 0xb6 <prvTestWaitCondition+0x24>
      a2:	80 e0       	ldi	r24, 0x00	; 0
      a4:	08 95       	ret
	}
	else
	{
		/* Task has to wait for all the bits in uxBitsToWaitFor to be set.
		Are they set already? */
		if( ( uxCurrentEventBits & uxBitsToWaitFor ) == uxBitsToWaitFor )
      a6:	9b 01       	movw	r18, r22
      a8:	28 23       	and	r18, r24
      aa:	39 23       	and	r19, r25
	{
		/* Task only has to wait for one bit within uxBitsToWaitFor to be
		set.  Is one already set? */
		if( ( uxCurrentEventBits & uxBitsToWaitFor ) != ( EventBits_t ) 0 )
		{
			xWaitConditionMet = pdTRUE;
      ac:	81 e0       	ldi	r24, 0x01	; 1
      ae:	62 17       	cp	r22, r18
      b0:	73 07       	cpc	r23, r19
      b2:	09 f0       	breq	.+2      	; 0xb6 <prvTestWaitCondition+0x24>
      b4:	80 e0       	ldi	r24, 0x00	; 0
			mtCOVERAGE_TEST_MARKER();
		}
	}

	return xWaitConditionMet;
}
      b6:	08 95       	ret

000000b8 <xEventGroupCreate>:
/*-----------------------------------------------------------*/

#if( configSUPPORT_DYNAMIC_ALLOCATION == 1 )

	EventGroupHandle_t xEventGroupCreate( void )
	{
      b8:	cf 93       	push	r28
      ba:	df 93       	push	r29
	EventGroup_t *pxEventBits;

		/* Allocate the event group. */
		pxEventBits = ( EventGroup_t * ) pvPortMalloc( sizeof( EventGroup_t ) );
      bc:	8b e0       	ldi	r24, 0x0B	; 11
      be:	90 e0       	ldi	r25, 0x00	; 0
      c0:	0e 94 06 03 	call	0x60c	; 0x60c <pvPortMalloc>
      c4:	ec 01       	movw	r28, r24

		if( pxEventBits != NULL )
      c6:	00 97       	sbiw	r24, 0x00	; 0
      c8:	31 f0       	breq	.+12     	; 0xd6 <xEventGroupCreate+0x1e>
		{
			pxEventBits->uxEventBits = 0;
      ca:	fc 01       	movw	r30, r24
      cc:	11 92       	st	Z+, r1
      ce:	11 92       	st	Z+, r1
      d0:	cf 01       	movw	r24, r30
			vListInitialise( &( pxEventBits->xTasksWaitingForBits ) );
      d2:	0e 94 df 03 	call	0x7be	; 0x7be <vListInitialise>
		{
			traceEVENT_GROUP_CREATE_FAILED();
		}

		return ( EventGroupHandle_t ) pxEventBits;
	}
      d6:	8c 2f       	mov	r24, r28
      d8:	9d 2f       	mov	r25, r29
      da:	df 91       	pop	r29
      dc:	cf 91       	pop	r28
      de:	08 95       	ret

000000e0 <xEventGroupWaitBits>:
	return uxReturn;
}
/*-----------------------------------------------------------*/

EventBits_t xEventGroupWaitBits( EventGroupHandle_t xEventGroup, const EventBits_t uxBitsToWaitFor, const BaseType_t xClearOnExit, const BaseType_t xWaitForAllBits, TickType_t xTicksToWait )
{
      e0:	af 92       	push	r10
      e2:	bf 92       	push	r11
      e4:	cf 92       	push	r12
      e6:	df 92       	push	r13
      e8:	ef 92       	push	r14
      ea:	ff 92       	push	r15
      ec:	0f 93       	push	r16
      ee:	1f 93       	push	r17
      f0:	cf 93       	push	r28
      f2:	df 93       	push	r29
      f4:	5c 01       	movw	r10, r24
      f6:	6b 01       	movw	r12, r22
      f8:	e4 2e       	mov	r14, r20
      fa:	f2 2e       	mov	r15, r18
	{
		configASSERT( !( ( xTaskGetSchedulerState() == taskSCHEDULER_SUSPENDED ) && ( xTicksToWait != 0 ) ) );
	}
	#endif

	vTaskSuspendAll();
      fc:	0e 94 79 0d 	call	0x1af2	; 0x1af2 <vTaskSuspendAll>
	{
		const EventBits_t uxCurrentEventBits = pxEventBits->uxEventBits;
     100:	f5 01       	movw	r30, r10
     102:	c0 81       	ld	r28, Z
     104:	d1 81       	ldd	r29, Z+1	; 0x01

		/* Check to see if the wait condition is already met or not. */
		xWaitConditionMet = prvTestWaitCondition( uxCurrentEventBits, uxBitsToWaitFor, xWaitForAllBits );
     106:	ce 01       	movw	r24, r28
     108:	b6 01       	movw	r22, r12
     10a:	4f 2d       	mov	r20, r15
     10c:	0e 94 49 00 	call	0x92	; 0x92 <prvTestWaitCondition>

		if( xWaitConditionMet != pdFALSE )
     110:	88 23       	and	r24, r24
     112:	51 f0       	breq	.+20     	; 0x128 <xEventGroupWaitBits+0x48>
			block. */
			uxReturn = uxCurrentEventBits;
			xTicksToWait = ( TickType_t ) 0;

			/* Clear the wait bits if requested to do so. */
			if( xClearOnExit != pdFALSE )
     114:	ee 20       	and	r14, r14
     116:	01 f1       	breq	.+64     	; 0x158 <xEventGroupWaitBits+0x78>
			{
				pxEventBits->uxEventBits &= ~uxBitsToWaitFor;
     118:	c0 94       	com	r12
     11a:	d0 94       	com	r13
     11c:	cc 22       	and	r12, r28
     11e:	dd 22       	and	r13, r29
     120:	f5 01       	movw	r30, r10
     122:	d1 82       	std	Z+1, r13	; 0x01
     124:	c0 82       	st	Z, r12
     126:	18 c0       	rjmp	.+48     	; 0x158 <xEventGroupWaitBits+0x78>
			else
			{
				mtCOVERAGE_TEST_MARKER();
			}
		}
		else if( xTicksToWait == ( TickType_t ) 0 )
     128:	01 15       	cp	r16, r1
     12a:	11 05       	cpc	r17, r1
     12c:	a9 f0       	breq	.+42     	; 0x158 <xEventGroupWaitBits+0x78>
		{
			/* The task is going to block to wait for its required bits to be
			set.  uxControlBits are used to remember the specified behaviour of
			this call to xEventGroupWaitBits() - for use when the event bits
			unblock the task. */
			if( xClearOnExit != pdFALSE )
     12e:	ee 20       	and	r14, r14
     130:	19 f4       	brne	.+6      	; 0x138 <xEventGroupWaitBits+0x58>
/*-----------------------------------------------------------*/

EventBits_t xEventGroupWaitBits( EventGroupHandle_t xEventGroup, const EventBits_t uxBitsToWaitFor, const BaseType_t xClearOnExit, const BaseType_t xWaitForAllBits, TickType_t xTicksToWait )
{
EventGroup_t *pxEventBits = ( EventGroup_t * ) xEventGroup;
EventBits_t uxReturn, uxControlBits = 0;
     132:	60 e0       	ldi	r22, 0x00	; 0
     134:	70 e0       	ldi	r23, 0x00	; 0
     136:	02 c0       	rjmp	.+4      	; 0x13c <xEventGroupWaitBits+0x5c>
			set.  uxControlBits are used to remember the specified behaviour of
			this call to xEventGroupWaitBits() - for use when the event bits
			unblock the task. */
			if( xClearOnExit != pdFALSE )
			{
				uxControlBits |= eventCLEAR_EVENTS_ON_EXIT_BIT;
     138:	60 e0       	ldi	r22, 0x00	; 0
     13a:	71 e0       	ldi	r23, 0x01	; 1
			else
			{
				mtCOVERAGE_TEST_MARKER();
			}

			if( xWaitForAllBits != pdFALSE )
     13c:	f1 10       	cpse	r15, r1
			{
				uxControlBits |= eventWAIT_FOR_ALL_BITS;
     13e:	74 60       	ori	r23, 0x04	; 4
			}

			/* Store the bits that the calling task is waiting for in the
			task's event list item so the kernel knows when a match is
			found.  Then enter the blocked state. */
			vTaskPlaceOnUnorderedEventList( &( pxEventBits->xTasksWaitingForBits ), ( uxBitsToWaitFor | uxControlBits ), xTicksToWait );
     140:	6c 29       	or	r22, r12
     142:	7d 29       	or	r23, r13
     144:	c5 01       	movw	r24, r10
     146:	02 96       	adiw	r24, 0x02	; 2
     148:	a8 01       	movw	r20, r16
     14a:	0e 94 06 10 	call	0x200c	; 0x200c <vTaskPlaceOnUnorderedEventList>
			uxReturn = 0;

			traceEVENT_GROUP_WAIT_BITS_BLOCK( xEventGroup, uxBitsToWaitFor );
		}
	}
	xAlreadyYielded = xTaskResumeAll();
     14e:	0e 94 3e 0e 	call	0x1c7c	; 0x1c7c <xTaskResumeAll>

	if( xTicksToWait != ( TickType_t ) 0 )
	{
		if( xAlreadyYielded == pdFALSE )
     152:	88 23       	and	r24, r24
     154:	39 f4       	brne	.+14     	; 0x164 <xEventGroupWaitBits+0x84>
     156:	04 c0       	rjmp	.+8      	; 0x160 <xEventGroupWaitBits+0x80>
			uxReturn = 0;

			traceEVENT_GROUP_WAIT_BITS_BLOCK( xEventGroup, uxBitsToWaitFor );
		}
	}
	xAlreadyYielded = xTaskResumeAll();
     158:	0e 94 3e 0e 	call	0x1c7c	; 0x1c7c <xTaskResumeAll>
     15c:	ce 01       	movw	r24, r28
     15e:	21 c0       	rjmp	.+66     	; 0x1a2 <xEventGroupWaitBits+0xc2>

	if( xTicksToWait != ( TickType_t ) 0 )
	{
		if( xAlreadyYielded == pdFALSE )
		{
			portYIELD_WITHIN_API();
     160:	0e 94 30 05 	call	0xa60	; 0xa60 <vPortYield>

		/* The task blocked to wait for its required bits to be set - at this
		point either the required bits were set or the block time expired.  If
		the required bits were set they will have been stored in the task's
		event list item, and they should now be retrieved then cleared. */
		uxReturn = uxTaskResetEventItemValue();
     164:	0e 94 8c 11 	call	0x2318	; 0x2318 <uxTaskResetEventItemValue>
     168:	ec 01       	movw	r28, r24

		if( ( uxReturn & eventUNBLOCKED_DUE_TO_BIT_SET ) == ( EventBits_t ) 0 )
     16a:	91 fd       	sbrc	r25, 1
     16c:	18 c0       	rjmp	.+48     	; 0x19e <xEventGroupWaitBits+0xbe>
		{
			taskENTER_CRITICAL();
     16e:	0f b6       	in	r0, 0x3f	; 63
     170:	f8 94       	cli
     172:	0f 92       	push	r0
			{
				/* The task timed out, just return the current event bit value. */
				uxReturn = pxEventBits->uxEventBits;
     174:	f5 01       	movw	r30, r10
     176:	c0 81       	ld	r28, Z
     178:	d1 81       	ldd	r29, Z+1	; 0x01

				/* It is possible that the event bits were updated between this
				task leaving the Blocked state and running again. */
				if( prvTestWaitCondition( uxReturn, uxBitsToWaitFor, xWaitForAllBits ) != pdFALSE )
     17a:	ce 01       	movw	r24, r28
     17c:	b6 01       	movw	r22, r12
     17e:	4f 2d       	mov	r20, r15
     180:	0e 94 49 00 	call	0x92	; 0x92 <prvTestWaitCondition>
     184:	88 23       	and	r24, r24
     186:	49 f0       	breq	.+18     	; 0x19a <xEventGroupWaitBits+0xba>
				{
					if( xClearOnExit != pdFALSE )
     188:	ee 20       	and	r14, r14
     18a:	39 f0       	breq	.+14     	; 0x19a <xEventGroupWaitBits+0xba>
					{
						pxEventBits->uxEventBits &= ~uxBitsToWaitFor;
     18c:	c0 94       	com	r12
     18e:	d0 94       	com	r13
     190:	cc 22       	and	r12, r28
     192:	dd 22       	and	r13, r29
     194:	f5 01       	movw	r30, r10
     196:	d1 82       	std	Z+1, r13	; 0x01
     198:	c0 82       	st	Z, r12
				else
				{
					mtCOVERAGE_TEST_MARKER();
				}
			}
			taskEXIT_CRITICAL();
     19a:	0f 90       	pop	r0
     19c:	0f be       	out	0x3f, r0	; 63
		{
			/* The task unblocked because the bits were set. */
		}

		/* The task blocked so control bits may have been set. */
		uxReturn &= ~eventEVENT_BITS_CONTROL_BYTES;
     19e:	ce 01       	movw	r24, r28
     1a0:	90 70       	andi	r25, 0x00	; 0
	}
	traceEVENT_GROUP_WAIT_BITS_END( xEventGroup, uxBitsToWaitFor, xTimeoutOccurred );

	return uxReturn;
}
     1a2:	df 91       	pop	r29
     1a4:	cf 91       	pop	r28
     1a6:	1f 91       	pop	r17
     1a8:	0f 91       	pop	r16
     1aa:	ff 90       	pop	r15
     1ac:	ef 90       	pop	r14
     1ae:	df 90       	pop	r13
     1b0:	cf 90       	pop	r12
     1b2:	bf 90       	pop	r11
     1b4:	af 90       	pop	r10
     1b6:	08 95       	ret

000001b8 <xEventGroupClearBits>:
/*-----------------------------------------------------------*/

EventBits_t xEventGroupClearBits( EventGroupHandle_t xEventGroup, const EventBits_t uxBitsToClear )
{
     1b8:	fc 01       	movw	r30, r24
	/* Check the user is not attempting to clear the bits used by the kernel
	itself. */
	configASSERT( xEventGroup );
	configASSERT( ( uxBitsToClear & eventEVENT_BITS_CONTROL_BYTES ) == 0 );

	taskENTER_CRITICAL();
     1ba:	0f b6       	in	r0, 0x3f	; 63
     1bc:	f8 94       	cli
     1be:	0f 92       	push	r0
	{
		traceEVENT_GROUP_CLEAR_BITS( xEventGroup, uxBitsToClear );

		/* The value returned is the event group value prior to the bits being
		cleared. */
		uxReturn = pxEventBits->uxEventBits;
     1c0:	80 81       	ld	r24, Z
     1c2:	91 81       	ldd	r25, Z+1	; 0x01

		/* Clear the bits. */
		pxEventBits->uxEventBits &= ~uxBitsToClear;
     1c4:	60 95       	com	r22
     1c6:	70 95       	com	r23
     1c8:	68 23       	and	r22, r24
     1ca:	79 23       	and	r23, r25
     1cc:	71 83       	std	Z+1, r23	; 0x01
     1ce:	60 83       	st	Z, r22
	}
	taskEXIT_CRITICAL();
     1d0:	0f 90       	pop	r0
     1d2:	0f be       	out	0x3f, r0	; 63

	return uxReturn;
}
     1d4:	08 95       	ret

000001d6 <xEventGroupGetBitsFromISR>:

#endif
/*-----------------------------------------------------------*/

EventBits_t xEventGroupGetBitsFromISR( EventGroupHandle_t xEventGroup )
{
     1d6:	fc 01       	movw	r30, r24
		uxReturn = pxEventBits->uxEventBits;
	}
	portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );

	return uxReturn;
}
     1d8:	80 81       	ld	r24, Z
     1da:	91 81       	ldd	r25, Z+1	; 0x01
     1dc:	08 95       	ret

000001de <xEventGroupSetBits>:
/*-----------------------------------------------------------*/

EventBits_t xEventGroupSetBits( EventGroupHandle_t xEventGroup, const EventBits_t uxBitsToSet )
{
     1de:	af 92       	push	r10
     1e0:	bf 92       	push	r11
     1e2:	cf 92       	push	r12
     1e4:	df 92       	push	r13
     1e6:	ef 92       	push	r14
     1e8:	ff 92       	push	r15
     1ea:	0f 93       	push	r16
     1ec:	1f 93       	push	r17
     1ee:	cf 93       	push	r28
     1f0:	df 93       	push	r29
     1f2:	8c 01       	movw	r16, r24
     1f4:	eb 01       	movw	r28, r22
	itself. */
	configASSERT( xEventGroup );
	configASSERT( ( uxBitsToSet & eventEVENT_BITS_CONTROL_BYTES ) == 0 );

	pxList = &( pxEventBits->xTasksWaitingForBits );
	pxListEnd = listGET_END_MARKER( pxList ); /*lint !e826 !e740 The mini list structure is used as the list end to save RAM.  This is checked and valid. */
     1f6:	0f 2e       	mov	r0, r31
     1f8:	f5 e0       	ldi	r31, 0x05	; 5
     1fa:	cf 2e       	mov	r12, r31
     1fc:	dd 24       	eor	r13, r13
     1fe:	f0 2d       	mov	r31, r0
     200:	c8 0e       	add	r12, r24
     202:	d9 1e       	adc	r13, r25
	vTaskSuspendAll();
     204:	0e 94 79 0d 	call	0x1af2	; 0x1af2 <vTaskSuspendAll>
	{
		traceEVENT_GROUP_SET_BITS( xEventGroup, uxBitsToSet );

		pxListItem = listGET_HEAD_ENTRY( pxList );
     208:	d8 01       	movw	r26, r16
     20a:	17 96       	adiw	r26, 0x07	; 7
     20c:	ed 91       	ld	r30, X+
     20e:	fc 91       	ld	r31, X
     210:	18 97       	sbiw	r26, 0x08	; 8

		/* Set the bits. */
		pxEventBits->uxEventBits |= uxBitsToSet;
     212:	8d 91       	ld	r24, X+
     214:	9c 91       	ld	r25, X
     216:	11 97       	sbiw	r26, 0x01	; 1
     218:	8c 2b       	or	r24, r28
     21a:	9d 2b       	or	r25, r29
     21c:	11 96       	adiw	r26, 0x01	; 1
     21e:	9c 93       	st	X, r25
     220:	8e 93       	st	-X, r24

		/* See if the new bit value should unblock any tasks. */
		while( pxListItem != pxListEnd )
     222:	ce 16       	cp	r12, r30
     224:	df 06       	cpc	r13, r31
     226:	c1 f1       	breq	.+112    	; 0x298 <xEventGroupSetBits+0xba>
EventBits_t xEventGroupSetBits( EventGroupHandle_t xEventGroup, const EventBits_t uxBitsToSet )
{
ListItem_t *pxListItem, *pxNext;
ListItem_t const *pxListEnd;
List_t *pxList;
EventBits_t uxBitsToClear = 0, uxBitsWaitedFor, uxControlBits;
     228:	aa 24       	eor	r10, r10
     22a:	bb 24       	eor	r11, r11
			if( ( uxControlBits & eventWAIT_FOR_ALL_BITS ) == ( EventBits_t ) 0 )
			{
				/* Just looking for single bit being set. */
				if( ( uxBitsWaitedFor & pxEventBits->uxEventBits ) != ( EventBits_t ) 0 )
				{
					xMatchFound = pdTRUE;
     22c:	ff 24       	eor	r15, r15
     22e:	f3 94       	inc	r15
     230:	ee 24       	eor	r14, r14
     232:	01 c0       	rjmp	.+2      	; 0x236 <xEventGroupSetBits+0x58>

		/* Set the bits. */
		pxEventBits->uxEventBits |= uxBitsToSet;

		/* See if the new bit value should unblock any tasks. */
		while( pxListItem != pxListEnd )
     234:	fe 01       	movw	r30, r28
		{
			pxNext = listGET_NEXT( pxListItem );
     236:	c2 81       	ldd	r28, Z+2	; 0x02
     238:	d3 81       	ldd	r29, Z+3	; 0x03
			uxBitsWaitedFor = listGET_LIST_ITEM_VALUE( pxListItem );
     23a:	80 81       	ld	r24, Z
     23c:	91 81       	ldd	r25, Z+1	; 0x01
			xMatchFound = pdFALSE;

			/* Split the bits waited for from the control bits. */
			uxControlBits = uxBitsWaitedFor & eventEVENT_BITS_CONTROL_BYTES;
     23e:	bc 01       	movw	r22, r24
     240:	60 70       	andi	r22, 0x00	; 0
			uxBitsWaitedFor &= ~eventEVENT_BITS_CONTROL_BYTES;
     242:	9c 01       	movw	r18, r24
     244:	30 70       	andi	r19, 0x00	; 0

			if( ( uxControlBits & eventWAIT_FOR_ALL_BITS ) == ( EventBits_t ) 0 )
     246:	92 fd       	sbrc	r25, 2
     248:	0b c0       	rjmp	.+22     	; 0x260 <xEventGroupSetBits+0x82>
			{
				/* Just looking for single bit being set. */
				if( ( uxBitsWaitedFor & pxEventBits->uxEventBits ) != ( EventBits_t ) 0 )
     24a:	d8 01       	movw	r26, r16
     24c:	8d 91       	ld	r24, X+
     24e:	9c 91       	ld	r25, X
     250:	11 97       	sbiw	r26, 0x01	; 1
     252:	82 23       	and	r24, r18
     254:	93 23       	and	r25, r19
				{
					xMatchFound = pdTRUE;
     256:	4f 2d       	mov	r20, r15
     258:	00 97       	sbiw	r24, 0x00	; 0
     25a:	69 f4       	brne	.+26     	; 0x276 <xEventGroupSetBits+0x98>
     25c:	4e 2d       	mov	r20, r14
     25e:	0b c0       	rjmp	.+22     	; 0x276 <xEventGroupSetBits+0x98>
				else
				{
					mtCOVERAGE_TEST_MARKER();
				}
			}
			else if( ( uxBitsWaitedFor & pxEventBits->uxEventBits ) == uxBitsWaitedFor )
     260:	d8 01       	movw	r26, r16
     262:	8d 91       	ld	r24, X+
     264:	9c 91       	ld	r25, X
     266:	11 97       	sbiw	r26, 0x01	; 1
     268:	82 23       	and	r24, r18
     26a:	93 23       	and	r25, r19
			if( ( uxControlBits & eventWAIT_FOR_ALL_BITS ) == ( EventBits_t ) 0 )
			{
				/* Just looking for single bit being set. */
				if( ( uxBitsWaitedFor & pxEventBits->uxEventBits ) != ( EventBits_t ) 0 )
				{
					xMatchFound = pdTRUE;
     26c:	4f 2d       	mov	r20, r15
     26e:	28 17       	cp	r18, r24
     270:	39 07       	cpc	r19, r25
     272:	09 f0       	breq	.+2      	; 0x276 <xEventGroupSetBits+0x98>
     274:	4e 2d       	mov	r20, r14
			else
			{
				/* Need all bits to be set, but not all the bits were set. */
			}

			if( xMatchFound != pdFALSE )
     276:	44 23       	and	r20, r20
     278:	59 f0       	breq	.+22     	; 0x290 <xEventGroupSetBits+0xb2>
			{
				/* The bits match.  Should the bits be cleared on exit? */
				if( ( uxControlBits & eventCLEAR_EVENTS_ON_EXIT_BIT ) != ( EventBits_t ) 0 )
     27a:	70 ff       	sbrs	r23, 0
     27c:	02 c0       	rjmp	.+4      	; 0x282 <xEventGroupSetBits+0xa4>
				{
					uxBitsToClear |= uxBitsWaitedFor;
     27e:	a2 2a       	or	r10, r18
     280:	b3 2a       	or	r11, r19
				/* Store the actual event flag value in the task's event list
				item before removing the task from the event list.  The
				eventUNBLOCKED_DUE_TO_BIT_SET bit is set so the task knows
				that is was unblocked due to its required bits matching, rather
				than because it timed out. */
				( void ) xTaskRemoveFromUnorderedEventList( pxListItem, pxEventBits->uxEventBits | eventUNBLOCKED_DUE_TO_BIT_SET );
     282:	d8 01       	movw	r26, r16
     284:	6d 91       	ld	r22, X+
     286:	7c 91       	ld	r23, X
     288:	72 60       	ori	r23, 0x02	; 2
     28a:	cf 01       	movw	r24, r30
     28c:	0e 94 6a 10 	call	0x20d4	; 0x20d4 <xTaskRemoveFromUnorderedEventList>

		/* Set the bits. */
		pxEventBits->uxEventBits |= uxBitsToSet;

		/* See if the new bit value should unblock any tasks. */
		while( pxListItem != pxListEnd )
     290:	cc 16       	cp	r12, r28
     292:	dd 06       	cpc	r13, r29
     294:	79 f6       	brne	.-98     	; 0x234 <xEventGroupSetBits+0x56>
     296:	02 c0       	rjmp	.+4      	; 0x29c <xEventGroupSetBits+0xbe>
EventBits_t xEventGroupSetBits( EventGroupHandle_t xEventGroup, const EventBits_t uxBitsToSet )
{
ListItem_t *pxListItem, *pxNext;
ListItem_t const *pxListEnd;
List_t *pxList;
EventBits_t uxBitsToClear = 0, uxBitsWaitedFor, uxControlBits;
     298:	aa 24       	eor	r10, r10
     29a:	bb 24       	eor	r11, r11
			pxListItem = pxNext;
		}

		/* Clear any bits that matched when the eventCLEAR_EVENTS_ON_EXIT_BIT
		bit was set in the control word. */
		pxEventBits->uxEventBits &= ~uxBitsToClear;
     29c:	c5 01       	movw	r24, r10
     29e:	80 95       	com	r24
     2a0:	90 95       	com	r25
     2a2:	f8 01       	movw	r30, r16
     2a4:	a0 80       	ld	r10, Z
     2a6:	b1 80       	ldd	r11, Z+1	; 0x01
     2a8:	a8 22       	and	r10, r24
     2aa:	b9 22       	and	r11, r25
     2ac:	b1 82       	std	Z+1, r11	; 0x01
     2ae:	a0 82       	st	Z, r10
	}
	( void ) xTaskResumeAll();
     2b0:	0e 94 3e 0e 	call	0x1c7c	; 0x1c7c <xTaskResumeAll>

	return pxEventBits->uxEventBits;
}
     2b4:	d8 01       	movw	r26, r16
     2b6:	8c 91       	ld	r24, X
     2b8:	11 96       	adiw	r26, 0x01	; 1
     2ba:	9c 91       	ld	r25, X
     2bc:	11 97       	sbiw	r26, 0x01	; 1
     2be:	df 91       	pop	r29
     2c0:	cf 91       	pop	r28
     2c2:	1f 91       	pop	r17
     2c4:	0f 91       	pop	r16
     2c6:	ff 90       	pop	r15
     2c8:	ef 90       	pop	r14
     2ca:	df 90       	pop	r13
     2cc:	cf 90       	pop	r12
     2ce:	bf 90       	pop	r11
     2d0:	af 90       	pop	r10
     2d2:	08 95       	ret

000002d4 <xEventGroupSync>:

#endif /* configSUPPORT_DYNAMIC_ALLOCATION */
/*-----------------------------------------------------------*/

EventBits_t xEventGroupSync( EventGroupHandle_t xEventGroup, const EventBits_t uxBitsToSet, const EventBits_t uxBitsToWaitFor, TickType_t xTicksToWait )
{
     2d4:	af 92       	push	r10
     2d6:	bf 92       	push	r11
     2d8:	cf 92       	push	r12
     2da:	df 92       	push	r13
     2dc:	ef 92       	push	r14
     2de:	ff 92       	push	r15
     2e0:	0f 93       	push	r16
     2e2:	1f 93       	push	r17
     2e4:	cf 93       	push	r28
     2e6:	df 93       	push	r29
     2e8:	6c 01       	movw	r12, r24
     2ea:	eb 01       	movw	r28, r22
     2ec:	7a 01       	movw	r14, r20
     2ee:	59 01       	movw	r10, r18
	{
		configASSERT( !( ( xTaskGetSchedulerState() == taskSCHEDULER_SUSPENDED ) && ( xTicksToWait != 0 ) ) );
	}
	#endif

	vTaskSuspendAll();
     2f0:	0e 94 79 0d 	call	0x1af2	; 0x1af2 <vTaskSuspendAll>
	{
		uxOriginalBitValue = pxEventBits->uxEventBits;
     2f4:	f6 01       	movw	r30, r12
     2f6:	00 81       	ld	r16, Z
     2f8:	11 81       	ldd	r17, Z+1	; 0x01

		( void ) xEventGroupSetBits( xEventGroup, uxBitsToSet );
     2fa:	c6 01       	movw	r24, r12
     2fc:	be 01       	movw	r22, r28
     2fe:	0e 94 ef 00 	call	0x1de	; 0x1de <xEventGroupSetBits>

		if( ( ( uxOriginalBitValue | uxBitsToSet ) & uxBitsToWaitFor ) == uxBitsToWaitFor )
     302:	c0 2b       	or	r28, r16
     304:	d1 2b       	or	r29, r17
     306:	c7 01       	movw	r24, r14
     308:	8c 23       	and	r24, r28
     30a:	9d 23       	and	r25, r29
     30c:	8e 15       	cp	r24, r14
     30e:	9f 05       	cpc	r25, r15
     310:	51 f4       	brne	.+20     	; 0x326 <xEventGroupSync+0x52>
			/* All the rendezvous bits are now set - no need to block. */
			uxReturn = ( uxOriginalBitValue | uxBitsToSet );

			/* Rendezvous always clear the bits.  They will have been cleared
			already unless this is the only task in the rendezvous. */
			pxEventBits->uxEventBits &= ~uxBitsToWaitFor;
     312:	80 95       	com	r24
     314:	90 95       	com	r25
     316:	f6 01       	movw	r30, r12
     318:	20 81       	ld	r18, Z
     31a:	31 81       	ldd	r19, Z+1	; 0x01
     31c:	82 23       	and	r24, r18
     31e:	93 23       	and	r25, r19
     320:	91 83       	std	Z+1, r25	; 0x01
     322:	80 83       	st	Z, r24
     324:	12 c0       	rjmp	.+36     	; 0x34a <xEventGroupSync+0x76>

			xTicksToWait = 0;
		}
		else
		{
			if( xTicksToWait != ( TickType_t ) 0 )
     326:	a1 14       	cp	r10, r1
     328:	b1 04       	cpc	r11, r1
     32a:	61 f0       	breq	.+24     	; 0x344 <xEventGroupSync+0x70>
				traceEVENT_GROUP_SYNC_BLOCK( xEventGroup, uxBitsToSet, uxBitsToWaitFor );

				/* Store the bits that the calling task is waiting for in the
				task's event list item so the kernel knows when a match is
				found.  Then enter the blocked state. */
				vTaskPlaceOnUnorderedEventList( &( pxEventBits->xTasksWaitingForBits ), ( uxBitsToWaitFor | eventCLEAR_EVENTS_ON_EXIT_BIT | eventWAIT_FOR_ALL_BITS ), xTicksToWait );
     32c:	b7 01       	movw	r22, r14
     32e:	75 60       	ori	r23, 0x05	; 5
     330:	c6 01       	movw	r24, r12
     332:	02 96       	adiw	r24, 0x02	; 2
     334:	a5 01       	movw	r20, r10
     336:	0e 94 06 10 	call	0x200c	; 0x200c <vTaskPlaceOnUnorderedEventList>
				specified - just return the current event bit value. */
				uxReturn = pxEventBits->uxEventBits;
			}
		}
	}
	xAlreadyYielded = xTaskResumeAll();
     33a:	0e 94 3e 0e 	call	0x1c7c	; 0x1c7c <xTaskResumeAll>

	if( xTicksToWait != ( TickType_t ) 0 )
	{
		if( xAlreadyYielded == pdFALSE )
     33e:	88 23       	and	r24, r24
     340:	49 f4       	brne	.+18     	; 0x354 <xEventGroupSync+0x80>
     342:	06 c0       	rjmp	.+12     	; 0x350 <xEventGroupSync+0x7c>
			}
			else
			{
				/* The rendezvous bits were not set, but no block time was
				specified - just return the current event bit value. */
				uxReturn = pxEventBits->uxEventBits;
     344:	f6 01       	movw	r30, r12
     346:	c0 81       	ld	r28, Z
     348:	d1 81       	ldd	r29, Z+1	; 0x01
			}
		}
	}
	xAlreadyYielded = xTaskResumeAll();
     34a:	0e 94 3e 0e 	call	0x1c7c	; 0x1c7c <xTaskResumeAll>
     34e:	1c c0       	rjmp	.+56     	; 0x388 <xEventGroupSync+0xb4>

	if( xTicksToWait != ( TickType_t ) 0 )
	{
		if( xAlreadyYielded == pdFALSE )
		{
			portYIELD_WITHIN_API();
     350:	0e 94 30 05 	call	0xa60	; 0xa60 <vPortYield>

		/* The task blocked to wait for its required bits to be set - at this
		point either the required bits were set or the block time expired.  If
		the required bits were set they will have been stored in the task's
		event list item, and they should now be retrieved then cleared. */
		uxReturn = uxTaskResetEventItemValue();
     354:	0e 94 8c 11 	call	0x2318	; 0x2318 <uxTaskResetEventItemValue>

		if( ( uxReturn & eventUNBLOCKED_DUE_TO_BIT_SET ) == ( EventBits_t ) 0 )
     358:	91 fd       	sbrc	r25, 1
     35a:	14 c0       	rjmp	.+40     	; 0x384 <xEventGroupSync+0xb0>
		{
			/* The task timed out, just return the current event bit value. */
			taskENTER_CRITICAL();
     35c:	0f b6       	in	r0, 0x3f	; 63
     35e:	f8 94       	cli
     360:	0f 92       	push	r0
			{
				uxReturn = pxEventBits->uxEventBits;
     362:	f6 01       	movw	r30, r12
     364:	80 81       	ld	r24, Z
     366:	91 81       	ldd	r25, Z+1	; 0x01

				/* Although the task got here because it timed out before the
				bits it was waiting for were set, it is possible that since it
				unblocked another task has set the bits.  If this is the case
				then it needs to clear the bits before exiting. */
				if( ( uxReturn & uxBitsToWaitFor ) == uxBitsToWaitFor )
     368:	97 01       	movw	r18, r14
     36a:	28 23       	and	r18, r24
     36c:	39 23       	and	r19, r25
     36e:	2e 15       	cp	r18, r14
     370:	3f 05       	cpc	r19, r15
     372:	31 f4       	brne	.+12     	; 0x380 <xEventGroupSync+0xac>
				{
					pxEventBits->uxEventBits &= ~uxBitsToWaitFor;
     374:	20 95       	com	r18
     376:	30 95       	com	r19
     378:	28 23       	and	r18, r24
     37a:	39 23       	and	r19, r25
     37c:	31 83       	std	Z+1, r19	; 0x01
     37e:	20 83       	st	Z, r18
				else
				{
					mtCOVERAGE_TEST_MARKER();
				}
			}
			taskEXIT_CRITICAL();
     380:	0f 90       	pop	r0
     382:	0f be       	out	0x3f, r0	; 63
			/* The task unblocked because the bits were set. */
		}

		/* Control bits might be set as the task had blocked should not be
		returned. */
		uxReturn &= ~eventEVENT_BITS_CONTROL_BYTES;
     384:	ec 01       	movw	r28, r24
     386:	d0 70       	andi	r29, 0x00	; 0
	}

	traceEVENT_GROUP_SYNC_END( xEventGroup, uxBitsToSet, uxBitsToWaitFor, xTimeoutOccurred );

	return uxReturn;
}
     388:	8c 2f       	mov	r24, r28
     38a:	9d 2f       	mov	r25, r29
     38c:	df 91       	pop	r29
     38e:	cf 91       	pop	r28
     390:	1f 91       	pop	r17
     392:	0f 91       	pop	r16
     394:	ff 90       	pop	r15
     396:	ef 90       	pop	r14
     398:	df 90       	pop	r13
     39a:	cf 90       	pop	r12
     39c:	bf 90       	pop	r11
     39e:	af 90       	pop	r10
     3a0:	08 95       	ret

000003a2 <vEventGroupDelete>:
	return pxEventBits->uxEventBits;
}
/*-----------------------------------------------------------*/

void vEventGroupDelete( EventGroupHandle_t xEventGroup )
{
     3a2:	cf 93       	push	r28
     3a4:	df 93       	push	r29
     3a6:	ec 01       	movw	r28, r24
EventGroup_t *pxEventBits = ( EventGroup_t * ) xEventGroup;
const List_t *pxTasksWaitingForBits = &( pxEventBits->xTasksWaitingForBits );

	vTaskSuspendAll();
     3a8:	0e 94 79 0d 	call	0x1af2	; 0x1af2 <vTaskSuspendAll>
	{
		traceEVENT_GROUP_DELETE( xEventGroup );

		while( listCURRENT_LIST_LENGTH( pxTasksWaitingForBits ) > ( UBaseType_t ) 0 )
     3ac:	8a 81       	ldd	r24, Y+2	; 0x02
     3ae:	88 23       	and	r24, r24
     3b0:	49 f0       	breq	.+18     	; 0x3c4 <vEventGroupDelete+0x22>
		{
			/* Unblock the task, returning 0 as the event list is being deleted
			and	cannot therefore have any bits set. */
			configASSERT( pxTasksWaitingForBits->xListEnd.pxNext != ( ListItem_t * ) &( pxTasksWaitingForBits->xListEnd ) );
			( void ) xTaskRemoveFromUnorderedEventList( pxTasksWaitingForBits->xListEnd.pxNext, eventUNBLOCKED_DUE_TO_BIT_SET );
     3b2:	8f 81       	ldd	r24, Y+7	; 0x07
     3b4:	98 85       	ldd	r25, Y+8	; 0x08
     3b6:	60 e0       	ldi	r22, 0x00	; 0
     3b8:	72 e0       	ldi	r23, 0x02	; 2
     3ba:	0e 94 6a 10 	call	0x20d4	; 0x20d4 <xTaskRemoveFromUnorderedEventList>

	vTaskSuspendAll();
	{
		traceEVENT_GROUP_DELETE( xEventGroup );

		while( listCURRENT_LIST_LENGTH( pxTasksWaitingForBits ) > ( UBaseType_t ) 0 )
     3be:	8a 81       	ldd	r24, Y+2	; 0x02
     3c0:	88 23       	and	r24, r24
     3c2:	b9 f7       	brne	.-18     	; 0x3b2 <vEventGroupDelete+0x10>

		#if( ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) && ( configSUPPORT_STATIC_ALLOCATION == 0 ) )
		{
			/* The event group can only have been allocated dynamically - free
			it again. */
			vPortFree( pxEventBits );
     3c4:	ce 01       	movw	r24, r28
     3c6:	0e 94 a6 03 	call	0x74c	; 0x74c <vPortFree>
				mtCOVERAGE_TEST_MARKER();
			}
		}
		#endif /* configSUPPORT_DYNAMIC_ALLOCATION */
	}
	( void ) xTaskResumeAll();
     3ca:	0e 94 3e 0e 	call	0x1c7c	; 0x1c7c <xTaskResumeAll>
}
     3ce:	df 91       	pop	r29
     3d0:	cf 91       	pop	r28
     3d2:	08 95       	ret

000003d4 <vEventGroupSetBitsCallback>:

/* For internal use only - execute a 'set bits' command that was pended from
an interrupt. */
void vEventGroupSetBitsCallback( void *pvEventGroup, const uint32_t ulBitsToSet )
{
	( void ) xEventGroupSetBits( pvEventGroup, ( EventBits_t ) ulBitsToSet );
     3d4:	ba 01       	movw	r22, r20
     3d6:	0e 94 ef 00 	call	0x1de	; 0x1de <xEventGroupSetBits>
}
     3da:	08 95       	ret

000003dc <vEventGroupClearBitsCallback>:

/* For internal use only - execute a 'clear bits' command that was pended from
an interrupt. */
void vEventGroupClearBitsCallback( void *pvEventGroup, const uint32_t ulBitsToClear )
{
	( void ) xEventGroupClearBits( pvEventGroup, ( EventBits_t ) ulBitsToClear );
     3dc:	ba 01       	movw	r22, r20
     3de:	0e 94 dc 00 	call	0x1b8	; 0x1b8 <xEventGroupClearBits>
}
     3e2:	08 95       	ret

000003e4 <Task2>:
	}
}
void Task2(void* pv)
{
	/* Initialization */
	DIO_Set_Pin_Direction(A,1,OUTPUT);
     3e4:	89 e3       	ldi	r24, 0x39	; 57
     3e6:	61 e0       	ldi	r22, 0x01	; 1
     3e8:	41 e0       	ldi	r20, 0x01	; 1
     3ea:	0e 94 73 02 	call	0x4e6	; 0x4e6 <DIO_Set_Pin_Direction>
	u8 semaphore_state;
	
	while(1)
	{
		semaphore_state = xSemaphoreTake(my_mutex,1000); /* timeout 1 second */
     3ee:	80 91 0a 04 	lds	r24, 0x040A
     3f2:	90 91 0b 04 	lds	r25, 0x040B
     3f6:	60 e0       	ldi	r22, 0x00	; 0
     3f8:	70 e0       	ldi	r23, 0x00	; 0
     3fa:	48 ee       	ldi	r20, 0xE8	; 232
     3fc:	53 e0       	ldi	r21, 0x03	; 3
     3fe:	20 e0       	ldi	r18, 0x00	; 0
     400:	0e 94 57 08 	call	0x10ae	; 0x10ae <xQueueGenericReceive>
		
		if (semaphore_state == pdTRUE )
     404:	81 30       	cpi	r24, 0x01	; 1
     406:	99 f7       	brne	.-26     	; 0x3ee <Task2+0xa>
		{
			DIO_Set_Pin_Value(A,0,LOW);
     408:	89 e3       	ldi	r24, 0x39	; 57
     40a:	60 e0       	ldi	r22, 0x00	; 0
     40c:	40 e0       	ldi	r20, 0x00	; 0
     40e:	0e 94 9a 02 	call	0x534	; 0x534 <DIO_Set_Pin_Value>
			xSemaphoreGive(my_mutex);
     412:	80 91 0a 04 	lds	r24, 0x040A
     416:	90 91 0b 04 	lds	r25, 0x040B
     41a:	60 e0       	ldi	r22, 0x00	; 0
     41c:	70 e0       	ldi	r23, 0x00	; 0
     41e:	40 e0       	ldi	r20, 0x00	; 0
     420:	50 e0       	ldi	r21, 0x00	; 0
     422:	20 e0       	ldi	r18, 0x00	; 0
     424:	0e 94 34 07 	call	0xe68	; 0xe68 <xQueueGenericSend>
			vTaskDelay(2000);
     428:	80 ed       	ldi	r24, 0xD0	; 208
     42a:	97 e0       	ldi	r25, 0x07	; 7
     42c:	0e 94 f6 0e 	call	0x1dec	; 0x1dec <vTaskDelay>
     430:	de cf       	rjmp	.-68     	; 0x3ee <Task2+0xa>

00000432 <Task1>:


void Task1(void* pv)
{
	/* Initialization */
	DIO_Set_Pin_Direction(A,0,OUTPUT);
     432:	89 e3       	ldi	r24, 0x39	; 57
     434:	60 e0       	ldi	r22, 0x00	; 0
     436:	41 e0       	ldi	r20, 0x01	; 1
     438:	0e 94 73 02 	call	0x4e6	; 0x4e6 <DIO_Set_Pin_Direction>
	u8 semaphore_state;
	while(1)
	{
		semaphore_state = xSemaphoreTake(my_mutex,1000); /* timeout 1 second */
     43c:	80 91 0a 04 	lds	r24, 0x040A
     440:	90 91 0b 04 	lds	r25, 0x040B
     444:	60 e0       	ldi	r22, 0x00	; 0
     446:	70 e0       	ldi	r23, 0x00	; 0
     448:	48 ee       	ldi	r20, 0xE8	; 232
     44a:	53 e0       	ldi	r21, 0x03	; 3
     44c:	20 e0       	ldi	r18, 0x00	; 0
     44e:	0e 94 57 08 	call	0x10ae	; 0x10ae <xQueueGenericReceive>
		
		if (semaphore_state == pdTRUE )
     452:	81 30       	cpi	r24, 0x01	; 1
     454:	99 f7       	brne	.-26     	; 0x43c <Task1+0xa>
		{
			DIO_Set_Pin_Value(A,0,HIGH);
     456:	89 e3       	ldi	r24, 0x39	; 57
     458:	60 e0       	ldi	r22, 0x00	; 0
     45a:	41 e0       	ldi	r20, 0x01	; 1
     45c:	0e 94 9a 02 	call	0x534	; 0x534 <DIO_Set_Pin_Value>
			vTaskDelay(2000);
     460:	80 ed       	ldi	r24, 0xD0	; 208
     462:	97 e0       	ldi	r25, 0x07	; 7
     464:	0e 94 f6 0e 	call	0x1dec	; 0x1dec <vTaskDelay>
			xSemaphoreGive(my_mutex);
     468:	80 91 0a 04 	lds	r24, 0x040A
     46c:	90 91 0b 04 	lds	r25, 0x040B
     470:	60 e0       	ldi	r22, 0x00	; 0
     472:	70 e0       	ldi	r23, 0x00	; 0
     474:	40 e0       	ldi	r20, 0x00	; 0
     476:	50 e0       	ldi	r21, 0x00	; 0
     478:	20 e0       	ldi	r18, 0x00	; 0
     47a:	0e 94 34 07 	call	0xe68	; 0xe68 <xQueueGenericSend>
			vTaskDelay(1000);
     47e:	88 ee       	ldi	r24, 0xE8	; 232
     480:	93 e0       	ldi	r25, 0x03	; 3
     482:	0e 94 f6 0e 	call	0x1dec	; 0x1dec <vTaskDelay>
     486:	da cf       	rjmp	.-76     	; 0x43c <Task1+0xa>

00000488 <main>:
SemaphoreHandle_t my_mutex;

int main(void)
{
	/* Create Tasks */
	xTaskCreate(Task1,"Ali",100,NULL,2,NULL);		/* HIGH Priority */
     488:	89 e1       	ldi	r24, 0x19	; 25
     48a:	92 e0       	ldi	r25, 0x02	; 2
     48c:	60 e6       	ldi	r22, 0x60	; 96
     48e:	70 e0       	ldi	r23, 0x00	; 0
     490:	44 e6       	ldi	r20, 0x64	; 100
     492:	50 e0       	ldi	r21, 0x00	; 0
     494:	20 e0       	ldi	r18, 0x00	; 0
     496:	30 e0       	ldi	r19, 0x00	; 0
     498:	02 e0       	ldi	r16, 0x02	; 2
     49a:	ee 24       	eor	r14, r14
     49c:	ff 24       	eor	r15, r15
     49e:	0e 94 b0 0a 	call	0x1560	; 0x1560 <xTaskCreate>
	xTaskCreate(Task2,"Morsy",100,NULL,1,NULL);		/* LOW  Priority */
     4a2:	82 ef       	ldi	r24, 0xF2	; 242
     4a4:	91 e0       	ldi	r25, 0x01	; 1
     4a6:	64 e6       	ldi	r22, 0x64	; 100
     4a8:	70 e0       	ldi	r23, 0x00	; 0
     4aa:	44 e6       	ldi	r20, 0x64	; 100
     4ac:	50 e0       	ldi	r21, 0x00	; 0
     4ae:	20 e0       	ldi	r18, 0x00	; 0
     4b0:	30 e0       	ldi	r19, 0x00	; 0
     4b2:	01 e0       	ldi	r16, 0x01	; 1
     4b4:	0e 94 b0 0a 	call	0x1560	; 0x1560 <xTaskCreate>
	
	/* Create semaphore Mutex */
	my_mutex = xSemaphoreCreateMutex();
     4b8:	81 e0       	ldi	r24, 0x01	; 1
     4ba:	0e 94 da 07 	call	0xfb4	; 0xfb4 <xQueueCreateMutex>
     4be:	90 93 0b 04 	sts	0x040B, r25
     4c2:	80 93 0a 04 	sts	0x040A, r24
	
	/* Start Scheduler*/
	vTaskStartScheduler();
     4c6:	0e 94 49 0d 	call	0x1a92	; 0x1a92 <vTaskStartScheduler>
     4ca:	ff cf       	rjmp	.-2      	; 0x4ca <main+0x42>

000004cc <DIO_Set_Port_Direction>:


/*        SET Direction         */ 
void DIO_Set_Port_Direction(u8 Base, u8 Direction)
{
	if((Direction == OUTPUT)||(Direction==1))
     4cc:	61 30       	cpi	r22, 0x01	; 1
     4ce:	29 f4       	brne	.+10     	; 0x4da <DIO_Set_Port_Direction+0xe>
	{
		(*(volatile u8*)(Base+1)) = 0xFF;
     4d0:	e8 2f       	mov	r30, r24
     4d2:	f0 e0       	ldi	r31, 0x00	; 0
     4d4:	8f ef       	ldi	r24, 0xFF	; 255
     4d6:	81 83       	std	Z+1, r24	; 0x01
     4d8:	08 95       	ret
	}
	else if((Direction == INPUT)||(Direction==0))
     4da:	66 23       	and	r22, r22
     4dc:	19 f4       	brne	.+6      	; 0x4e4 <DIO_Set_Port_Direction+0x18>
	{
		(*(volatile u8*)(Base+1)) = 0x00;
     4de:	e8 2f       	mov	r30, r24
     4e0:	f0 e0       	ldi	r31, 0x00	; 0
     4e2:	11 82       	std	Z+1, r1	; 0x01
     4e4:	08 95       	ret

000004e6 <DIO_Set_Pin_Direction>:


void DIO_Set_Pin_Direction(u8 Base, u8 PIN, u8 Direction)
{

	if((Direction == OUTPUT) || (Direction == 1))
     4e6:	41 30       	cpi	r20, 0x01	; 1
     4e8:	79 f4       	brne	.+30     	; 0x508 <DIO_Set_Pin_Direction+0x22>
	{
		//SET_BIT((*(volatile u8*)(Base+1)),PIN);  // OUTPUT = 1
		(*(volatile u8*)(Base+1))|=(1<<PIN);
     4ea:	e8 2f       	mov	r30, r24
     4ec:	f0 e0       	ldi	r31, 0x00	; 0
     4ee:	21 81       	ldd	r18, Z+1	; 0x01
     4f0:	81 e0       	ldi	r24, 0x01	; 1
     4f2:	90 e0       	ldi	r25, 0x00	; 0
     4f4:	ac 01       	movw	r20, r24
     4f6:	02 c0       	rjmp	.+4      	; 0x4fc <DIO_Set_Pin_Direction+0x16>
     4f8:	44 0f       	add	r20, r20
     4fa:	55 1f       	adc	r21, r21
     4fc:	6a 95       	dec	r22
     4fe:	e2 f7       	brpl	.-8      	; 0x4f8 <DIO_Set_Pin_Direction+0x12>
     500:	ba 01       	movw	r22, r20
     502:	62 2b       	or	r22, r18
     504:	61 83       	std	Z+1, r22	; 0x01
     506:	08 95       	ret
	}
	else if((Direction == INPUT) || (Direction == 0))
     508:	44 23       	and	r20, r20
     50a:	79 f4       	brne	.+30     	; 0x52a <DIO_Set_Pin_Direction+0x44>
	{
		//CLR_BIT((*(volatile u8*)(Base+1)),PIN); // INPUT = 0;
		(*(volatile u8*)(Base+1))&=(~(1<<PIN)); 
     50c:	e8 2f       	mov	r30, r24
     50e:	f0 e0       	ldi	r31, 0x00	; 0
     510:	21 81       	ldd	r18, Z+1	; 0x01
     512:	81 e0       	ldi	r24, 0x01	; 1
     514:	90 e0       	ldi	r25, 0x00	; 0
     516:	ac 01       	movw	r20, r24
     518:	02 c0       	rjmp	.+4      	; 0x51e <DIO_Set_Pin_Direction+0x38>
     51a:	44 0f       	add	r20, r20
     51c:	55 1f       	adc	r21, r21
     51e:	6a 95       	dec	r22
     520:	e2 f7       	brpl	.-8      	; 0x51a <DIO_Set_Pin_Direction+0x34>
     522:	ba 01       	movw	r22, r20
     524:	60 95       	com	r22
     526:	62 23       	and	r22, r18
     528:	61 83       	std	Z+1, r22	; 0x01
     52a:	08 95       	ret

0000052c <DIO_Set_Port_Value>:


/*        SET Value         */ 
void DIO_Set_Port_Value(u8 Base, u8 Value)
{
	(*(volatile u8*)(Base+2)) = Value;
     52c:	e8 2f       	mov	r30, r24
     52e:	f0 e0       	ldi	r31, 0x00	; 0
     530:	62 83       	std	Z+2, r22	; 0x02
}
     532:	08 95       	ret

00000534 <DIO_Set_Pin_Value>:

void DIO_Set_Pin_Value(u8 Base,u8 PIN, u8 Value)
{
	if((Value == HIGH) || (Value == 1))
     534:	41 30       	cpi	r20, 0x01	; 1
     536:	79 f4       	brne	.+30     	; 0x556 <DIO_Set_Pin_Value+0x22>
	{	//SET_BIT((*(volatile u8*)(Base+2)),PIN);
		(*(volatile u8*)(Base+2))|=(1<<PIN);
     538:	e8 2f       	mov	r30, r24
     53a:	f0 e0       	ldi	r31, 0x00	; 0
     53c:	22 81       	ldd	r18, Z+2	; 0x02
     53e:	81 e0       	ldi	r24, 0x01	; 1
     540:	90 e0       	ldi	r25, 0x00	; 0
     542:	ac 01       	movw	r20, r24
     544:	02 c0       	rjmp	.+4      	; 0x54a <DIO_Set_Pin_Value+0x16>
     546:	44 0f       	add	r20, r20
     548:	55 1f       	adc	r21, r21
     54a:	6a 95       	dec	r22
     54c:	e2 f7       	brpl	.-8      	; 0x546 <DIO_Set_Pin_Value+0x12>
     54e:	ba 01       	movw	r22, r20
     550:	62 2b       	or	r22, r18
     552:	62 83       	std	Z+2, r22	; 0x02
     554:	08 95       	ret
	}
	else if((Value == LOW) || (Value == 0))
     556:	44 23       	and	r20, r20
     558:	79 f4       	brne	.+30     	; 0x578 <DIO_Set_Pin_Value+0x44>
	{
		(*(volatile u8*)(Base+2))&=(~(1<<PIN));
     55a:	e8 2f       	mov	r30, r24
     55c:	f0 e0       	ldi	r31, 0x00	; 0
     55e:	22 81       	ldd	r18, Z+2	; 0x02
     560:	81 e0       	ldi	r24, 0x01	; 1
     562:	90 e0       	ldi	r25, 0x00	; 0
     564:	ac 01       	movw	r20, r24
     566:	02 c0       	rjmp	.+4      	; 0x56c <DIO_Set_Pin_Value+0x38>
     568:	44 0f       	add	r20, r20
     56a:	55 1f       	adc	r21, r21
     56c:	6a 95       	dec	r22
     56e:	e2 f7       	brpl	.-8      	; 0x568 <DIO_Set_Pin_Value+0x34>
     570:	ba 01       	movw	r22, r20
     572:	60 95       	com	r22
     574:	62 23       	and	r22, r18
     576:	62 83       	std	Z+2, r22	; 0x02
     578:	08 95       	ret

0000057a <DIO_Get_Port_value>:
	}
}

/*        Get Value         */ 
u8 DIO_Get_Port_value(u8 Base)
{
     57a:	cf 93       	push	r28
     57c:	df 93       	push	r29
     57e:	0f 92       	push	r0
     580:	cd b7       	in	r28, 0x3d	; 61
     582:	de b7       	in	r29, 0x3e	; 62
	 volatile u8 Value;
	Value = (*(volatile u8*)(Base));
     584:	e8 2f       	mov	r30, r24
     586:	f0 e0       	ldi	r31, 0x00	; 0
     588:	80 81       	ld	r24, Z
     58a:	89 83       	std	Y+1, r24	; 0x01
	return Value;
     58c:	89 81       	ldd	r24, Y+1	; 0x01
}
     58e:	0f 90       	pop	r0
     590:	df 91       	pop	r29
     592:	cf 91       	pop	r28
     594:	08 95       	ret

00000596 <DIO_Get_Pin_value>:


u8 DIO_Get_Pin_value (u8 Base, u8 PIN)
{
     596:	cf 93       	push	r28
     598:	df 93       	push	r29
     59a:	0f 92       	push	r0
     59c:	cd b7       	in	r28, 0x3d	; 61
     59e:	de b7       	in	r29, 0x3e	; 62
	volatile u8 Value;
	Value = ((*(volatile u8*)(Base))>>PIN)&1;	
     5a0:	e8 2f       	mov	r30, r24
     5a2:	f0 e0       	ldi	r31, 0x00	; 0
     5a4:	80 81       	ld	r24, Z
     5a6:	90 e0       	ldi	r25, 0x00	; 0
     5a8:	9c 01       	movw	r18, r24
     5aa:	02 c0       	rjmp	.+4      	; 0x5b0 <DIO_Get_Pin_value+0x1a>
     5ac:	35 95       	asr	r19
     5ae:	27 95       	ror	r18
     5b0:	6a 95       	dec	r22
     5b2:	e2 f7       	brpl	.-8      	; 0x5ac <DIO_Get_Pin_value+0x16>
     5b4:	b9 01       	movw	r22, r18
     5b6:	61 70       	andi	r22, 0x01	; 1
     5b8:	69 83       	std	Y+1, r22	; 0x01
	return Value;
     5ba:	89 81       	ldd	r24, Y+1	; 0x01
}
     5bc:	0f 90       	pop	r0
     5be:	df 91       	pop	r29
     5c0:	cf 91       	pop	r28
     5c2:	08 95       	ret

000005c4 <DIO_Toggle_Pin>:

void DIO_Toggle_Pin(u8 Base, u8 PIN)
{
	*((volatile u8*)(Base+2))^=(1<<PIN);
     5c4:	e8 2f       	mov	r30, r24
     5c6:	f0 e0       	ldi	r31, 0x00	; 0
     5c8:	22 81       	ldd	r18, Z+2	; 0x02
     5ca:	81 e0       	ldi	r24, 0x01	; 1
     5cc:	90 e0       	ldi	r25, 0x00	; 0
     5ce:	ac 01       	movw	r20, r24
     5d0:	02 c0       	rjmp	.+4      	; 0x5d6 <DIO_Toggle_Pin+0x12>
     5d2:	44 0f       	add	r20, r20
     5d4:	55 1f       	adc	r21, r21
     5d6:	6a 95       	dec	r22
     5d8:	e2 f7       	brpl	.-8      	; 0x5d2 <DIO_Toggle_Pin+0xe>
     5da:	ba 01       	movw	r22, r20
     5dc:	62 27       	eor	r22, r18
     5de:	62 83       	std	Z+2, r22	; 0x02
}
     5e0:	08 95       	ret

000005e2 <DIO_SET_HIGH_Nipple_Value>:
/* Set HIGH NIPPLE */

void DIO_SET_HIGH_Nipple_Value(u8 Base, u8 Data)
{
	Data<<=4;
	(*(volatile u8*)(Base+2)) &=0x0f;  //to CLR HIGH NIPPLE Pins before write 
     5e2:	e8 2f       	mov	r30, r24
     5e4:	f0 e0       	ldi	r31, 0x00	; 0
     5e6:	82 81       	ldd	r24, Z+2	; 0x02
     5e8:	8f 70       	andi	r24, 0x0F	; 15
     5ea:	82 83       	std	Z+2, r24	; 0x02
	(*(volatile u8*)(Base+2)) ^=Data;
     5ec:	82 81       	ldd	r24, Z+2	; 0x02

/* Set HIGH NIPPLE */

void DIO_SET_HIGH_Nipple_Value(u8 Base, u8 Data)
{
	Data<<=4;
     5ee:	62 95       	swap	r22
     5f0:	60 7f       	andi	r22, 0xF0	; 240
	(*(volatile u8*)(Base+2)) &=0x0f;  //to CLR HIGH NIPPLE Pins before write 
	(*(volatile u8*)(Base+2)) ^=Data;
     5f2:	68 27       	eor	r22, r24
     5f4:	62 83       	std	Z+2, r22	; 0x02
	
} 
     5f6:	08 95       	ret

000005f8 <DIO_SET_LOW_Nipple_Value>:

/* Set LOW NIPPLE */

void DIO_SET_LOW_Nipple_Value(u8 Base, u8 Data)
{
	(*(volatile u8*)(Base+2)) &=0xf0;  //to CLR LOW NIPPLE before write
     5f8:	e8 2f       	mov	r30, r24
     5fa:	f0 e0       	ldi	r31, 0x00	; 0
     5fc:	82 81       	ldd	r24, Z+2	; 0x02
     5fe:	80 7f       	andi	r24, 0xF0	; 240
     600:	82 83       	std	Z+2, r24	; 0x02
	(*(volatile u8*)(Base+2)) ^=(Data & 0x0F) ;
     602:	82 81       	ldd	r24, Z+2	; 0x02
     604:	6f 70       	andi	r22, 0x0F	; 15
     606:	68 27       	eor	r22, r24
     608:	62 83       	std	Z+2, r22	; 0x02
	
}
     60a:	08 95       	ret

0000060c <pvPortMalloc>:
	pxIterator->pxNextFreeBlock = pxBlockToInsert;									\
}
/*-----------------------------------------------------------*/

void *pvPortMalloc( size_t xWantedSize )
{
     60c:	0f 93       	push	r16
     60e:	1f 93       	push	r17
     610:	cf 93       	push	r28
     612:	df 93       	push	r29
     614:	ec 01       	movw	r28, r24
BlockLink_t *pxBlock, *pxPreviousBlock, *pxNewBlockLink;
static BaseType_t xHeapHasBeenInitialised = pdFALSE;
void *pvReturn = NULL;

	vTaskSuspendAll();
     616:	0e 94 79 0d 	call	0x1af2	; 0x1af2 <vTaskSuspendAll>
	{
		/* If this is the first call to malloc then the heap will require
		initialisation to setup the list of free blocks. */
		if( xHeapHasBeenInitialised == pdFALSE )
     61a:	80 91 72 00 	lds	r24, 0x0072
     61e:	88 23       	and	r24, r24
     620:	f9 f4       	brne	.+62     	; 0x660 <pvPortMalloc+0x54>
	/* Ensure the heap starts on a correctly aligned boundary. */
	pucAlignedHeap = ( uint8_t * ) ( ( ( portPOINTER_SIZE_TYPE ) &ucHeap[ portBYTE_ALIGNMENT ] ) & ( ~( ( portPOINTER_SIZE_TYPE ) portBYTE_ALIGNMENT_MASK ) ) );

	/* xStart is used to hold a pointer to the first item in the list of free
	blocks.  The void cast is used to prevent compiler warnings. */
	xStart.pxNextFreeBlock = ( void * ) pucAlignedHeap;
     622:	8c e7       	ldi	r24, 0x7C	; 124
     624:	90 e0       	ldi	r25, 0x00	; 0
     626:	90 93 74 00 	sts	0x0074, r25
     62a:	80 93 73 00 	sts	0x0073, r24
	xStart.xBlockSize = ( size_t ) 0;
     62e:	10 92 76 00 	sts	0x0076, r1
     632:	10 92 75 00 	sts	0x0075, r1

	/* xEnd is used to mark the end of the list of free blocks. */
	xEnd.xBlockSize = configADJUSTED_HEAP_SIZE;
     636:	8f e1       	ldi	r24, 0x1F	; 31
     638:	93 e0       	ldi	r25, 0x03	; 3
     63a:	90 93 7a 00 	sts	0x007A, r25
     63e:	80 93 79 00 	sts	0x0079, r24
	xEnd.pxNextFreeBlock = NULL;
     642:	e9 e7       	ldi	r30, 0x79	; 121
     644:	f0 e0       	ldi	r31, 0x00	; 0
     646:	12 92       	st	-Z, r1
     648:	12 92       	st	-Z, r1

	/* To start with there is a single free block that is sized to take up the
	entire heap space. */
	pxFirstFreeBlock = ( void * ) pucAlignedHeap;
	pxFirstFreeBlock->xBlockSize = configADJUSTED_HEAP_SIZE;
     64a:	90 93 7f 00 	sts	0x007F, r25
     64e:	80 93 7e 00 	sts	0x007E, r24
	pxFirstFreeBlock->pxNextFreeBlock = &xEnd;
     652:	f0 93 7d 00 	sts	0x007D, r31
     656:	e0 93 7c 00 	sts	0x007C, r30
		/* If this is the first call to malloc then the heap will require
		initialisation to setup the list of free blocks. */
		if( xHeapHasBeenInitialised == pdFALSE )
		{
			prvHeapInit();
			xHeapHasBeenInitialised = pdTRUE;
     65a:	81 e0       	ldi	r24, 0x01	; 1
     65c:	80 93 72 00 	sts	0x0072, r24
		}

		/* The wanted size is increased so it can contain a BlockLink_t
		structure in addition to the requested amount of bytes. */
		if( xWantedSize > 0 )
     660:	20 97       	sbiw	r28, 0x00	; 0
     662:	09 f4       	brne	.+2      	; 0x666 <pvPortMalloc+0x5a>
     664:	62 c0       	rjmp	.+196    	; 0x72a <pvPortMalloc+0x11e>
		{
			xWantedSize += heapSTRUCT_SIZE;
     666:	9e 01       	movw	r18, r28
     668:	2c 5f       	subi	r18, 0xFC	; 252
     66a:	3f 4f       	sbci	r19, 0xFF	; 255
				/* Byte alignment required. */
				xWantedSize += ( portBYTE_ALIGNMENT - ( xWantedSize & portBYTE_ALIGNMENT_MASK ) );
			}
		}

		if( ( xWantedSize > 0 ) && ( xWantedSize < configADJUSTED_HEAP_SIZE ) )
     66c:	23 96       	adiw	r28, 0x03	; 3
     66e:	83 e0       	ldi	r24, 0x03	; 3
     670:	ce 31       	cpi	r28, 0x1E	; 30
     672:	d8 07       	cpc	r29, r24
     674:	08 f0       	brcs	.+2      	; 0x678 <pvPortMalloc+0x6c>
     676:	5c c0       	rjmp	.+184    	; 0x730 <pvPortMalloc+0x124>
		{
			/* Blocks are stored in byte order - traverse the list from the start
			(smallest) block until one of adequate size is found. */
			pxPreviousBlock = &xStart;
			pxBlock = xStart.pxNextFreeBlock;
     678:	e0 91 73 00 	lds	r30, 0x0073
     67c:	f0 91 74 00 	lds	r31, 0x0074

		if( ( xWantedSize > 0 ) && ( xWantedSize < configADJUSTED_HEAP_SIZE ) )
		{
			/* Blocks are stored in byte order - traverse the list from the start
			(smallest) block until one of adequate size is found. */
			pxPreviousBlock = &xStart;
     680:	a3 e7       	ldi	r26, 0x73	; 115
     682:	b0 e0       	ldi	r27, 0x00	; 0
			pxBlock = xStart.pxNextFreeBlock;
			while( ( pxBlock->xBlockSize < xWantedSize ) && ( pxBlock->pxNextFreeBlock != NULL ) )
     684:	02 c0       	rjmp	.+4      	; 0x68a <pvPortMalloc+0x7e>
     686:	df 01       	movw	r26, r30
			{
				pxPreviousBlock = pxBlock;
				pxBlock = pxBlock->pxNextFreeBlock;
     688:	fc 01       	movw	r30, r24
		{
			/* Blocks are stored in byte order - traverse the list from the start
			(smallest) block until one of adequate size is found. */
			pxPreviousBlock = &xStart;
			pxBlock = xStart.pxNextFreeBlock;
			while( ( pxBlock->xBlockSize < xWantedSize ) && ( pxBlock->pxNextFreeBlock != NULL ) )
     68a:	82 81       	ldd	r24, Z+2	; 0x02
     68c:	93 81       	ldd	r25, Z+3	; 0x03
     68e:	82 17       	cp	r24, r18
     690:	93 07       	cpc	r25, r19
     692:	20 f4       	brcc	.+8      	; 0x69c <pvPortMalloc+0x90>
     694:	80 81       	ld	r24, Z
     696:	91 81       	ldd	r25, Z+1	; 0x01
     698:	00 97       	sbiw	r24, 0x00	; 0
     69a:	a9 f7       	brne	.-22     	; 0x686 <pvPortMalloc+0x7a>
				pxPreviousBlock = pxBlock;
				pxBlock = pxBlock->pxNextFreeBlock;
			}

			/* If we found the end marker then a block of adequate size was not found. */
			if( pxBlock != &xEnd )
     69c:	c0 e0       	ldi	r28, 0x00	; 0
     69e:	e7 37       	cpi	r30, 0x77	; 119
     6a0:	fc 07       	cpc	r31, r28
     6a2:	09 f4       	brne	.+2      	; 0x6a6 <pvPortMalloc+0x9a>
     6a4:	48 c0       	rjmp	.+144    	; 0x736 <pvPortMalloc+0x12a>
			{
				/* Return the memory space - jumping over the BlockLink_t structure
				at its start. */
				pvReturn = ( void * ) ( ( ( uint8_t * ) pxPreviousBlock->pxNextFreeBlock ) + heapSTRUCT_SIZE );
     6a6:	8d 91       	ld	r24, X+
     6a8:	9c 91       	ld	r25, X
     6aa:	11 97       	sbiw	r26, 0x01	; 1
     6ac:	8c 01       	movw	r16, r24
     6ae:	0c 5f       	subi	r16, 0xFC	; 252
     6b0:	1f 4f       	sbci	r17, 0xFF	; 255

				/* This block is being returned for use so must be taken out of the
				list of free blocks. */
				pxPreviousBlock->pxNextFreeBlock = pxBlock->pxNextFreeBlock;
     6b2:	80 81       	ld	r24, Z
     6b4:	91 81       	ldd	r25, Z+1	; 0x01
     6b6:	11 96       	adiw	r26, 0x01	; 1
     6b8:	9c 93       	st	X, r25
     6ba:	8e 93       	st	-X, r24

				/* If the block is larger than required it can be split into two. */
				if( ( pxBlock->xBlockSize - xWantedSize ) > heapMINIMUM_BLOCK_SIZE )
     6bc:	82 81       	ldd	r24, Z+2	; 0x02
     6be:	93 81       	ldd	r25, Z+3	; 0x03
     6c0:	82 1b       	sub	r24, r18
     6c2:	93 0b       	sbc	r25, r19
     6c4:	89 30       	cpi	r24, 0x09	; 9
     6c6:	91 05       	cpc	r25, r1
     6c8:	18 f1       	brcs	.+70     	; 0x710 <pvPortMalloc+0x104>
				{
					/* This block is to be split into two.  Create a new block
					following the number of bytes requested. The void cast is
					used to prevent byte alignment warnings from the compiler. */
					pxNewBlockLink = ( void * ) ( ( ( uint8_t * ) pxBlock ) + xWantedSize );
     6ca:	af 01       	movw	r20, r30
     6cc:	42 0f       	add	r20, r18
     6ce:	53 1f       	adc	r21, r19

					/* Calculate the sizes of two blocks split from the single
					block. */
					pxNewBlockLink->xBlockSize = pxBlock->xBlockSize - xWantedSize;
     6d0:	da 01       	movw	r26, r20
     6d2:	13 96       	adiw	r26, 0x03	; 3
     6d4:	9c 93       	st	X, r25
     6d6:	8e 93       	st	-X, r24
     6d8:	12 97       	sbiw	r26, 0x02	; 2
					pxBlock->xBlockSize = xWantedSize;
     6da:	33 83       	std	Z+3, r19	; 0x03
     6dc:	22 83       	std	Z+2, r18	; 0x02

					/* Insert the new block into the list of free blocks. */
					prvInsertBlockIntoFreeList( ( pxNewBlockLink ) );
     6de:	12 96       	adiw	r26, 0x02	; 2
     6e0:	2d 91       	ld	r18, X+
     6e2:	3c 91       	ld	r19, X
     6e4:	13 97       	sbiw	r26, 0x03	; 3
     6e6:	63 e7       	ldi	r22, 0x73	; 115
     6e8:	70 e0       	ldi	r23, 0x00	; 0
     6ea:	01 c0       	rjmp	.+2      	; 0x6ee <pvPortMalloc+0xe2>
     6ec:	bd 01       	movw	r22, r26
     6ee:	eb 01       	movw	r28, r22
     6f0:	a8 81       	ld	r26, Y
     6f2:	b9 81       	ldd	r27, Y+1	; 0x01
     6f4:	12 96       	adiw	r26, 0x02	; 2
     6f6:	8d 91       	ld	r24, X+
     6f8:	9c 91       	ld	r25, X
     6fa:	13 97       	sbiw	r26, 0x03	; 3
     6fc:	82 17       	cp	r24, r18
     6fe:	93 07       	cpc	r25, r19
     700:	a8 f3       	brcs	.-22     	; 0x6ec <pvPortMalloc+0xe0>
     702:	ea 01       	movw	r28, r20
     704:	b9 83       	std	Y+1, r27	; 0x01
     706:	a8 83       	st	Y, r26
     708:	db 01       	movw	r26, r22
     70a:	11 96       	adiw	r26, 0x01	; 1
     70c:	5c 93       	st	X, r21
     70e:	4e 93       	st	-X, r20
				}

				xFreeBytesRemaining -= pxBlock->xBlockSize;
     710:	80 91 6a 00 	lds	r24, 0x006A
     714:	90 91 6b 00 	lds	r25, 0x006B
     718:	22 81       	ldd	r18, Z+2	; 0x02
     71a:	33 81       	ldd	r19, Z+3	; 0x03
     71c:	82 1b       	sub	r24, r18
     71e:	93 0b       	sbc	r25, r19
     720:	90 93 6b 00 	sts	0x006B, r25
     724:	80 93 6a 00 	sts	0x006A, r24
     728:	08 c0       	rjmp	.+16     	; 0x73a <pvPortMalloc+0x12e>

void *pvPortMalloc( size_t xWantedSize )
{
BlockLink_t *pxBlock, *pxPreviousBlock, *pxNewBlockLink;
static BaseType_t xHeapHasBeenInitialised = pdFALSE;
void *pvReturn = NULL;
     72a:	00 e0       	ldi	r16, 0x00	; 0
     72c:	10 e0       	ldi	r17, 0x00	; 0
     72e:	05 c0       	rjmp	.+10     	; 0x73a <pvPortMalloc+0x12e>
     730:	00 e0       	ldi	r16, 0x00	; 0
     732:	10 e0       	ldi	r17, 0x00	; 0
     734:	02 c0       	rjmp	.+4      	; 0x73a <pvPortMalloc+0x12e>
     736:	00 e0       	ldi	r16, 0x00	; 0
     738:	10 e0       	ldi	r17, 0x00	; 0
			}
		}

		traceMALLOC( pvReturn, xWantedSize );
	}
	( void ) xTaskResumeAll();
     73a:	0e 94 3e 0e 	call	0x1c7c	; 0x1c7c <xTaskResumeAll>
		}
	}
	#endif

	return pvReturn;
}
     73e:	80 2f       	mov	r24, r16
     740:	91 2f       	mov	r25, r17
     742:	df 91       	pop	r29
     744:	cf 91       	pop	r28
     746:	1f 91       	pop	r17
     748:	0f 91       	pop	r16
     74a:	08 95       	ret

0000074c <vPortFree>:
/*-----------------------------------------------------------*/

void vPortFree( void *pv )
{
     74c:	0f 93       	push	r16
     74e:	1f 93       	push	r17
     750:	cf 93       	push	r28
     752:	df 93       	push	r29
     754:	ec 01       	movw	r28, r24
uint8_t *puc = ( uint8_t * ) pv;
BlockLink_t *pxLink;

	if( pv != NULL )
     756:	00 97       	sbiw	r24, 0x00	; 0
     758:	39 f1       	breq	.+78     	; 0x7a8 <vPortFree+0x5c>
		before it. */
		puc -= heapSTRUCT_SIZE;

		/* This unexpected casting is to keep some compilers from issuing
		byte alignment warnings. */
		pxLink = ( void * ) puc;
     75a:	8c 01       	movw	r16, r24
     75c:	04 50       	subi	r16, 0x04	; 4
     75e:	10 40       	sbci	r17, 0x00	; 0

		vTaskSuspendAll();
     760:	0e 94 79 0d 	call	0x1af2	; 0x1af2 <vTaskSuspendAll>
		{
			/* Add this block to the list of free blocks. */
			prvInsertBlockIntoFreeList( ( ( BlockLink_t * ) pxLink ) );
     764:	f8 01       	movw	r30, r16
     766:	22 81       	ldd	r18, Z+2	; 0x02
     768:	33 81       	ldd	r19, Z+3	; 0x03
     76a:	a3 e7       	ldi	r26, 0x73	; 115
     76c:	b0 e0       	ldi	r27, 0x00	; 0
     76e:	01 c0       	rjmp	.+2      	; 0x772 <vPortFree+0x26>
     770:	df 01       	movw	r26, r30
     772:	ed 91       	ld	r30, X+
     774:	fc 91       	ld	r31, X
     776:	11 97       	sbiw	r26, 0x01	; 1
     778:	82 81       	ldd	r24, Z+2	; 0x02
     77a:	93 81       	ldd	r25, Z+3	; 0x03
     77c:	82 17       	cp	r24, r18
     77e:	93 07       	cpc	r25, r19
     780:	b8 f3       	brcs	.-18     	; 0x770 <vPortFree+0x24>
     782:	24 97       	sbiw	r28, 0x04	; 4
     784:	f9 83       	std	Y+1, r31	; 0x01
     786:	e8 83       	st	Y, r30
     788:	0d 93       	st	X+, r16
     78a:	1c 93       	st	X, r17
			xFreeBytesRemaining += pxLink->xBlockSize;
     78c:	80 91 6a 00 	lds	r24, 0x006A
     790:	90 91 6b 00 	lds	r25, 0x006B
     794:	2a 81       	ldd	r18, Y+2	; 0x02
     796:	3b 81       	ldd	r19, Y+3	; 0x03
     798:	82 0f       	add	r24, r18
     79a:	93 1f       	adc	r25, r19
     79c:	90 93 6b 00 	sts	0x006B, r25
     7a0:	80 93 6a 00 	sts	0x006A, r24
			traceFREE( pv, pxLink->xBlockSize );
		}
		( void ) xTaskResumeAll();
     7a4:	0e 94 3e 0e 	call	0x1c7c	; 0x1c7c <xTaskResumeAll>
	}
}
     7a8:	df 91       	pop	r29
     7aa:	cf 91       	pop	r28
     7ac:	1f 91       	pop	r17
     7ae:	0f 91       	pop	r16
     7b0:	08 95       	ret

000007b2 <xPortGetFreeHeapSize>:
/*-----------------------------------------------------------*/

size_t xPortGetFreeHeapSize( void )
{
	return xFreeBytesRemaining;
}
     7b2:	80 91 6a 00 	lds	r24, 0x006A
     7b6:	90 91 6b 00 	lds	r25, 0x006B
     7ba:	08 95       	ret

000007bc <vPortInitialiseBlocks>:
/*-----------------------------------------------------------*/

void vPortInitialiseBlocks( void )
{
	/* This just exists to keep the linker quiet. */
}
     7bc:	08 95       	ret

000007be <vListInitialise>:
/*-----------------------------------------------------------
 * PUBLIC LIST API documented in list.h
 *----------------------------------------------------------*/

void vListInitialise( List_t * const pxList )
{
     7be:	fc 01       	movw	r30, r24
	/* The list structure contains a list item which is used to mark the
	end of the list.  To initialise the list the list end is inserted
	as the only list entry. */
	pxList->pxIndex = ( ListItem_t * ) &( pxList->xListEnd );			/*lint !e826 !e740 The mini list structure is used as the list end to save RAM.  This is checked and valid. */
     7c0:	03 96       	adiw	r24, 0x03	; 3
     7c2:	92 83       	std	Z+2, r25	; 0x02
     7c4:	81 83       	std	Z+1, r24	; 0x01

	/* The list end value is the highest possible value in the list to
	ensure it remains at the end of the list. */
	pxList->xListEnd.xItemValue = portMAX_DELAY;
     7c6:	2f ef       	ldi	r18, 0xFF	; 255
     7c8:	3f ef       	ldi	r19, 0xFF	; 255
     7ca:	34 83       	std	Z+4, r19	; 0x04
     7cc:	23 83       	std	Z+3, r18	; 0x03

	/* The list end next and previous pointers point to itself so we know
	when the list is empty. */
	pxList->xListEnd.pxNext = ( ListItem_t * ) &( pxList->xListEnd );	/*lint !e826 !e740 The mini list structure is used as the list end to save RAM.  This is checked and valid. */
     7ce:	96 83       	std	Z+6, r25	; 0x06
     7d0:	85 83       	std	Z+5, r24	; 0x05
	pxList->xListEnd.pxPrevious = ( ListItem_t * ) &( pxList->xListEnd );/*lint !e826 !e740 The mini list structure is used as the list end to save RAM.  This is checked and valid. */
     7d2:	90 87       	std	Z+8, r25	; 0x08
     7d4:	87 83       	std	Z+7, r24	; 0x07

	pxList->uxNumberOfItems = ( UBaseType_t ) 0U;
     7d6:	10 82       	st	Z, r1

	/* Write known values into the list if
	configUSE_LIST_DATA_INTEGRITY_CHECK_BYTES is set to 1. */
	listSET_LIST_INTEGRITY_CHECK_1_VALUE( pxList );
	listSET_LIST_INTEGRITY_CHECK_2_VALUE( pxList );
}
     7d8:	08 95       	ret

000007da <vListInitialiseItem>:
/*-----------------------------------------------------------*/

void vListInitialiseItem( ListItem_t * const pxItem )
{
	/* Make sure the list item is not recorded as being on a list. */
	pxItem->pvContainer = NULL;
     7da:	fc 01       	movw	r30, r24
     7dc:	11 86       	std	Z+9, r1	; 0x09
     7de:	10 86       	std	Z+8, r1	; 0x08

	/* Write known values into the list item if
	configUSE_LIST_DATA_INTEGRITY_CHECK_BYTES is set to 1. */
	listSET_FIRST_LIST_ITEM_INTEGRITY_CHECK_VALUE( pxItem );
	listSET_SECOND_LIST_ITEM_INTEGRITY_CHECK_VALUE( pxItem );
}
     7e0:	08 95       	ret

000007e2 <vListInsertEnd>:
/*-----------------------------------------------------------*/

void vListInsertEnd( List_t * const pxList, ListItem_t * const pxNewListItem )
{
     7e2:	cf 93       	push	r28
     7e4:	df 93       	push	r29
     7e6:	fb 01       	movw	r30, r22
ListItem_t * const pxIndex = pxList->pxIndex;
     7e8:	dc 01       	movw	r26, r24
     7ea:	11 96       	adiw	r26, 0x01	; 1
     7ec:	cd 91       	ld	r28, X+
     7ee:	dc 91       	ld	r29, X
     7f0:	12 97       	sbiw	r26, 0x02	; 2
	listTEST_LIST_ITEM_INTEGRITY( pxNewListItem );

	/* Insert a new list item into pxList, but rather than sort the list,
	makes the new list item the last item to be removed by a call to
	listGET_OWNER_OF_NEXT_ENTRY(). */
	pxNewListItem->pxNext = pxIndex;
     7f2:	d3 83       	std	Z+3, r29	; 0x03
     7f4:	c2 83       	std	Z+2, r28	; 0x02
	pxNewListItem->pxPrevious = pxIndex->pxPrevious;
     7f6:	2c 81       	ldd	r18, Y+4	; 0x04
     7f8:	3d 81       	ldd	r19, Y+5	; 0x05
     7fa:	35 83       	std	Z+5, r19	; 0x05
     7fc:	24 83       	std	Z+4, r18	; 0x04

	/* Only used during decision coverage testing. */
	mtCOVERAGE_TEST_DELAY();

	pxIndex->pxPrevious->pxNext = pxNewListItem;
     7fe:	ac 81       	ldd	r26, Y+4	; 0x04
     800:	bd 81       	ldd	r27, Y+5	; 0x05
     802:	13 96       	adiw	r26, 0x03	; 3
     804:	7c 93       	st	X, r23
     806:	6e 93       	st	-X, r22
     808:	12 97       	sbiw	r26, 0x02	; 2
	pxIndex->pxPrevious = pxNewListItem;
     80a:	7d 83       	std	Y+5, r23	; 0x05
     80c:	6c 83       	std	Y+4, r22	; 0x04

	/* Remember which list the item is in. */
	pxNewListItem->pvContainer = ( void * ) pxList;
     80e:	91 87       	std	Z+9, r25	; 0x09
     810:	80 87       	std	Z+8, r24	; 0x08

	( pxList->uxNumberOfItems )++;
     812:	fc 01       	movw	r30, r24
     814:	20 81       	ld	r18, Z
     816:	2f 5f       	subi	r18, 0xFF	; 255
     818:	20 83       	st	Z, r18
}
     81a:	df 91       	pop	r29
     81c:	cf 91       	pop	r28
     81e:	08 95       	ret

00000820 <vListInsert>:
/*-----------------------------------------------------------*/

void vListInsert( List_t * const pxList, ListItem_t * const pxNewListItem )
{
     820:	cf 93       	push	r28
     822:	df 93       	push	r29
     824:	ac 01       	movw	r20, r24
     826:	eb 01       	movw	r28, r22
ListItem_t *pxIterator;
const TickType_t xValueOfInsertion = pxNewListItem->xItemValue;
     828:	28 81       	ld	r18, Y
     82a:	39 81       	ldd	r19, Y+1	; 0x01
	new list item should be placed after it.  This ensures that TCB's which are
	stored in ready lists (all of which have the same xItemValue value) get a
	share of the CPU.  However, if the xItemValue is the same as the back marker
	the iteration loop below will not end.  Therefore the value is checked
	first, and the algorithm slightly modified if necessary. */
	if( xValueOfInsertion == portMAX_DELAY )
     82c:	8f ef       	ldi	r24, 0xFF	; 255
     82e:	2f 3f       	cpi	r18, 0xFF	; 255
     830:	38 07       	cpc	r19, r24
     832:	21 f4       	brne	.+8      	; 0x83c <vListInsert+0x1c>
	{
		pxIterator = pxList->xListEnd.pxPrevious;
     834:	fa 01       	movw	r30, r20
     836:	a7 81       	ldd	r26, Z+7	; 0x07
     838:	b0 85       	ldd	r27, Z+8	; 0x08
     83a:	0d c0       	rjmp	.+26     	; 0x856 <vListInsert+0x36>
			4) Using a queue or semaphore before it has been initialised or
			   before the scheduler has been started (are interrupts firing
			   before vTaskStartScheduler() has been called?).
		**********************************************************************/

		for( pxIterator = ( ListItem_t * ) &( pxList->xListEnd ); pxIterator->pxNext->xItemValue <= xValueOfInsertion; pxIterator = pxIterator->pxNext ) /*lint !e826 !e740 The mini list structure is used as the list end to save RAM.  This is checked and valid. */
     83c:	da 01       	movw	r26, r20
     83e:	13 96       	adiw	r26, 0x03	; 3
     840:	01 c0       	rjmp	.+2      	; 0x844 <vListInsert+0x24>
     842:	df 01       	movw	r26, r30
     844:	12 96       	adiw	r26, 0x02	; 2
     846:	ed 91       	ld	r30, X+
     848:	fc 91       	ld	r31, X
     84a:	13 97       	sbiw	r26, 0x03	; 3
     84c:	80 81       	ld	r24, Z
     84e:	91 81       	ldd	r25, Z+1	; 0x01
     850:	28 17       	cp	r18, r24
     852:	39 07       	cpc	r19, r25
     854:	b0 f7       	brcc	.-20     	; 0x842 <vListInsert+0x22>
			/* There is nothing to do here, just iterating to the wanted
			insertion position. */
		}
	}

	pxNewListItem->pxNext = pxIterator->pxNext;
     856:	12 96       	adiw	r26, 0x02	; 2
     858:	ed 91       	ld	r30, X+
     85a:	fc 91       	ld	r31, X
     85c:	13 97       	sbiw	r26, 0x03	; 3
     85e:	fb 83       	std	Y+3, r31	; 0x03
     860:	ea 83       	std	Y+2, r30	; 0x02
	pxNewListItem->pxNext->pxPrevious = pxNewListItem;
     862:	d5 83       	std	Z+5, r29	; 0x05
     864:	c4 83       	std	Z+4, r28	; 0x04
	pxNewListItem->pxPrevious = pxIterator;
     866:	bd 83       	std	Y+5, r27	; 0x05
     868:	ac 83       	std	Y+4, r26	; 0x04
	pxIterator->pxNext = pxNewListItem;
     86a:	13 96       	adiw	r26, 0x03	; 3
     86c:	dc 93       	st	X, r29
     86e:	ce 93       	st	-X, r28
     870:	12 97       	sbiw	r26, 0x02	; 2

	/* Remember which list the item is in.  This allows fast removal of the
	item later. */
	pxNewListItem->pvContainer = ( void * ) pxList;
     872:	59 87       	std	Y+9, r21	; 0x09
     874:	48 87       	std	Y+8, r20	; 0x08

	( pxList->uxNumberOfItems )++;
     876:	fa 01       	movw	r30, r20
     878:	80 81       	ld	r24, Z
     87a:	8f 5f       	subi	r24, 0xFF	; 255
     87c:	80 83       	st	Z, r24
}
     87e:	df 91       	pop	r29
     880:	cf 91       	pop	r28
     882:	08 95       	ret

00000884 <uxListRemove>:
/*-----------------------------------------------------------*/

UBaseType_t uxListRemove( ListItem_t * const pxItemToRemove )
{
     884:	cf 93       	push	r28
     886:	df 93       	push	r29
     888:	fc 01       	movw	r30, r24
/* The list item knows which list it is in.  Obtain the list from the list
item. */
List_t * const pxList = ( List_t * ) pxItemToRemove->pvContainer;
     88a:	c0 85       	ldd	r28, Z+8	; 0x08
     88c:	d1 85       	ldd	r29, Z+9	; 0x09

	pxItemToRemove->pxNext->pxPrevious = pxItemToRemove->pxPrevious;
     88e:	a2 81       	ldd	r26, Z+2	; 0x02
     890:	b3 81       	ldd	r27, Z+3	; 0x03
     892:	84 81       	ldd	r24, Z+4	; 0x04
     894:	95 81       	ldd	r25, Z+5	; 0x05
     896:	15 96       	adiw	r26, 0x05	; 5
     898:	9c 93       	st	X, r25
     89a:	8e 93       	st	-X, r24
     89c:	14 97       	sbiw	r26, 0x04	; 4
	pxItemToRemove->pxPrevious->pxNext = pxItemToRemove->pxNext;
     89e:	a4 81       	ldd	r26, Z+4	; 0x04
     8a0:	b5 81       	ldd	r27, Z+5	; 0x05
     8a2:	82 81       	ldd	r24, Z+2	; 0x02
     8a4:	93 81       	ldd	r25, Z+3	; 0x03
     8a6:	13 96       	adiw	r26, 0x03	; 3
     8a8:	9c 93       	st	X, r25
     8aa:	8e 93       	st	-X, r24
     8ac:	12 97       	sbiw	r26, 0x02	; 2

	/* Only used during decision coverage testing. */
	mtCOVERAGE_TEST_DELAY();

	/* Make sure the index is left pointing to a valid item. */
	if( pxList->pxIndex == pxItemToRemove )
     8ae:	a9 81       	ldd	r26, Y+1	; 0x01
     8b0:	ba 81       	ldd	r27, Y+2	; 0x02
     8b2:	ae 17       	cp	r26, r30
     8b4:	bf 07       	cpc	r27, r31
     8b6:	31 f4       	brne	.+12     	; 0x8c4 <uxListRemove+0x40>
	{
		pxList->pxIndex = pxItemToRemove->pxPrevious;
     8b8:	14 96       	adiw	r26, 0x04	; 4
     8ba:	8d 91       	ld	r24, X+
     8bc:	9c 91       	ld	r25, X
     8be:	15 97       	sbiw	r26, 0x05	; 5
     8c0:	9a 83       	std	Y+2, r25	; 0x02
     8c2:	89 83       	std	Y+1, r24	; 0x01
	else
	{
		mtCOVERAGE_TEST_MARKER();
	}

	pxItemToRemove->pvContainer = NULL;
     8c4:	11 86       	std	Z+9, r1	; 0x09
     8c6:	10 86       	std	Z+8, r1	; 0x08
	( pxList->uxNumberOfItems )--;
     8c8:	88 81       	ld	r24, Y
     8ca:	81 50       	subi	r24, 0x01	; 1
     8cc:	88 83       	st	Y, r24

	return pxList->uxNumberOfItems;
}
     8ce:	df 91       	pop	r29
     8d0:	cf 91       	pop	r28
     8d2:	08 95       	ret

000008d4 <pxPortInitialiseStack>:
uint16_t usAddress;

	/* Place a few bytes of known values on the bottom of the stack. 
	This is just useful for debugging. */

	*pxTopOfStack = 0x11;
     8d4:	21 e1       	ldi	r18, 0x11	; 17
     8d6:	fc 01       	movw	r30, r24
     8d8:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = 0x22;
     8da:	31 97       	sbiw	r30, 0x01	; 1
     8dc:	32 e2       	ldi	r19, 0x22	; 34
     8de:	30 83       	st	Z, r19
	pxTopOfStack--;
	*pxTopOfStack = 0x33;
     8e0:	fc 01       	movw	r30, r24
     8e2:	32 97       	sbiw	r30, 0x02	; 2
     8e4:	a3 e3       	ldi	r26, 0x33	; 51
     8e6:	a0 83       	st	Z, r26
	/*lint -e950 -e611 -e923 Lint doesn't like this much - but nothing I can do about it. */

	/* The start of the task code will be popped off the stack last, so place
	it on first. */
	usAddress = ( uint16_t ) pxCode;
	*pxTopOfStack = ( StackType_t ) ( usAddress & ( uint16_t ) 0x00ff );
     8e8:	fc 01       	movw	r30, r24
     8ea:	33 97       	sbiw	r30, 0x03	; 3
     8ec:	60 83       	st	Z, r22
	pxTopOfStack--;

	usAddress >>= 8;
	*pxTopOfStack = ( StackType_t ) ( usAddress & ( uint16_t ) 0x00ff );
     8ee:	fc 01       	movw	r30, r24
     8f0:	34 97       	sbiw	r30, 0x04	; 4
     8f2:	70 83       	st	Z, r23

	/* Next simulate the stack as if after a call to portSAVE_CONTEXT().  
	portSAVE_CONTEXT places the flags on the stack immediately after r0
	to ensure the interrupts get disabled as soon as possible, and so ensuring
	the stack use is minimal should a context switch interrupt occur. */
	*pxTopOfStack = ( StackType_t ) 0x00;	/* R0 */
     8f4:	fc 01       	movw	r30, r24
     8f6:	35 97       	sbiw	r30, 0x05	; 5
     8f8:	10 82       	st	Z, r1
	pxTopOfStack--;
	*pxTopOfStack = portFLAGS_INT_ENABLED;
     8fa:	fc 01       	movw	r30, r24
     8fc:	36 97       	sbiw	r30, 0x06	; 6
     8fe:	60 e8       	ldi	r22, 0x80	; 128
     900:	60 83       	st	Z, r22
	pxTopOfStack--;


	/* Now the remaining registers.   The compiler expects R1 to be 0. */
	*pxTopOfStack = ( StackType_t ) 0x00;	/* R1 */
     902:	fc 01       	movw	r30, r24
     904:	37 97       	sbiw	r30, 0x07	; 7
     906:	10 82       	st	Z, r1
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x02;	/* R2 */
     908:	fc 01       	movw	r30, r24
     90a:	38 97       	sbiw	r30, 0x08	; 8
     90c:	62 e0       	ldi	r22, 0x02	; 2
     90e:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x03;	/* R3 */
     910:	fc 01       	movw	r30, r24
     912:	39 97       	sbiw	r30, 0x09	; 9
     914:	63 e0       	ldi	r22, 0x03	; 3
     916:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x04;	/* R4 */
     918:	fc 01       	movw	r30, r24
     91a:	3a 97       	sbiw	r30, 0x0a	; 10
     91c:	64 e0       	ldi	r22, 0x04	; 4
     91e:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x05;	/* R5 */
     920:	fc 01       	movw	r30, r24
     922:	3b 97       	sbiw	r30, 0x0b	; 11
     924:	65 e0       	ldi	r22, 0x05	; 5
     926:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x06;	/* R6 */
     928:	fc 01       	movw	r30, r24
     92a:	3c 97       	sbiw	r30, 0x0c	; 12
     92c:	66 e0       	ldi	r22, 0x06	; 6
     92e:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x07;	/* R7 */
     930:	fc 01       	movw	r30, r24
     932:	3d 97       	sbiw	r30, 0x0d	; 13
     934:	67 e0       	ldi	r22, 0x07	; 7
     936:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x08;	/* R8 */
     938:	fc 01       	movw	r30, r24
     93a:	3e 97       	sbiw	r30, 0x0e	; 14
     93c:	68 e0       	ldi	r22, 0x08	; 8
     93e:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x09;	/* R9 */
     940:	fc 01       	movw	r30, r24
     942:	3f 97       	sbiw	r30, 0x0f	; 15
     944:	69 e0       	ldi	r22, 0x09	; 9
     946:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x10;	/* R10 */
     948:	fc 01       	movw	r30, r24
     94a:	70 97       	sbiw	r30, 0x10	; 16
     94c:	60 e1       	ldi	r22, 0x10	; 16
     94e:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x11;	/* R11 */
     950:	fc 01       	movw	r30, r24
     952:	71 97       	sbiw	r30, 0x11	; 17
     954:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x12;	/* R12 */
     956:	fc 01       	movw	r30, r24
     958:	72 97       	sbiw	r30, 0x12	; 18
     95a:	22 e1       	ldi	r18, 0x12	; 18
     95c:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x13;	/* R13 */
     95e:	fc 01       	movw	r30, r24
     960:	73 97       	sbiw	r30, 0x13	; 19
     962:	23 e1       	ldi	r18, 0x13	; 19
     964:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x14;	/* R14 */
     966:	fc 01       	movw	r30, r24
     968:	74 97       	sbiw	r30, 0x14	; 20
     96a:	24 e1       	ldi	r18, 0x14	; 20
     96c:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x15;	/* R15 */
     96e:	fc 01       	movw	r30, r24
     970:	75 97       	sbiw	r30, 0x15	; 21
     972:	25 e1       	ldi	r18, 0x15	; 21
     974:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x16;	/* R16 */
     976:	fc 01       	movw	r30, r24
     978:	76 97       	sbiw	r30, 0x16	; 22
     97a:	26 e1       	ldi	r18, 0x16	; 22
     97c:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x17;	/* R17 */
     97e:	fc 01       	movw	r30, r24
     980:	77 97       	sbiw	r30, 0x17	; 23
     982:	27 e1       	ldi	r18, 0x17	; 23
     984:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x18;	/* R18 */
     986:	fc 01       	movw	r30, r24
     988:	78 97       	sbiw	r30, 0x18	; 24
     98a:	28 e1       	ldi	r18, 0x18	; 24
     98c:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x19;	/* R19 */
     98e:	fc 01       	movw	r30, r24
     990:	79 97       	sbiw	r30, 0x19	; 25
     992:	29 e1       	ldi	r18, 0x19	; 25
     994:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x20;	/* R20 */
     996:	fc 01       	movw	r30, r24
     998:	7a 97       	sbiw	r30, 0x1a	; 26
     99a:	20 e2       	ldi	r18, 0x20	; 32
     99c:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x21;	/* R21 */
     99e:	fc 01       	movw	r30, r24
     9a0:	7b 97       	sbiw	r30, 0x1b	; 27
     9a2:	21 e2       	ldi	r18, 0x21	; 33
     9a4:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x22;	/* R22 */
     9a6:	fc 01       	movw	r30, r24
     9a8:	7c 97       	sbiw	r30, 0x1c	; 28
     9aa:	30 83       	st	Z, r19
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x23;	/* R23 */
     9ac:	fc 01       	movw	r30, r24
     9ae:	7d 97       	sbiw	r30, 0x1d	; 29
     9b0:	23 e2       	ldi	r18, 0x23	; 35
     9b2:	20 83       	st	Z, r18
	pxTopOfStack--;

	/* Place the parameter on the stack in the expected location. */
	usAddress = ( uint16_t ) pvParameters;
	*pxTopOfStack = ( StackType_t ) ( usAddress & ( uint16_t ) 0x00ff );
     9b4:	fc 01       	movw	r30, r24
     9b6:	7e 97       	sbiw	r30, 0x1e	; 30
     9b8:	40 83       	st	Z, r20
	pxTopOfStack--;

	usAddress >>= 8;
	*pxTopOfStack = ( StackType_t ) ( usAddress & ( uint16_t ) 0x00ff );
     9ba:	fc 01       	movw	r30, r24
     9bc:	7f 97       	sbiw	r30, 0x1f	; 31
     9be:	50 83       	st	Z, r21
	pxTopOfStack--;

	*pxTopOfStack = ( StackType_t ) 0x26;	/* R26 X */
     9c0:	fc 01       	movw	r30, r24
     9c2:	b0 97       	sbiw	r30, 0x20	; 32
     9c4:	26 e2       	ldi	r18, 0x26	; 38
     9c6:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x27;	/* R27 */
     9c8:	fc 01       	movw	r30, r24
     9ca:	b1 97       	sbiw	r30, 0x21	; 33
     9cc:	27 e2       	ldi	r18, 0x27	; 39
     9ce:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x28;	/* R28 Y */
     9d0:	fc 01       	movw	r30, r24
     9d2:	b2 97       	sbiw	r30, 0x22	; 34
     9d4:	28 e2       	ldi	r18, 0x28	; 40
     9d6:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x29;	/* R29 */
     9d8:	fc 01       	movw	r30, r24
     9da:	b3 97       	sbiw	r30, 0x23	; 35
     9dc:	29 e2       	ldi	r18, 0x29	; 41
     9de:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x30;	/* R30 Z */
     9e0:	fc 01       	movw	r30, r24
     9e2:	b4 97       	sbiw	r30, 0x24	; 36
     9e4:	20 e3       	ldi	r18, 0x30	; 48
     9e6:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x031;	/* R31 */
     9e8:	fc 01       	movw	r30, r24
     9ea:	b5 97       	sbiw	r30, 0x25	; 37
     9ec:	21 e3       	ldi	r18, 0x31	; 49
     9ee:	20 83       	st	Z, r18
	pxTopOfStack--;

	/*lint +e950 +e611 +e923 */

	return pxTopOfStack;
     9f0:	86 97       	sbiw	r24, 0x26	; 38
}
     9f2:	08 95       	ret

000009f4 <xPortStartScheduler>:
	/* Setup compare match value for compare match A.  Interrupts are disabled 
	before this is called so we need not worry here. */
	ucLowByte = ( uint8_t ) ( ulCompareMatch & ( uint32_t ) 0xff );
	ulCompareMatch >>= 8;
	ucHighByte = ( uint8_t ) ( ulCompareMatch & ( uint32_t ) 0xff );
	OCR1AH = ucHighByte;
     9f4:	1b bc       	out	0x2b, r1	; 43
	OCR1AL = ucLowByte;
     9f6:	8c e7       	ldi	r24, 0x7C	; 124
     9f8:	8a bd       	out	0x2a, r24	; 42

	/* Setup clock source and compare match behaviour. */
	ucLowByte = portCLEAR_COUNTER_ON_MATCH | portPRESCALE_64;
	TCCR1B = ucLowByte;
     9fa:	8b e0       	ldi	r24, 0x0B	; 11
     9fc:	8e bd       	out	0x2e, r24	; 46

	/* Enable the interrupt - this is okay as interrupt are currently globally
	disabled. */
	ucLowByte = TIMSK;
     9fe:	89 b7       	in	r24, 0x39	; 57
	ucLowByte |= portCOMPARE_MATCH_A_INTERRUPT_ENABLE;
     a00:	80 61       	ori	r24, 0x10	; 16
	TIMSK = ucLowByte;
     a02:	89 bf       	out	0x39, r24	; 57
{
	/* Setup the hardware to generate the tick. */
	prvSetupTimerInterrupt();

	/* Restore the context of the first task that is going to run. */
	portRESTORE_CONTEXT();
     a04:	a0 91 9b 03 	lds	r26, 0x039B
     a08:	b0 91 9c 03 	lds	r27, 0x039C
     a0c:	cd 91       	ld	r28, X+
     a0e:	cd bf       	out	0x3d, r28	; 61
     a10:	dd 91       	ld	r29, X+
     a12:	de bf       	out	0x3e, r29	; 62
     a14:	ff 91       	pop	r31
     a16:	ef 91       	pop	r30
     a18:	df 91       	pop	r29
     a1a:	cf 91       	pop	r28
     a1c:	bf 91       	pop	r27
     a1e:	af 91       	pop	r26
     a20:	9f 91       	pop	r25
     a22:	8f 91       	pop	r24
     a24:	7f 91       	pop	r23
     a26:	6f 91       	pop	r22
     a28:	5f 91       	pop	r21
     a2a:	4f 91       	pop	r20
     a2c:	3f 91       	pop	r19
     a2e:	2f 91       	pop	r18
     a30:	1f 91       	pop	r17
     a32:	0f 91       	pop	r16
     a34:	ff 90       	pop	r15
     a36:	ef 90       	pop	r14
     a38:	df 90       	pop	r13
     a3a:	cf 90       	pop	r12
     a3c:	bf 90       	pop	r11
     a3e:	af 90       	pop	r10
     a40:	9f 90       	pop	r9
     a42:	8f 90       	pop	r8
     a44:	7f 90       	pop	r7
     a46:	6f 90       	pop	r6
     a48:	5f 90       	pop	r5
     a4a:	4f 90       	pop	r4
     a4c:	3f 90       	pop	r3
     a4e:	2f 90       	pop	r2
     a50:	1f 90       	pop	r1
     a52:	0f 90       	pop	r0
     a54:	0f be       	out	0x3f, r0	; 63
     a56:	0f 90       	pop	r0

	/* Simulate a function call end as generated by the compiler.  We will now
	jump to the start of the task the context of which we have just restored. */
	asm volatile ( "ret" );
     a58:	08 95       	ret

	/* Should not get here. */
	return pdTRUE;
}
     a5a:	81 e0       	ldi	r24, 0x01	; 1
     a5c:	08 95       	ret

00000a5e <vPortEndScheduler>:

void vPortEndScheduler( void )
{
	/* It is unlikely that the AVR port will get stopped.  If required simply
	disable the tick interrupt here. */
}
     a5e:	08 95       	ret

00000a60 <vPortYield>:
 * can use a naked attribute.
 */
void vPortYield( void ) __attribute__ ( ( naked ) );
void vPortYield( void )
{
	portSAVE_CONTEXT();
     a60:	0f 92       	push	r0
     a62:	0f b6       	in	r0, 0x3f	; 63
     a64:	f8 94       	cli
     a66:	0f 92       	push	r0
     a68:	1f 92       	push	r1
     a6a:	11 24       	eor	r1, r1
     a6c:	2f 92       	push	r2
     a6e:	3f 92       	push	r3
     a70:	4f 92       	push	r4
     a72:	5f 92       	push	r5
     a74:	6f 92       	push	r6
     a76:	7f 92       	push	r7
     a78:	8f 92       	push	r8
     a7a:	9f 92       	push	r9
     a7c:	af 92       	push	r10
     a7e:	bf 92       	push	r11
     a80:	cf 92       	push	r12
     a82:	df 92       	push	r13
     a84:	ef 92       	push	r14
     a86:	ff 92       	push	r15
     a88:	0f 93       	push	r16
     a8a:	1f 93       	push	r17
     a8c:	2f 93       	push	r18
     a8e:	3f 93       	push	r19
     a90:	4f 93       	push	r20
     a92:	5f 93       	push	r21
     a94:	6f 93       	push	r22
     a96:	7f 93       	push	r23
     a98:	8f 93       	push	r24
     a9a:	9f 93       	push	r25
     a9c:	af 93       	push	r26
     a9e:	bf 93       	push	r27
     aa0:	cf 93       	push	r28
     aa2:	df 93       	push	r29
     aa4:	ef 93       	push	r30
     aa6:	ff 93       	push	r31
     aa8:	a0 91 9b 03 	lds	r26, 0x039B
     aac:	b0 91 9c 03 	lds	r27, 0x039C
     ab0:	0d b6       	in	r0, 0x3d	; 61
     ab2:	0d 92       	st	X+, r0
     ab4:	0e b6       	in	r0, 0x3e	; 62
     ab6:	0d 92       	st	X+, r0
	vTaskSwitchContext();
     ab8:	0e 94 49 0f 	call	0x1e92	; 0x1e92 <vTaskSwitchContext>
	portRESTORE_CONTEXT();
     abc:	a0 91 9b 03 	lds	r26, 0x039B
     ac0:	b0 91 9c 03 	lds	r27, 0x039C
     ac4:	cd 91       	ld	r28, X+
     ac6:	cd bf       	out	0x3d, r28	; 61
     ac8:	dd 91       	ld	r29, X+
     aca:	de bf       	out	0x3e, r29	; 62
     acc:	ff 91       	pop	r31
     ace:	ef 91       	pop	r30
     ad0:	df 91       	pop	r29
     ad2:	cf 91       	pop	r28
     ad4:	bf 91       	pop	r27
     ad6:	af 91       	pop	r26
     ad8:	9f 91       	pop	r25
     ada:	8f 91       	pop	r24
     adc:	7f 91       	pop	r23
     ade:	6f 91       	pop	r22
     ae0:	5f 91       	pop	r21
     ae2:	4f 91       	pop	r20
     ae4:	3f 91       	pop	r19
     ae6:	2f 91       	pop	r18
     ae8:	1f 91       	pop	r17
     aea:	0f 91       	pop	r16
     aec:	ff 90       	pop	r15
     aee:	ef 90       	pop	r14
     af0:	df 90       	pop	r13
     af2:	cf 90       	pop	r12
     af4:	bf 90       	pop	r11
     af6:	af 90       	pop	r10
     af8:	9f 90       	pop	r9
     afa:	8f 90       	pop	r8
     afc:	7f 90       	pop	r7
     afe:	6f 90       	pop	r6
     b00:	5f 90       	pop	r5
     b02:	4f 90       	pop	r4
     b04:	3f 90       	pop	r3
     b06:	2f 90       	pop	r2
     b08:	1f 90       	pop	r1
     b0a:	0f 90       	pop	r0
     b0c:	0f be       	out	0x3f, r0	; 63
     b0e:	0f 90       	pop	r0

	asm volatile ( "ret" );
     b10:	08 95       	ret

00000b12 <vPortYieldFromTick>:
 * call comes from the tick ISR.
 */
void vPortYieldFromTick( void ) __attribute__ ( ( naked ) );
void vPortYieldFromTick( void )
{
	portSAVE_CONTEXT();
     b12:	0f 92       	push	r0
     b14:	0f b6       	in	r0, 0x3f	; 63
     b16:	f8 94       	cli
     b18:	0f 92       	push	r0
     b1a:	1f 92       	push	r1
     b1c:	11 24       	eor	r1, r1
     b1e:	2f 92       	push	r2
     b20:	3f 92       	push	r3
     b22:	4f 92       	push	r4
     b24:	5f 92       	push	r5
     b26:	6f 92       	push	r6
     b28:	7f 92       	push	r7
     b2a:	8f 92       	push	r8
     b2c:	9f 92       	push	r9
     b2e:	af 92       	push	r10
     b30:	bf 92       	push	r11
     b32:	cf 92       	push	r12
     b34:	df 92       	push	r13
     b36:	ef 92       	push	r14
     b38:	ff 92       	push	r15
     b3a:	0f 93       	push	r16
     b3c:	1f 93       	push	r17
     b3e:	2f 93       	push	r18
     b40:	3f 93       	push	r19
     b42:	4f 93       	push	r20
     b44:	5f 93       	push	r21
     b46:	6f 93       	push	r22
     b48:	7f 93       	push	r23
     b4a:	8f 93       	push	r24
     b4c:	9f 93       	push	r25
     b4e:	af 93       	push	r26
     b50:	bf 93       	push	r27
     b52:	cf 93       	push	r28
     b54:	df 93       	push	r29
     b56:	ef 93       	push	r30
     b58:	ff 93       	push	r31
     b5a:	a0 91 9b 03 	lds	r26, 0x039B
     b5e:	b0 91 9c 03 	lds	r27, 0x039C
     b62:	0d b6       	in	r0, 0x3d	; 61
     b64:	0d 92       	st	X+, r0
     b66:	0e b6       	in	r0, 0x3e	; 62
     b68:	0d 92       	st	X+, r0
	if( xTaskIncrementTick() != pdFALSE )
     b6a:	0e 94 99 0d 	call	0x1b32	; 0x1b32 <xTaskIncrementTick>
     b6e:	88 23       	and	r24, r24
     b70:	11 f0       	breq	.+4      	; 0xb76 <vPortYieldFromTick+0x64>
	{
		vTaskSwitchContext();
     b72:	0e 94 49 0f 	call	0x1e92	; 0x1e92 <vTaskSwitchContext>
	}
	portRESTORE_CONTEXT();
     b76:	a0 91 9b 03 	lds	r26, 0x039B
     b7a:	b0 91 9c 03 	lds	r27, 0x039C
     b7e:	cd 91       	ld	r28, X+
     b80:	cd bf       	out	0x3d, r28	; 61
     b82:	dd 91       	ld	r29, X+
     b84:	de bf       	out	0x3e, r29	; 62
     b86:	ff 91       	pop	r31
     b88:	ef 91       	pop	r30
     b8a:	df 91       	pop	r29
     b8c:	cf 91       	pop	r28
     b8e:	bf 91       	pop	r27
     b90:	af 91       	pop	r26
     b92:	9f 91       	pop	r25
     b94:	8f 91       	pop	r24
     b96:	7f 91       	pop	r23
     b98:	6f 91       	pop	r22
     b9a:	5f 91       	pop	r21
     b9c:	4f 91       	pop	r20
     b9e:	3f 91       	pop	r19
     ba0:	2f 91       	pop	r18
     ba2:	1f 91       	pop	r17
     ba4:	0f 91       	pop	r16
     ba6:	ff 90       	pop	r15
     ba8:	ef 90       	pop	r14
     baa:	df 90       	pop	r13
     bac:	cf 90       	pop	r12
     bae:	bf 90       	pop	r11
     bb0:	af 90       	pop	r10
     bb2:	9f 90       	pop	r9
     bb4:	8f 90       	pop	r8
     bb6:	7f 90       	pop	r7
     bb8:	6f 90       	pop	r6
     bba:	5f 90       	pop	r5
     bbc:	4f 90       	pop	r4
     bbe:	3f 90       	pop	r3
     bc0:	2f 90       	pop	r2
     bc2:	1f 90       	pop	r1
     bc4:	0f 90       	pop	r0
     bc6:	0f be       	out	0x3f, r0	; 63
     bc8:	0f 90       	pop	r0

	asm volatile ( "ret" );
     bca:	08 95       	ret

00000bcc <__vector_7>:
	 * count is incremented after the context is saved.
	 */
	void TIMER1_COMPA_vect( void ) __attribute__ ( ( signal, naked ) );
	void TIMER1_COMPA_vect( void )
	{
		vPortYieldFromTick();
     bcc:	0e 94 89 05 	call	0xb12	; 0xb12 <vPortYieldFromTick>
		asm volatile ( "reti" );
     bd0:	18 95       	reti

00000bd2 <prvIsQueueEmpty>:

static BaseType_t prvIsQueueEmpty( const Queue_t *pxQueue )
{
BaseType_t xReturn;

	taskENTER_CRITICAL();
     bd2:	0f b6       	in	r0, 0x3f	; 63
     bd4:	f8 94       	cli
     bd6:	0f 92       	push	r0
	{
		if( pxQueue->uxMessagesWaiting == ( UBaseType_t )  0 )
     bd8:	fc 01       	movw	r30, r24
     bda:	92 8d       	ldd	r25, Z+26	; 0x1a
		else
		{
			xReturn = pdFALSE;
		}
	}
	taskEXIT_CRITICAL();
     bdc:	0f 90       	pop	r0
     bde:	0f be       	out	0x3f, r0	; 63

	taskENTER_CRITICAL();
	{
		if( pxQueue->uxMessagesWaiting == ( UBaseType_t )  0 )
		{
			xReturn = pdTRUE;
     be0:	81 e0       	ldi	r24, 0x01	; 1
     be2:	91 11       	cpse	r25, r1
     be4:	80 e0       	ldi	r24, 0x00	; 0
		}
	}
	taskEXIT_CRITICAL();

	return xReturn;
}
     be6:	08 95       	ret

00000be8 <prvCopyDataFromQueue>:
	return xReturn;
}
/*-----------------------------------------------------------*/

static void prvCopyDataFromQueue( Queue_t * const pxQueue, void * const pvBuffer )
{
     be8:	fc 01       	movw	r30, r24
	if( pxQueue->uxItemSize != ( UBaseType_t ) 0 )
     bea:	44 8d       	ldd	r20, Z+28	; 0x1c
     bec:	44 23       	and	r20, r20
     bee:	c1 f0       	breq	.+48     	; 0xc20 <prvCopyDataFromQueue+0x38>
	{
		pxQueue->u.pcReadFrom += pxQueue->uxItemSize;
     bf0:	26 81       	ldd	r18, Z+6	; 0x06
     bf2:	37 81       	ldd	r19, Z+7	; 0x07
     bf4:	24 0f       	add	r18, r20
     bf6:	31 1d       	adc	r19, r1
     bf8:	37 83       	std	Z+7, r19	; 0x07
     bfa:	26 83       	std	Z+6, r18	; 0x06
		if( pxQueue->u.pcReadFrom >= pxQueue->pcTail ) /*lint !e946 MISRA exception justified as use of the relational operator is the cleanest solutions. */
     bfc:	a2 81       	ldd	r26, Z+2	; 0x02
     bfe:	b3 81       	ldd	r27, Z+3	; 0x03
     c00:	2a 17       	cp	r18, r26
     c02:	3b 07       	cpc	r19, r27
     c04:	20 f0       	brcs	.+8      	; 0xc0e <prvCopyDataFromQueue+0x26>
		{
			pxQueue->u.pcReadFrom = pxQueue->pcHead;
     c06:	20 81       	ld	r18, Z
     c08:	31 81       	ldd	r19, Z+1	; 0x01
     c0a:	37 83       	std	Z+7, r19	; 0x07
     c0c:	26 83       	std	Z+6, r18	; 0x06
		}
		else
		{
			mtCOVERAGE_TEST_MARKER();
		}
		( void ) memcpy( ( void * ) pvBuffer, ( void * ) pxQueue->u.pcReadFrom, ( size_t ) pxQueue->uxItemSize ); /*lint !e961 !e418 MISRA exception as the casts are only redundant for some ports.  Also previous logic ensures a null pointer can only be passed to memcpy() when the count is 0. */
     c0e:	36 81       	ldd	r19, Z+6	; 0x06
     c10:	27 81       	ldd	r18, Z+7	; 0x07
     c12:	86 2f       	mov	r24, r22
     c14:	97 2f       	mov	r25, r23
     c16:	63 2f       	mov	r22, r19
     c18:	72 2f       	mov	r23, r18
     c1a:	50 e0       	ldi	r21, 0x00	; 0
     c1c:	0e 94 0b 14 	call	0x2816	; 0x2816 <memcpy>
     c20:	08 95       	ret

00000c22 <prvUnlockQueue>:
	}
}
/*-----------------------------------------------------------*/

static void prvUnlockQueue( Queue_t * const pxQueue )
{
     c22:	ef 92       	push	r14
     c24:	ff 92       	push	r15
     c26:	0f 93       	push	r16
     c28:	1f 93       	push	r17
     c2a:	cf 93       	push	r28
     c2c:	8c 01       	movw	r16, r24

	/* The lock counts contains the number of extra data items placed or
	removed from the queue while the queue was locked.  When a queue is
	locked items can be added or removed, but the event lists cannot be
	updated. */
	taskENTER_CRITICAL();
     c2e:	0f b6       	in	r0, 0x3f	; 63
     c30:	f8 94       	cli
     c32:	0f 92       	push	r0
	{
		int8_t cTxLock = pxQueue->cTxLock;
     c34:	fc 01       	movw	r30, r24
     c36:	c6 8d       	ldd	r28, Z+30	; 0x1e

		/* See if data was added to the queue while it was locked. */
		while( cTxLock > queueLOCKED_UNMODIFIED )
     c38:	1c 16       	cp	r1, r28
     c3a:	cc f4       	brge	.+50     	; 0xc6e <prvUnlockQueue+0x4c>
			}
			#else /* configUSE_QUEUE_SETS */
			{
				/* Tasks that are removed from the event list will get added to
				the pending ready list as the scheduler is still suspended. */
				if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
     c3c:	81 89       	ldd	r24, Z+17	; 0x11
     c3e:	88 23       	and	r24, r24
     c40:	31 f4       	brne	.+12     	; 0xc4e <prvUnlockQueue+0x2c>
     c42:	15 c0       	rjmp	.+42     	; 0xc6e <prvUnlockQueue+0x4c>
     c44:	f8 01       	movw	r30, r16
     c46:	81 89       	ldd	r24, Z+17	; 0x11
     c48:	88 23       	and	r24, r24
     c4a:	41 f4       	brne	.+16     	; 0xc5c <prvUnlockQueue+0x3a>
     c4c:	10 c0       	rjmp	.+32     	; 0xc6e <prvUnlockQueue+0x4c>
				{
					if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )
     c4e:	0f 2e       	mov	r0, r31
     c50:	f1 e1       	ldi	r31, 0x11	; 17
     c52:	ef 2e       	mov	r14, r31
     c54:	ff 24       	eor	r15, r15
     c56:	f0 2d       	mov	r31, r0
     c58:	e0 0e       	add	r14, r16
     c5a:	f1 1e       	adc	r15, r17
     c5c:	c7 01       	movw	r24, r14
     c5e:	0e 94 1f 10 	call	0x203e	; 0x203e <xTaskRemoveFromEventList>
     c62:	88 23       	and	r24, r24
     c64:	11 f0       	breq	.+4      	; 0xc6a <prvUnlockQueue+0x48>
					{
						/* The task waiting has a higher priority so record that
						a context switch is required. */
						vTaskMissedYield();
     c66:	0e 94 e4 10 	call	0x21c8	; 0x21c8 <vTaskMissedYield>
					break;
				}
			}
			#endif /* configUSE_QUEUE_SETS */

			--cTxLock;
     c6a:	c1 50       	subi	r28, 0x01	; 1
	taskENTER_CRITICAL();
	{
		int8_t cTxLock = pxQueue->cTxLock;

		/* See if data was added to the queue while it was locked. */
		while( cTxLock > queueLOCKED_UNMODIFIED )
     c6c:	59 f7       	brne	.-42     	; 0xc44 <prvUnlockQueue+0x22>
			#endif /* configUSE_QUEUE_SETS */

			--cTxLock;
		}

		pxQueue->cTxLock = queueUNLOCKED;
     c6e:	8f ef       	ldi	r24, 0xFF	; 255
     c70:	f8 01       	movw	r30, r16
     c72:	86 8f       	std	Z+30, r24	; 0x1e
	}
	taskEXIT_CRITICAL();
     c74:	0f 90       	pop	r0
     c76:	0f be       	out	0x3f, r0	; 63

	/* Do the same for the Rx lock. */
	taskENTER_CRITICAL();
     c78:	0f b6       	in	r0, 0x3f	; 63
     c7a:	f8 94       	cli
     c7c:	0f 92       	push	r0
	{
		int8_t cRxLock = pxQueue->cRxLock;
     c7e:	f8 01       	movw	r30, r16
     c80:	c5 8d       	ldd	r28, Z+29	; 0x1d

		while( cRxLock > queueLOCKED_UNMODIFIED )
     c82:	1c 16       	cp	r1, r28
     c84:	c4 f4       	brge	.+48     	; 0xcb6 <prvUnlockQueue+0x94>
		{
			if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToSend ) ) == pdFALSE )
     c86:	80 85       	ldd	r24, Z+8	; 0x08
     c88:	88 23       	and	r24, r24
     c8a:	31 f4       	brne	.+12     	; 0xc98 <prvUnlockQueue+0x76>
     c8c:	14 c0       	rjmp	.+40     	; 0xcb6 <prvUnlockQueue+0x94>
     c8e:	f8 01       	movw	r30, r16
     c90:	80 85       	ldd	r24, Z+8	; 0x08
     c92:	88 23       	and	r24, r24
     c94:	39 f4       	brne	.+14     	; 0xca4 <prvUnlockQueue+0x82>
     c96:	0f c0       	rjmp	.+30     	; 0xcb6 <prvUnlockQueue+0x94>
			{
				if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) != pdFALSE )
     c98:	ee 24       	eor	r14, r14
     c9a:	ff 24       	eor	r15, r15
     c9c:	68 94       	set
     c9e:	e3 f8       	bld	r14, 3
     ca0:	e0 0e       	add	r14, r16
     ca2:	f1 1e       	adc	r15, r17
     ca4:	c7 01       	movw	r24, r14
     ca6:	0e 94 1f 10 	call	0x203e	; 0x203e <xTaskRemoveFromEventList>
     caa:	88 23       	and	r24, r24
     cac:	11 f0       	breq	.+4      	; 0xcb2 <prvUnlockQueue+0x90>
				{
					vTaskMissedYield();
     cae:	0e 94 e4 10 	call	0x21c8	; 0x21c8 <vTaskMissedYield>
				else
				{
					mtCOVERAGE_TEST_MARKER();
				}

				--cRxLock;
     cb2:	c1 50       	subi	r28, 0x01	; 1
	/* Do the same for the Rx lock. */
	taskENTER_CRITICAL();
	{
		int8_t cRxLock = pxQueue->cRxLock;

		while( cRxLock > queueLOCKED_UNMODIFIED )
     cb4:	61 f7       	brne	.-40     	; 0xc8e <prvUnlockQueue+0x6c>
			{
				break;
			}
		}

		pxQueue->cRxLock = queueUNLOCKED;
     cb6:	8f ef       	ldi	r24, 0xFF	; 255
     cb8:	f8 01       	movw	r30, r16
     cba:	85 8f       	std	Z+29, r24	; 0x1d
	}
	taskEXIT_CRITICAL();
     cbc:	0f 90       	pop	r0
     cbe:	0f be       	out	0x3f, r0	; 63
}
     cc0:	cf 91       	pop	r28
     cc2:	1f 91       	pop	r17
     cc4:	0f 91       	pop	r16
     cc6:	ff 90       	pop	r15
     cc8:	ef 90       	pop	r14
     cca:	08 95       	ret

00000ccc <prvCopyDataToQueue>:

#endif /* configUSE_TRACE_FACILITY */
/*-----------------------------------------------------------*/

static BaseType_t prvCopyDataToQueue( Queue_t * const pxQueue, const void *pvItemToQueue, const BaseType_t xPosition )
{
     ccc:	0f 93       	push	r16
     cce:	1f 93       	push	r17
     cd0:	cf 93       	push	r28
     cd2:	df 93       	push	r29
     cd4:	ec 01       	movw	r28, r24
     cd6:	14 2f       	mov	r17, r20
BaseType_t xReturn = pdFALSE;
UBaseType_t uxMessagesWaiting;

	/* This function is called from a critical section. */

	uxMessagesWaiting = pxQueue->uxMessagesWaiting;
     cd8:	0a 8d       	ldd	r16, Y+26	; 0x1a

	if( pxQueue->uxItemSize == ( UBaseType_t ) 0 )
     cda:	4c 8d       	ldd	r20, Y+28	; 0x1c
     cdc:	44 23       	and	r20, r20
     cde:	61 f4       	brne	.+24     	; 0xcf8 <prvCopyDataToQueue+0x2c>
	{
		#if ( configUSE_MUTEXES == 1 )
		{
			if( pxQueue->uxQueueType == queueQUEUE_IS_MUTEX )
     ce0:	88 81       	ld	r24, Y
     ce2:	99 81       	ldd	r25, Y+1	; 0x01
     ce4:	00 97       	sbiw	r24, 0x00	; 0
     ce6:	09 f0       	breq	.+2      	; 0xcea <prvCopyDataToQueue+0x1e>
     ce8:	42 c0       	rjmp	.+132    	; 0xd6e <prvCopyDataToQueue+0xa2>
			{
				/* The mutex is no longer being held. */
				xReturn = xTaskPriorityDisinherit( ( void * ) pxQueue->pxMutexHolder );
     cea:	8a 81       	ldd	r24, Y+2	; 0x02
     cec:	9b 81       	ldd	r25, Y+3	; 0x03
     cee:	0e 94 4b 11 	call	0x2296	; 0x2296 <xTaskPriorityDisinherit>
				pxQueue->pxMutexHolder = NULL;
     cf2:	1b 82       	std	Y+3, r1	; 0x03
     cf4:	1a 82       	std	Y+2, r1	; 0x02
     cf6:	42 c0       	rjmp	.+132    	; 0xd7c <prvCopyDataToQueue+0xb0>
				mtCOVERAGE_TEST_MARKER();
			}
		}
		#endif /* configUSE_MUTEXES */
	}
	else if( xPosition == queueSEND_TO_BACK )
     cf8:	11 23       	and	r17, r17
     cfa:	b9 f4       	brne	.+46     	; 0xd2a <prvCopyDataToQueue+0x5e>
	{
		( void ) memcpy( ( void * ) pxQueue->pcWriteTo, pvItemToQueue, ( size_t ) pxQueue->uxItemSize ); /*lint !e961 !e418 MISRA exception as the casts are only redundant for some ports, plus previous logic ensures a null pointer can only be passed to memcpy() if the copy size is 0. */
     cfc:	8c 81       	ldd	r24, Y+4	; 0x04
     cfe:	9d 81       	ldd	r25, Y+5	; 0x05
     d00:	50 e0       	ldi	r21, 0x00	; 0
     d02:	0e 94 0b 14 	call	0x2816	; 0x2816 <memcpy>
		pxQueue->pcWriteTo += pxQueue->uxItemSize;
     d06:	2c 8d       	ldd	r18, Y+28	; 0x1c
     d08:	8c 81       	ldd	r24, Y+4	; 0x04
     d0a:	9d 81       	ldd	r25, Y+5	; 0x05
     d0c:	82 0f       	add	r24, r18
     d0e:	91 1d       	adc	r25, r1
     d10:	9d 83       	std	Y+5, r25	; 0x05
     d12:	8c 83       	std	Y+4, r24	; 0x04
		if( pxQueue->pcWriteTo >= pxQueue->pcTail ) /*lint !e946 MISRA exception justified as comparison of pointers is the cleanest solution. */
     d14:	2a 81       	ldd	r18, Y+2	; 0x02
     d16:	3b 81       	ldd	r19, Y+3	; 0x03
     d18:	82 17       	cp	r24, r18
     d1a:	93 07       	cpc	r25, r19
     d1c:	50 f1       	brcs	.+84     	; 0xd72 <prvCopyDataToQueue+0xa6>
		{
			pxQueue->pcWriteTo = pxQueue->pcHead;
     d1e:	88 81       	ld	r24, Y
     d20:	99 81       	ldd	r25, Y+1	; 0x01
     d22:	9d 83       	std	Y+5, r25	; 0x05
     d24:	8c 83       	std	Y+4, r24	; 0x04
#endif /* configUSE_TRACE_FACILITY */
/*-----------------------------------------------------------*/

static BaseType_t prvCopyDataToQueue( Queue_t * const pxQueue, const void *pvItemToQueue, const BaseType_t xPosition )
{
BaseType_t xReturn = pdFALSE;
     d26:	80 e0       	ldi	r24, 0x00	; 0
     d28:	29 c0       	rjmp	.+82     	; 0xd7c <prvCopyDataToQueue+0xb0>
			mtCOVERAGE_TEST_MARKER();
		}
	}
	else
	{
		( void ) memcpy( ( void * ) pxQueue->u.pcReadFrom, pvItemToQueue, ( size_t ) pxQueue->uxItemSize ); /*lint !e961 MISRA exception as the casts are only redundant for some ports. */
     d2a:	8e 81       	ldd	r24, Y+6	; 0x06
     d2c:	9f 81       	ldd	r25, Y+7	; 0x07
     d2e:	50 e0       	ldi	r21, 0x00	; 0
     d30:	0e 94 0b 14 	call	0x2816	; 0x2816 <memcpy>
		pxQueue->u.pcReadFrom -= pxQueue->uxItemSize;
     d34:	4c 8d       	ldd	r20, Y+28	; 0x1c
     d36:	50 e0       	ldi	r21, 0x00	; 0
     d38:	50 95       	com	r21
     d3a:	41 95       	neg	r20
     d3c:	5f 4f       	sbci	r21, 0xFF	; 255
     d3e:	8e 81       	ldd	r24, Y+6	; 0x06
     d40:	9f 81       	ldd	r25, Y+7	; 0x07
     d42:	84 0f       	add	r24, r20
     d44:	95 1f       	adc	r25, r21
     d46:	9f 83       	std	Y+7, r25	; 0x07
     d48:	8e 83       	std	Y+6, r24	; 0x06
		if( pxQueue->u.pcReadFrom < pxQueue->pcHead ) /*lint !e946 MISRA exception justified as comparison of pointers is the cleanest solution. */
     d4a:	28 81       	ld	r18, Y
     d4c:	39 81       	ldd	r19, Y+1	; 0x01
     d4e:	82 17       	cp	r24, r18
     d50:	93 07       	cpc	r25, r19
     d52:	30 f4       	brcc	.+12     	; 0xd60 <prvCopyDataToQueue+0x94>
		{
			pxQueue->u.pcReadFrom = ( pxQueue->pcTail - pxQueue->uxItemSize );
     d54:	8a 81       	ldd	r24, Y+2	; 0x02
     d56:	9b 81       	ldd	r25, Y+3	; 0x03
     d58:	84 0f       	add	r24, r20
     d5a:	95 1f       	adc	r25, r21
     d5c:	9f 83       	std	Y+7, r25	; 0x07
     d5e:	8e 83       	std	Y+6, r24	; 0x06
		else
		{
			mtCOVERAGE_TEST_MARKER();
		}

		if( xPosition == queueOVERWRITE )
     d60:	12 30       	cpi	r17, 0x02	; 2
     d62:	49 f4       	brne	.+18     	; 0xd76 <prvCopyDataToQueue+0xaa>
		{
			if( uxMessagesWaiting > ( UBaseType_t ) 0 )
     d64:	00 23       	and	r16, r16
     d66:	49 f0       	breq	.+18     	; 0xd7a <prvCopyDataToQueue+0xae>
			{
				/* An item is not being added but overwritten, so subtract
				one from the recorded number of items in the queue so when
				one is added again below the number of recorded items remains
				correct. */
				--uxMessagesWaiting;
     d68:	01 50       	subi	r16, 0x01	; 1
#endif /* configUSE_TRACE_FACILITY */
/*-----------------------------------------------------------*/

static BaseType_t prvCopyDataToQueue( Queue_t * const pxQueue, const void *pvItemToQueue, const BaseType_t xPosition )
{
BaseType_t xReturn = pdFALSE;
     d6a:	80 e0       	ldi	r24, 0x00	; 0
     d6c:	07 c0       	rjmp	.+14     	; 0xd7c <prvCopyDataToQueue+0xb0>
     d6e:	80 e0       	ldi	r24, 0x00	; 0
     d70:	05 c0       	rjmp	.+10     	; 0xd7c <prvCopyDataToQueue+0xb0>
     d72:	80 e0       	ldi	r24, 0x00	; 0
     d74:	03 c0       	rjmp	.+6      	; 0xd7c <prvCopyDataToQueue+0xb0>
     d76:	80 e0       	ldi	r24, 0x00	; 0
     d78:	01 c0       	rjmp	.+2      	; 0xd7c <prvCopyDataToQueue+0xb0>
     d7a:	80 e0       	ldi	r24, 0x00	; 0
		{
			mtCOVERAGE_TEST_MARKER();
		}
	}

	pxQueue->uxMessagesWaiting = uxMessagesWaiting + 1;
     d7c:	0f 5f       	subi	r16, 0xFF	; 255
     d7e:	0a 8f       	std	Y+26, r16	; 0x1a

	return xReturn;
}
     d80:	df 91       	pop	r29
     d82:	cf 91       	pop	r28
     d84:	1f 91       	pop	r17
     d86:	0f 91       	pop	r16
     d88:	08 95       	ret

00000d8a <xQueueGenericReset>:
	}														\
	taskEXIT_CRITICAL()
/*-----------------------------------------------------------*/

BaseType_t xQueueGenericReset( QueueHandle_t xQueue, BaseType_t xNewQueue )
{
     d8a:	cf 93       	push	r28
     d8c:	df 93       	push	r29
     d8e:	ec 01       	movw	r28, r24
Queue_t * const pxQueue = ( Queue_t * ) xQueue;

	configASSERT( pxQueue );

	taskENTER_CRITICAL();
     d90:	0f b6       	in	r0, 0x3f	; 63
     d92:	f8 94       	cli
     d94:	0f 92       	push	r0
	{
		pxQueue->pcTail = pxQueue->pcHead + ( pxQueue->uxLength * pxQueue->uxItemSize );
     d96:	48 81       	ld	r20, Y
     d98:	59 81       	ldd	r21, Y+1	; 0x01
     d9a:	2b 8d       	ldd	r18, Y+27	; 0x1b
     d9c:	30 e0       	ldi	r19, 0x00	; 0
     d9e:	ec 8d       	ldd	r30, Y+28	; 0x1c
     da0:	f0 e0       	ldi	r31, 0x00	; 0
     da2:	2e 9f       	mul	r18, r30
     da4:	c0 01       	movw	r24, r0
     da6:	2f 9f       	mul	r18, r31
     da8:	90 0d       	add	r25, r0
     daa:	3e 9f       	mul	r19, r30
     dac:	90 0d       	add	r25, r0
     dae:	11 24       	eor	r1, r1
     db0:	84 0f       	add	r24, r20
     db2:	95 1f       	adc	r25, r21
     db4:	9b 83       	std	Y+3, r25	; 0x03
     db6:	8a 83       	std	Y+2, r24	; 0x02
		pxQueue->uxMessagesWaiting = ( UBaseType_t ) 0U;
     db8:	1a 8e       	std	Y+26, r1	; 0x1a
		pxQueue->pcWriteTo = pxQueue->pcHead;
     dba:	5d 83       	std	Y+5, r21	; 0x05
     dbc:	4c 83       	std	Y+4, r20	; 0x04
		pxQueue->u.pcReadFrom = pxQueue->pcHead + ( ( pxQueue->uxLength - ( UBaseType_t ) 1U ) * pxQueue->uxItemSize );
     dbe:	c9 01       	movw	r24, r18
     dc0:	01 97       	sbiw	r24, 0x01	; 1
     dc2:	e8 9f       	mul	r30, r24
     dc4:	90 01       	movw	r18, r0
     dc6:	e9 9f       	mul	r30, r25
     dc8:	30 0d       	add	r19, r0
     dca:	f8 9f       	mul	r31, r24
     dcc:	30 0d       	add	r19, r0
     dce:	11 24       	eor	r1, r1
     dd0:	24 0f       	add	r18, r20
     dd2:	35 1f       	adc	r19, r21
     dd4:	3f 83       	std	Y+7, r19	; 0x07
     dd6:	2e 83       	std	Y+6, r18	; 0x06
		pxQueue->cRxLock = queueUNLOCKED;
     dd8:	8f ef       	ldi	r24, 0xFF	; 255
     dda:	8d 8f       	std	Y+29, r24	; 0x1d
		pxQueue->cTxLock = queueUNLOCKED;
     ddc:	8e 8f       	std	Y+30, r24	; 0x1e

		if( xNewQueue == pdFALSE )
     dde:	66 23       	and	r22, r22
     de0:	61 f4       	brne	.+24     	; 0xdfa <xQueueGenericReset+0x70>
			/* If there are tasks blocked waiting to read from the queue, then
			the tasks will remain blocked as after this function exits the queue
			will still be empty.  If there are tasks blocked waiting to write to
			the queue, then one should be unblocked as after this function exits
			it will be possible to write to it. */
			if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToSend ) ) == pdFALSE )
     de2:	88 85       	ldd	r24, Y+8	; 0x08
     de4:	88 23       	and	r24, r24
     de6:	89 f0       	breq	.+34     	; 0xe0a <xQueueGenericReset+0x80>
			{
				if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) != pdFALSE )
     de8:	ce 01       	movw	r24, r28
     dea:	08 96       	adiw	r24, 0x08	; 8
     dec:	0e 94 1f 10 	call	0x203e	; 0x203e <xTaskRemoveFromEventList>
     df0:	88 23       	and	r24, r24
     df2:	59 f0       	breq	.+22     	; 0xe0a <xQueueGenericReset+0x80>
				{
					queueYIELD_IF_USING_PREEMPTION();
     df4:	0e 94 30 05 	call	0xa60	; 0xa60 <vPortYield>
     df8:	08 c0       	rjmp	.+16     	; 0xe0a <xQueueGenericReset+0x80>
			}
		}
		else
		{
			/* Ensure the event queues start in the correct state. */
			vListInitialise( &( pxQueue->xTasksWaitingToSend ) );
     dfa:	ce 01       	movw	r24, r28
     dfc:	08 96       	adiw	r24, 0x08	; 8
     dfe:	0e 94 df 03 	call	0x7be	; 0x7be <vListInitialise>
			vListInitialise( &( pxQueue->xTasksWaitingToReceive ) );
     e02:	ce 01       	movw	r24, r28
     e04:	41 96       	adiw	r24, 0x11	; 17
     e06:	0e 94 df 03 	call	0x7be	; 0x7be <vListInitialise>
		}
	}
	taskEXIT_CRITICAL();
     e0a:	0f 90       	pop	r0
     e0c:	0f be       	out	0x3f, r0	; 63

	/* A value is returned for calling semantic consistency with previous
	versions. */
	return pdPASS;
}
     e0e:	81 e0       	ldi	r24, 0x01	; 1
     e10:	df 91       	pop	r29
     e12:	cf 91       	pop	r28
     e14:	08 95       	ret

00000e16 <xQueueGenericCreate>:
/*-----------------------------------------------------------*/

#if( configSUPPORT_DYNAMIC_ALLOCATION == 1 )

	QueueHandle_t xQueueGenericCreate( const UBaseType_t uxQueueLength, const UBaseType_t uxItemSize, const uint8_t ucQueueType )
	{
     e16:	0f 93       	push	r16
     e18:	1f 93       	push	r17
     e1a:	cf 93       	push	r28
     e1c:	df 93       	push	r29
     e1e:	08 2f       	mov	r16, r24
     e20:	16 2f       	mov	r17, r22
	size_t xQueueSizeInBytes;
	uint8_t *pucQueueStorage;

		configASSERT( uxQueueLength > ( UBaseType_t ) 0 );

		if( uxItemSize == ( UBaseType_t ) 0 )
     e22:	66 23       	and	r22, r22
     e24:	21 f0       	breq	.+8      	; 0xe2e <xQueueGenericCreate+0x18>
		}
		else
		{
			/* Allocate enough space to hold the maximum number of items that
			can be in the queue at any time. */
			xQueueSizeInBytes = ( size_t ) ( uxQueueLength * uxItemSize ); /*lint !e961 MISRA exception as the casts are only redundant for some ports. */
     e26:	68 9f       	mul	r22, r24
     e28:	c0 01       	movw	r24, r0
     e2a:	11 24       	eor	r1, r1
     e2c:	02 c0       	rjmp	.+4      	; 0xe32 <xQueueGenericCreate+0x1c>
		configASSERT( uxQueueLength > ( UBaseType_t ) 0 );

		if( uxItemSize == ( UBaseType_t ) 0 )
		{
			/* There is not going to be a queue storage area. */
			xQueueSizeInBytes = ( size_t ) 0;
     e2e:	80 e0       	ldi	r24, 0x00	; 0
     e30:	90 e0       	ldi	r25, 0x00	; 0
			/* Allocate enough space to hold the maximum number of items that
			can be in the queue at any time. */
			xQueueSizeInBytes = ( size_t ) ( uxQueueLength * uxItemSize ); /*lint !e961 MISRA exception as the casts are only redundant for some ports. */
		}

		pxNewQueue = ( Queue_t * ) pvPortMalloc( sizeof( Queue_t ) + xQueueSizeInBytes );
     e32:	4f 96       	adiw	r24, 0x1f	; 31
     e34:	0e 94 06 03 	call	0x60c	; 0x60c <pvPortMalloc>
     e38:	ec 01       	movw	r28, r24

		if( pxNewQueue != NULL )
     e3a:	00 97       	sbiw	r24, 0x00	; 0
     e3c:	71 f0       	breq	.+28     	; 0xe5a <xQueueGenericCreate+0x44>
{
	/* Remove compiler warnings about unused parameters should
	configUSE_TRACE_FACILITY not be set to 1. */
	( void ) ucQueueType;

	if( uxItemSize == ( UBaseType_t ) 0 )
     e3e:	11 23       	and	r17, r17
     e40:	19 f4       	brne	.+6      	; 0xe48 <xQueueGenericCreate+0x32>
	{
		/* No RAM was allocated for the queue storage area, but PC head cannot
		be set to NULL because NULL is used as a key to say the queue is used as
		a mutex.  Therefore just set pcHead to point to the queue as a benign
		value that is known to be within the memory map. */
		pxNewQueue->pcHead = ( int8_t * ) pxNewQueue;
     e42:	99 83       	std	Y+1, r25	; 0x01
     e44:	88 83       	st	Y, r24
     e46:	03 c0       	rjmp	.+6      	; 0xe4e <xQueueGenericCreate+0x38>

		if( pxNewQueue != NULL )
		{
			/* Jump past the queue structure to find the location of the queue
			storage area. */
			pucQueueStorage = ( ( uint8_t * ) pxNewQueue ) + sizeof( Queue_t );
     e48:	4f 96       	adiw	r24, 0x1f	; 31
		pxNewQueue->pcHead = ( int8_t * ) pxNewQueue;
	}
	else
	{
		/* Set the head to the start of the queue storage area. */
		pxNewQueue->pcHead = ( int8_t * ) pucQueueStorage;
     e4a:	99 83       	std	Y+1, r25	; 0x01
     e4c:	88 83       	st	Y, r24
	}

	/* Initialise the queue members as described where the queue type is
	defined. */
	pxNewQueue->uxLength = uxQueueLength;
     e4e:	0b 8f       	std	Y+27, r16	; 0x1b
	pxNewQueue->uxItemSize = uxItemSize;
     e50:	1c 8f       	std	Y+28, r17	; 0x1c
	( void ) xQueueGenericReset( pxNewQueue, pdTRUE );
     e52:	ce 01       	movw	r24, r28
     e54:	61 e0       	ldi	r22, 0x01	; 1
     e56:	0e 94 c5 06 	call	0xd8a	; 0xd8a <xQueueGenericReset>

			prvInitialiseNewQueue( uxQueueLength, uxItemSize, pucQueueStorage, ucQueueType, pxNewQueue );
		}

		return pxNewQueue;
	}
     e5a:	8c 2f       	mov	r24, r28
     e5c:	9d 2f       	mov	r25, r29
     e5e:	df 91       	pop	r29
     e60:	cf 91       	pop	r28
     e62:	1f 91       	pop	r17
     e64:	0f 91       	pop	r16
     e66:	08 95       	ret

00000e68 <xQueueGenericSend>:

#endif /* ( ( configUSE_COUNTING_SEMAPHORES == 1 ) && ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) ) */
/*-----------------------------------------------------------*/

BaseType_t xQueueGenericSend( QueueHandle_t xQueue, const void * const pvItemToQueue, TickType_t xTicksToWait, const BaseType_t xCopyPosition )
{
     e68:	8f 92       	push	r8
     e6a:	9f 92       	push	r9
     e6c:	bf 92       	push	r11
     e6e:	cf 92       	push	r12
     e70:	df 92       	push	r13
     e72:	ef 92       	push	r14
     e74:	ff 92       	push	r15
     e76:	0f 93       	push	r16
     e78:	1f 93       	push	r17
     e7a:	cf 93       	push	r28
     e7c:	df 93       	push	r29
     e7e:	00 d0       	rcall	.+0      	; 0xe80 <xQueueGenericSend+0x18>
     e80:	00 d0       	rcall	.+0      	; 0xe82 <xQueueGenericSend+0x1a>
     e82:	0f 92       	push	r0
     e84:	cd b7       	in	r28, 0x3d	; 61
     e86:	de b7       	in	r29, 0x3e	; 62
     e88:	8c 01       	movw	r16, r24
     e8a:	4b 01       	movw	r8, r22
     e8c:	5d 83       	std	Y+5, r21	; 0x05
     e8e:	4c 83       	std	Y+4, r20	; 0x04
     e90:	e2 2e       	mov	r14, r18
BaseType_t xEntryTimeSet = pdFALSE, xYieldRequired;
     e92:	ff 24       	eor	r15, r15
				else if( xEntryTimeSet == pdFALSE )
				{
					/* The queue was full and a block time was specified so
					configure the timeout structure. */
					vTaskSetTimeOutState( &xTimeOut );
					xEntryTimeSet = pdTRUE;
     e94:	bb 24       	eor	r11, r11
     e96:	b3 94       	inc	r11
		if( xTaskCheckForTimeOut( &xTimeOut, &xTicksToWait ) == pdFALSE )
		{
			if( prvIsQueueFull( pxQueue ) != pdFALSE )
			{
				traceBLOCKING_ON_QUEUE_SEND( pxQueue );
				vTaskPlaceOnEventList( &( pxQueue->xTasksWaitingToSend ), xTicksToWait );
     e98:	cc 24       	eor	r12, r12
     e9a:	dd 24       	eor	r13, r13
     e9c:	68 94       	set
     e9e:	c3 f8       	bld	r12, 3
     ea0:	c8 0e       	add	r12, r24
     ea2:	d9 1e       	adc	r13, r25
	/* This function relaxes the coding standard somewhat to allow return
	statements within the function itself.  This is done in the interest
	of execution time efficiency. */
	for( ;; )
	{
		taskENTER_CRITICAL();
     ea4:	0f b6       	in	r0, 0x3f	; 63
     ea6:	f8 94       	cli
     ea8:	0f 92       	push	r0
		{
			/* Is there room on the queue now?  The running task must be the
			highest priority task wanting to access the queue.  If the head item
			in the queue is to be overwritten then it does not matter if the
			queue is full. */
			if( ( pxQueue->uxMessagesWaiting < pxQueue->uxLength ) || ( xCopyPosition == queueOVERWRITE ) )
     eaa:	f8 01       	movw	r30, r16
     eac:	92 8d       	ldd	r25, Z+26	; 0x1a
     eae:	83 8d       	ldd	r24, Z+27	; 0x1b
     eb0:	98 17       	cp	r25, r24
     eb2:	18 f0       	brcs	.+6      	; 0xeba <xQueueGenericSend+0x52>
     eb4:	f2 e0       	ldi	r31, 0x02	; 2
     eb6:	ef 16       	cp	r14, r31
     eb8:	d1 f4       	brne	.+52     	; 0xeee <xQueueGenericSend+0x86>
			{
				traceQUEUE_SEND( pxQueue );
				xYieldRequired = prvCopyDataToQueue( pxQueue, pvItemToQueue, xCopyPosition );
     eba:	c8 01       	movw	r24, r16
     ebc:	b4 01       	movw	r22, r8
     ebe:	4e 2d       	mov	r20, r14
     ec0:	0e 94 66 06 	call	0xccc	; 0xccc <prvCopyDataToQueue>
				}
				#else /* configUSE_QUEUE_SETS */
				{
					/* If there was a task waiting for data to arrive on the
					queue then unblock it now. */
					if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
     ec4:	f8 01       	movw	r30, r16
     ec6:	91 89       	ldd	r25, Z+17	; 0x11
     ec8:	99 23       	and	r25, r25
     eca:	49 f0       	breq	.+18     	; 0xede <xQueueGenericSend+0x76>
					{
						if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )
     ecc:	c8 01       	movw	r24, r16
     ece:	41 96       	adiw	r24, 0x11	; 17
     ed0:	0e 94 1f 10 	call	0x203e	; 0x203e <xTaskRemoveFromEventList>
     ed4:	88 23       	and	r24, r24
     ed6:	39 f0       	breq	.+14     	; 0xee6 <xQueueGenericSend+0x7e>
						{
							/* The unblocked task has a priority higher than
							our own so yield immediately.  Yes it is ok to do
							this from within the critical section - the kernel
							takes care of that. */
							queueYIELD_IF_USING_PREEMPTION();
     ed8:	0e 94 30 05 	call	0xa60	; 0xa60 <vPortYield>
     edc:	04 c0       	rjmp	.+8      	; 0xee6 <xQueueGenericSend+0x7e>
						else
						{
							mtCOVERAGE_TEST_MARKER();
						}
					}
					else if( xYieldRequired != pdFALSE )
     ede:	88 23       	and	r24, r24
     ee0:	11 f0       	breq	.+4      	; 0xee6 <xQueueGenericSend+0x7e>
					{
						/* This path is a special case that will only get
						executed if the task was holding multiple mutexes and
						the mutexes were given back in an order that is
						different to that in which they were taken. */
						queueYIELD_IF_USING_PREEMPTION();
     ee2:	0e 94 30 05 	call	0xa60	; 0xa60 <vPortYield>
						mtCOVERAGE_TEST_MARKER();
					}
				}
				#endif /* configUSE_QUEUE_SETS */

				taskEXIT_CRITICAL();
     ee6:	0f 90       	pop	r0
     ee8:	0f be       	out	0x3f, r0	; 63
				return pdPASS;
     eea:	81 e0       	ldi	r24, 0x01	; 1
     eec:	52 c0       	rjmp	.+164    	; 0xf92 <xQueueGenericSend+0x12a>
			}
			else
			{
				if( xTicksToWait == ( TickType_t ) 0 )
     eee:	8c 81       	ldd	r24, Y+4	; 0x04
     ef0:	9d 81       	ldd	r25, Y+5	; 0x05
     ef2:	00 97       	sbiw	r24, 0x00	; 0
     ef4:	21 f4       	brne	.+8      	; 0xefe <xQueueGenericSend+0x96>
				{
					/* The queue was full and no block time is specified (or
					the block time has expired) so leave now. */
					taskEXIT_CRITICAL();
     ef6:	0f 90       	pop	r0
     ef8:	0f be       	out	0x3f, r0	; 63

					/* Return to the original privilege level before exiting
					the function. */
					traceQUEUE_SEND_FAILED( pxQueue );
					return errQUEUE_FULL;
     efa:	80 e0       	ldi	r24, 0x00	; 0
     efc:	4a c0       	rjmp	.+148    	; 0xf92 <xQueueGenericSend+0x12a>
				}
				else if( xEntryTimeSet == pdFALSE )
     efe:	ff 20       	and	r15, r15
     f00:	29 f4       	brne	.+10     	; 0xf0c <xQueueGenericSend+0xa4>
				{
					/* The queue was full and a block time was specified so
					configure the timeout structure. */
					vTaskSetTimeOutState( &xTimeOut );
     f02:	ce 01       	movw	r24, r28
     f04:	01 96       	adiw	r24, 0x01	; 1
     f06:	0e 94 a4 10 	call	0x2148	; 0x2148 <vTaskSetTimeOutState>
					xEntryTimeSet = pdTRUE;
     f0a:	fb 2c       	mov	r15, r11
					/* Entry time was already set. */
					mtCOVERAGE_TEST_MARKER();
				}
			}
		}
		taskEXIT_CRITICAL();
     f0c:	0f 90       	pop	r0
     f0e:	0f be       	out	0x3f, r0	; 63

		/* Interrupts and other tasks can send to and receive from the queue
		now the critical section has been exited. */

		vTaskSuspendAll();
     f10:	0e 94 79 0d 	call	0x1af2	; 0x1af2 <vTaskSuspendAll>
		prvLockQueue( pxQueue );
     f14:	0f b6       	in	r0, 0x3f	; 63
     f16:	f8 94       	cli
     f18:	0f 92       	push	r0
     f1a:	f8 01       	movw	r30, r16
     f1c:	85 8d       	ldd	r24, Z+29	; 0x1d
     f1e:	8f 3f       	cpi	r24, 0xFF	; 255
     f20:	09 f4       	brne	.+2      	; 0xf24 <xQueueGenericSend+0xbc>
     f22:	15 8e       	std	Z+29, r1	; 0x1d
     f24:	f8 01       	movw	r30, r16
     f26:	86 8d       	ldd	r24, Z+30	; 0x1e
     f28:	8f 3f       	cpi	r24, 0xFF	; 255
     f2a:	09 f4       	brne	.+2      	; 0xf2e <xQueueGenericSend+0xc6>
     f2c:	16 8e       	std	Z+30, r1	; 0x1e
     f2e:	0f 90       	pop	r0
     f30:	0f be       	out	0x3f, r0	; 63

		/* Update the timeout state to see if it has expired yet. */
		if( xTaskCheckForTimeOut( &xTimeOut, &xTicksToWait ) == pdFALSE )
     f32:	ce 01       	movw	r24, r28
     f34:	01 96       	adiw	r24, 0x01	; 1
     f36:	be 01       	movw	r22, r28
     f38:	6c 5f       	subi	r22, 0xFC	; 252
     f3a:	7f 4f       	sbci	r23, 0xFF	; 255
     f3c:	0e 94 af 10 	call	0x215e	; 0x215e <xTaskCheckForTimeOut>
     f40:	88 23       	and	r24, r24
     f42:	09 f5       	brne	.+66     	; 0xf86 <xQueueGenericSend+0x11e>

static BaseType_t prvIsQueueFull( const Queue_t *pxQueue )
{
BaseType_t xReturn;

	taskENTER_CRITICAL();
     f44:	0f b6       	in	r0, 0x3f	; 63
     f46:	f8 94       	cli
     f48:	0f 92       	push	r0
	{
		if( pxQueue->uxMessagesWaiting == pxQueue->uxLength )
     f4a:	f8 01       	movw	r30, r16
     f4c:	92 8d       	ldd	r25, Z+26	; 0x1a
		else
		{
			xReturn = pdFALSE;
		}
	}
	taskEXIT_CRITICAL();
     f4e:	0f 90       	pop	r0
     f50:	0f be       	out	0x3f, r0	; 63
		prvLockQueue( pxQueue );

		/* Update the timeout state to see if it has expired yet. */
		if( xTaskCheckForTimeOut( &xTimeOut, &xTicksToWait ) == pdFALSE )
		{
			if( prvIsQueueFull( pxQueue ) != pdFALSE )
     f52:	f8 01       	movw	r30, r16
     f54:	83 8d       	ldd	r24, Z+27	; 0x1b
     f56:	98 17       	cp	r25, r24
     f58:	81 f4       	brne	.+32     	; 0xf7a <xQueueGenericSend+0x112>
			{
				traceBLOCKING_ON_QUEUE_SEND( pxQueue );
				vTaskPlaceOnEventList( &( pxQueue->xTasksWaitingToSend ), xTicksToWait );
     f5a:	6c 81       	ldd	r22, Y+4	; 0x04
     f5c:	7d 81       	ldd	r23, Y+5	; 0x05
     f5e:	c6 01       	movw	r24, r12
     f60:	0e 94 f4 0f 	call	0x1fe8	; 0x1fe8 <vTaskPlaceOnEventList>
				/* Unlocking the queue means queue events can effect the
				event list.  It is possible	that interrupts occurring now
				remove this task from the event	list again - but as the
				scheduler is suspended the task will go onto the pending
				ready last instead of the actual ready list. */
				prvUnlockQueue( pxQueue );
     f64:	c8 01       	movw	r24, r16
     f66:	0e 94 11 06 	call	0xc22	; 0xc22 <prvUnlockQueue>
				/* Resuming the scheduler will move tasks from the pending
				ready list into the ready list - so it is feasible that this
				task is already in a ready list before it yields - in which
				case the yield will not cause a context switch unless there
				is also a higher priority task in the pending ready list. */
				if( xTaskResumeAll() == pdFALSE )
     f6a:	0e 94 3e 0e 	call	0x1c7c	; 0x1c7c <xTaskResumeAll>
     f6e:	88 23       	and	r24, r24
     f70:	09 f0       	breq	.+2      	; 0xf74 <xQueueGenericSend+0x10c>
     f72:	98 cf       	rjmp	.-208    	; 0xea4 <xQueueGenericSend+0x3c>
				{
					portYIELD_WITHIN_API();
     f74:	0e 94 30 05 	call	0xa60	; 0xa60 <vPortYield>
     f78:	95 cf       	rjmp	.-214    	; 0xea4 <xQueueGenericSend+0x3c>
				}
			}
			else
			{
				/* Try again. */
				prvUnlockQueue( pxQueue );
     f7a:	c8 01       	movw	r24, r16
     f7c:	0e 94 11 06 	call	0xc22	; 0xc22 <prvUnlockQueue>
				( void ) xTaskResumeAll();
     f80:	0e 94 3e 0e 	call	0x1c7c	; 0x1c7c <xTaskResumeAll>
     f84:	8f cf       	rjmp	.-226    	; 0xea4 <xQueueGenericSend+0x3c>
			}
		}
		else
		{
			/* The timeout has expired. */
			prvUnlockQueue( pxQueue );
     f86:	c8 01       	movw	r24, r16
     f88:	0e 94 11 06 	call	0xc22	; 0xc22 <prvUnlockQueue>
			( void ) xTaskResumeAll();
     f8c:	0e 94 3e 0e 	call	0x1c7c	; 0x1c7c <xTaskResumeAll>

			traceQUEUE_SEND_FAILED( pxQueue );
			return errQUEUE_FULL;
     f90:	80 e0       	ldi	r24, 0x00	; 0
		}
	}
}
     f92:	0f 90       	pop	r0
     f94:	0f 90       	pop	r0
     f96:	0f 90       	pop	r0
     f98:	0f 90       	pop	r0
     f9a:	0f 90       	pop	r0
     f9c:	df 91       	pop	r29
     f9e:	cf 91       	pop	r28
     fa0:	1f 91       	pop	r17
     fa2:	0f 91       	pop	r16
     fa4:	ff 90       	pop	r15
     fa6:	ef 90       	pop	r14
     fa8:	df 90       	pop	r13
     faa:	cf 90       	pop	r12
     fac:	bf 90       	pop	r11
     fae:	9f 90       	pop	r9
     fb0:	8f 90       	pop	r8
     fb2:	08 95       	ret

00000fb4 <xQueueCreateMutex>:
/*-----------------------------------------------------------*/

#if( ( configUSE_MUTEXES == 1 ) && ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) )

	QueueHandle_t xQueueCreateMutex( const uint8_t ucQueueType )
	{
     fb4:	cf 93       	push	r28
     fb6:	df 93       	push	r29
     fb8:	48 2f       	mov	r20, r24
	Queue_t *pxNewQueue;
	const UBaseType_t uxMutexLength = ( UBaseType_t ) 1, uxMutexSize = ( UBaseType_t ) 0;

		pxNewQueue = ( Queue_t * ) xQueueGenericCreate( uxMutexLength, uxMutexSize, ucQueueType );
     fba:	81 e0       	ldi	r24, 0x01	; 1
     fbc:	60 e0       	ldi	r22, 0x00	; 0
     fbe:	0e 94 0b 07 	call	0xe16	; 0xe16 <xQueueGenericCreate>
     fc2:	ec 01       	movw	r28, r24

#if( configUSE_MUTEXES == 1 )

	static void prvInitialiseMutex( Queue_t *pxNewQueue )
	{
		if( pxNewQueue != NULL )
     fc4:	00 97       	sbiw	r24, 0x00	; 0
     fc6:	61 f0       	breq	.+24     	; 0xfe0 <xQueueCreateMutex+0x2c>
		{
			/* The queue create function will set all the queue structure members
			correctly for a generic queue, but this function is creating a
			mutex.  Overwrite those members that need to be set differently -
			in particular the information required for priority inheritance. */
			pxNewQueue->pxMutexHolder = NULL;
     fc8:	1b 82       	std	Y+3, r1	; 0x03
     fca:	1a 82       	std	Y+2, r1	; 0x02
			pxNewQueue->uxQueueType = queueQUEUE_IS_MUTEX;
     fcc:	19 82       	std	Y+1, r1	; 0x01
     fce:	18 82       	st	Y, r1

			/* In case this is a recursive mutex. */
			pxNewQueue->u.uxRecursiveCallCount = 0;
     fd0:	1e 82       	std	Y+6, r1	; 0x06

			traceCREATE_MUTEX( pxNewQueue );

			/* Start with the semaphore in the expected state. */
			( void ) xQueueGenericSend( pxNewQueue, NULL, ( TickType_t ) 0U, queueSEND_TO_BACK );
     fd2:	60 e0       	ldi	r22, 0x00	; 0
     fd4:	70 e0       	ldi	r23, 0x00	; 0
     fd6:	40 e0       	ldi	r20, 0x00	; 0
     fd8:	50 e0       	ldi	r21, 0x00	; 0
     fda:	20 e0       	ldi	r18, 0x00	; 0
     fdc:	0e 94 34 07 	call	0xe68	; 0xe68 <xQueueGenericSend>

		pxNewQueue = ( Queue_t * ) xQueueGenericCreate( uxMutexLength, uxMutexSize, ucQueueType );
		prvInitialiseMutex( pxNewQueue );

		return pxNewQueue;
	}
     fe0:	8c 2f       	mov	r24, r28
     fe2:	9d 2f       	mov	r25, r29
     fe4:	df 91       	pop	r29
     fe6:	cf 91       	pop	r28
     fe8:	08 95       	ret

00000fea <xQueueGenericSendFromISR>:
	}
}
/*-----------------------------------------------------------*/

BaseType_t xQueueGenericSendFromISR( QueueHandle_t xQueue, const void * const pvItemToQueue, BaseType_t * const pxHigherPriorityTaskWoken, const BaseType_t xCopyPosition )
{
     fea:	ef 92       	push	r14
     fec:	ff 92       	push	r15
     fee:	0f 93       	push	r16
     ff0:	1f 93       	push	r17
     ff2:	cf 93       	push	r28
     ff4:	8c 01       	movw	r16, r24
     ff6:	7a 01       	movw	r14, r20
	read, instead return a flag to say whether a context switch is required or
	not (i.e. has a task with a higher priority than us been woken by this
	post). */
	uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
	{
		if( ( pxQueue->uxMessagesWaiting < pxQueue->uxLength ) || ( xCopyPosition == queueOVERWRITE ) )
     ff8:	fc 01       	movw	r30, r24
     ffa:	92 8d       	ldd	r25, Z+26	; 0x1a
     ffc:	83 8d       	ldd	r24, Z+27	; 0x1b
     ffe:	98 17       	cp	r25, r24
    1000:	10 f0       	brcs	.+4      	; 0x1006 <xQueueGenericSendFromISR+0x1c>
    1002:	22 30       	cpi	r18, 0x02	; 2
    1004:	f1 f4       	brne	.+60     	; 0x1042 <xQueueGenericSendFromISR+0x58>
		{
			const int8_t cTxLock = pxQueue->cTxLock;
    1006:	f8 01       	movw	r30, r16
    1008:	c6 8d       	ldd	r28, Z+30	; 0x1e
			/* Semaphores use xQueueGiveFromISR(), so pxQueue will not be a
			semaphore or mutex.  That means prvCopyDataToQueue() cannot result
			in a task disinheriting a priority and prvCopyDataToQueue() can be
			called here even though the disinherit function does not check if
			the scheduler is suspended before accessing the ready lists. */
			( void ) prvCopyDataToQueue( pxQueue, pvItemToQueue, xCopyPosition );
    100a:	c8 01       	movw	r24, r16
    100c:	42 2f       	mov	r20, r18
    100e:	0e 94 66 06 	call	0xccc	; 0xccc <prvCopyDataToQueue>

			/* The event list is not altered if the queue is locked.  This will
			be done when the queue is unlocked later. */
			if( cTxLock == queueUNLOCKED )
    1012:	cf 3f       	cpi	r28, 0xFF	; 255
    1014:	89 f4       	brne	.+34     	; 0x1038 <xQueueGenericSendFromISR+0x4e>
						}
					}
				}
				#else /* configUSE_QUEUE_SETS */
				{
					if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
    1016:	f8 01       	movw	r30, r16
    1018:	81 89       	ldd	r24, Z+17	; 0x11
    101a:	88 23       	and	r24, r24
    101c:	a1 f0       	breq	.+40     	; 0x1046 <xQueueGenericSendFromISR+0x5c>
					{
						if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )
    101e:	c8 01       	movw	r24, r16
    1020:	41 96       	adiw	r24, 0x11	; 17
    1022:	0e 94 1f 10 	call	0x203e	; 0x203e <xTaskRemoveFromEventList>
    1026:	88 23       	and	r24, r24
    1028:	81 f0       	breq	.+32     	; 0x104a <xQueueGenericSendFromISR+0x60>
						{
							/* The task waiting has a higher priority so record that a
							context	switch is required. */
							if( pxHigherPriorityTaskWoken != NULL )
    102a:	e1 14       	cp	r14, r1
    102c:	f1 04       	cpc	r15, r1
    102e:	79 f0       	breq	.+30     	; 0x104e <xQueueGenericSendFromISR+0x64>
							{
								*pxHigherPriorityTaskWoken = pdTRUE;
    1030:	81 e0       	ldi	r24, 0x01	; 1
    1032:	f7 01       	movw	r30, r14
    1034:	80 83       	st	Z, r24
    1036:	0c c0       	rjmp	.+24     	; 0x1050 <xQueueGenericSendFromISR+0x66>
			}
			else
			{
				/* Increment the lock count so the task that unlocks the queue
				knows that data was posted while it was locked. */
				pxQueue->cTxLock = ( int8_t ) ( cTxLock + 1 );
    1038:	cf 5f       	subi	r28, 0xFF	; 255
    103a:	f8 01       	movw	r30, r16
    103c:	c6 8f       	std	Z+30, r28	; 0x1e
			}

			xReturn = pdPASS;
    103e:	81 e0       	ldi	r24, 0x01	; 1
    1040:	07 c0       	rjmp	.+14     	; 0x1050 <xQueueGenericSendFromISR+0x66>
		}
		else
		{
			traceQUEUE_SEND_FROM_ISR_FAILED( pxQueue );
			xReturn = errQUEUE_FULL;
    1042:	80 e0       	ldi	r24, 0x00	; 0
    1044:	05 c0       	rjmp	.+10     	; 0x1050 <xQueueGenericSendFromISR+0x66>
				/* Increment the lock count so the task that unlocks the queue
				knows that data was posted while it was locked. */
				pxQueue->cTxLock = ( int8_t ) ( cTxLock + 1 );
			}

			xReturn = pdPASS;
    1046:	81 e0       	ldi	r24, 0x01	; 1
    1048:	03 c0       	rjmp	.+6      	; 0x1050 <xQueueGenericSendFromISR+0x66>
    104a:	81 e0       	ldi	r24, 0x01	; 1
    104c:	01 c0       	rjmp	.+2      	; 0x1050 <xQueueGenericSendFromISR+0x66>
    104e:	81 e0       	ldi	r24, 0x01	; 1
		}
	}
	portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );

	return xReturn;
}
    1050:	cf 91       	pop	r28
    1052:	1f 91       	pop	r17
    1054:	0f 91       	pop	r16
    1056:	ff 90       	pop	r15
    1058:	ef 90       	pop	r14
    105a:	08 95       	ret

0000105c <xQueueGiveFromISR>:
/*-----------------------------------------------------------*/

BaseType_t xQueueGiveFromISR( QueueHandle_t xQueue, BaseType_t * const pxHigherPriorityTaskWoken )
{
    105c:	cf 93       	push	r28
    105e:	df 93       	push	r29
    1060:	fc 01       	movw	r30, r24
    1062:	eb 01       	movw	r28, r22
	link: http://www.freertos.org/RTOS-Cortex-M3-M4.html */
	portASSERT_IF_INTERRUPT_PRIORITY_INVALID();

	uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
	{
		const UBaseType_t uxMessagesWaiting = pxQueue->uxMessagesWaiting;
    1064:	82 8d       	ldd	r24, Z+26	; 0x1a

		/* When the queue is used to implement a semaphore no data is ever
		moved through the queue but it is still valid to see if the queue 'has
		space'. */
		if( uxMessagesWaiting < pxQueue->uxLength )
    1066:	93 8d       	ldd	r25, Z+27	; 0x1b
    1068:	89 17       	cp	r24, r25
    106a:	b8 f4       	brcc	.+46     	; 0x109a <xQueueGiveFromISR+0x3e>
		{
			const int8_t cTxLock = pxQueue->cTxLock;
    106c:	96 8d       	ldd	r25, Z+30	; 0x1e
			holder - and if there is a mutex holder then the mutex cannot be
			given from an ISR.  As this is the ISR version of the function it
			can be assumed there is no mutex holder and no need to determine if
			priority disinheritance is needed.  Simply increase the count of
			messages (semaphores) available. */
			pxQueue->uxMessagesWaiting = uxMessagesWaiting + 1;
    106e:	8f 5f       	subi	r24, 0xFF	; 255
    1070:	82 8f       	std	Z+26, r24	; 0x1a

			/* The event list is not altered if the queue is locked.  This will
			be done when the queue is unlocked later. */
			if( cTxLock == queueUNLOCKED )
    1072:	9f 3f       	cpi	r25, 0xFF	; 255
    1074:	71 f4       	brne	.+28     	; 0x1092 <xQueueGiveFromISR+0x36>
						}
					}
				}
				#else /* configUSE_QUEUE_SETS */
				{
					if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
    1076:	81 89       	ldd	r24, Z+17	; 0x11
    1078:	88 23       	and	r24, r24
    107a:	89 f0       	breq	.+34     	; 0x109e <xQueueGiveFromISR+0x42>
					{
						if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )
    107c:	cf 01       	movw	r24, r30
    107e:	41 96       	adiw	r24, 0x11	; 17
    1080:	0e 94 1f 10 	call	0x203e	; 0x203e <xTaskRemoveFromEventList>
    1084:	88 23       	and	r24, r24
    1086:	69 f0       	breq	.+26     	; 0x10a2 <xQueueGiveFromISR+0x46>
						{
							/* The task waiting has a higher priority so record that a
							context	switch is required. */
							if( pxHigherPriorityTaskWoken != NULL )
    1088:	20 97       	sbiw	r28, 0x00	; 0
    108a:	69 f0       	breq	.+26     	; 0x10a6 <xQueueGiveFromISR+0x4a>
							{
								*pxHigherPriorityTaskWoken = pdTRUE;
    108c:	81 e0       	ldi	r24, 0x01	; 1
    108e:	88 83       	st	Y, r24
    1090:	0b c0       	rjmp	.+22     	; 0x10a8 <xQueueGiveFromISR+0x4c>
			}
			else
			{
				/* Increment the lock count so the task that unlocks the queue
				knows that data was posted while it was locked. */
				pxQueue->cTxLock = ( int8_t ) ( cTxLock + 1 );
    1092:	9f 5f       	subi	r25, 0xFF	; 255
    1094:	96 8f       	std	Z+30, r25	; 0x1e
			}

			xReturn = pdPASS;
    1096:	81 e0       	ldi	r24, 0x01	; 1
    1098:	07 c0       	rjmp	.+14     	; 0x10a8 <xQueueGiveFromISR+0x4c>
		}
		else
		{
			traceQUEUE_SEND_FROM_ISR_FAILED( pxQueue );
			xReturn = errQUEUE_FULL;
    109a:	80 e0       	ldi	r24, 0x00	; 0
    109c:	05 c0       	rjmp	.+10     	; 0x10a8 <xQueueGiveFromISR+0x4c>
				/* Increment the lock count so the task that unlocks the queue
				knows that data was posted while it was locked. */
				pxQueue->cTxLock = ( int8_t ) ( cTxLock + 1 );
			}

			xReturn = pdPASS;
    109e:	81 e0       	ldi	r24, 0x01	; 1
    10a0:	03 c0       	rjmp	.+6      	; 0x10a8 <xQueueGiveFromISR+0x4c>
    10a2:	81 e0       	ldi	r24, 0x01	; 1
    10a4:	01 c0       	rjmp	.+2      	; 0x10a8 <xQueueGiveFromISR+0x4c>
    10a6:	81 e0       	ldi	r24, 0x01	; 1
		}
	}
	portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );

	return xReturn;
}
    10a8:	df 91       	pop	r29
    10aa:	cf 91       	pop	r28
    10ac:	08 95       	ret

000010ae <xQueueGenericReceive>:
/*-----------------------------------------------------------*/

BaseType_t xQueueGenericReceive( QueueHandle_t xQueue, void * const pvBuffer, TickType_t xTicksToWait, const BaseType_t xJustPeeking )
{
    10ae:	8f 92       	push	r8
    10b0:	9f 92       	push	r9
    10b2:	af 92       	push	r10
    10b4:	bf 92       	push	r11
    10b6:	cf 92       	push	r12
    10b8:	df 92       	push	r13
    10ba:	ef 92       	push	r14
    10bc:	ff 92       	push	r15
    10be:	0f 93       	push	r16
    10c0:	1f 93       	push	r17
    10c2:	cf 93       	push	r28
    10c4:	df 93       	push	r29
    10c6:	00 d0       	rcall	.+0      	; 0x10c8 <xQueueGenericReceive+0x1a>
    10c8:	00 d0       	rcall	.+0      	; 0x10ca <xQueueGenericReceive+0x1c>
    10ca:	0f 92       	push	r0
    10cc:	cd b7       	in	r28, 0x3d	; 61
    10ce:	de b7       	in	r29, 0x3e	; 62
    10d0:	7c 01       	movw	r14, r24
    10d2:	4b 01       	movw	r8, r22
    10d4:	5d 83       	std	Y+5, r21	; 0x05
    10d6:	4c 83       	std	Y+4, r20	; 0x04
    10d8:	c2 2e       	mov	r12, r18
BaseType_t xEntryTimeSet = pdFALSE;
    10da:	00 e0       	ldi	r16, 0x00	; 0
				else if( xEntryTimeSet == pdFALSE )
				{
					/* The queue was empty and a block time was specified so
					configure the timeout structure. */
					vTaskSetTimeOutState( &xTimeOut );
					xEntryTimeSet = pdTRUE;
    10dc:	dd 24       	eor	r13, r13
    10de:	d3 94       	inc	r13
						mtCOVERAGE_TEST_MARKER();
					}
				}
				#endif

				vTaskPlaceOnEventList( &( pxQueue->xTasksWaitingToReceive ), xTicksToWait );
    10e0:	0f 2e       	mov	r0, r31
    10e2:	f1 e1       	ldi	r31, 0x11	; 17
    10e4:	af 2e       	mov	r10, r31
    10e6:	bb 24       	eor	r11, r11
    10e8:	f0 2d       	mov	r31, r0
    10ea:	a8 0e       	add	r10, r24
    10ec:	b9 1e       	adc	r11, r25
	statements within the function itself.  This is done in the interest
	of execution time efficiency. */

	for( ;; )
	{
		taskENTER_CRITICAL();
    10ee:	0f b6       	in	r0, 0x3f	; 63
    10f0:	f8 94       	cli
    10f2:	0f 92       	push	r0
		{
			const UBaseType_t uxMessagesWaiting = pxQueue->uxMessagesWaiting;
    10f4:	f7 01       	movw	r30, r14
    10f6:	12 8d       	ldd	r17, Z+26	; 0x1a

			/* Is there data in the queue now?  To be running the calling task
			must be the highest priority task wanting to access the queue. */
			if( uxMessagesWaiting > ( UBaseType_t ) 0 )
    10f8:	11 23       	and	r17, r17
    10fa:	99 f1       	breq	.+102    	; 0x1162 <xQueueGenericReceive+0xb4>
			{
				/* Remember the read position in case the queue is only being
				peeked. */
				pcOriginalReadPosition = pxQueue->u.pcReadFrom;
    10fc:	a6 80       	ldd	r10, Z+6	; 0x06
    10fe:	b7 80       	ldd	r11, Z+7	; 0x07

				prvCopyDataFromQueue( pxQueue, pvBuffer );
    1100:	c7 01       	movw	r24, r14
    1102:	b4 01       	movw	r22, r8
    1104:	0e 94 f4 05 	call	0xbe8	; 0xbe8 <prvCopyDataFromQueue>

				if( xJustPeeking == pdFALSE )
    1108:	cc 20       	and	r12, r12
    110a:	c9 f4       	brne	.+50     	; 0x113e <xQueueGenericReceive+0x90>
				{
					traceQUEUE_RECEIVE( pxQueue );

					/* Actually removing data, not just peeking. */
					pxQueue->uxMessagesWaiting = uxMessagesWaiting - 1;
    110c:	11 50       	subi	r17, 0x01	; 1
    110e:	f7 01       	movw	r30, r14
    1110:	12 8f       	std	Z+26, r17	; 0x1a

					#if ( configUSE_MUTEXES == 1 )
					{
						if( pxQueue->uxQueueType == queueQUEUE_IS_MUTEX )
    1112:	80 81       	ld	r24, Z
    1114:	91 81       	ldd	r25, Z+1	; 0x01
    1116:	00 97       	sbiw	r24, 0x00	; 0
    1118:	29 f4       	brne	.+10     	; 0x1124 <xQueueGenericReceive+0x76>
						{
							/* Record the information required to implement
							priority inheritance should it become necessary. */
							pxQueue->pxMutexHolder = ( int8_t * ) pvTaskIncrementMutexHeldCount(); /*lint !e961 Cast is not redundant as TaskHandle_t is a typedef. */
    111a:	0e 94 a4 11 	call	0x2348	; 0x2348 <pvTaskIncrementMutexHeldCount>
    111e:	f7 01       	movw	r30, r14
    1120:	93 83       	std	Z+3, r25	; 0x03
    1122:	82 83       	std	Z+2, r24	; 0x02
							mtCOVERAGE_TEST_MARKER();
						}
					}
					#endif /* configUSE_MUTEXES */

					if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToSend ) ) == pdFALSE )
    1124:	f7 01       	movw	r30, r14
    1126:	80 85       	ldd	r24, Z+8	; 0x08
    1128:	88 23       	and	r24, r24
    112a:	b9 f0       	breq	.+46     	; 0x115a <xQueueGenericReceive+0xac>
					{
						if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) != pdFALSE )
    112c:	c7 01       	movw	r24, r14
    112e:	08 96       	adiw	r24, 0x08	; 8
    1130:	0e 94 1f 10 	call	0x203e	; 0x203e <xTaskRemoveFromEventList>
    1134:	88 23       	and	r24, r24
    1136:	89 f0       	breq	.+34     	; 0x115a <xQueueGenericReceive+0xac>
						{
							queueYIELD_IF_USING_PREEMPTION();
    1138:	0e 94 30 05 	call	0xa60	; 0xa60 <vPortYield>
    113c:	0e c0       	rjmp	.+28     	; 0x115a <xQueueGenericReceive+0xac>
				{
					traceQUEUE_PEEK( pxQueue );

					/* The data is not being removed, so reset the read
					pointer. */
					pxQueue->u.pcReadFrom = pcOriginalReadPosition;
    113e:	f7 01       	movw	r30, r14
    1140:	b7 82       	std	Z+7, r11	; 0x07
    1142:	a6 82       	std	Z+6, r10	; 0x06

					/* The data is being left in the queue, so see if there are
					any other tasks waiting for the data. */
					if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
    1144:	81 89       	ldd	r24, Z+17	; 0x11
    1146:	88 23       	and	r24, r24
    1148:	41 f0       	breq	.+16     	; 0x115a <xQueueGenericReceive+0xac>
					{
						if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )
    114a:	c7 01       	movw	r24, r14
    114c:	41 96       	adiw	r24, 0x11	; 17
    114e:	0e 94 1f 10 	call	0x203e	; 0x203e <xTaskRemoveFromEventList>
    1152:	88 23       	and	r24, r24
    1154:	11 f0       	breq	.+4      	; 0x115a <xQueueGenericReceive+0xac>
						{
							/* The task waiting has a higher priority than this task. */
							queueYIELD_IF_USING_PREEMPTION();
    1156:	0e 94 30 05 	call	0xa60	; 0xa60 <vPortYield>
					{
						mtCOVERAGE_TEST_MARKER();
					}
				}

				taskEXIT_CRITICAL();
    115a:	0f 90       	pop	r0
    115c:	0f be       	out	0x3f, r0	; 63
				return pdPASS;
    115e:	81 e0       	ldi	r24, 0x01	; 1
    1160:	61 c0       	rjmp	.+194    	; 0x1224 <xQueueGenericReceive+0x176>
			}
			else
			{
				if( xTicksToWait == ( TickType_t ) 0 )
    1162:	8c 81       	ldd	r24, Y+4	; 0x04
    1164:	9d 81       	ldd	r25, Y+5	; 0x05
    1166:	00 97       	sbiw	r24, 0x00	; 0
    1168:	21 f4       	brne	.+8      	; 0x1172 <xQueueGenericReceive+0xc4>
				{
					/* The queue was empty and no block time is specified (or
					the block time has expired) so leave now. */
					taskEXIT_CRITICAL();
    116a:	0f 90       	pop	r0
    116c:	0f be       	out	0x3f, r0	; 63
					traceQUEUE_RECEIVE_FAILED( pxQueue );
					return errQUEUE_EMPTY;
    116e:	80 e0       	ldi	r24, 0x00	; 0
    1170:	59 c0       	rjmp	.+178    	; 0x1224 <xQueueGenericReceive+0x176>
				}
				else if( xEntryTimeSet == pdFALSE )
    1172:	00 23       	and	r16, r16
    1174:	29 f4       	brne	.+10     	; 0x1180 <xQueueGenericReceive+0xd2>
				{
					/* The queue was empty and a block time was specified so
					configure the timeout structure. */
					vTaskSetTimeOutState( &xTimeOut );
    1176:	ce 01       	movw	r24, r28
    1178:	01 96       	adiw	r24, 0x01	; 1
    117a:	0e 94 a4 10 	call	0x2148	; 0x2148 <vTaskSetTimeOutState>
					xEntryTimeSet = pdTRUE;
    117e:	0d 2d       	mov	r16, r13
					/* Entry time was already set. */
					mtCOVERAGE_TEST_MARKER();
				}
			}
		}
		taskEXIT_CRITICAL();
    1180:	0f 90       	pop	r0
    1182:	0f be       	out	0x3f, r0	; 63

		/* Interrupts and other tasks can send to and receive from the queue
		now the critical section has been exited. */

		vTaskSuspendAll();
    1184:	0e 94 79 0d 	call	0x1af2	; 0x1af2 <vTaskSuspendAll>
		prvLockQueue( pxQueue );
    1188:	0f b6       	in	r0, 0x3f	; 63
    118a:	f8 94       	cli
    118c:	0f 92       	push	r0
    118e:	f7 01       	movw	r30, r14
    1190:	85 8d       	ldd	r24, Z+29	; 0x1d
    1192:	8f 3f       	cpi	r24, 0xFF	; 255
    1194:	09 f4       	brne	.+2      	; 0x1198 <xQueueGenericReceive+0xea>
    1196:	15 8e       	std	Z+29, r1	; 0x1d
    1198:	f7 01       	movw	r30, r14
    119a:	86 8d       	ldd	r24, Z+30	; 0x1e
    119c:	8f 3f       	cpi	r24, 0xFF	; 255
    119e:	09 f4       	brne	.+2      	; 0x11a2 <xQueueGenericReceive+0xf4>
    11a0:	16 8e       	std	Z+30, r1	; 0x1e
    11a2:	0f 90       	pop	r0
    11a4:	0f be       	out	0x3f, r0	; 63

		/* Update the timeout state to see if it has expired yet. */
		if( xTaskCheckForTimeOut( &xTimeOut, &xTicksToWait ) == pdFALSE )
    11a6:	ce 01       	movw	r24, r28
    11a8:	01 96       	adiw	r24, 0x01	; 1
    11aa:	be 01       	movw	r22, r28
    11ac:	6c 5f       	subi	r22, 0xFC	; 252
    11ae:	7f 4f       	sbci	r23, 0xFF	; 255
    11b0:	0e 94 af 10 	call	0x215e	; 0x215e <xTaskCheckForTimeOut>
    11b4:	88 23       	and	r24, r24
    11b6:	51 f5       	brne	.+84     	; 0x120c <xQueueGenericReceive+0x15e>
		{
			if( prvIsQueueEmpty( pxQueue ) != pdFALSE )
    11b8:	c7 01       	movw	r24, r14
    11ba:	0e 94 e9 05 	call	0xbd2	; 0xbd2 <prvIsQueueEmpty>
    11be:	88 23       	and	r24, r24
    11c0:	f9 f0       	breq	.+62     	; 0x1200 <xQueueGenericReceive+0x152>
			{
				traceBLOCKING_ON_QUEUE_RECEIVE( pxQueue );

				#if ( configUSE_MUTEXES == 1 )
				{
					if( pxQueue->uxQueueType == queueQUEUE_IS_MUTEX )
    11c2:	f7 01       	movw	r30, r14
    11c4:	80 81       	ld	r24, Z
    11c6:	91 81       	ldd	r25, Z+1	; 0x01
    11c8:	00 97       	sbiw	r24, 0x00	; 0
    11ca:	51 f4       	brne	.+20     	; 0x11e0 <xQueueGenericReceive+0x132>
					{
						taskENTER_CRITICAL();
    11cc:	0f b6       	in	r0, 0x3f	; 63
    11ce:	f8 94       	cli
    11d0:	0f 92       	push	r0
						{
							vTaskPriorityInherit( ( void * ) pxQueue->pxMutexHolder );
    11d2:	f7 01       	movw	r30, r14
    11d4:	82 81       	ldd	r24, Z+2	; 0x02
    11d6:	93 81       	ldd	r25, Z+3	; 0x03
    11d8:	0e 94 ed 10 	call	0x21da	; 0x21da <vTaskPriorityInherit>
						}
						taskEXIT_CRITICAL();
    11dc:	0f 90       	pop	r0
    11de:	0f be       	out	0x3f, r0	; 63
						mtCOVERAGE_TEST_MARKER();
					}
				}
				#endif

				vTaskPlaceOnEventList( &( pxQueue->xTasksWaitingToReceive ), xTicksToWait );
    11e0:	6c 81       	ldd	r22, Y+4	; 0x04
    11e2:	7d 81       	ldd	r23, Y+5	; 0x05
    11e4:	c5 01       	movw	r24, r10
    11e6:	0e 94 f4 0f 	call	0x1fe8	; 0x1fe8 <vTaskPlaceOnEventList>
				prvUnlockQueue( pxQueue );
    11ea:	c7 01       	movw	r24, r14
    11ec:	0e 94 11 06 	call	0xc22	; 0xc22 <prvUnlockQueue>
				if( xTaskResumeAll() == pdFALSE )
    11f0:	0e 94 3e 0e 	call	0x1c7c	; 0x1c7c <xTaskResumeAll>
    11f4:	88 23       	and	r24, r24
    11f6:	09 f0       	breq	.+2      	; 0x11fa <xQueueGenericReceive+0x14c>
    11f8:	7a cf       	rjmp	.-268    	; 0x10ee <xQueueGenericReceive+0x40>
				{
					portYIELD_WITHIN_API();
    11fa:	0e 94 30 05 	call	0xa60	; 0xa60 <vPortYield>
    11fe:	77 cf       	rjmp	.-274    	; 0x10ee <xQueueGenericReceive+0x40>
				}
			}
			else
			{
				/* Try again. */
				prvUnlockQueue( pxQueue );
    1200:	c7 01       	movw	r24, r14
    1202:	0e 94 11 06 	call	0xc22	; 0xc22 <prvUnlockQueue>
				( void ) xTaskResumeAll();
    1206:	0e 94 3e 0e 	call	0x1c7c	; 0x1c7c <xTaskResumeAll>
    120a:	71 cf       	rjmp	.-286    	; 0x10ee <xQueueGenericReceive+0x40>
			}
		}
		else
		{
			prvUnlockQueue( pxQueue );
    120c:	c7 01       	movw	r24, r14
    120e:	0e 94 11 06 	call	0xc22	; 0xc22 <prvUnlockQueue>
			( void ) xTaskResumeAll();
    1212:	0e 94 3e 0e 	call	0x1c7c	; 0x1c7c <xTaskResumeAll>

			if( prvIsQueueEmpty( pxQueue ) != pdFALSE )
    1216:	c7 01       	movw	r24, r14
    1218:	0e 94 e9 05 	call	0xbd2	; 0xbd2 <prvIsQueueEmpty>
    121c:	88 23       	and	r24, r24
    121e:	09 f4       	brne	.+2      	; 0x1222 <xQueueGenericReceive+0x174>
    1220:	66 cf       	rjmp	.-308    	; 0x10ee <xQueueGenericReceive+0x40>
			{
				traceQUEUE_RECEIVE_FAILED( pxQueue );
				return errQUEUE_EMPTY;
    1222:	80 e0       	ldi	r24, 0x00	; 0
			{
				mtCOVERAGE_TEST_MARKER();
			}
		}
	}
}
    1224:	0f 90       	pop	r0
    1226:	0f 90       	pop	r0
    1228:	0f 90       	pop	r0
    122a:	0f 90       	pop	r0
    122c:	0f 90       	pop	r0
    122e:	df 91       	pop	r29
    1230:	cf 91       	pop	r28
    1232:	1f 91       	pop	r17
    1234:	0f 91       	pop	r16
    1236:	ff 90       	pop	r15
    1238:	ef 90       	pop	r14
    123a:	df 90       	pop	r13
    123c:	cf 90       	pop	r12
    123e:	bf 90       	pop	r11
    1240:	af 90       	pop	r10
    1242:	9f 90       	pop	r9
    1244:	8f 90       	pop	r8
    1246:	08 95       	ret

00001248 <xQueueReceiveFromISR>:
/*-----------------------------------------------------------*/

BaseType_t xQueueReceiveFromISR( QueueHandle_t xQueue, void * const pvBuffer, BaseType_t * const pxHigherPriorityTaskWoken )
{
    1248:	ef 92       	push	r14
    124a:	ff 92       	push	r15
    124c:	0f 93       	push	r16
    124e:	1f 93       	push	r17
    1250:	cf 93       	push	r28
    1252:	df 93       	push	r29
    1254:	8c 01       	movw	r16, r24
    1256:	7a 01       	movw	r14, r20
	link: http://www.freertos.org/RTOS-Cortex-M3-M4.html */
	portASSERT_IF_INTERRUPT_PRIORITY_INVALID();

	uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
	{
		const UBaseType_t uxMessagesWaiting = pxQueue->uxMessagesWaiting;
    1258:	fc 01       	movw	r30, r24
    125a:	c2 8d       	ldd	r28, Z+26	; 0x1a

		/* Cannot block in an ISR, so check there is data available. */
		if( uxMessagesWaiting > ( UBaseType_t ) 0 )
    125c:	cc 23       	and	r28, r28
    125e:	e9 f0       	breq	.+58     	; 0x129a <xQueueReceiveFromISR+0x52>
		{
			const int8_t cRxLock = pxQueue->cRxLock;
    1260:	d5 8d       	ldd	r29, Z+29	; 0x1d

			traceQUEUE_RECEIVE_FROM_ISR( pxQueue );

			prvCopyDataFromQueue( pxQueue, pvBuffer );
    1262:	0e 94 f4 05 	call	0xbe8	; 0xbe8 <prvCopyDataFromQueue>
			pxQueue->uxMessagesWaiting = uxMessagesWaiting - 1;
    1266:	c1 50       	subi	r28, 0x01	; 1
    1268:	f8 01       	movw	r30, r16
    126a:	c2 8f       	std	Z+26, r28	; 0x1a

			/* If the queue is locked the event list will not be modified.
			Instead update the lock count so the task that unlocks the queue
			will know that an ISR has removed data while the queue was
			locked. */
			if( cRxLock == queueUNLOCKED )
    126c:	df 3f       	cpi	r29, 0xFF	; 255
    126e:	81 f4       	brne	.+32     	; 0x1290 <xQueueReceiveFromISR+0x48>
			{
				if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToSend ) ) == pdFALSE )
    1270:	80 85       	ldd	r24, Z+8	; 0x08
    1272:	88 23       	and	r24, r24
    1274:	a1 f0       	breq	.+40     	; 0x129e <xQueueReceiveFromISR+0x56>
				{
					if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) != pdFALSE )
    1276:	c8 01       	movw	r24, r16
    1278:	08 96       	adiw	r24, 0x08	; 8
    127a:	0e 94 1f 10 	call	0x203e	; 0x203e <xTaskRemoveFromEventList>
    127e:	88 23       	and	r24, r24
    1280:	81 f0       	breq	.+32     	; 0x12a2 <xQueueReceiveFromISR+0x5a>
					{
						/* The task waiting has a higher priority than us so
						force a context switch. */
						if( pxHigherPriorityTaskWoken != NULL )
    1282:	e1 14       	cp	r14, r1
    1284:	f1 04       	cpc	r15, r1
    1286:	79 f0       	breq	.+30     	; 0x12a6 <xQueueReceiveFromISR+0x5e>
						{
							*pxHigherPriorityTaskWoken = pdTRUE;
    1288:	81 e0       	ldi	r24, 0x01	; 1
    128a:	f7 01       	movw	r30, r14
    128c:	80 83       	st	Z, r24
    128e:	0c c0       	rjmp	.+24     	; 0x12a8 <xQueueReceiveFromISR+0x60>
			}
			else
			{
				/* Increment the lock count so the task that unlocks the queue
				knows that data was removed while it was locked. */
				pxQueue->cRxLock = ( int8_t ) ( cRxLock + 1 );
    1290:	df 5f       	subi	r29, 0xFF	; 255
    1292:	f8 01       	movw	r30, r16
    1294:	d5 8f       	std	Z+29, r29	; 0x1d
			}

			xReturn = pdPASS;
    1296:	81 e0       	ldi	r24, 0x01	; 1
    1298:	07 c0       	rjmp	.+14     	; 0x12a8 <xQueueReceiveFromISR+0x60>
		}
		else
		{
			xReturn = pdFAIL;
    129a:	80 e0       	ldi	r24, 0x00	; 0
    129c:	05 c0       	rjmp	.+10     	; 0x12a8 <xQueueReceiveFromISR+0x60>
				/* Increment the lock count so the task that unlocks the queue
				knows that data was removed while it was locked. */
				pxQueue->cRxLock = ( int8_t ) ( cRxLock + 1 );
			}

			xReturn = pdPASS;
    129e:	81 e0       	ldi	r24, 0x01	; 1
    12a0:	03 c0       	rjmp	.+6      	; 0x12a8 <xQueueReceiveFromISR+0x60>
    12a2:	81 e0       	ldi	r24, 0x01	; 1
    12a4:	01 c0       	rjmp	.+2      	; 0x12a8 <xQueueReceiveFromISR+0x60>
    12a6:	81 e0       	ldi	r24, 0x01	; 1
		}
	}
	portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );

	return xReturn;
}
    12a8:	df 91       	pop	r29
    12aa:	cf 91       	pop	r28
    12ac:	1f 91       	pop	r17
    12ae:	0f 91       	pop	r16
    12b0:	ff 90       	pop	r15
    12b2:	ef 90       	pop	r14
    12b4:	08 95       	ret

000012b6 <xQueuePeekFromISR>:
/*-----------------------------------------------------------*/

BaseType_t xQueuePeekFromISR( QueueHandle_t xQueue,  void * const pvBuffer )
{
    12b6:	0f 93       	push	r16
    12b8:	1f 93       	push	r17
    12ba:	cf 93       	push	r28
    12bc:	df 93       	push	r29
    12be:	ec 01       	movw	r28, r24
	portASSERT_IF_INTERRUPT_PRIORITY_INVALID();

	uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
	{
		/* Cannot block in an ISR, so check there is data available. */
		if( pxQueue->uxMessagesWaiting > ( UBaseType_t ) 0 )
    12c0:	8a 8d       	ldd	r24, Y+26	; 0x1a
    12c2:	88 23       	and	r24, r24
    12c4:	49 f0       	breq	.+18     	; 0x12d8 <xQueuePeekFromISR+0x22>
		{
			traceQUEUE_PEEK_FROM_ISR( pxQueue );

			/* Remember the read position so it can be reset as nothing is
			actually being removed from the queue. */
			pcOriginalReadPosition = pxQueue->u.pcReadFrom;
    12c6:	0e 81       	ldd	r16, Y+6	; 0x06
    12c8:	1f 81       	ldd	r17, Y+7	; 0x07
			prvCopyDataFromQueue( pxQueue, pvBuffer );
    12ca:	ce 01       	movw	r24, r28
    12cc:	0e 94 f4 05 	call	0xbe8	; 0xbe8 <prvCopyDataFromQueue>
			pxQueue->u.pcReadFrom = pcOriginalReadPosition;
    12d0:	1f 83       	std	Y+7, r17	; 0x07
    12d2:	0e 83       	std	Y+6, r16	; 0x06

			xReturn = pdPASS;
    12d4:	81 e0       	ldi	r24, 0x01	; 1
    12d6:	01 c0       	rjmp	.+2      	; 0x12da <xQueuePeekFromISR+0x24>
		}
		else
		{
			xReturn = pdFAIL;
    12d8:	80 e0       	ldi	r24, 0x00	; 0
		}
	}
	portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );

	return xReturn;
}
    12da:	df 91       	pop	r29
    12dc:	cf 91       	pop	r28
    12de:	1f 91       	pop	r17
    12e0:	0f 91       	pop	r16
    12e2:	08 95       	ret

000012e4 <uxQueueMessagesWaiting>:
{
UBaseType_t uxReturn;

	configASSERT( xQueue );

	taskENTER_CRITICAL();
    12e4:	0f b6       	in	r0, 0x3f	; 63
    12e6:	f8 94       	cli
    12e8:	0f 92       	push	r0
	{
		uxReturn = ( ( Queue_t * ) xQueue )->uxMessagesWaiting;
    12ea:	fc 01       	movw	r30, r24
    12ec:	82 8d       	ldd	r24, Z+26	; 0x1a
	}
	taskEXIT_CRITICAL();
    12ee:	0f 90       	pop	r0
    12f0:	0f be       	out	0x3f, r0	; 63

	return uxReturn;
} /*lint !e818 Pointer cannot be declared const as xQueue is a typedef not pointer. */
    12f2:	08 95       	ret

000012f4 <uxQueueSpacesAvailable>:
/*-----------------------------------------------------------*/

UBaseType_t uxQueueSpacesAvailable( const QueueHandle_t xQueue )
{
    12f4:	fc 01       	movw	r30, r24
Queue_t *pxQueue;

	pxQueue = ( Queue_t * ) xQueue;
	configASSERT( pxQueue );

	taskENTER_CRITICAL();
    12f6:	0f b6       	in	r0, 0x3f	; 63
    12f8:	f8 94       	cli
    12fa:	0f 92       	push	r0
	{
		uxReturn = pxQueue->uxLength - pxQueue->uxMessagesWaiting;
    12fc:	92 8d       	ldd	r25, Z+26	; 0x1a
	}
	taskEXIT_CRITICAL();
    12fe:	0f 90       	pop	r0
    1300:	0f be       	out	0x3f, r0	; 63
	pxQueue = ( Queue_t * ) xQueue;
	configASSERT( pxQueue );

	taskENTER_CRITICAL();
	{
		uxReturn = pxQueue->uxLength - pxQueue->uxMessagesWaiting;
    1302:	83 8d       	ldd	r24, Z+27	; 0x1b
	}
	taskEXIT_CRITICAL();

	return uxReturn;
} /*lint !e818 Pointer cannot be declared const as xQueue is a typedef not pointer. */
    1304:	89 1b       	sub	r24, r25
    1306:	08 95       	ret

00001308 <uxQueueMessagesWaitingFromISR>:
{
UBaseType_t uxReturn;

	configASSERT( xQueue );

	uxReturn = ( ( Queue_t * ) xQueue )->uxMessagesWaiting;
    1308:	fc 01       	movw	r30, r24
    130a:	82 8d       	ldd	r24, Z+26	; 0x1a

	return uxReturn;
} /*lint !e818 Pointer cannot be declared const as xQueue is a typedef not pointer. */
    130c:	08 95       	ret

0000130e <xQueueIsQueueEmptyFromISR>:
BaseType_t xQueueIsQueueEmptyFromISR( const QueueHandle_t xQueue )
{
BaseType_t xReturn;

	configASSERT( xQueue );
	if( ( ( Queue_t * ) xQueue )->uxMessagesWaiting == ( UBaseType_t ) 0 )
    130e:	fc 01       	movw	r30, r24
    1310:	92 8d       	ldd	r25, Z+26	; 0x1a
	{
		xReturn = pdTRUE;
    1312:	81 e0       	ldi	r24, 0x01	; 1
    1314:	91 11       	cpse	r25, r1
    1316:	80 e0       	ldi	r24, 0x00	; 0
	{
		xReturn = pdFALSE;
	}

	return xReturn;
} /*lint !e818 xQueue could not be pointer to const because it is a typedef. */
    1318:	08 95       	ret

0000131a <xQueueIsQueueFullFromISR>:
	return xReturn;
}
/*-----------------------------------------------------------*/

BaseType_t xQueueIsQueueFullFromISR( const QueueHandle_t xQueue )
{
    131a:	fc 01       	movw	r30, r24
BaseType_t xReturn;

	configASSERT( xQueue );
	if( ( ( Queue_t * ) xQueue )->uxMessagesWaiting == ( ( Queue_t * ) xQueue )->uxLength )
    131c:	22 8d       	ldd	r18, Z+26	; 0x1a
	{
		xReturn = pdTRUE;
    131e:	81 e0       	ldi	r24, 0x01	; 1
    1320:	93 8d       	ldd	r25, Z+27	; 0x1b
    1322:	29 13       	cpse	r18, r25
    1324:	80 e0       	ldi	r24, 0x00	; 0
	{
		xReturn = pdFALSE;
	}

	return xReturn;
} /*lint !e818 xQueue could not be pointer to const because it is a typedef. */
    1326:	08 95       	ret

00001328 <vQueueAddToRegistry>:
/*-----------------------------------------------------------*/

#if ( configQUEUE_REGISTRY_SIZE > 0 )

	void vQueueAddToRegistry( QueueHandle_t xQueue, const char *pcQueueName ) /*lint !e971 Unqualified char types are allowed for strings and single characters only. */
	{
    1328:	dc 01       	movw	r26, r24

		/* See if there is an empty space in the registry.  A NULL name denotes
		a free slot. */
		for( ux = ( UBaseType_t ) 0U; ux < ( UBaseType_t ) configQUEUE_REGISTRY_SIZE; ux++ )
		{
			if( xQueueRegistry[ ux ].pcQueueName == NULL )
    132a:	80 91 0c 04 	lds	r24, 0x040C
    132e:	90 91 0d 04 	lds	r25, 0x040D
    1332:	00 97       	sbiw	r24, 0x00	; 0
    1334:	51 f0       	breq	.+20     	; 0x134a <vQueueAddToRegistry+0x22>
    1336:	e0 e1       	ldi	r30, 0x10	; 16
    1338:	f4 e0       	ldi	r31, 0x04	; 4
    133a:	21 e0       	ldi	r18, 0x01	; 1
    133c:	30 e0       	ldi	r19, 0x00	; 0
    133e:	a9 01       	movw	r20, r18
    1340:	80 81       	ld	r24, Z
    1342:	91 81       	ldd	r25, Z+1	; 0x01
    1344:	00 97       	sbiw	r24, 0x00	; 0
    1346:	79 f4       	brne	.+30     	; 0x1366 <vQueueAddToRegistry+0x3e>
    1348:	02 c0       	rjmp	.+4      	; 0x134e <vQueueAddToRegistry+0x26>
    134a:	40 e0       	ldi	r20, 0x00	; 0
    134c:	50 e0       	ldi	r21, 0x00	; 0
			{
				/* Store the information on this queue. */
				xQueueRegistry[ ux ].pcQueueName = pcQueueName;
    134e:	fa 01       	movw	r30, r20
    1350:	ee 0f       	add	r30, r30
    1352:	ff 1f       	adc	r31, r31
    1354:	ee 0f       	add	r30, r30
    1356:	ff 1f       	adc	r31, r31
    1358:	e4 5f       	subi	r30, 0xF4	; 244
    135a:	fb 4f       	sbci	r31, 0xFB	; 251
    135c:	71 83       	std	Z+1, r23	; 0x01
    135e:	60 83       	st	Z, r22
				xQueueRegistry[ ux ].xHandle = xQueue;
    1360:	b3 83       	std	Z+3, r27	; 0x03
    1362:	a2 83       	std	Z+2, r26	; 0x02

				traceQUEUE_REGISTRY_ADD( xQueue, pcQueueName );
				break;
    1364:	08 95       	ret
    1366:	2f 5f       	subi	r18, 0xFF	; 255
    1368:	3f 4f       	sbci	r19, 0xFF	; 255
    136a:	34 96       	adiw	r30, 0x04	; 4
	{
	UBaseType_t ux;

		/* See if there is an empty space in the registry.  A NULL name denotes
		a free slot. */
		for( ux = ( UBaseType_t ) 0U; ux < ( UBaseType_t ) configQUEUE_REGISTRY_SIZE; ux++ )
    136c:	28 30       	cpi	r18, 0x08	; 8
    136e:	31 05       	cpc	r19, r1
    1370:	31 f7       	brne	.-52     	; 0x133e <vQueueAddToRegistry+0x16>
    1372:	08 95       	ret

00001374 <pcQueueGetName>:
/*-----------------------------------------------------------*/

#if ( configQUEUE_REGISTRY_SIZE > 0 )

	const char *pcQueueGetName( QueueHandle_t xQueue ) /*lint !e971 Unqualified char types are allowed for strings and single characters only. */
	{
    1374:	ac 01       	movw	r20, r24

		/* Note there is nothing here to protect against another task adding or
		removing entries from the registry while it is being searched. */
		for( ux = ( UBaseType_t ) 0U; ux < ( UBaseType_t ) configQUEUE_REGISTRY_SIZE; ux++ )
		{
			if( xQueueRegistry[ ux ].xHandle == xQueue )
    1376:	80 91 0e 04 	lds	r24, 0x040E
    137a:	90 91 0f 04 	lds	r25, 0x040F
    137e:	84 17       	cp	r24, r20
    1380:	95 07       	cpc	r25, r21
    1382:	59 f0       	breq	.+22     	; 0x139a <pcQueueGetName+0x26>
    1384:	e2 e1       	ldi	r30, 0x12	; 18
    1386:	f4 e0       	ldi	r31, 0x04	; 4
    1388:	21 e0       	ldi	r18, 0x01	; 1
    138a:	30 e0       	ldi	r19, 0x00	; 0
    138c:	b9 01       	movw	r22, r18
    138e:	80 81       	ld	r24, Z
    1390:	91 81       	ldd	r25, Z+1	; 0x01
    1392:	84 17       	cp	r24, r20
    1394:	95 07       	cpc	r25, r21
    1396:	69 f4       	brne	.+26     	; 0x13b2 <pcQueueGetName+0x3e>
    1398:	02 c0       	rjmp	.+4      	; 0x139e <pcQueueGetName+0x2a>
    139a:	60 e0       	ldi	r22, 0x00	; 0
    139c:	70 e0       	ldi	r23, 0x00	; 0
			{
				pcReturn = xQueueRegistry[ ux ].pcQueueName;
    139e:	fb 01       	movw	r30, r22
    13a0:	ee 0f       	add	r30, r30
    13a2:	ff 1f       	adc	r31, r31
    13a4:	ee 0f       	add	r30, r30
    13a6:	ff 1f       	adc	r31, r31
    13a8:	e4 5f       	subi	r30, 0xF4	; 244
    13aa:	fb 4f       	sbci	r31, 0xFB	; 251
    13ac:	80 81       	ld	r24, Z
    13ae:	91 81       	ldd	r25, Z+1	; 0x01
				break;
    13b0:	08 95       	ret
    13b2:	2f 5f       	subi	r18, 0xFF	; 255
    13b4:	3f 4f       	sbci	r19, 0xFF	; 255
    13b6:	34 96       	adiw	r30, 0x04	; 4
	UBaseType_t ux;
	const char *pcReturn = NULL; /*lint !e971 Unqualified char types are allowed for strings and single characters only. */

		/* Note there is nothing here to protect against another task adding or
		removing entries from the registry while it is being searched. */
		for( ux = ( UBaseType_t ) 0U; ux < ( UBaseType_t ) configQUEUE_REGISTRY_SIZE; ux++ )
    13b8:	28 30       	cpi	r18, 0x08	; 8
    13ba:	31 05       	cpc	r19, r1
    13bc:	39 f7       	brne	.-50     	; 0x138c <pcQueueGetName+0x18>
#if ( configQUEUE_REGISTRY_SIZE > 0 )

	const char *pcQueueGetName( QueueHandle_t xQueue ) /*lint !e971 Unqualified char types are allowed for strings and single characters only. */
	{
	UBaseType_t ux;
	const char *pcReturn = NULL; /*lint !e971 Unqualified char types are allowed for strings and single characters only. */
    13be:	80 e0       	ldi	r24, 0x00	; 0
    13c0:	90 e0       	ldi	r25, 0x00	; 0
				mtCOVERAGE_TEST_MARKER();
			}
		}

		return pcReturn;
	}
    13c2:	08 95       	ret

000013c4 <vQueueUnregisterQueue>:
/*-----------------------------------------------------------*/

#if ( configQUEUE_REGISTRY_SIZE > 0 )

	void vQueueUnregisterQueue( QueueHandle_t xQueue )
	{
    13c4:	ac 01       	movw	r20, r24

		/* See if the handle of the queue being unregistered in actually in the
		registry. */
		for( ux = ( UBaseType_t ) 0U; ux < ( UBaseType_t ) configQUEUE_REGISTRY_SIZE; ux++ )
		{
			if( xQueueRegistry[ ux ].xHandle == xQueue )
    13c6:	80 91 0e 04 	lds	r24, 0x040E
    13ca:	90 91 0f 04 	lds	r25, 0x040F
    13ce:	84 17       	cp	r24, r20
    13d0:	95 07       	cpc	r25, r21
    13d2:	59 f0       	breq	.+22     	; 0x13ea <vQueueUnregisterQueue+0x26>
    13d4:	e2 e1       	ldi	r30, 0x12	; 18
    13d6:	f4 e0       	ldi	r31, 0x04	; 4
    13d8:	21 e0       	ldi	r18, 0x01	; 1
    13da:	30 e0       	ldi	r19, 0x00	; 0
    13dc:	b9 01       	movw	r22, r18
    13de:	80 81       	ld	r24, Z
    13e0:	91 81       	ldd	r25, Z+1	; 0x01
    13e2:	84 17       	cp	r24, r20
    13e4:	95 07       	cpc	r25, r21
    13e6:	79 f4       	brne	.+30     	; 0x1406 <vQueueUnregisterQueue+0x42>
    13e8:	02 c0       	rjmp	.+4      	; 0x13ee <vQueueUnregisterQueue+0x2a>
    13ea:	60 e0       	ldi	r22, 0x00	; 0
    13ec:	70 e0       	ldi	r23, 0x00	; 0
			{
				/* Set the name to NULL to show that this slot if free again. */
				xQueueRegistry[ ux ].pcQueueName = NULL;
    13ee:	fb 01       	movw	r30, r22
    13f0:	ee 0f       	add	r30, r30
    13f2:	ff 1f       	adc	r31, r31
    13f4:	ee 0f       	add	r30, r30
    13f6:	ff 1f       	adc	r31, r31
    13f8:	e4 5f       	subi	r30, 0xF4	; 244
    13fa:	fb 4f       	sbci	r31, 0xFB	; 251
    13fc:	11 82       	std	Z+1, r1	; 0x01
    13fe:	10 82       	st	Z, r1

				/* Set the handle to NULL to ensure the same queue handle cannot
				appear in the registry twice if it is added, removed, then
				added again. */
				xQueueRegistry[ ux ].xHandle = ( QueueHandle_t ) 0;
    1400:	13 82       	std	Z+3, r1	; 0x03
    1402:	12 82       	std	Z+2, r1	; 0x02
				break;
    1404:	08 95       	ret
    1406:	2f 5f       	subi	r18, 0xFF	; 255
    1408:	3f 4f       	sbci	r19, 0xFF	; 255
    140a:	34 96       	adiw	r30, 0x04	; 4
	{
	UBaseType_t ux;

		/* See if the handle of the queue being unregistered in actually in the
		registry. */
		for( ux = ( UBaseType_t ) 0U; ux < ( UBaseType_t ) configQUEUE_REGISTRY_SIZE; ux++ )
    140c:	28 30       	cpi	r18, 0x08	; 8
    140e:	31 05       	cpc	r19, r1
    1410:	29 f7       	brne	.-54     	; 0x13dc <vQueueUnregisterQueue+0x18>
    1412:	08 95       	ret

00001414 <vQueueDelete>:
	return uxReturn;
} /*lint !e818 Pointer cannot be declared const as xQueue is a typedef not pointer. */
/*-----------------------------------------------------------*/

void vQueueDelete( QueueHandle_t xQueue )
{
    1414:	cf 93       	push	r28
    1416:	df 93       	push	r29
    1418:	ec 01       	movw	r28, r24
	configASSERT( pxQueue );
	traceQUEUE_DELETE( pxQueue );

	#if ( configQUEUE_REGISTRY_SIZE > 0 )
	{
		vQueueUnregisterQueue( pxQueue );
    141a:	0e 94 e2 09 	call	0x13c4	; 0x13c4 <vQueueUnregisterQueue>

	#if( ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) && ( configSUPPORT_STATIC_ALLOCATION == 0 ) )
	{
		/* The queue can only have been allocated dynamically - free it
		again. */
		vPortFree( pxQueue );
    141e:	ce 01       	movw	r24, r28
    1420:	0e 94 a6 03 	call	0x74c	; 0x74c <vPortFree>
		/* The queue must have been statically allocated, so is not going to be
		deleted.  Avoid compiler warnings about the unused parameter. */
		( void ) pxQueue;
	}
	#endif /* configSUPPORT_DYNAMIC_ALLOCATION */
}
    1424:	df 91       	pop	r29
    1426:	cf 91       	pop	r28
    1428:	08 95       	ret

0000142a <prvTaskIsTaskSuspended>:
/*-----------------------------------------------------------*/

#if ( INCLUDE_vTaskSuspend == 1 )

	static BaseType_t prvTaskIsTaskSuspended( const TaskHandle_t xTask )
	{
    142a:	fc 01       	movw	r30, r24

		/* It does not make sense to check if the calling task is suspended. */
		configASSERT( xTask );

		/* Is the task being resumed actually in the suspended list? */
		if( listIS_CONTAINED_WITHIN( &xSuspendedTaskList, &( pxTCB->xStateListItem ) ) != pdFALSE )
    142c:	82 85       	ldd	r24, Z+10	; 0x0a
    142e:	93 85       	ldd	r25, Z+11	; 0x0b
    1430:	23 e0       	ldi	r18, 0x03	; 3
    1432:	8f 3f       	cpi	r24, 0xFF	; 255
    1434:	92 07       	cpc	r25, r18
    1436:	61 f4       	brne	.+24     	; 0x1450 <prvTaskIsTaskSuspended+0x26>
		{
			/* Has the task already been resumed from within an ISR? */
			if( listIS_CONTAINED_WITHIN( &xPendingReadyList, &( pxTCB->xEventListItem ) ) == pdFALSE )
    1438:	24 89       	ldd	r18, Z+20	; 0x14
    143a:	35 89       	ldd	r19, Z+21	; 0x15
    143c:	83 e0       	ldi	r24, 0x03	; 3
    143e:	2d 3e       	cpi	r18, 0xED	; 237
    1440:	38 07       	cpc	r19, r24
    1442:	41 f0       	breq	.+16     	; 0x1454 <prvTaskIsTaskSuspended+0x2a>

#if ( INCLUDE_vTaskSuspend == 1 )

	static BaseType_t prvTaskIsTaskSuspended( const TaskHandle_t xTask )
	{
	BaseType_t xReturn = pdFALSE;
    1444:	81 e0       	ldi	r24, 0x01	; 1
    1446:	21 15       	cp	r18, r1
    1448:	31 05       	cpc	r19, r1
    144a:	29 f0       	breq	.+10     	; 0x1456 <prvTaskIsTaskSuspended+0x2c>
    144c:	80 e0       	ldi	r24, 0x00	; 0
    144e:	08 95       	ret
    1450:	80 e0       	ldi	r24, 0x00	; 0
    1452:	08 95       	ret
    1454:	80 e0       	ldi	r24, 0x00	; 0
		{
			mtCOVERAGE_TEST_MARKER();
		}

		return xReturn;
	} /*lint !e818 xTask cannot be a pointer to const because it is a typedef. */
    1456:	08 95       	ret

00001458 <prvResetNextTaskUnblockTime>:

static void prvResetNextTaskUnblockTime( void )
{
TCB_t *pxTCB;

	if( listLIST_IS_EMPTY( pxDelayedTaskList ) != pdFALSE )
    1458:	e0 91 ab 03 	lds	r30, 0x03AB
    145c:	f0 91 ac 03 	lds	r31, 0x03AC
    1460:	80 81       	ld	r24, Z
    1462:	88 23       	and	r24, r24
    1464:	39 f4       	brne	.+14     	; 0x1474 <prvResetNextTaskUnblockTime+0x1c>
	{
		/* The new current delayed list is empty.  Set xNextTaskUnblockTime to
		the maximum possible value so it is	extremely unlikely that the
		if( xTickCount >= xNextTaskUnblockTime ) test will pass until
		there is an item in the delayed list. */
		xNextTaskUnblockTime = portMAX_DELAY;
    1466:	8f ef       	ldi	r24, 0xFF	; 255
    1468:	9f ef       	ldi	r25, 0xFF	; 255
    146a:	90 93 9f 03 	sts	0x039F, r25
    146e:	80 93 9e 03 	sts	0x039E, r24
    1472:	08 95       	ret
	{
		/* The new current delayed list is not empty, get the value of
		the item at the head of the delayed list.  This is the time at
		which the task at the head of the delayed list should be removed
		from the Blocked state. */
		( pxTCB ) = ( TCB_t * ) listGET_OWNER_OF_HEAD_ENTRY( pxDelayedTaskList );
    1474:	e0 91 ab 03 	lds	r30, 0x03AB
    1478:	f0 91 ac 03 	lds	r31, 0x03AC
    147c:	05 80       	ldd	r0, Z+5	; 0x05
    147e:	f6 81       	ldd	r31, Z+6	; 0x06
    1480:	e0 2d       	mov	r30, r0
		xNextTaskUnblockTime = listGET_LIST_ITEM_VALUE( &( ( pxTCB )->xStateListItem ) );
    1482:	06 80       	ldd	r0, Z+6	; 0x06
    1484:	f7 81       	ldd	r31, Z+7	; 0x07
    1486:	e0 2d       	mov	r30, r0
    1488:	82 81       	ldd	r24, Z+2	; 0x02
    148a:	93 81       	ldd	r25, Z+3	; 0x03
    148c:	90 93 9f 03 	sts	0x039F, r25
    1490:	80 93 9e 03 	sts	0x039E, r24
    1494:	08 95       	ret

00001496 <prvAddCurrentTaskToDelayedList>:
#endif /* configUSE_TASK_NOTIFICATIONS */
/*-----------------------------------------------------------*/


static void prvAddCurrentTaskToDelayedList( TickType_t xTicksToWait, const BaseType_t xCanBlockIndefinitely )
{
    1496:	ef 92       	push	r14
    1498:	ff 92       	push	r15
    149a:	1f 93       	push	r17
    149c:	cf 93       	push	r28
    149e:	df 93       	push	r29
    14a0:	ec 01       	movw	r28, r24
    14a2:	16 2f       	mov	r17, r22
TickType_t xTimeToWake;
const TickType_t xConstTickCount = xTickCount;
    14a4:	e0 90 a5 03 	lds	r14, 0x03A5
    14a8:	f0 90 a6 03 	lds	r15, 0x03A6
	}
	#endif

	/* Remove the task from the ready list before adding it to the blocked list
	as the same list item is used for both lists. */
	if( uxListRemove( &( pxCurrentTCB->xStateListItem ) ) == ( UBaseType_t ) 0 )
    14ac:	80 91 9b 03 	lds	r24, 0x039B
    14b0:	90 91 9c 03 	lds	r25, 0x039C
    14b4:	02 96       	adiw	r24, 0x02	; 2
    14b6:	0e 94 42 04 	call	0x884	; 0x884 <uxListRemove>
		mtCOVERAGE_TEST_MARKER();
	}

	#if ( INCLUDE_vTaskSuspend == 1 )
	{
		if( ( xTicksToWait == portMAX_DELAY ) && ( xCanBlockIndefinitely != pdFALSE ) )
    14ba:	8f ef       	ldi	r24, 0xFF	; 255
    14bc:	cf 3f       	cpi	r28, 0xFF	; 255
    14be:	d8 07       	cpc	r29, r24
    14c0:	69 f4       	brne	.+26     	; 0x14dc <prvAddCurrentTaskToDelayedList+0x46>
    14c2:	11 23       	and	r17, r17
    14c4:	59 f0       	breq	.+22     	; 0x14dc <prvAddCurrentTaskToDelayedList+0x46>
		{
			/* Add the task to the suspended task list instead of a delayed task
			list to ensure it is not woken by a timing event.  It will block
			indefinitely. */
			vListInsertEnd( &xSuspendedTaskList, &( pxCurrentTCB->xStateListItem ) );
    14c6:	60 91 9b 03 	lds	r22, 0x039B
    14ca:	70 91 9c 03 	lds	r23, 0x039C
    14ce:	6e 5f       	subi	r22, 0xFE	; 254
    14d0:	7f 4f       	sbci	r23, 0xFF	; 255
    14d2:	8f ef       	ldi	r24, 0xFF	; 255
    14d4:	93 e0       	ldi	r25, 0x03	; 3
    14d6:	0e 94 f1 03 	call	0x7e2	; 0x7e2 <vListInsertEnd>
    14da:	2f c0       	rjmp	.+94     	; 0x153a <prvAddCurrentTaskToDelayedList+0xa4>
		else
		{
			/* Calculate the time at which the task should be woken if the event
			does not occur.  This may overflow but this doesn't matter, the
			kernel will manage it correctly. */
			xTimeToWake = xConstTickCount + xTicksToWait;
    14dc:	ce 0d       	add	r28, r14
    14de:	df 1d       	adc	r29, r15

			/* The list item will be inserted in wake time order. */
			listSET_LIST_ITEM_VALUE( &( pxCurrentTCB->xStateListItem ), xTimeToWake );
    14e0:	e0 91 9b 03 	lds	r30, 0x039B
    14e4:	f0 91 9c 03 	lds	r31, 0x039C
    14e8:	d3 83       	std	Z+3, r29	; 0x03
    14ea:	c2 83       	std	Z+2, r28	; 0x02

			if( xTimeToWake < xConstTickCount )
    14ec:	ce 15       	cp	r28, r14
    14ee:	df 05       	cpc	r29, r15
    14f0:	68 f4       	brcc	.+26     	; 0x150c <prvAddCurrentTaskToDelayedList+0x76>
			{
				/* Wake time has overflowed.  Place this item in the overflow
				list. */
				vListInsert( pxOverflowDelayedTaskList, &( pxCurrentTCB->xStateListItem ) );
    14f2:	80 91 a9 03 	lds	r24, 0x03A9
    14f6:	90 91 aa 03 	lds	r25, 0x03AA
    14fa:	60 91 9b 03 	lds	r22, 0x039B
    14fe:	70 91 9c 03 	lds	r23, 0x039C
    1502:	6e 5f       	subi	r22, 0xFE	; 254
    1504:	7f 4f       	sbci	r23, 0xFF	; 255
    1506:	0e 94 10 04 	call	0x820	; 0x820 <vListInsert>
    150a:	17 c0       	rjmp	.+46     	; 0x153a <prvAddCurrentTaskToDelayedList+0xa4>
			}
			else
			{
				/* The wake time has not overflowed, so the current block list
				is used. */
				vListInsert( pxDelayedTaskList, &( pxCurrentTCB->xStateListItem ) );
    150c:	80 91 ab 03 	lds	r24, 0x03AB
    1510:	90 91 ac 03 	lds	r25, 0x03AC
    1514:	60 91 9b 03 	lds	r22, 0x039B
    1518:	70 91 9c 03 	lds	r23, 0x039C
    151c:	6e 5f       	subi	r22, 0xFE	; 254
    151e:	7f 4f       	sbci	r23, 0xFF	; 255
    1520:	0e 94 10 04 	call	0x820	; 0x820 <vListInsert>

				/* If the task entering the blocked state was placed at the
				head of the list of blocked tasks then xNextTaskUnblockTime
				needs to be updated too. */
				if( xTimeToWake < xNextTaskUnblockTime )
    1524:	80 91 9e 03 	lds	r24, 0x039E
    1528:	90 91 9f 03 	lds	r25, 0x039F
    152c:	c8 17       	cp	r28, r24
    152e:	d9 07       	cpc	r29, r25
    1530:	20 f4       	brcc	.+8      	; 0x153a <prvAddCurrentTaskToDelayedList+0xa4>
				{
					xNextTaskUnblockTime = xTimeToWake;
    1532:	d0 93 9f 03 	sts	0x039F, r29
    1536:	c0 93 9e 03 	sts	0x039E, r28

		/* Avoid compiler warning when INCLUDE_vTaskSuspend is not 1. */
		( void ) xCanBlockIndefinitely;
	}
	#endif /* INCLUDE_vTaskSuspend */
}
    153a:	df 91       	pop	r29
    153c:	cf 91       	pop	r28
    153e:	1f 91       	pop	r17
    1540:	ff 90       	pop	r15
    1542:	ef 90       	pop	r14
    1544:	08 95       	ret

00001546 <prvDeleteTCB>:
/*-----------------------------------------------------------*/

#if ( INCLUDE_vTaskDelete == 1 )

	static void prvDeleteTCB( TCB_t *pxTCB )
	{
    1546:	cf 93       	push	r28
    1548:	df 93       	push	r29
    154a:	ec 01       	movw	r28, r24

		#if( ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) && ( configSUPPORT_STATIC_ALLOCATION == 0 ) && ( portUSING_MPU_WRAPPERS == 0 ) )
		{
			/* The task can only have been allocated dynamically - free both
			the stack and TCB. */
			vPortFree( pxTCB->pxStack );
    154c:	8f 89       	ldd	r24, Y+23	; 0x17
    154e:	98 8d       	ldd	r25, Y+24	; 0x18
    1550:	0e 94 a6 03 	call	0x74c	; 0x74c <vPortFree>
			vPortFree( pxTCB );
    1554:	ce 01       	movw	r24, r28
    1556:	0e 94 a6 03 	call	0x74c	; 0x74c <vPortFree>
				configASSERT( pxTCB->ucStaticallyAllocated == tskSTATICALLY_ALLOCATED_STACK_AND_TCB	)
				mtCOVERAGE_TEST_MARKER();
			}
		}
		#endif /* configSUPPORT_DYNAMIC_ALLOCATION */
	}
    155a:	df 91       	pop	r29
    155c:	cf 91       	pop	r28
    155e:	08 95       	ret

00001560 <xTaskCreate>:
							const char * const pcName,
							const uint16_t usStackDepth,
							void * const pvParameters,
							UBaseType_t uxPriority,
							TaskHandle_t * const pxCreatedTask ) /*lint !e971 Unqualified char types are allowed for strings and single characters only. */
	{
    1560:	2f 92       	push	r2
    1562:	3f 92       	push	r3
    1564:	4f 92       	push	r4
    1566:	5f 92       	push	r5
    1568:	6f 92       	push	r6
    156a:	7f 92       	push	r7
    156c:	8f 92       	push	r8
    156e:	9f 92       	push	r9
    1570:	af 92       	push	r10
    1572:	bf 92       	push	r11
    1574:	df 92       	push	r13
    1576:	ef 92       	push	r14
    1578:	ff 92       	push	r15
    157a:	0f 93       	push	r16
    157c:	1f 93       	push	r17
    157e:	cf 93       	push	r28
    1580:	df 93       	push	r29
    1582:	3c 01       	movw	r6, r24
    1584:	5b 01       	movw	r10, r22
    1586:	ea 01       	movw	r28, r20
    1588:	29 01       	movw	r4, r18
    158a:	d0 2e       	mov	r13, r16
    158c:	47 01       	movw	r8, r14
		#else /* portSTACK_GROWTH */
		{
		StackType_t *pxStack;

			/* Allocate space for the stack used by the task being created. */
			pxStack = ( StackType_t * ) pvPortMalloc( ( ( ( size_t ) usStackDepth ) * sizeof( StackType_t ) ) ); /*lint !e961 MISRA exception as the casts are only redundant for some ports. */
    158e:	ca 01       	movw	r24, r20
    1590:	0e 94 06 03 	call	0x60c	; 0x60c <pvPortMalloc>
    1594:	7c 01       	movw	r14, r24

			if( pxStack != NULL )
    1596:	00 97       	sbiw	r24, 0x00	; 0
    1598:	09 f4       	brne	.+2      	; 0x159c <xTaskCreate+0x3c>
    159a:	ed c0       	rjmp	.+474    	; 0x1776 <xTaskCreate+0x216>
			{
				/* Allocate space for the TCB. */
				pxNewTCB = ( TCB_t * ) pvPortMalloc( sizeof( TCB_t ) ); /*lint !e961 MISRA exception as the casts are only redundant for some paths. */
    159c:	8a e2       	ldi	r24, 0x2A	; 42
    159e:	90 e0       	ldi	r25, 0x00	; 0
    15a0:	0e 94 06 03 	call	0x60c	; 0x60c <pvPortMalloc>
    15a4:	8c 01       	movw	r16, r24

				if( pxNewTCB != NULL )
    15a6:	00 97       	sbiw	r24, 0x00	; 0
    15a8:	81 f0       	breq	.+32     	; 0x15ca <xTaskCreate+0x6a>
				{
					/* Store the stack location in the TCB. */
					pxNewTCB->pxStack = pxStack;
    15aa:	fc 01       	movw	r30, r24
    15ac:	f0 8e       	std	Z+24, r15	; 0x18
    15ae:	e7 8a       	std	Z+23, r14	; 0x17
	grows from high memory to low (as per the 80x86) or vice versa.
	portSTACK_GROWTH is used to make the result positive or negative as required
	by the port. */
	#if( portSTACK_GROWTH < 0 )
	{
		pxTopOfStack = pxNewTCB->pxStack + ( ulStackDepth - ( uint32_t ) 1 );
    15b0:	21 97       	sbiw	r28, 0x01	; 1
    15b2:	17 01       	movw	r2, r14
    15b4:	2c 0e       	add	r2, r28
    15b6:	3d 1e       	adc	r3, r29
	#endif /* portSTACK_GROWTH */

	/* Store the task name in the TCB. */
	for( x = ( UBaseType_t ) 0; x < ( UBaseType_t ) configMAX_TASK_NAME_LEN; x++ )
	{
		pxNewTCB->pcTaskName[ x ] = pcName[ x ];
    15b8:	f5 01       	movw	r30, r10
    15ba:	80 81       	ld	r24, Z
    15bc:	f8 01       	movw	r30, r16
    15be:	81 8f       	std	Z+25, r24	; 0x19

		/* Don't copy all configMAX_TASK_NAME_LEN if the string is shorter than
		configMAX_TASK_NAME_LEN characters just in case the memory after the
		string is not accessible (extremely unlikely). */
		if( pcName[ x ] == 0x00 )
    15c0:	f5 01       	movw	r30, r10
    15c2:	80 81       	ld	r24, Z
    15c4:	88 23       	and	r24, r24
    15c6:	31 f4       	brne	.+12     	; 0x15d4 <xTaskCreate+0x74>
    15c8:	13 c0       	rjmp	.+38     	; 0x15f0 <xTaskCreate+0x90>
				}
				else
				{
					/* The stack cannot be used as the TCB was not created.  Free
					it again. */
					vPortFree( pxStack );
    15ca:	c7 01       	movw	r24, r14
    15cc:	0e 94 a6 03 	call	0x74c	; 0x74c <vPortFree>
			prvAddNewTaskToReadyList( pxNewTCB );
			xReturn = pdPASS;
		}
		else
		{
			xReturn = errCOULD_NOT_ALLOCATE_REQUIRED_MEMORY;
    15d0:	8f ef       	ldi	r24, 0xFF	; 255
    15d2:	d6 c0       	rjmp	.+428    	; 0x1780 <xTaskCreate+0x220>
#endif /* portUSING_MPU_WRAPPERS */
/*-----------------------------------------------------------*/

#if( configSUPPORT_DYNAMIC_ALLOCATION == 1 )

	BaseType_t xTaskCreate(	TaskFunction_t pxTaskCode,
    15d4:	e8 01       	movw	r28, r16
    15d6:	6a 96       	adiw	r28, 0x1a	; 26
    15d8:	d5 01       	movw	r26, r10
    15da:	11 96       	adiw	r26, 0x01	; 1
		pxNewTCB->pxEndOfStack = pxNewTCB->pxStack + ( ulStackDepth - ( uint32_t ) 1 );
	}
	#endif /* portSTACK_GROWTH */

	/* Store the task name in the TCB. */
	for( x = ( UBaseType_t ) 0; x < ( UBaseType_t ) configMAX_TASK_NAME_LEN; x++ )
    15dc:	81 e0       	ldi	r24, 0x01	; 1
#endif /* portUSING_MPU_WRAPPERS */
/*-----------------------------------------------------------*/

#if( configSUPPORT_DYNAMIC_ALLOCATION == 1 )

	BaseType_t xTaskCreate(	TaskFunction_t pxTaskCode,
    15de:	fd 01       	movw	r30, r26
	#endif /* portSTACK_GROWTH */

	/* Store the task name in the TCB. */
	for( x = ( UBaseType_t ) 0; x < ( UBaseType_t ) configMAX_TASK_NAME_LEN; x++ )
	{
		pxNewTCB->pcTaskName[ x ] = pcName[ x ];
    15e0:	9d 91       	ld	r25, X+
    15e2:	99 93       	st	Y+, r25

		/* Don't copy all configMAX_TASK_NAME_LEN if the string is shorter than
		configMAX_TASK_NAME_LEN characters just in case the memory after the
		string is not accessible (extremely unlikely). */
		if( pcName[ x ] == 0x00 )
    15e4:	90 81       	ld	r25, Z
    15e6:	99 23       	and	r25, r25
    15e8:	19 f0       	breq	.+6      	; 0x15f0 <xTaskCreate+0x90>
		pxNewTCB->pxEndOfStack = pxNewTCB->pxStack + ( ulStackDepth - ( uint32_t ) 1 );
	}
	#endif /* portSTACK_GROWTH */

	/* Store the task name in the TCB. */
	for( x = ( UBaseType_t ) 0; x < ( UBaseType_t ) configMAX_TASK_NAME_LEN; x++ )
    15ea:	8f 5f       	subi	r24, 0xFF	; 255
    15ec:	8a 30       	cpi	r24, 0x0A	; 10
    15ee:	b9 f7       	brne	.-18     	; 0x15de <xTaskCreate+0x7e>
		}
	}

	/* Ensure the name string is terminated in the case that the string length
	was greater or equal to configMAX_TASK_NAME_LEN. */
	pxNewTCB->pcTaskName[ configMAX_TASK_NAME_LEN - 1 ] = '\0';
    15f0:	f8 01       	movw	r30, r16
    15f2:	12 a2       	lds	r17, 0x92
    15f4:	cd 2d       	mov	r28, r13
    15f6:	c5 30       	cpi	r28, 0x05	; 5
    15f8:	08 f0       	brcs	.+2      	; 0x15fc <xTaskCreate+0x9c>
    15fa:	c4 e0       	ldi	r28, 0x04	; 4
	else
	{
		mtCOVERAGE_TEST_MARKER();
	}

	pxNewTCB->uxPriority = uxPriority;
    15fc:	f8 01       	movw	r30, r16
    15fe:	c6 8b       	std	Z+22, r28	; 0x16
	#if ( configUSE_MUTEXES == 1 )
	{
		pxNewTCB->uxBasePriority = uxPriority;
    1600:	c3 a3       	lds	r28, 0x53
		pxNewTCB->uxMutexesHeld = 0;
    1602:	14 a2       	lds	r17, 0x94
	}
	#endif /* configUSE_MUTEXES */

	vListInitialiseItem( &( pxNewTCB->xStateListItem ) );
    1604:	ee 24       	eor	r14, r14
    1606:	ff 24       	eor	r15, r15
    1608:	68 94       	set
    160a:	e1 f8       	bld	r14, 1
    160c:	e0 0e       	add	r14, r16
    160e:	f1 1e       	adc	r15, r17
    1610:	c7 01       	movw	r24, r14
    1612:	0e 94 ed 03 	call	0x7da	; 0x7da <vListInitialiseItem>
	vListInitialiseItem( &( pxNewTCB->xEventListItem ) );
    1616:	c8 01       	movw	r24, r16
    1618:	0c 96       	adiw	r24, 0x0c	; 12
    161a:	0e 94 ed 03 	call	0x7da	; 0x7da <vListInitialiseItem>

	/* Set the pxNewTCB as a link back from the ListItem_t.  This is so we can get
	back to	the containing TCB from a generic item in a list. */
	listSET_LIST_ITEM_OWNER( &( pxNewTCB->xStateListItem ), pxNewTCB );
    161e:	f8 01       	movw	r30, r16
    1620:	11 87       	std	Z+9, r17	; 0x09
    1622:	00 87       	std	Z+8, r16	; 0x08

	/* Event lists are always in priority order. */
	listSET_LIST_ITEM_VALUE( &( pxNewTCB->xEventListItem ), ( TickType_t ) configMAX_PRIORITIES - ( TickType_t ) uxPriority ); /*lint !e961 MISRA exception as the casts are only redundant for some ports. */
    1624:	85 e0       	ldi	r24, 0x05	; 5
    1626:	90 e0       	ldi	r25, 0x00	; 0
    1628:	8c 1b       	sub	r24, r28
    162a:	91 09       	sbc	r25, r1
    162c:	95 87       	std	Z+13, r25	; 0x0d
    162e:	84 87       	std	Z+12, r24	; 0x0c
	listSET_LIST_ITEM_OWNER( &( pxNewTCB->xEventListItem ), pxNewTCB );
    1630:	13 8b       	std	Z+19, r17	; 0x13
    1632:	02 8b       	std	Z+18, r16	; 0x12
	}
	#endif

	#if ( configUSE_TASK_NOTIFICATIONS == 1 )
	{
		pxNewTCB->ulNotifiedValue = 0;
    1634:	15 a2       	lds	r17, 0x95
    1636:	16 a2       	lds	r17, 0x96
    1638:	17 a2       	lds	r17, 0x97
    163a:	10 a6       	lds	r17, 0xb0
		pxNewTCB->ucNotifyState = taskNOT_WAITING_NOTIFICATION;
    163c:	11 a6       	lds	r17, 0xb1
	{
		pxNewTCB->pxTopOfStack = pxPortInitialiseStack( pxTopOfStack, pxTaskCode, pvParameters, xRunPrivileged );
	}
	#else /* portUSING_MPU_WRAPPERS */
	{
		pxNewTCB->pxTopOfStack = pxPortInitialiseStack( pxTopOfStack, pxTaskCode, pvParameters );
    163e:	c1 01       	movw	r24, r2
    1640:	b3 01       	movw	r22, r6
    1642:	a2 01       	movw	r20, r4
    1644:	0e 94 6a 04 	call	0x8d4	; 0x8d4 <pxPortInitialiseStack>
    1648:	f8 01       	movw	r30, r16
    164a:	91 83       	std	Z+1, r25	; 0x01
    164c:	80 83       	st	Z, r24
	}
	#endif /* portUSING_MPU_WRAPPERS */

	if( ( void * ) pxCreatedTask != NULL )
    164e:	81 14       	cp	r8, r1
    1650:	91 04       	cpc	r9, r1
    1652:	19 f0       	breq	.+6      	; 0x165a <xTaskCreate+0xfa>
	{
		/* Pass the handle out in an anonymous way.  The handle can be used to
		change the created task's priority, delete the created task, etc.*/
		*pxCreatedTask = ( TaskHandle_t ) pxNewTCB;
    1654:	f4 01       	movw	r30, r8
    1656:	11 83       	std	Z+1, r17	; 0x01
    1658:	00 83       	st	Z, r16

static void prvAddNewTaskToReadyList( TCB_t *pxNewTCB )
{
	/* Ensure interrupts don't access the task lists while the lists are being
	updated. */
	taskENTER_CRITICAL();
    165a:	0f b6       	in	r0, 0x3f	; 63
    165c:	f8 94       	cli
    165e:	0f 92       	push	r0
	{
		uxCurrentNumberOfTasks++;
    1660:	80 91 a7 03 	lds	r24, 0x03A7
    1664:	8f 5f       	subi	r24, 0xFF	; 255
    1666:	80 93 a7 03 	sts	0x03A7, r24
		if( pxCurrentTCB == NULL )
    166a:	80 91 9b 03 	lds	r24, 0x039B
    166e:	90 91 9c 03 	lds	r25, 0x039C
    1672:	00 97       	sbiw	r24, 0x00	; 0
    1674:	09 f0       	breq	.+2      	; 0x1678 <xTaskCreate+0x118>
    1676:	3f c0       	rjmp	.+126    	; 0x16f6 <xTaskCreate+0x196>
		{
			/* There are no other tasks, or all the other tasks are in
			the suspended state - make this the current task. */
			pxCurrentTCB = pxNewTCB;
    1678:	10 93 9c 03 	sts	0x039C, r17
    167c:	00 93 9b 03 	sts	0x039B, r16

			if( uxCurrentNumberOfTasks == ( UBaseType_t ) 1 )
    1680:	80 91 a7 03 	lds	r24, 0x03A7
    1684:	81 30       	cpi	r24, 0x01	; 1
    1686:	09 f0       	breq	.+2      	; 0x168a <xTaskCreate+0x12a>
    1688:	47 c0       	rjmp	.+142    	; 0x1718 <xTaskCreate+0x1b8>
    168a:	c0 e0       	ldi	r28, 0x00	; 0
    168c:	d0 e0       	ldi	r29, 0x00	; 0
{
UBaseType_t uxPriority;

	for( uxPriority = ( UBaseType_t ) 0U; uxPriority < ( UBaseType_t ) configMAX_PRIORITIES; uxPriority++ )
	{
		vListInitialise( &( pxReadyTasksLists[ uxPriority ] ) );
    168e:	ce 01       	movw	r24, r28
    1690:	88 0f       	add	r24, r24
    1692:	99 1f       	adc	r25, r25
    1694:	88 0f       	add	r24, r24
    1696:	99 1f       	adc	r25, r25
    1698:	88 0f       	add	r24, r24
    169a:	99 1f       	adc	r25, r25
    169c:	8c 0f       	add	r24, r28
    169e:	9d 1f       	adc	r25, r29
    16a0:	82 55       	subi	r24, 0x52	; 82
    16a2:	9c 4f       	sbci	r25, 0xFC	; 252
    16a4:	0e 94 df 03 	call	0x7be	; 0x7be <vListInitialise>
    16a8:	21 96       	adiw	r28, 0x01	; 1

static void prvInitialiseTaskLists( void )
{
UBaseType_t uxPriority;

	for( uxPriority = ( UBaseType_t ) 0U; uxPriority < ( UBaseType_t ) configMAX_PRIORITIES; uxPriority++ )
    16aa:	c5 30       	cpi	r28, 0x05	; 5
    16ac:	d1 05       	cpc	r29, r1
    16ae:	79 f7       	brne	.-34     	; 0x168e <xTaskCreate+0x12e>
	{
		vListInitialise( &( pxReadyTasksLists[ uxPriority ] ) );
	}

	vListInitialise( &xDelayedTaskList1 );
    16b0:	cb ed       	ldi	r28, 0xDB	; 219
    16b2:	d3 e0       	ldi	r29, 0x03	; 3
    16b4:	ce 01       	movw	r24, r28
    16b6:	0e 94 df 03 	call	0x7be	; 0x7be <vListInitialise>
	vListInitialise( &xDelayedTaskList2 );
    16ba:	0f 2e       	mov	r0, r31
    16bc:	f4 ee       	ldi	r31, 0xE4	; 228
    16be:	af 2e       	mov	r10, r31
    16c0:	f3 e0       	ldi	r31, 0x03	; 3
    16c2:	bf 2e       	mov	r11, r31
    16c4:	f0 2d       	mov	r31, r0
    16c6:	c5 01       	movw	r24, r10
    16c8:	0e 94 df 03 	call	0x7be	; 0x7be <vListInitialise>
	vListInitialise( &xPendingReadyList );
    16cc:	8d ee       	ldi	r24, 0xED	; 237
    16ce:	93 e0       	ldi	r25, 0x03	; 3
    16d0:	0e 94 df 03 	call	0x7be	; 0x7be <vListInitialise>

	#if ( INCLUDE_vTaskDelete == 1 )
	{
		vListInitialise( &xTasksWaitingTermination );
    16d4:	86 ef       	ldi	r24, 0xF6	; 246
    16d6:	93 e0       	ldi	r25, 0x03	; 3
    16d8:	0e 94 df 03 	call	0x7be	; 0x7be <vListInitialise>
	}
	#endif /* INCLUDE_vTaskDelete */

	#if ( INCLUDE_vTaskSuspend == 1 )
	{
		vListInitialise( &xSuspendedTaskList );
    16dc:	8f ef       	ldi	r24, 0xFF	; 255
    16de:	93 e0       	ldi	r25, 0x03	; 3
    16e0:	0e 94 df 03 	call	0x7be	; 0x7be <vListInitialise>
	}
	#endif /* INCLUDE_vTaskSuspend */

	/* Start with pxDelayedTaskList using list1 and the pxOverflowDelayedTaskList
	using list2. */
	pxDelayedTaskList = &xDelayedTaskList1;
    16e4:	d0 93 ac 03 	sts	0x03AC, r29
    16e8:	c0 93 ab 03 	sts	0x03AB, r28
	pxOverflowDelayedTaskList = &xDelayedTaskList2;
    16ec:	b0 92 aa 03 	sts	0x03AA, r11
    16f0:	a0 92 a9 03 	sts	0x03A9, r10
    16f4:	11 c0       	rjmp	.+34     	; 0x1718 <xTaskCreate+0x1b8>
		else
		{
			/* If the scheduler is not already running, make this task the
			current task if it is the highest priority task to be created
			so far. */
			if( xSchedulerRunning == pdFALSE )
    16f6:	80 91 a3 03 	lds	r24, 0x03A3
    16fa:	88 23       	and	r24, r24
    16fc:	69 f4       	brne	.+26     	; 0x1718 <xTaskCreate+0x1b8>
			{
				if( pxCurrentTCB->uxPriority <= pxNewTCB->uxPriority )
    16fe:	e0 91 9b 03 	lds	r30, 0x039B
    1702:	f0 91 9c 03 	lds	r31, 0x039C
    1706:	96 89       	ldd	r25, Z+22	; 0x16
    1708:	f8 01       	movw	r30, r16
    170a:	86 89       	ldd	r24, Z+22	; 0x16
    170c:	89 17       	cp	r24, r25
    170e:	20 f0       	brcs	.+8      	; 0x1718 <xTaskCreate+0x1b8>
				{
					pxCurrentTCB = pxNewTCB;
    1710:	10 93 9c 03 	sts	0x039C, r17
    1714:	00 93 9b 03 	sts	0x039B, r16
			{
				mtCOVERAGE_TEST_MARKER();
			}
		}

		uxTaskNumber++;
    1718:	80 91 ad 03 	lds	r24, 0x03AD
    171c:	8f 5f       	subi	r24, 0xFF	; 255
    171e:	80 93 ad 03 	sts	0x03AD, r24
			pxNewTCB->uxTCBNumber = uxTaskNumber;
		}
		#endif /* configUSE_TRACE_FACILITY */
		traceTASK_CREATE( pxNewTCB );

		prvAddTaskToReadyList( pxNewTCB );
    1722:	f8 01       	movw	r30, r16
    1724:	86 89       	ldd	r24, Z+22	; 0x16
    1726:	90 91 a4 03 	lds	r25, 0x03A4
    172a:	98 17       	cp	r25, r24
    172c:	10 f4       	brcc	.+4      	; 0x1732 <xTaskCreate+0x1d2>
    172e:	80 93 a4 03 	sts	0x03A4, r24
    1732:	90 e0       	ldi	r25, 0x00	; 0
    1734:	9c 01       	movw	r18, r24
    1736:	22 0f       	add	r18, r18
    1738:	33 1f       	adc	r19, r19
    173a:	22 0f       	add	r18, r18
    173c:	33 1f       	adc	r19, r19
    173e:	22 0f       	add	r18, r18
    1740:	33 1f       	adc	r19, r19
    1742:	82 0f       	add	r24, r18
    1744:	93 1f       	adc	r25, r19
    1746:	82 55       	subi	r24, 0x52	; 82
    1748:	9c 4f       	sbci	r25, 0xFC	; 252
    174a:	b7 01       	movw	r22, r14
    174c:	0e 94 f1 03 	call	0x7e2	; 0x7e2 <vListInsertEnd>

		portSETUP_TCB( pxNewTCB );
	}
	taskEXIT_CRITICAL();
    1750:	0f 90       	pop	r0
    1752:	0f be       	out	0x3f, r0	; 63

	if( xSchedulerRunning != pdFALSE )
    1754:	80 91 a3 03 	lds	r24, 0x03A3
    1758:	88 23       	and	r24, r24
    175a:	79 f0       	breq	.+30     	; 0x177a <xTaskCreate+0x21a>
	{
		/* If the created task is of a higher priority than the current task
		then it should run now. */
		if( pxCurrentTCB->uxPriority < pxNewTCB->uxPriority )
    175c:	e0 91 9b 03 	lds	r30, 0x039B
    1760:	f0 91 9c 03 	lds	r31, 0x039C
    1764:	96 89       	ldd	r25, Z+22	; 0x16
    1766:	f8 01       	movw	r30, r16
    1768:	86 89       	ldd	r24, Z+22	; 0x16
    176a:	98 17       	cp	r25, r24
    176c:	40 f4       	brcc	.+16     	; 0x177e <xTaskCreate+0x21e>
		{
			taskYIELD_IF_USING_PREEMPTION();
    176e:	0e 94 30 05 	call	0xa60	; 0xa60 <vPortYield>
			}
			#endif /* configSUPPORT_STATIC_ALLOCATION */

			prvInitialiseNewTask( pxTaskCode, pcName, ( uint32_t ) usStackDepth, pvParameters, uxPriority, pxCreatedTask, pxNewTCB, NULL );
			prvAddNewTaskToReadyList( pxNewTCB );
			xReturn = pdPASS;
    1772:	81 e0       	ldi	r24, 0x01	; 1
    1774:	05 c0       	rjmp	.+10     	; 0x1780 <xTaskCreate+0x220>
		}
		else
		{
			xReturn = errCOULD_NOT_ALLOCATE_REQUIRED_MEMORY;
    1776:	8f ef       	ldi	r24, 0xFF	; 255
    1778:	03 c0       	rjmp	.+6      	; 0x1780 <xTaskCreate+0x220>
			}
			#endif /* configSUPPORT_STATIC_ALLOCATION */

			prvInitialiseNewTask( pxTaskCode, pcName, ( uint32_t ) usStackDepth, pvParameters, uxPriority, pxCreatedTask, pxNewTCB, NULL );
			prvAddNewTaskToReadyList( pxNewTCB );
			xReturn = pdPASS;
    177a:	81 e0       	ldi	r24, 0x01	; 1
    177c:	01 c0       	rjmp	.+2      	; 0x1780 <xTaskCreate+0x220>
    177e:	81 e0       	ldi	r24, 0x01	; 1
		{
			xReturn = errCOULD_NOT_ALLOCATE_REQUIRED_MEMORY;
		}

		return xReturn;
	}
    1780:	df 91       	pop	r29
    1782:	cf 91       	pop	r28
    1784:	1f 91       	pop	r17
    1786:	0f 91       	pop	r16
    1788:	ff 90       	pop	r15
    178a:	ef 90       	pop	r14
    178c:	df 90       	pop	r13
    178e:	bf 90       	pop	r11
    1790:	af 90       	pop	r10
    1792:	9f 90       	pop	r9
    1794:	8f 90       	pop	r8
    1796:	7f 90       	pop	r7
    1798:	6f 90       	pop	r6
    179a:	5f 90       	pop	r5
    179c:	4f 90       	pop	r4
    179e:	3f 90       	pop	r3
    17a0:	2f 90       	pop	r2
    17a2:	08 95       	ret

000017a4 <vTaskDelete>:
/*-----------------------------------------------------------*/

#if ( INCLUDE_vTaskDelete == 1 )

	void vTaskDelete( TaskHandle_t xTaskToDelete )
	{
    17a4:	0f 93       	push	r16
    17a6:	1f 93       	push	r17
    17a8:	cf 93       	push	r28
    17aa:	df 93       	push	r29
	TCB_t *pxTCB;

		taskENTER_CRITICAL();
    17ac:	0f b6       	in	r0, 0x3f	; 63
    17ae:	f8 94       	cli
    17b0:	0f 92       	push	r0
		{
			/* If null is passed in here then it is the calling task that is
			being deleted. */
			pxTCB = prvGetTCBFromHandle( xTaskToDelete );
    17b2:	00 97       	sbiw	r24, 0x00	; 0
    17b4:	29 f4       	brne	.+10     	; 0x17c0 <vTaskDelete+0x1c>
    17b6:	c0 91 9b 03 	lds	r28, 0x039B
    17ba:	d0 91 9c 03 	lds	r29, 0x039C
    17be:	01 c0       	rjmp	.+2      	; 0x17c2 <vTaskDelete+0x1e>
    17c0:	ec 01       	movw	r28, r24

			/* Remove task from the ready list. */
			if( uxListRemove( &( pxTCB->xStateListItem ) ) == ( UBaseType_t ) 0 )
    17c2:	8e 01       	movw	r16, r28
    17c4:	0e 5f       	subi	r16, 0xFE	; 254
    17c6:	1f 4f       	sbci	r17, 0xFF	; 255
    17c8:	c8 01       	movw	r24, r16
    17ca:	0e 94 42 04 	call	0x884	; 0x884 <uxListRemove>
			{
				mtCOVERAGE_TEST_MARKER();
			}

			/* Is the task waiting on an event also? */
			if( listLIST_ITEM_CONTAINER( &( pxTCB->xEventListItem ) ) != NULL )
    17ce:	8c 89       	ldd	r24, Y+20	; 0x14
    17d0:	9d 89       	ldd	r25, Y+21	; 0x15
    17d2:	00 97       	sbiw	r24, 0x00	; 0
    17d4:	21 f0       	breq	.+8      	; 0x17de <vTaskDelete+0x3a>
			{
				( void ) uxListRemove( &( pxTCB->xEventListItem ) );
    17d6:	ce 01       	movw	r24, r28
    17d8:	0c 96       	adiw	r24, 0x0c	; 12
    17da:	0e 94 42 04 	call	0x884	; 0x884 <uxListRemove>

			/* Increment the uxTaskNumber also so kernel aware debuggers can
			detect that the task lists need re-generating.  This is done before
			portPRE_TASK_DELETE_HOOK() as in the Windows port that macro will
			not return. */
			uxTaskNumber++;
    17de:	80 91 ad 03 	lds	r24, 0x03AD
    17e2:	8f 5f       	subi	r24, 0xFF	; 255
    17e4:	80 93 ad 03 	sts	0x03AD, r24

			if( pxTCB == pxCurrentTCB )
    17e8:	80 91 9b 03 	lds	r24, 0x039B
    17ec:	90 91 9c 03 	lds	r25, 0x039C
    17f0:	c8 17       	cp	r28, r24
    17f2:	d9 07       	cpc	r29, r25
    17f4:	59 f4       	brne	.+22     	; 0x180c <vTaskDelete+0x68>
				/* A task is deleting itself.  This cannot complete within the
				task itself, as a context switch to another task is required.
				Place the task in the termination list.  The idle task will
				check the termination list and free up any memory allocated by
				the scheduler for the TCB and stack of the deleted task. */
				vListInsertEnd( &xTasksWaitingTermination, &( pxTCB->xStateListItem ) );
    17f6:	86 ef       	ldi	r24, 0xF6	; 246
    17f8:	93 e0       	ldi	r25, 0x03	; 3
    17fa:	b8 01       	movw	r22, r16
    17fc:	0e 94 f1 03 	call	0x7e2	; 0x7e2 <vListInsertEnd>

				/* Increment the ucTasksDeleted variable so the idle task knows
				there is a task that has been deleted and that it should therefore
				check the xTasksWaitingTermination list. */
				++uxDeletedTasksWaitingCleanUp;
    1800:	80 91 a8 03 	lds	r24, 0x03A8
    1804:	8f 5f       	subi	r24, 0xFF	; 255
    1806:	80 93 a8 03 	sts	0x03A8, r24
    180a:	0a c0       	rjmp	.+20     	; 0x1820 <vTaskDelete+0x7c>
				required. */
				portPRE_TASK_DELETE_HOOK( pxTCB, &xYieldPending );
			}
			else
			{
				--uxCurrentNumberOfTasks;
    180c:	80 91 a7 03 	lds	r24, 0x03A7
    1810:	81 50       	subi	r24, 0x01	; 1
    1812:	80 93 a7 03 	sts	0x03A7, r24
				prvDeleteTCB( pxTCB );
    1816:	ce 01       	movw	r24, r28
    1818:	0e 94 a3 0a 	call	0x1546	; 0x1546 <prvDeleteTCB>

				/* Reset the next expected unblock time in case it referred to
				the task that has just been deleted. */
				prvResetNextTaskUnblockTime();
    181c:	0e 94 2c 0a 	call	0x1458	; 0x1458 <prvResetNextTaskUnblockTime>
			}

			traceTASK_DELETE( pxTCB );
		}
		taskEXIT_CRITICAL();
    1820:	0f 90       	pop	r0
    1822:	0f be       	out	0x3f, r0	; 63

		/* Force a reschedule if it is the currently running task that has just
		been deleted. */
		if( xSchedulerRunning != pdFALSE )
    1824:	80 91 a3 03 	lds	r24, 0x03A3
    1828:	88 23       	and	r24, r24
    182a:	49 f0       	breq	.+18     	; 0x183e <vTaskDelete+0x9a>
		{
			if( pxTCB == pxCurrentTCB )
    182c:	80 91 9b 03 	lds	r24, 0x039B
    1830:	90 91 9c 03 	lds	r25, 0x039C
    1834:	c8 17       	cp	r28, r24
    1836:	d9 07       	cpc	r29, r25
    1838:	11 f4       	brne	.+4      	; 0x183e <vTaskDelete+0x9a>
			{
				configASSERT( uxSchedulerSuspended == 0 );
				portYIELD_WITHIN_API();
    183a:	0e 94 30 05 	call	0xa60	; 0xa60 <vPortYield>
			else
			{
				mtCOVERAGE_TEST_MARKER();
			}
		}
	}
    183e:	df 91       	pop	r29
    1840:	cf 91       	pop	r28
    1842:	1f 91       	pop	r17
    1844:	0f 91       	pop	r16
    1846:	08 95       	ret

00001848 <uxTaskPriorityGet>:
	UBaseType_t uxTaskPriorityGet( TaskHandle_t xTask )
	{
	TCB_t *pxTCB;
	UBaseType_t uxReturn;

		taskENTER_CRITICAL();
    1848:	0f b6       	in	r0, 0x3f	; 63
    184a:	f8 94       	cli
    184c:	0f 92       	push	r0
		{
			/* If null is passed in here then it is the priority of the that
			called uxTaskPriorityGet() that is being queried. */
			pxTCB = prvGetTCBFromHandle( xTask );
    184e:	00 97       	sbiw	r24, 0x00	; 0
    1850:	29 f4       	brne	.+10     	; 0x185c <uxTaskPriorityGet+0x14>
    1852:	e0 91 9b 03 	lds	r30, 0x039B
    1856:	f0 91 9c 03 	lds	r31, 0x039C
    185a:	01 c0       	rjmp	.+2      	; 0x185e <uxTaskPriorityGet+0x16>
    185c:	fc 01       	movw	r30, r24
			uxReturn = pxTCB->uxPriority;
		}
		taskEXIT_CRITICAL();
    185e:	0f 90       	pop	r0
    1860:	0f be       	out	0x3f, r0	; 63

		return uxReturn;
	}
    1862:	86 89       	ldd	r24, Z+22	; 0x16
    1864:	08 95       	ret

00001866 <uxTaskPriorityGetFromISR>:

		uxSavedInterruptState = portSET_INTERRUPT_MASK_FROM_ISR();
		{
			/* If null is passed in here then it is the priority of the calling
			task that is being queried. */
			pxTCB = prvGetTCBFromHandle( xTask );
    1866:	00 97       	sbiw	r24, 0x00	; 0
    1868:	29 f4       	brne	.+10     	; 0x1874 <uxTaskPriorityGetFromISR+0xe>
    186a:	e0 91 9b 03 	lds	r30, 0x039B
    186e:	f0 91 9c 03 	lds	r31, 0x039C
    1872:	01 c0       	rjmp	.+2      	; 0x1876 <uxTaskPriorityGetFromISR+0x10>
    1874:	fc 01       	movw	r30, r24
			uxReturn = pxTCB->uxPriority;
		}
		portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptState );

		return uxReturn;
	}
    1876:	86 89       	ldd	r24, Z+22	; 0x16
    1878:	08 95       	ret

0000187a <vTaskPrioritySet>:
/*-----------------------------------------------------------*/

#if ( INCLUDE_vTaskPrioritySet == 1 )

	void vTaskPrioritySet( TaskHandle_t xTask, UBaseType_t uxNewPriority )
	{
    187a:	ef 92       	push	r14
    187c:	ff 92       	push	r15
    187e:	1f 93       	push	r17
    1880:	cf 93       	push	r28
    1882:	df 93       	push	r29
	TCB_t *pxTCB;
	UBaseType_t uxCurrentBasePriority, uxPriorityUsedOnEntry;
	BaseType_t xYieldRequired = pdFALSE;
    1884:	65 30       	cpi	r22, 0x05	; 5
    1886:	08 f0       	brcs	.+2      	; 0x188a <vTaskPrioritySet+0x10>
    1888:	64 e0       	ldi	r22, 0x04	; 4
		else
		{
			mtCOVERAGE_TEST_MARKER();
		}

		taskENTER_CRITICAL();
    188a:	0f b6       	in	r0, 0x3f	; 63
    188c:	f8 94       	cli
    188e:	0f 92       	push	r0
		{
			/* If null is passed in here then it is the priority of the calling
			task that is being changed. */
			pxTCB = prvGetTCBFromHandle( xTask );
    1890:	00 97       	sbiw	r24, 0x00	; 0
    1892:	29 f4       	brne	.+10     	; 0x189e <vTaskPrioritySet+0x24>
    1894:	c0 91 9b 03 	lds	r28, 0x039B
    1898:	d0 91 9c 03 	lds	r29, 0x039C
    189c:	01 c0       	rjmp	.+2      	; 0x18a0 <vTaskPrioritySet+0x26>
    189e:	ec 01       	movw	r28, r24

			traceTASK_PRIORITY_SET( pxTCB, uxNewPriority );

			#if ( configUSE_MUTEXES == 1 )
			{
				uxCurrentBasePriority = pxTCB->uxBasePriority;
    18a0:	2b a1       	lds	r18, 0x4b
			{
				uxCurrentBasePriority = pxTCB->uxPriority;
			}
			#endif

			if( uxCurrentBasePriority != uxNewPriority )
    18a2:	26 17       	cp	r18, r22
    18a4:	09 f4       	brne	.+2      	; 0x18a8 <vTaskPrioritySet+0x2e>
    18a6:	61 c0       	rjmp	.+194    	; 0x196a <vTaskPrioritySet+0xf0>
			{
				/* The priority change may have readied a task of higher
				priority than the calling task. */
				if( uxNewPriority > uxCurrentBasePriority )
    18a8:	26 17       	cp	r18, r22
    18aa:	88 f4       	brcc	.+34     	; 0x18ce <vTaskPrioritySet+0x54>
				{
					if( pxTCB != pxCurrentTCB )
    18ac:	80 91 9b 03 	lds	r24, 0x039B
    18b0:	90 91 9c 03 	lds	r25, 0x039C
    18b4:	c8 17       	cp	r28, r24
    18b6:	d9 07       	cpc	r29, r25
    18b8:	a1 f0       	breq	.+40     	; 0x18e2 <vTaskPrioritySet+0x68>
					{
						/* The priority of a task other than the currently
						running task is being raised.  Is the priority being
						raised above that of the running task? */
						if( uxNewPriority >= pxCurrentTCB->uxPriority )
    18ba:	e0 91 9b 03 	lds	r30, 0x039B
    18be:	f0 91 9c 03 	lds	r31, 0x039C
						{
							xYieldRequired = pdTRUE;
    18c2:	11 e0       	ldi	r17, 0x01	; 1
    18c4:	86 89       	ldd	r24, Z+22	; 0x16
    18c6:	68 17       	cp	r22, r24
    18c8:	68 f4       	brcc	.+26     	; 0x18e4 <vTaskPrioritySet+0x6a>
    18ca:	10 e0       	ldi	r17, 0x00	; 0
    18cc:	0b c0       	rjmp	.+22     	; 0x18e4 <vTaskPrioritySet+0x6a>
						/* The priority of the running task is being raised,
						but the running task must already be the highest
						priority task able to run so no yield is required. */
					}
				}
				else if( pxTCB == pxCurrentTCB )
    18ce:	80 91 9b 03 	lds	r24, 0x039B
    18d2:	90 91 9c 03 	lds	r25, 0x039C
						/* The priority of a task other than the currently
						running task is being raised.  Is the priority being
						raised above that of the running task? */
						if( uxNewPriority >= pxCurrentTCB->uxPriority )
						{
							xYieldRequired = pdTRUE;
    18d6:	11 e0       	ldi	r17, 0x01	; 1
    18d8:	c8 17       	cp	r28, r24
    18da:	d9 07       	cpc	r29, r25
    18dc:	19 f0       	breq	.+6      	; 0x18e4 <vTaskPrioritySet+0x6a>
    18de:	10 e0       	ldi	r17, 0x00	; 0
    18e0:	01 c0       	rjmp	.+2      	; 0x18e4 <vTaskPrioritySet+0x6a>

	void vTaskPrioritySet( TaskHandle_t xTask, UBaseType_t uxNewPriority )
	{
	TCB_t *pxTCB;
	UBaseType_t uxCurrentBasePriority, uxPriorityUsedOnEntry;
	BaseType_t xYieldRequired = pdFALSE;
    18e2:	10 e0       	ldi	r17, 0x00	; 0
				}

				/* Remember the ready list the task might be referenced from
				before its uxPriority member is changed so the
				taskRESET_READY_PRIORITY() macro can function correctly. */
				uxPriorityUsedOnEntry = pxTCB->uxPriority;
    18e4:	8e 89       	ldd	r24, Y+22	; 0x16

				#if ( configUSE_MUTEXES == 1 )
				{
					/* Only change the priority being used if the task is not
					currently using an inherited priority. */
					if( pxTCB->uxBasePriority == pxTCB->uxPriority )
    18e6:	28 17       	cp	r18, r24
    18e8:	09 f4       	brne	.+2      	; 0x18ec <vTaskPrioritySet+0x72>
					{
						pxTCB->uxPriority = uxNewPriority;
    18ea:	6e 8b       	std	Y+22, r22	; 0x16
					{
						mtCOVERAGE_TEST_MARKER();
					}

					/* The base priority gets set whatever. */
					pxTCB->uxBasePriority = uxNewPriority;
    18ec:	6b a3       	lds	r22, 0x5b
				}
				#endif

				/* Only reset the event list item value if the value is not
				being used for anything else. */
				if( ( listGET_LIST_ITEM_VALUE( &( pxTCB->xEventListItem ) ) & taskEVENT_LIST_ITEM_VALUE_IN_USE ) == 0UL )
    18ee:	2c 85       	ldd	r18, Y+12	; 0x0c
    18f0:	3d 85       	ldd	r19, Y+13	; 0x0d
    18f2:	33 23       	and	r19, r19
    18f4:	34 f0       	brlt	.+12     	; 0x1902 <vTaskPrioritySet+0x88>
				{
					listSET_LIST_ITEM_VALUE( &( pxTCB->xEventListItem ), ( ( TickType_t ) configMAX_PRIORITIES - ( TickType_t ) uxNewPriority ) ); /*lint !e961 MISRA exception as the casts are only redundant for some ports. */
    18f6:	25 e0       	ldi	r18, 0x05	; 5
    18f8:	30 e0       	ldi	r19, 0x00	; 0
    18fa:	26 1b       	sub	r18, r22
    18fc:	31 09       	sbc	r19, r1
    18fe:	3d 87       	std	Y+13, r19	; 0x0d
    1900:	2c 87       	std	Y+12, r18	; 0x0c

				/* If the task is in the blocked or suspended list we need do
				nothing more than change it's priority variable. However, if
				the task is in a ready list it needs to be removed and placed
				in the list appropriate to its new priority. */
				if( listIS_CONTAINED_WITHIN( &( pxReadyTasksLists[ uxPriorityUsedOnEntry ] ), &( pxTCB->xStateListItem ) ) != pdFALSE )
    1902:	90 e0       	ldi	r25, 0x00	; 0
    1904:	9c 01       	movw	r18, r24
    1906:	22 0f       	add	r18, r18
    1908:	33 1f       	adc	r19, r19
    190a:	22 0f       	add	r18, r18
    190c:	33 1f       	adc	r19, r19
    190e:	22 0f       	add	r18, r18
    1910:	33 1f       	adc	r19, r19
    1912:	82 0f       	add	r24, r18
    1914:	93 1f       	adc	r25, r19
    1916:	82 55       	subi	r24, 0x52	; 82
    1918:	9c 4f       	sbci	r25, 0xFC	; 252
    191a:	2a 85       	ldd	r18, Y+10	; 0x0a
    191c:	3b 85       	ldd	r19, Y+11	; 0x0b
    191e:	28 17       	cp	r18, r24
    1920:	39 07       	cpc	r19, r25
    1922:	f9 f4       	brne	.+62     	; 0x1962 <vTaskPrioritySet+0xe8>
				{
					/* The task is currently in its ready list - remove before adding
					it to it's new ready list.  As we are in a critical section we
					can do this even if the scheduler is suspended. */
					if( uxListRemove( &( pxTCB->xStateListItem ) ) == ( UBaseType_t ) 0 )
    1924:	ee 24       	eor	r14, r14
    1926:	ff 24       	eor	r15, r15
    1928:	68 94       	set
    192a:	e1 f8       	bld	r14, 1
    192c:	ec 0e       	add	r14, r28
    192e:	fd 1e       	adc	r15, r29
    1930:	c7 01       	movw	r24, r14
    1932:	0e 94 42 04 	call	0x884	; 0x884 <uxListRemove>
					}
					else
					{
						mtCOVERAGE_TEST_MARKER();
					}
					prvAddTaskToReadyList( pxTCB );
    1936:	8e 89       	ldd	r24, Y+22	; 0x16
    1938:	90 91 a4 03 	lds	r25, 0x03A4
    193c:	98 17       	cp	r25, r24
    193e:	10 f4       	brcc	.+4      	; 0x1944 <vTaskPrioritySet+0xca>
    1940:	80 93 a4 03 	sts	0x03A4, r24
    1944:	90 e0       	ldi	r25, 0x00	; 0
    1946:	9c 01       	movw	r18, r24
    1948:	22 0f       	add	r18, r18
    194a:	33 1f       	adc	r19, r19
    194c:	22 0f       	add	r18, r18
    194e:	33 1f       	adc	r19, r19
    1950:	22 0f       	add	r18, r18
    1952:	33 1f       	adc	r19, r19
    1954:	82 0f       	add	r24, r18
    1956:	93 1f       	adc	r25, r19
    1958:	82 55       	subi	r24, 0x52	; 82
    195a:	9c 4f       	sbci	r25, 0xFC	; 252
    195c:	b7 01       	movw	r22, r14
    195e:	0e 94 f1 03 	call	0x7e2	; 0x7e2 <vListInsertEnd>
				else
				{
					mtCOVERAGE_TEST_MARKER();
				}

				if( xYieldRequired != pdFALSE )
    1962:	11 23       	and	r17, r17
    1964:	11 f0       	breq	.+4      	; 0x196a <vTaskPrioritySet+0xf0>
				{
					taskYIELD_IF_USING_PREEMPTION();
    1966:	0e 94 30 05 	call	0xa60	; 0xa60 <vPortYield>
				/* Remove compiler warning about unused variables when the port
				optimised task selection is not being used. */
				( void ) uxPriorityUsedOnEntry;
			}
		}
		taskEXIT_CRITICAL();
    196a:	0f 90       	pop	r0
    196c:	0f be       	out	0x3f, r0	; 63
	}
    196e:	df 91       	pop	r29
    1970:	cf 91       	pop	r28
    1972:	1f 91       	pop	r17
    1974:	ff 90       	pop	r15
    1976:	ef 90       	pop	r14
    1978:	08 95       	ret

0000197a <vTaskResume>:
/*-----------------------------------------------------------*/

#if ( INCLUDE_vTaskSuspend == 1 )

	void vTaskResume( TaskHandle_t xTaskToResume )
	{
    197a:	0f 93       	push	r16
    197c:	1f 93       	push	r17
    197e:	cf 93       	push	r28
    1980:	df 93       	push	r29
    1982:	ec 01       	movw	r28, r24
		/* It does not make sense to resume the calling task. */
		configASSERT( xTaskToResume );

		/* The parameter cannot be NULL as it is impossible to resume the
		currently executing task. */
		if( ( pxTCB != NULL ) && ( pxTCB != pxCurrentTCB ) )
    1984:	00 97       	sbiw	r24, 0x00	; 0
    1986:	b9 f1       	breq	.+110    	; 0x19f6 <vTaskResume+0x7c>
    1988:	80 91 9b 03 	lds	r24, 0x039B
    198c:	90 91 9c 03 	lds	r25, 0x039C
    1990:	c8 17       	cp	r28, r24
    1992:	d9 07       	cpc	r29, r25
    1994:	81 f1       	breq	.+96     	; 0x19f6 <vTaskResume+0x7c>
		{
			taskENTER_CRITICAL();
    1996:	0f b6       	in	r0, 0x3f	; 63
    1998:	f8 94       	cli
    199a:	0f 92       	push	r0
			{
				if( prvTaskIsTaskSuspended( pxTCB ) != pdFALSE )
    199c:	ce 01       	movw	r24, r28
    199e:	0e 94 15 0a 	call	0x142a	; 0x142a <prvTaskIsTaskSuspended>
    19a2:	88 23       	and	r24, r24
    19a4:	31 f1       	breq	.+76     	; 0x19f2 <vTaskResume+0x78>
				{
					traceTASK_RESUME( pxTCB );

					/* As we are in a critical section we can access the ready
					lists even if the scheduler is suspended. */
					( void ) uxListRemove(  &( pxTCB->xStateListItem ) );
    19a6:	8e 01       	movw	r16, r28
    19a8:	0e 5f       	subi	r16, 0xFE	; 254
    19aa:	1f 4f       	sbci	r17, 0xFF	; 255
    19ac:	c8 01       	movw	r24, r16
    19ae:	0e 94 42 04 	call	0x884	; 0x884 <uxListRemove>
					prvAddTaskToReadyList( pxTCB );
    19b2:	8e 89       	ldd	r24, Y+22	; 0x16
    19b4:	90 91 a4 03 	lds	r25, 0x03A4
    19b8:	98 17       	cp	r25, r24
    19ba:	10 f4       	brcc	.+4      	; 0x19c0 <vTaskResume+0x46>
    19bc:	80 93 a4 03 	sts	0x03A4, r24
    19c0:	90 e0       	ldi	r25, 0x00	; 0
    19c2:	9c 01       	movw	r18, r24
    19c4:	22 0f       	add	r18, r18
    19c6:	33 1f       	adc	r19, r19
    19c8:	22 0f       	add	r18, r18
    19ca:	33 1f       	adc	r19, r19
    19cc:	22 0f       	add	r18, r18
    19ce:	33 1f       	adc	r19, r19
    19d0:	82 0f       	add	r24, r18
    19d2:	93 1f       	adc	r25, r19
    19d4:	82 55       	subi	r24, 0x52	; 82
    19d6:	9c 4f       	sbci	r25, 0xFC	; 252
    19d8:	b8 01       	movw	r22, r16
    19da:	0e 94 f1 03 	call	0x7e2	; 0x7e2 <vListInsertEnd>

					/* We may have just resumed a higher priority task. */
					if( pxTCB->uxPriority >= pxCurrentTCB->uxPriority )
    19de:	e0 91 9b 03 	lds	r30, 0x039B
    19e2:	f0 91 9c 03 	lds	r31, 0x039C
    19e6:	9e 89       	ldd	r25, Y+22	; 0x16
    19e8:	86 89       	ldd	r24, Z+22	; 0x16
    19ea:	98 17       	cp	r25, r24
    19ec:	10 f0       	brcs	.+4      	; 0x19f2 <vTaskResume+0x78>
					{
						/* This yield may not cause the task just resumed to run,
						but will leave the lists in the correct state for the
						next yield. */
						taskYIELD_IF_USING_PREEMPTION();
    19ee:	0e 94 30 05 	call	0xa60	; 0xa60 <vPortYield>
				else
				{
					mtCOVERAGE_TEST_MARKER();
				}
			}
			taskEXIT_CRITICAL();
    19f2:	0f 90       	pop	r0
    19f4:	0f be       	out	0x3f, r0	; 63
		}
		else
		{
			mtCOVERAGE_TEST_MARKER();
		}
	}
    19f6:	df 91       	pop	r29
    19f8:	cf 91       	pop	r28
    19fa:	1f 91       	pop	r17
    19fc:	0f 91       	pop	r16
    19fe:	08 95       	ret

00001a00 <xTaskResumeFromISR>:
/*-----------------------------------------------------------*/

#if ( ( INCLUDE_xTaskResumeFromISR == 1 ) && ( INCLUDE_vTaskSuspend == 1 ) )

	BaseType_t xTaskResumeFromISR( TaskHandle_t xTaskToResume )
	{
    1a00:	ef 92       	push	r14
    1a02:	ff 92       	push	r15
    1a04:	1f 93       	push	r17
    1a06:	cf 93       	push	r28
    1a08:	df 93       	push	r29
    1a0a:	ec 01       	movw	r28, r24
		http://www.freertos.org/RTOS-Cortex-M3-M4.html */
		portASSERT_IF_INTERRUPT_PRIORITY_INVALID();

		uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
		{
			if( prvTaskIsTaskSuspended( pxTCB ) != pdFALSE )
    1a0c:	0e 94 15 0a 	call	0x142a	; 0x142a <prvTaskIsTaskSuspended>
    1a10:	88 23       	and	r24, r24
    1a12:	b9 f1       	breq	.+110    	; 0x1a82 <xTaskResumeFromISR+0x82>
			{
				traceTASK_RESUME_FROM_ISR( pxTCB );

				/* Check the ready lists can be accessed. */
				if( uxSchedulerSuspended == ( UBaseType_t ) pdFALSE )
    1a14:	80 91 9d 03 	lds	r24, 0x039D
    1a18:	88 23       	and	r24, r24
    1a1a:	51 f5       	brne	.+84     	; 0x1a70 <xTaskResumeFromISR+0x70>
				{
					/* Ready lists can be accessed so move the task from the
					suspended list to the ready list directly. */
					if( pxTCB->uxPriority >= pxCurrentTCB->uxPriority )
    1a1c:	e0 91 9b 03 	lds	r30, 0x039B
    1a20:	f0 91 9c 03 	lds	r31, 0x039C

#if ( ( INCLUDE_xTaskResumeFromISR == 1 ) && ( INCLUDE_vTaskSuspend == 1 ) )

	BaseType_t xTaskResumeFromISR( TaskHandle_t xTaskToResume )
	{
	BaseType_t xYieldRequired = pdFALSE;
    1a24:	11 e0       	ldi	r17, 0x01	; 1
    1a26:	9e 89       	ldd	r25, Y+22	; 0x16
    1a28:	86 89       	ldd	r24, Z+22	; 0x16
    1a2a:	98 17       	cp	r25, r24
    1a2c:	08 f4       	brcc	.+2      	; 0x1a30 <xTaskResumeFromISR+0x30>
    1a2e:	10 e0       	ldi	r17, 0x00	; 0
					else
					{
						mtCOVERAGE_TEST_MARKER();
					}

					( void ) uxListRemove( &( pxTCB->xStateListItem ) );
    1a30:	ee 24       	eor	r14, r14
    1a32:	ff 24       	eor	r15, r15
    1a34:	68 94       	set
    1a36:	e1 f8       	bld	r14, 1
    1a38:	ec 0e       	add	r14, r28
    1a3a:	fd 1e       	adc	r15, r29
    1a3c:	c7 01       	movw	r24, r14
    1a3e:	0e 94 42 04 	call	0x884	; 0x884 <uxListRemove>
					prvAddTaskToReadyList( pxTCB );
    1a42:	8e 89       	ldd	r24, Y+22	; 0x16
    1a44:	90 91 a4 03 	lds	r25, 0x03A4
    1a48:	98 17       	cp	r25, r24
    1a4a:	10 f4       	brcc	.+4      	; 0x1a50 <xTaskResumeFromISR+0x50>
    1a4c:	80 93 a4 03 	sts	0x03A4, r24
    1a50:	90 e0       	ldi	r25, 0x00	; 0
    1a52:	9c 01       	movw	r18, r24
    1a54:	22 0f       	add	r18, r18
    1a56:	33 1f       	adc	r19, r19
    1a58:	22 0f       	add	r18, r18
    1a5a:	33 1f       	adc	r19, r19
    1a5c:	22 0f       	add	r18, r18
    1a5e:	33 1f       	adc	r19, r19
    1a60:	82 0f       	add	r24, r18
    1a62:	93 1f       	adc	r25, r19
    1a64:	82 55       	subi	r24, 0x52	; 82
    1a66:	9c 4f       	sbci	r25, 0xFC	; 252
    1a68:	b7 01       	movw	r22, r14
    1a6a:	0e 94 f1 03 	call	0x7e2	; 0x7e2 <vListInsertEnd>
    1a6e:	0a c0       	rjmp	.+20     	; 0x1a84 <xTaskResumeFromISR+0x84>
				else
				{
					/* The delayed or ready lists cannot be accessed so the task
					is held in the pending ready list until the scheduler is
					unsuspended. */
					vListInsertEnd( &( xPendingReadyList ), &( pxTCB->xEventListItem ) );
    1a70:	be 01       	movw	r22, r28
    1a72:	64 5f       	subi	r22, 0xF4	; 244
    1a74:	7f 4f       	sbci	r23, 0xFF	; 255
    1a76:	8d ee       	ldi	r24, 0xED	; 237
    1a78:	93 e0       	ldi	r25, 0x03	; 3
    1a7a:	0e 94 f1 03 	call	0x7e2	; 0x7e2 <vListInsertEnd>

#if ( ( INCLUDE_xTaskResumeFromISR == 1 ) && ( INCLUDE_vTaskSuspend == 1 ) )

	BaseType_t xTaskResumeFromISR( TaskHandle_t xTaskToResume )
	{
	BaseType_t xYieldRequired = pdFALSE;
    1a7e:	10 e0       	ldi	r17, 0x00	; 0
    1a80:	01 c0       	rjmp	.+2      	; 0x1a84 <xTaskResumeFromISR+0x84>
    1a82:	10 e0       	ldi	r17, 0x00	; 0
			}
		}
		portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );

		return xYieldRequired;
	}
    1a84:	81 2f       	mov	r24, r17
    1a86:	df 91       	pop	r29
    1a88:	cf 91       	pop	r28
    1a8a:	1f 91       	pop	r17
    1a8c:	ff 90       	pop	r15
    1a8e:	ef 90       	pop	r14
    1a90:	08 95       	ret

00001a92 <vTaskStartScheduler>:

#endif /* ( ( INCLUDE_xTaskResumeFromISR == 1 ) && ( INCLUDE_vTaskSuspend == 1 ) ) */
/*-----------------------------------------------------------*/

void vTaskStartScheduler( void )
{
    1a92:	ef 92       	push	r14
    1a94:	ff 92       	push	r15
    1a96:	0f 93       	push	r16
		}
	}
	#else
	{
		/* The Idle task is being created using dynamically allocated RAM. */
		xReturn = xTaskCreate(	prvIdleTask,
    1a98:	8e eb       	ldi	r24, 0xBE	; 190
    1a9a:	9e e0       	ldi	r25, 0x0E	; 14
    1a9c:	6c e6       	ldi	r22, 0x6C	; 108
    1a9e:	70 e0       	ldi	r23, 0x00	; 0
    1aa0:	48 ec       	ldi	r20, 0xC8	; 200
    1aa2:	50 e0       	ldi	r21, 0x00	; 0
    1aa4:	20 e0       	ldi	r18, 0x00	; 0
    1aa6:	30 e0       	ldi	r19, 0x00	; 0
    1aa8:	00 e0       	ldi	r16, 0x00	; 0
    1aaa:	0f 2e       	mov	r0, r31
    1aac:	f8 e0       	ldi	r31, 0x08	; 8
    1aae:	ef 2e       	mov	r14, r31
    1ab0:	f4 e0       	ldi	r31, 0x04	; 4
    1ab2:	ff 2e       	mov	r15, r31
    1ab4:	f0 2d       	mov	r31, r0
    1ab6:	0e 94 b0 0a 	call	0x1560	; 0x1560 <xTaskCreate>
			mtCOVERAGE_TEST_MARKER();
		}
	}
	#endif /* configUSE_TIMERS */

	if( xReturn == pdPASS )
    1aba:	81 30       	cpi	r24, 0x01	; 1
    1abc:	81 f4       	brne	.+32     	; 0x1ade <vTaskStartScheduler+0x4c>
		/* Interrupts are turned off here, to ensure a tick does not occur
		before or during the call to xPortStartScheduler().  The stacks of
		the created tasks contain a status word with interrupts switched on
		so interrupts will automatically get re-enabled when the first task
		starts to run. */
		portDISABLE_INTERRUPTS();
    1abe:	f8 94       	cli
			structure specific to the task that will run first. */
			_impure_ptr = &( pxCurrentTCB->xNewLib_reent );
		}
		#endif /* configUSE_NEWLIB_REENTRANT */

		xNextTaskUnblockTime = portMAX_DELAY;
    1ac0:	8f ef       	ldi	r24, 0xFF	; 255
    1ac2:	9f ef       	ldi	r25, 0xFF	; 255
    1ac4:	90 93 9f 03 	sts	0x039F, r25
    1ac8:	80 93 9e 03 	sts	0x039E, r24
		xSchedulerRunning = pdTRUE;
    1acc:	81 e0       	ldi	r24, 0x01	; 1
    1ace:	80 93 a3 03 	sts	0x03A3, r24
		xTickCount = ( TickType_t ) 0U;
    1ad2:	10 92 a6 03 	sts	0x03A6, r1
    1ad6:	10 92 a5 03 	sts	0x03A5, r1
		the run time counter time base. */
		portCONFIGURE_TIMER_FOR_RUN_TIME_STATS();

		/* Setting up the timer tick is hardware specific and thus in the
		portable interface. */
		if( xPortStartScheduler() != pdFALSE )
    1ada:	0e 94 fa 04 	call	0x9f4	; 0x9f4 <xPortStartScheduler>
	}

	/* Prevent compiler warnings if INCLUDE_xTaskGetIdleTaskHandle is set to 0,
	meaning xIdleTaskHandle is not used anywhere else. */
	( void ) xIdleTaskHandle;
}
    1ade:	0f 91       	pop	r16
    1ae0:	ff 90       	pop	r15
    1ae2:	ef 90       	pop	r14
    1ae4:	08 95       	ret

00001ae6 <vTaskEndScheduler>:
void vTaskEndScheduler( void )
{
	/* Stop the scheduler interrupts and call the portable scheduler end
	routine so the original ISRs can be restored if necessary.  The port
	layer must ensure interrupts enable	bit is left in the correct state. */
	portDISABLE_INTERRUPTS();
    1ae6:	f8 94       	cli
	xSchedulerRunning = pdFALSE;
    1ae8:	10 92 a3 03 	sts	0x03A3, r1
	vPortEndScheduler();
    1aec:	0e 94 2f 05 	call	0xa5e	; 0xa5e <vPortEndScheduler>
}
    1af0:	08 95       	ret

00001af2 <vTaskSuspendAll>:
{
	/* A critical section is not required as the variable is of type
	BaseType_t.  Please read Richard Barry's reply in the following link to a
	post in the FreeRTOS support forum before reporting this as a bug! -
	http://goo.gl/wu4acr */
	++uxSchedulerSuspended;
    1af2:	80 91 9d 03 	lds	r24, 0x039D
    1af6:	8f 5f       	subi	r24, 0xFF	; 255
    1af8:	80 93 9d 03 	sts	0x039D, r24
}
    1afc:	08 95       	ret

00001afe <xTaskGetTickCount>:
TickType_t xTaskGetTickCount( void )
{
TickType_t xTicks;

	/* Critical section required if running on a 16 bit processor. */
	portTICK_TYPE_ENTER_CRITICAL();
    1afe:	0f b6       	in	r0, 0x3f	; 63
    1b00:	f8 94       	cli
    1b02:	0f 92       	push	r0
	{
		xTicks = xTickCount;
    1b04:	80 91 a5 03 	lds	r24, 0x03A5
    1b08:	90 91 a6 03 	lds	r25, 0x03A6
	}
	portTICK_TYPE_EXIT_CRITICAL();
    1b0c:	0f 90       	pop	r0
    1b0e:	0f be       	out	0x3f, r0	; 63

	return xTicks;
}
    1b10:	08 95       	ret

00001b12 <xTaskGetTickCountFromISR>:
	link: http://www.freertos.org/RTOS-Cortex-M3-M4.html */
	portASSERT_IF_INTERRUPT_PRIORITY_INVALID();

	uxSavedInterruptStatus = portTICK_TYPE_SET_INTERRUPT_MASK_FROM_ISR();
	{
		xReturn = xTickCount;
    1b12:	80 91 a5 03 	lds	r24, 0x03A5
    1b16:	90 91 a6 03 	lds	r25, 0x03A6
	}
	portTICK_TYPE_CLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );

	return xReturn;
}
    1b1a:	08 95       	ret

00001b1c <uxTaskGetNumberOfTasks>:

UBaseType_t uxTaskGetNumberOfTasks( void )
{
	/* A critical section is not required because the variables are of type
	BaseType_t. */
	return uxCurrentNumberOfTasks;
    1b1c:	80 91 a7 03 	lds	r24, 0x03A7
}
    1b20:	08 95       	ret

00001b22 <pcTaskGetName>:
{
TCB_t *pxTCB;

	/* If null is passed in here then the name of the calling task is being
	queried. */
	pxTCB = prvGetTCBFromHandle( xTaskToQuery );
    1b22:	00 97       	sbiw	r24, 0x00	; 0
    1b24:	21 f4       	brne	.+8      	; 0x1b2e <pcTaskGetName+0xc>
    1b26:	80 91 9b 03 	lds	r24, 0x039B
    1b2a:	90 91 9c 03 	lds	r25, 0x039C
	configASSERT( pxTCB );
	return &( pxTCB->pcTaskName[ 0 ] );
    1b2e:	49 96       	adiw	r24, 0x19	; 25
}
    1b30:	08 95       	ret

00001b32 <xTaskIncrementTick>:

#endif /* INCLUDE_xTaskAbortDelay */
/*----------------------------------------------------------*/

BaseType_t xTaskIncrementTick( void )
{
    1b32:	cf 92       	push	r12
    1b34:	df 92       	push	r13
    1b36:	ef 92       	push	r14
    1b38:	ff 92       	push	r15
    1b3a:	0f 93       	push	r16
    1b3c:	1f 93       	push	r17
    1b3e:	cf 93       	push	r28
    1b40:	df 93       	push	r29

	/* Called by the portable layer each time a tick interrupt occurs.
	Increments the tick then checks to see if the new tick value will cause any
	tasks to be unblocked. */
	traceTASK_INCREMENT_TICK( xTickCount );
	if( uxSchedulerSuspended == ( UBaseType_t ) pdFALSE )
    1b42:	80 91 9d 03 	lds	r24, 0x039D
    1b46:	88 23       	and	r24, r24
    1b48:	09 f0       	breq	.+2      	; 0x1b4c <xTaskIncrementTick+0x1a>
    1b4a:	82 c0       	rjmp	.+260    	; 0x1c50 <xTaskIncrementTick+0x11e>
	{
		/* Minor optimisation.  The tick count cannot change in this
		block. */
		const TickType_t xConstTickCount = xTickCount + 1;
    1b4c:	c0 90 a5 03 	lds	r12, 0x03A5
    1b50:	d0 90 a6 03 	lds	r13, 0x03A6
    1b54:	08 94       	sec
    1b56:	c1 1c       	adc	r12, r1
    1b58:	d1 1c       	adc	r13, r1

		/* Increment the RTOS tick, switching the delayed and overflowed
		delayed lists if it wraps to 0. */
		xTickCount = xConstTickCount;
    1b5a:	d0 92 a6 03 	sts	0x03A6, r13
    1b5e:	c0 92 a5 03 	sts	0x03A5, r12

		if( xConstTickCount == ( TickType_t ) 0U )
    1b62:	c1 14       	cp	r12, r1
    1b64:	d1 04       	cpc	r13, r1
    1b66:	b9 f4       	brne	.+46     	; 0x1b96 <xTaskIncrementTick+0x64>
		{
			taskSWITCH_DELAYED_LISTS();
    1b68:	80 91 ab 03 	lds	r24, 0x03AB
    1b6c:	90 91 ac 03 	lds	r25, 0x03AC
    1b70:	20 91 a9 03 	lds	r18, 0x03A9
    1b74:	30 91 aa 03 	lds	r19, 0x03AA
    1b78:	30 93 ac 03 	sts	0x03AC, r19
    1b7c:	20 93 ab 03 	sts	0x03AB, r18
    1b80:	90 93 aa 03 	sts	0x03AA, r25
    1b84:	80 93 a9 03 	sts	0x03A9, r24
    1b88:	80 91 a0 03 	lds	r24, 0x03A0
    1b8c:	8f 5f       	subi	r24, 0xFF	; 255
    1b8e:	80 93 a0 03 	sts	0x03A0, r24
    1b92:	0e 94 2c 0a 	call	0x1458	; 0x1458 <prvResetNextTaskUnblockTime>

		/* See if this tick has made a timeout expire.  Tasks are stored in
		the	queue in the order of their wake time - meaning once one task
		has been found whose block time has not expired there is no need to
		look any further down the list. */
		if( xConstTickCount >= xNextTaskUnblockTime )
    1b96:	80 91 9e 03 	lds	r24, 0x039E
    1b9a:	90 91 9f 03 	lds	r25, 0x039F
    1b9e:	c8 16       	cp	r12, r24
    1ba0:	d9 06       	cpc	r13, r25
    1ba2:	20 f4       	brcc	.+8      	; 0x1bac <xTaskIncrementTick+0x7a>

BaseType_t xTaskIncrementTick( void )
{
TCB_t * pxTCB;
TickType_t xItemValue;
BaseType_t xSwitchRequired = pdFALSE;
    1ba4:	ff 24       	eor	r15, r15
    1ba6:	5a c0       	rjmp	.+180    	; 0x1c5c <xTaskIncrementTick+0x12a>
						only be performed if the unblocked task has a
						priority that is equal to or higher than the
						currently executing task. */
						if( pxTCB->uxPriority >= pxCurrentTCB->uxPriority )
						{
							xSwitchRequired = pdTRUE;
    1ba8:	fe 2c       	mov	r15, r14
    1baa:	03 c0       	rjmp	.+6      	; 0x1bb2 <xTaskIncrementTick+0x80>

		/* See if this tick has made a timeout expire.  Tasks are stored in
		the	queue in the order of their wake time - meaning once one task
		has been found whose block time has not expired there is no need to
		look any further down the list. */
		if( xConstTickCount >= xNextTaskUnblockTime )
    1bac:	ff 24       	eor	r15, r15
						only be performed if the unblocked task has a
						priority that is equal to or higher than the
						currently executing task. */
						if( pxTCB->uxPriority >= pxCurrentTCB->uxPriority )
						{
							xSwitchRequired = pdTRUE;
    1bae:	ee 24       	eor	r14, r14
    1bb0:	e3 94       	inc	r14
		look any further down the list. */
		if( xConstTickCount >= xNextTaskUnblockTime )
		{
			for( ;; )
			{
				if( listLIST_IS_EMPTY( pxDelayedTaskList ) != pdFALSE )
    1bb2:	e0 91 ab 03 	lds	r30, 0x03AB
    1bb6:	f0 91 ac 03 	lds	r31, 0x03AC
    1bba:	80 81       	ld	r24, Z
    1bbc:	88 23       	and	r24, r24
    1bbe:	39 f4       	brne	.+14     	; 0x1bce <xTaskIncrementTick+0x9c>
					/* The delayed list is empty.  Set xNextTaskUnblockTime
					to the maximum possible value so it is extremely
					unlikely that the
					if( xTickCount >= xNextTaskUnblockTime ) test will pass
					next time through. */
					xNextTaskUnblockTime = portMAX_DELAY; /*lint !e961 MISRA exception as the casts are only redundant for some ports. */
    1bc0:	8f ef       	ldi	r24, 0xFF	; 255
    1bc2:	9f ef       	ldi	r25, 0xFF	; 255
    1bc4:	90 93 9f 03 	sts	0x039F, r25
    1bc8:	80 93 9e 03 	sts	0x039E, r24
					break;
    1bcc:	47 c0       	rjmp	.+142    	; 0x1c5c <xTaskIncrementTick+0x12a>
				{
					/* The delayed list is not empty, get the value of the
					item at the head of the delayed list.  This is the time
					at which the task at the head of the delayed list must
					be removed from the Blocked state. */
					pxTCB = ( TCB_t * ) listGET_OWNER_OF_HEAD_ENTRY( pxDelayedTaskList );
    1bce:	e0 91 ab 03 	lds	r30, 0x03AB
    1bd2:	f0 91 ac 03 	lds	r31, 0x03AC
    1bd6:	05 80       	ldd	r0, Z+5	; 0x05
    1bd8:	f6 81       	ldd	r31, Z+6	; 0x06
    1bda:	e0 2d       	mov	r30, r0
    1bdc:	c6 81       	ldd	r28, Z+6	; 0x06
    1bde:	d7 81       	ldd	r29, Z+7	; 0x07
					xItemValue = listGET_LIST_ITEM_VALUE( &( pxTCB->xStateListItem ) );
    1be0:	8a 81       	ldd	r24, Y+2	; 0x02
    1be2:	9b 81       	ldd	r25, Y+3	; 0x03

					if( xConstTickCount < xItemValue )
    1be4:	c8 16       	cp	r12, r24
    1be6:	d9 06       	cpc	r13, r25
    1be8:	28 f4       	brcc	.+10     	; 0x1bf4 <xTaskIncrementTick+0xc2>
						/* It is not time to unblock this item yet, but the
						item value is the time at which the task at the head
						of the blocked list must be removed from the Blocked
						state -	so record the item value in
						xNextTaskUnblockTime. */
						xNextTaskUnblockTime = xItemValue;
    1bea:	90 93 9f 03 	sts	0x039F, r25
    1bee:	80 93 9e 03 	sts	0x039E, r24
						break;
    1bf2:	34 c0       	rjmp	.+104    	; 0x1c5c <xTaskIncrementTick+0x12a>
					{
						mtCOVERAGE_TEST_MARKER();
					}

					/* It is time to remove the item from the Blocked state. */
					( void ) uxListRemove( &( pxTCB->xStateListItem ) );
    1bf4:	8e 01       	movw	r16, r28
    1bf6:	0e 5f       	subi	r16, 0xFE	; 254
    1bf8:	1f 4f       	sbci	r17, 0xFF	; 255
    1bfa:	c8 01       	movw	r24, r16
    1bfc:	0e 94 42 04 	call	0x884	; 0x884 <uxListRemove>

					/* Is the task waiting on an event also?  If so remove
					it from the event list. */
					if( listLIST_ITEM_CONTAINER( &( pxTCB->xEventListItem ) ) != NULL )
    1c00:	8c 89       	ldd	r24, Y+20	; 0x14
    1c02:	9d 89       	ldd	r25, Y+21	; 0x15
    1c04:	00 97       	sbiw	r24, 0x00	; 0
    1c06:	21 f0       	breq	.+8      	; 0x1c10 <xTaskIncrementTick+0xde>
					{
						( void ) uxListRemove( &( pxTCB->xEventListItem ) );
    1c08:	ce 01       	movw	r24, r28
    1c0a:	0c 96       	adiw	r24, 0x0c	; 12
    1c0c:	0e 94 42 04 	call	0x884	; 0x884 <uxListRemove>
						mtCOVERAGE_TEST_MARKER();
					}

					/* Place the unblocked task into the appropriate ready
					list. */
					prvAddTaskToReadyList( pxTCB );
    1c10:	8e 89       	ldd	r24, Y+22	; 0x16
    1c12:	90 91 a4 03 	lds	r25, 0x03A4
    1c16:	98 17       	cp	r25, r24
    1c18:	10 f4       	brcc	.+4      	; 0x1c1e <xTaskIncrementTick+0xec>
    1c1a:	80 93 a4 03 	sts	0x03A4, r24
    1c1e:	90 e0       	ldi	r25, 0x00	; 0
    1c20:	9c 01       	movw	r18, r24
    1c22:	22 0f       	add	r18, r18
    1c24:	33 1f       	adc	r19, r19
    1c26:	22 0f       	add	r18, r18
    1c28:	33 1f       	adc	r19, r19
    1c2a:	22 0f       	add	r18, r18
    1c2c:	33 1f       	adc	r19, r19
    1c2e:	82 0f       	add	r24, r18
    1c30:	93 1f       	adc	r25, r19
    1c32:	82 55       	subi	r24, 0x52	; 82
    1c34:	9c 4f       	sbci	r25, 0xFC	; 252
    1c36:	b8 01       	movw	r22, r16
    1c38:	0e 94 f1 03 	call	0x7e2	; 0x7e2 <vListInsertEnd>
					{
						/* Preemption is on, but a context switch should
						only be performed if the unblocked task has a
						priority that is equal to or higher than the
						currently executing task. */
						if( pxTCB->uxPriority >= pxCurrentTCB->uxPriority )
    1c3c:	e0 91 9b 03 	lds	r30, 0x039B
    1c40:	f0 91 9c 03 	lds	r31, 0x039C
    1c44:	9e 89       	ldd	r25, Y+22	; 0x16
    1c46:	86 89       	ldd	r24, Z+22	; 0x16
    1c48:	98 17       	cp	r25, r24
    1c4a:	08 f0       	brcs	.+2      	; 0x1c4e <xTaskIncrementTick+0x11c>
    1c4c:	ad cf       	rjmp	.-166    	; 0x1ba8 <xTaskIncrementTick+0x76>
    1c4e:	b1 cf       	rjmp	.-158    	; 0x1bb2 <xTaskIncrementTick+0x80>
		}
		#endif /* configUSE_TICK_HOOK */
	}
	else
	{
		++uxPendedTicks;
    1c50:	80 91 a2 03 	lds	r24, 0x03A2
    1c54:	8f 5f       	subi	r24, 0xFF	; 255
    1c56:	80 93 a2 03 	sts	0x03A2, r24

BaseType_t xTaskIncrementTick( void )
{
TCB_t * pxTCB;
TickType_t xItemValue;
BaseType_t xSwitchRequired = pdFALSE;
    1c5a:	ff 24       	eor	r15, r15
		#endif
	}

	#if ( configUSE_PREEMPTION == 1 )
	{
		if( xYieldPending != pdFALSE )
    1c5c:	80 91 a1 03 	lds	r24, 0x03A1
    1c60:	88 23       	and	r24, r24
    1c62:	11 f0       	breq	.+4      	; 0x1c68 <xTaskIncrementTick+0x136>
		{
			xSwitchRequired = pdTRUE;
    1c64:	ff 24       	eor	r15, r15
    1c66:	f3 94       	inc	r15
		}
	}
	#endif /* configUSE_PREEMPTION */

	return xSwitchRequired;
}
    1c68:	8f 2d       	mov	r24, r15
    1c6a:	df 91       	pop	r29
    1c6c:	cf 91       	pop	r28
    1c6e:	1f 91       	pop	r17
    1c70:	0f 91       	pop	r16
    1c72:	ff 90       	pop	r15
    1c74:	ef 90       	pop	r14
    1c76:	df 90       	pop	r13
    1c78:	cf 90       	pop	r12
    1c7a:	08 95       	ret

00001c7c <xTaskResumeAll>:

#endif /* configUSE_TICKLESS_IDLE */
/*----------------------------------------------------------*/

BaseType_t xTaskResumeAll( void )
{
    1c7c:	df 92       	push	r13
    1c7e:	ef 92       	push	r14
    1c80:	ff 92       	push	r15
    1c82:	0f 93       	push	r16
    1c84:	1f 93       	push	r17
    1c86:	cf 93       	push	r28
    1c88:	df 93       	push	r29
	/* It is possible that an ISR caused a task to be removed from an event
	list while the scheduler was suspended.  If this was the case then the
	removed task will have been added to the xPendingReadyList.  Once the
	scheduler has been resumed it is safe to move all the pending ready
	tasks from this list into their appropriate ready list. */
	taskENTER_CRITICAL();
    1c8a:	0f b6       	in	r0, 0x3f	; 63
    1c8c:	f8 94       	cli
    1c8e:	0f 92       	push	r0
	{
		--uxSchedulerSuspended;
    1c90:	80 91 9d 03 	lds	r24, 0x039D
    1c94:	81 50       	subi	r24, 0x01	; 1
    1c96:	80 93 9d 03 	sts	0x039D, r24

		if( uxSchedulerSuspended == ( UBaseType_t ) pdFALSE )
    1c9a:	80 91 9d 03 	lds	r24, 0x039D
    1c9e:	88 23       	and	r24, r24
    1ca0:	09 f0       	breq	.+2      	; 0x1ca4 <xTaskResumeAll+0x28>
    1ca2:	5f c0       	rjmp	.+190    	; 0x1d62 <xTaskResumeAll+0xe6>
		{
			if( uxCurrentNumberOfTasks > ( UBaseType_t ) 0U )
    1ca4:	80 91 a7 03 	lds	r24, 0x03A7
    1ca8:	88 23       	and	r24, r24
    1caa:	91 f5       	brne	.+100    	; 0x1d10 <xTaskResumeAll+0x94>
    1cac:	5d c0       	rjmp	.+186    	; 0x1d68 <xTaskResumeAll+0xec>
			{
				/* Move any readied tasks from the pending list into the
				appropriate ready list. */
				while( listLIST_IS_EMPTY( &xPendingReadyList ) == pdFALSE )
				{
					pxTCB = ( TCB_t * ) listGET_OWNER_OF_HEAD_ENTRY( ( &xPendingReadyList ) );
    1cae:	e0 91 f2 03 	lds	r30, 0x03F2
    1cb2:	f0 91 f3 03 	lds	r31, 0x03F3
    1cb6:	c6 81       	ldd	r28, Z+6	; 0x06
    1cb8:	d7 81       	ldd	r29, Z+7	; 0x07
					( void ) uxListRemove( &( pxTCB->xEventListItem ) );
    1cba:	ce 01       	movw	r24, r28
    1cbc:	0c 96       	adiw	r24, 0x0c	; 12
    1cbe:	0e 94 42 04 	call	0x884	; 0x884 <uxListRemove>
					( void ) uxListRemove( &( pxTCB->xStateListItem ) );
    1cc2:	8e 01       	movw	r16, r28
    1cc4:	0e 5f       	subi	r16, 0xFE	; 254
    1cc6:	1f 4f       	sbci	r17, 0xFF	; 255
    1cc8:	c8 01       	movw	r24, r16
    1cca:	0e 94 42 04 	call	0x884	; 0x884 <uxListRemove>
					prvAddTaskToReadyList( pxTCB );
    1cce:	8e 89       	ldd	r24, Y+22	; 0x16
    1cd0:	90 91 a4 03 	lds	r25, 0x03A4
    1cd4:	98 17       	cp	r25, r24
    1cd6:	10 f4       	brcc	.+4      	; 0x1cdc <xTaskResumeAll+0x60>
    1cd8:	80 93 a4 03 	sts	0x03A4, r24
    1cdc:	90 e0       	ldi	r25, 0x00	; 0
    1cde:	9c 01       	movw	r18, r24
    1ce0:	22 0f       	add	r18, r18
    1ce2:	33 1f       	adc	r19, r19
    1ce4:	22 0f       	add	r18, r18
    1ce6:	33 1f       	adc	r19, r19
    1ce8:	22 0f       	add	r18, r18
    1cea:	33 1f       	adc	r19, r19
    1cec:	82 0f       	add	r24, r18
    1cee:	93 1f       	adc	r25, r19
    1cf0:	82 55       	subi	r24, 0x52	; 82
    1cf2:	9c 4f       	sbci	r25, 0xFC	; 252
    1cf4:	b8 01       	movw	r22, r16
    1cf6:	0e 94 f1 03 	call	0x7e2	; 0x7e2 <vListInsertEnd>

					/* If the moved task has a priority higher than the current
					task then a yield must be performed. */
					if( pxTCB->uxPriority >= pxCurrentTCB->uxPriority )
    1cfa:	e0 91 9b 03 	lds	r30, 0x039B
    1cfe:	f0 91 9c 03 	lds	r31, 0x039C
    1d02:	9e 89       	ldd	r25, Y+22	; 0x16
    1d04:	86 89       	ldd	r24, Z+22	; 0x16
    1d06:	98 17       	cp	r25, r24
    1d08:	68 f0       	brcs	.+26     	; 0x1d24 <xTaskResumeAll+0xa8>
					{
						xYieldPending = pdTRUE;
    1d0a:	d0 92 a1 03 	sts	0x03A1, r13
    1d0e:	0a c0       	rjmp	.+20     	; 0x1d24 <xTaskResumeAll+0xa8>
	{
		--uxSchedulerSuspended;

		if( uxSchedulerSuspended == ( UBaseType_t ) pdFALSE )
		{
			if( uxCurrentNumberOfTasks > ( UBaseType_t ) 0U )
    1d10:	c0 e0       	ldi	r28, 0x00	; 0
    1d12:	d0 e0       	ldi	r29, 0x00	; 0
			{
				/* Move any readied tasks from the pending list into the
				appropriate ready list. */
				while( listLIST_IS_EMPTY( &xPendingReadyList ) == pdFALSE )
    1d14:	0f 2e       	mov	r0, r31
    1d16:	fd ee       	ldi	r31, 0xED	; 237
    1d18:	ef 2e       	mov	r14, r31
    1d1a:	f3 e0       	ldi	r31, 0x03	; 3
    1d1c:	ff 2e       	mov	r15, r31
    1d1e:	f0 2d       	mov	r31, r0

					/* If the moved task has a priority higher than the current
					task then a yield must be performed. */
					if( pxTCB->uxPriority >= pxCurrentTCB->uxPriority )
					{
						xYieldPending = pdTRUE;
    1d20:	dd 24       	eor	r13, r13
    1d22:	d3 94       	inc	r13
		{
			if( uxCurrentNumberOfTasks > ( UBaseType_t ) 0U )
			{
				/* Move any readied tasks from the pending list into the
				appropriate ready list. */
				while( listLIST_IS_EMPTY( &xPendingReadyList ) == pdFALSE )
    1d24:	f7 01       	movw	r30, r14
    1d26:	80 81       	ld	r24, Z
    1d28:	88 23       	and	r24, r24
    1d2a:	09 f6       	brne	.-126    	; 0x1cae <xTaskResumeAll+0x32>
					{
						mtCOVERAGE_TEST_MARKER();
					}
				}

				if( pxTCB != NULL )
    1d2c:	20 97       	sbiw	r28, 0x00	; 0
    1d2e:	11 f0       	breq	.+4      	; 0x1d34 <xTaskResumeAll+0xb8>
					which may have prevented the next unblock time from being
					re-calculated, in which case re-calculate it now.  Mainly
					important for low power tickless implementations, where
					this can prevent an unnecessary exit from low power
					state. */
					prvResetNextTaskUnblockTime();
    1d30:	0e 94 2c 0a 	call	0x1458	; 0x1458 <prvResetNextTaskUnblockTime>
				/* If any ticks occurred while the scheduler was suspended then
				they should be processed now.  This ensures the tick count does
				not	slip, and that any delayed tasks are resumed at the correct
				time. */
				{
					UBaseType_t uxPendedCounts = uxPendedTicks; /* Non-volatile copy. */
    1d34:	c0 91 a2 03 	lds	r28, 0x03A2

					if( uxPendedCounts > ( UBaseType_t ) 0U )
    1d38:	cc 23       	and	r28, r28
    1d3a:	59 f0       	breq	.+22     	; 0x1d52 <xTaskResumeAll+0xd6>
					{
						do
						{
							if( xTaskIncrementTick() != pdFALSE )
							{
								xYieldPending = pdTRUE;
    1d3c:	01 e0       	ldi	r16, 0x01	; 1

					if( uxPendedCounts > ( UBaseType_t ) 0U )
					{
						do
						{
							if( xTaskIncrementTick() != pdFALSE )
    1d3e:	0e 94 99 0d 	call	0x1b32	; 0x1b32 <xTaskIncrementTick>
    1d42:	88 23       	and	r24, r24
    1d44:	11 f0       	breq	.+4      	; 0x1d4a <xTaskResumeAll+0xce>
							{
								xYieldPending = pdTRUE;
    1d46:	00 93 a1 03 	sts	0x03A1, r16
							}
							else
							{
								mtCOVERAGE_TEST_MARKER();
							}
							--uxPendedCounts;
    1d4a:	c1 50       	subi	r28, 0x01	; 1
						} while( uxPendedCounts > ( UBaseType_t ) 0U );
    1d4c:	c1 f7       	brne	.-16     	; 0x1d3e <xTaskResumeAll+0xc2>

						uxPendedTicks = 0;
    1d4e:	10 92 a2 03 	sts	0x03A2, r1
					{
						mtCOVERAGE_TEST_MARKER();
					}
				}

				if( xYieldPending != pdFALSE )
    1d52:	80 91 a1 03 	lds	r24, 0x03A1
    1d56:	88 23       	and	r24, r24
    1d58:	31 f0       	breq	.+12     	; 0x1d66 <xTaskResumeAll+0xea>
					#if( configUSE_PREEMPTION != 0 )
					{
						xAlreadyYielded = pdTRUE;
					}
					#endif
					taskYIELD_IF_USING_PREEMPTION();
    1d5a:	0e 94 30 05 	call	0xa60	; 0xa60 <vPortYield>

				if( xYieldPending != pdFALSE )
				{
					#if( configUSE_PREEMPTION != 0 )
					{
						xAlreadyYielded = pdTRUE;
    1d5e:	81 e0       	ldi	r24, 0x01	; 1
    1d60:	03 c0       	rjmp	.+6      	; 0x1d68 <xTaskResumeAll+0xec>
/*----------------------------------------------------------*/

BaseType_t xTaskResumeAll( void )
{
TCB_t *pxTCB = NULL;
BaseType_t xAlreadyYielded = pdFALSE;
    1d62:	80 e0       	ldi	r24, 0x00	; 0
    1d64:	01 c0       	rjmp	.+2      	; 0x1d68 <xTaskResumeAll+0xec>
    1d66:	80 e0       	ldi	r24, 0x00	; 0
		else
		{
			mtCOVERAGE_TEST_MARKER();
		}
	}
	taskEXIT_CRITICAL();
    1d68:	0f 90       	pop	r0
    1d6a:	0f be       	out	0x3f, r0	; 63

	return xAlreadyYielded;
}
    1d6c:	df 91       	pop	r29
    1d6e:	cf 91       	pop	r28
    1d70:	1f 91       	pop	r17
    1d72:	0f 91       	pop	r16
    1d74:	ff 90       	pop	r15
    1d76:	ef 90       	pop	r14
    1d78:	df 90       	pop	r13
    1d7a:	08 95       	ret

00001d7c <prvIdleTask>:
		too often in the idle task. */
		while( uxDeletedTasksWaitingCleanUp > ( UBaseType_t ) 0U )
		{
			vTaskSuspendAll();
			{
				xListIsEmpty = listLIST_IS_EMPTY( &xTasksWaitingTermination );
    1d7c:	06 ef       	ldi	r16, 0xF6	; 246
    1d7e:	13 e0       	ldi	r17, 0x03	; 3

			A critical region is not required here as we are just reading from
			the list, and an occasional incorrect value will not matter.  If
			the ready list at the idle priority contains more than one task
			then a task other than the idle task is ready to execute. */
			if( listCURRENT_LIST_LENGTH( &( pxReadyTasksLists[ tskIDLE_PRIORITY ] ) ) > ( UBaseType_t ) 1 )
    1d80:	0f 2e       	mov	r0, r31
    1d82:	fe ea       	ldi	r31, 0xAE	; 174
    1d84:	ef 2e       	mov	r14, r31
    1d86:	f3 e0       	ldi	r31, 0x03	; 3
    1d88:	ff 2e       	mov	r15, r31
    1d8a:	f0 2d       	mov	r31, r0
    1d8c:	24 c0       	rjmp	.+72     	; 0x1dd6 <prvIdleTask+0x5a>

		/* ucTasksDeleted is used to prevent vTaskSuspendAll() being called
		too often in the idle task. */
		while( uxDeletedTasksWaitingCleanUp > ( UBaseType_t ) 0U )
		{
			vTaskSuspendAll();
    1d8e:	0e 94 79 0d 	call	0x1af2	; 0x1af2 <vTaskSuspendAll>
			{
				xListIsEmpty = listLIST_IS_EMPTY( &xTasksWaitingTermination );
    1d92:	f8 01       	movw	r30, r16
    1d94:	c0 81       	ld	r28, Z
			}
			( void ) xTaskResumeAll();
    1d96:	0e 94 3e 0e 	call	0x1c7c	; 0x1c7c <xTaskResumeAll>

			if( xListIsEmpty == pdFALSE )
    1d9a:	cc 23       	and	r28, r28
    1d9c:	e1 f0       	breq	.+56     	; 0x1dd6 <prvIdleTask+0x5a>
			{
				TCB_t *pxTCB;

				taskENTER_CRITICAL();
    1d9e:	0f b6       	in	r0, 0x3f	; 63
    1da0:	f8 94       	cli
    1da2:	0f 92       	push	r0
				{
					pxTCB = ( TCB_t * ) listGET_OWNER_OF_HEAD_ENTRY( ( &xTasksWaitingTermination ) );
    1da4:	e0 91 fb 03 	lds	r30, 0x03FB
    1da8:	f0 91 fc 03 	lds	r31, 0x03FC
    1dac:	c6 81       	ldd	r28, Z+6	; 0x06
    1dae:	d7 81       	ldd	r29, Z+7	; 0x07
					( void ) uxListRemove( &( pxTCB->xStateListItem ) );
    1db0:	ce 01       	movw	r24, r28
    1db2:	02 96       	adiw	r24, 0x02	; 2
    1db4:	0e 94 42 04 	call	0x884	; 0x884 <uxListRemove>
					--uxCurrentNumberOfTasks;
    1db8:	80 91 a7 03 	lds	r24, 0x03A7
    1dbc:	81 50       	subi	r24, 0x01	; 1
    1dbe:	80 93 a7 03 	sts	0x03A7, r24
					--uxDeletedTasksWaitingCleanUp;
    1dc2:	80 91 a8 03 	lds	r24, 0x03A8
    1dc6:	81 50       	subi	r24, 0x01	; 1
    1dc8:	80 93 a8 03 	sts	0x03A8, r24
				}
				taskEXIT_CRITICAL();
    1dcc:	0f 90       	pop	r0
    1dce:	0f be       	out	0x3f, r0	; 63

				prvDeleteTCB( pxTCB );
    1dd0:	ce 01       	movw	r24, r28
    1dd2:	0e 94 a3 0a 	call	0x1546	; 0x1546 <prvDeleteTCB>
	{
		BaseType_t xListIsEmpty;

		/* ucTasksDeleted is used to prevent vTaskSuspendAll() being called
		too often in the idle task. */
		while( uxDeletedTasksWaitingCleanUp > ( UBaseType_t ) 0U )
    1dd6:	80 91 a8 03 	lds	r24, 0x03A8
    1dda:	88 23       	and	r24, r24
    1ddc:	c1 f6       	brne	.-80     	; 0x1d8e <prvIdleTask+0x12>

			A critical region is not required here as we are just reading from
			the list, and an occasional incorrect value will not matter.  If
			the ready list at the idle priority contains more than one task
			then a task other than the idle task is ready to execute. */
			if( listCURRENT_LIST_LENGTH( &( pxReadyTasksLists[ tskIDLE_PRIORITY ] ) ) > ( UBaseType_t ) 1 )
    1dde:	f7 01       	movw	r30, r14
    1de0:	80 81       	ld	r24, Z
    1de2:	82 30       	cpi	r24, 0x02	; 2
    1de4:	c0 f3       	brcs	.-16     	; 0x1dd6 <prvIdleTask+0x5a>
			{
				taskYIELD();
    1de6:	0e 94 30 05 	call	0xa60	; 0xa60 <vPortYield>
    1dea:	f5 cf       	rjmp	.-22     	; 0x1dd6 <prvIdleTask+0x5a>

00001dec <vTaskDelay>:
/*-----------------------------------------------------------*/

#if ( INCLUDE_vTaskDelay == 1 )

	void vTaskDelay( const TickType_t xTicksToDelay )
	{
    1dec:	cf 93       	push	r28
    1dee:	df 93       	push	r29
    1df0:	ec 01       	movw	r28, r24
	BaseType_t xAlreadyYielded = pdFALSE;

		/* A delay time of zero just forces a reschedule. */
		if( xTicksToDelay > ( TickType_t ) 0U )
    1df2:	00 97       	sbiw	r24, 0x00	; 0
    1df4:	51 f0       	breq	.+20     	; 0x1e0a <vTaskDelay+0x1e>
		{
			configASSERT( uxSchedulerSuspended == 0 );
			vTaskSuspendAll();
    1df6:	0e 94 79 0d 	call	0x1af2	; 0x1af2 <vTaskSuspendAll>
				list or removed from the blocked list until the scheduler
				is resumed.

				This task cannot be in an event list as it is the currently
				executing task. */
				prvAddCurrentTaskToDelayedList( xTicksToDelay, pdFALSE );
    1dfa:	ce 01       	movw	r24, r28
    1dfc:	60 e0       	ldi	r22, 0x00	; 0
    1dfe:	0e 94 4b 0a 	call	0x1496	; 0x1496 <prvAddCurrentTaskToDelayedList>
			}
			xAlreadyYielded = xTaskResumeAll();
    1e02:	0e 94 3e 0e 	call	0x1c7c	; 0x1c7c <xTaskResumeAll>
			mtCOVERAGE_TEST_MARKER();
		}

		/* Force a reschedule if xTaskResumeAll has not already done so, we may
		have put ourselves to sleep. */
		if( xAlreadyYielded == pdFALSE )
    1e06:	88 23       	and	r24, r24
    1e08:	11 f4       	brne	.+4      	; 0x1e0e <vTaskDelay+0x22>
		{
			portYIELD_WITHIN_API();
    1e0a:	0e 94 30 05 	call	0xa60	; 0xa60 <vPortYield>
		}
		else
		{
			mtCOVERAGE_TEST_MARKER();
		}
	}
    1e0e:	df 91       	pop	r29
    1e10:	cf 91       	pop	r28
    1e12:	08 95       	ret

00001e14 <vTaskDelayUntil>:
/*-----------------------------------------------------------*/

#if ( INCLUDE_vTaskDelayUntil == 1 )

	void vTaskDelayUntil( TickType_t * const pxPreviousWakeTime, const TickType_t xTimeIncrement )
	{
    1e14:	0f 93       	push	r16
    1e16:	1f 93       	push	r17
    1e18:	cf 93       	push	r28
    1e1a:	df 93       	push	r29
    1e1c:	8c 01       	movw	r16, r24
    1e1e:	eb 01       	movw	r28, r22

		configASSERT( pxPreviousWakeTime );
		configASSERT( ( xTimeIncrement > 0U ) );
		configASSERT( uxSchedulerSuspended == 0 );

		vTaskSuspendAll();
    1e20:	0e 94 79 0d 	call	0x1af2	; 0x1af2 <vTaskSuspendAll>
		{
			/* Minor optimisation.  The tick count cannot change in this
			block. */
			const TickType_t xConstTickCount = xTickCount;
    1e24:	80 91 a5 03 	lds	r24, 0x03A5
    1e28:	90 91 a6 03 	lds	r25, 0x03A6

			/* Generate the tick time at which the task wants to wake. */
			xTimeToWake = *pxPreviousWakeTime + xTimeIncrement;
    1e2c:	f8 01       	movw	r30, r16
    1e2e:	20 81       	ld	r18, Z
    1e30:	31 81       	ldd	r19, Z+1	; 0x01
    1e32:	c2 0f       	add	r28, r18
    1e34:	d3 1f       	adc	r29, r19

			if( xConstTickCount < *pxPreviousWakeTime )
    1e36:	82 17       	cp	r24, r18
    1e38:	93 07       	cpc	r25, r19
    1e3a:	48 f4       	brcc	.+18     	; 0x1e4e <vTaskDelayUntil+0x3a>
				/* The tick count has overflowed since this function was
				lasted called.  In this case the only time we should ever
				actually delay is if the wake time has also	overflowed,
				and the wake time is greater than the tick time.  When this
				is the case it is as if neither time had overflowed. */
				if( ( xTimeToWake < *pxPreviousWakeTime ) && ( xTimeToWake > xConstTickCount ) )
    1e3c:	c2 17       	cp	r28, r18
    1e3e:	d3 07       	cpc	r29, r19
    1e40:	f8 f4       	brcc	.+62     	; 0x1e80 <vTaskDelayUntil+0x6c>
					mtCOVERAGE_TEST_MARKER();
				}
			}

			/* Update the wake time ready for the next call. */
			*pxPreviousWakeTime = xTimeToWake;
    1e42:	d1 83       	std	Z+1, r29	; 0x01
    1e44:	c0 83       	st	Z, r28

			if( xShouldDelay != pdFALSE )
    1e46:	8c 17       	cp	r24, r28
    1e48:	9d 07       	cpc	r25, r29
    1e4a:	78 f4       	brcc	.+30     	; 0x1e6a <vTaskDelayUntil+0x56>
    1e4c:	07 c0       	rjmp	.+14     	; 0x1e5c <vTaskDelayUntil+0x48>
			else
			{
				/* The tick time has not overflowed.  In this case we will
				delay if either the wake time has overflowed, and/or the
				tick time is less than the wake time. */
				if( ( xTimeToWake < *pxPreviousWakeTime ) || ( xTimeToWake > xConstTickCount ) )
    1e4e:	c2 17       	cp	r28, r18
    1e50:	d3 07       	cpc	r29, r19
    1e52:	90 f0       	brcs	.+36     	; 0x1e78 <vTaskDelayUntil+0x64>
    1e54:	8c 17       	cp	r24, r28
    1e56:	9d 07       	cpc	r25, r29
    1e58:	78 f0       	brcs	.+30     	; 0x1e78 <vTaskDelayUntil+0x64>
    1e5a:	12 c0       	rjmp	.+36     	; 0x1e80 <vTaskDelayUntil+0x6c>
			{
				traceTASK_DELAY_UNTIL( xTimeToWake );

				/* prvAddCurrentTaskToDelayedList() needs the block time, not
				the time to wake, so subtract the current tick count. */
				prvAddCurrentTaskToDelayedList( xTimeToWake - xConstTickCount, pdFALSE );
    1e5c:	9e 01       	movw	r18, r28
    1e5e:	28 1b       	sub	r18, r24
    1e60:	39 0b       	sbc	r19, r25
    1e62:	c9 01       	movw	r24, r18
    1e64:	60 e0       	ldi	r22, 0x00	; 0
    1e66:	0e 94 4b 0a 	call	0x1496	; 0x1496 <prvAddCurrentTaskToDelayedList>
			else
			{
				mtCOVERAGE_TEST_MARKER();
			}
		}
		xAlreadyYielded = xTaskResumeAll();
    1e6a:	0e 94 3e 0e 	call	0x1c7c	; 0x1c7c <xTaskResumeAll>

		/* Force a reschedule if xTaskResumeAll has not already done so, we may
		have put ourselves to sleep. */
		if( xAlreadyYielded == pdFALSE )
    1e6e:	88 23       	and	r24, r24
    1e70:	59 f4       	brne	.+22     	; 0x1e88 <vTaskDelayUntil+0x74>
		{
			portYIELD_WITHIN_API();
    1e72:	0e 94 30 05 	call	0xa60	; 0xa60 <vPortYield>
    1e76:	08 c0       	rjmp	.+16     	; 0x1e88 <vTaskDelayUntil+0x74>
					mtCOVERAGE_TEST_MARKER();
				}
			}

			/* Update the wake time ready for the next call. */
			*pxPreviousWakeTime = xTimeToWake;
    1e78:	f8 01       	movw	r30, r16
    1e7a:	d1 83       	std	Z+1, r29	; 0x01
    1e7c:	c0 83       	st	Z, r28
    1e7e:	ee cf       	rjmp	.-36     	; 0x1e5c <vTaskDelayUntil+0x48>
    1e80:	f8 01       	movw	r30, r16
    1e82:	d1 83       	std	Z+1, r29	; 0x01
    1e84:	c0 83       	st	Z, r28
    1e86:	f1 cf       	rjmp	.-30     	; 0x1e6a <vTaskDelayUntil+0x56>
		}
		else
		{
			mtCOVERAGE_TEST_MARKER();
		}
	}
    1e88:	df 91       	pop	r29
    1e8a:	cf 91       	pop	r28
    1e8c:	1f 91       	pop	r17
    1e8e:	0f 91       	pop	r16
    1e90:	08 95       	ret

00001e92 <vTaskSwitchContext>:
#endif /* configUSE_APPLICATION_TASK_TAG */
/*-----------------------------------------------------------*/

void vTaskSwitchContext( void )
{
	if( uxSchedulerSuspended != ( UBaseType_t ) pdFALSE )
    1e92:	80 91 9d 03 	lds	r24, 0x039D
    1e96:	88 23       	and	r24, r24
    1e98:	21 f0       	breq	.+8      	; 0x1ea2 <vTaskSwitchContext+0x10>
	{
		/* The scheduler is currently suspended - do not allow a context
		switch. */
		xYieldPending = pdTRUE;
    1e9a:	81 e0       	ldi	r24, 0x01	; 1
    1e9c:	80 93 a1 03 	sts	0x03A1, r24
    1ea0:	08 95       	ret
	}
	else
	{
		xYieldPending = pdFALSE;
    1ea2:	10 92 a1 03 	sts	0x03A1, r1
		/* Check for stack overflow, if configured. */
		taskCHECK_FOR_STACK_OVERFLOW();

		/* Select a new task to run using either the generic C or port
		optimised asm code. */
		taskSELECT_HIGHEST_PRIORITY_TASK();
    1ea6:	20 91 a4 03 	lds	r18, 0x03A4
    1eaa:	82 2f       	mov	r24, r18
    1eac:	90 e0       	ldi	r25, 0x00	; 0
    1eae:	fc 01       	movw	r30, r24
    1eb0:	ee 0f       	add	r30, r30
    1eb2:	ff 1f       	adc	r31, r31
    1eb4:	ee 0f       	add	r30, r30
    1eb6:	ff 1f       	adc	r31, r31
    1eb8:	ee 0f       	add	r30, r30
    1eba:	ff 1f       	adc	r31, r31
    1ebc:	e8 0f       	add	r30, r24
    1ebe:	f9 1f       	adc	r31, r25
    1ec0:	e2 55       	subi	r30, 0x52	; 82
    1ec2:	fc 4f       	sbci	r31, 0xFC	; 252
    1ec4:	30 81       	ld	r19, Z
    1ec6:	33 23       	and	r19, r19
    1ec8:	89 f4       	brne	.+34     	; 0x1eec <vTaskSwitchContext+0x5a>
    1eca:	21 50       	subi	r18, 0x01	; 1
    1ecc:	82 2f       	mov	r24, r18
    1ece:	90 e0       	ldi	r25, 0x00	; 0
    1ed0:	fc 01       	movw	r30, r24
    1ed2:	ee 0f       	add	r30, r30
    1ed4:	ff 1f       	adc	r31, r31
    1ed6:	ee 0f       	add	r30, r30
    1ed8:	ff 1f       	adc	r31, r31
    1eda:	ee 0f       	add	r30, r30
    1edc:	ff 1f       	adc	r31, r31
    1ede:	e8 0f       	add	r30, r24
    1ee0:	f9 1f       	adc	r31, r25
    1ee2:	e2 55       	subi	r30, 0x52	; 82
    1ee4:	fc 4f       	sbci	r31, 0xFC	; 252
    1ee6:	30 81       	ld	r19, Z
    1ee8:	33 23       	and	r19, r19
    1eea:	79 f3       	breq	.-34     	; 0x1eca <vTaskSwitchContext+0x38>
    1eec:	dc 01       	movw	r26, r24
    1eee:	aa 0f       	add	r26, r26
    1ef0:	bb 1f       	adc	r27, r27
    1ef2:	aa 0f       	add	r26, r26
    1ef4:	bb 1f       	adc	r27, r27
    1ef6:	aa 0f       	add	r26, r26
    1ef8:	bb 1f       	adc	r27, r27
    1efa:	8a 0f       	add	r24, r26
    1efc:	9b 1f       	adc	r25, r27
    1efe:	dc 01       	movw	r26, r24
    1f00:	a2 55       	subi	r26, 0x52	; 82
    1f02:	bc 4f       	sbci	r27, 0xFC	; 252
    1f04:	11 96       	adiw	r26, 0x01	; 1
    1f06:	ed 91       	ld	r30, X+
    1f08:	fc 91       	ld	r31, X
    1f0a:	12 97       	sbiw	r26, 0x02	; 2
    1f0c:	02 80       	ldd	r0, Z+2	; 0x02
    1f0e:	f3 81       	ldd	r31, Z+3	; 0x03
    1f10:	e0 2d       	mov	r30, r0
    1f12:	12 96       	adiw	r26, 0x02	; 2
    1f14:	fc 93       	st	X, r31
    1f16:	ee 93       	st	-X, r30
    1f18:	11 97       	sbiw	r26, 0x01	; 1
    1f1a:	cd 01       	movw	r24, r26
    1f1c:	03 96       	adiw	r24, 0x03	; 3
    1f1e:	e8 17       	cp	r30, r24
    1f20:	f9 07       	cpc	r31, r25
    1f22:	31 f4       	brne	.+12     	; 0x1f30 <vTaskSwitchContext+0x9e>
    1f24:	82 81       	ldd	r24, Z+2	; 0x02
    1f26:	93 81       	ldd	r25, Z+3	; 0x03
    1f28:	12 96       	adiw	r26, 0x02	; 2
    1f2a:	9c 93       	st	X, r25
    1f2c:	8e 93       	st	-X, r24
    1f2e:	11 97       	sbiw	r26, 0x01	; 1
    1f30:	11 96       	adiw	r26, 0x01	; 1
    1f32:	ed 91       	ld	r30, X+
    1f34:	fc 91       	ld	r31, X
    1f36:	12 97       	sbiw	r26, 0x02	; 2
    1f38:	86 81       	ldd	r24, Z+6	; 0x06
    1f3a:	97 81       	ldd	r25, Z+7	; 0x07
    1f3c:	90 93 9c 03 	sts	0x039C, r25
    1f40:	80 93 9b 03 	sts	0x039B, r24
    1f44:	20 93 a4 03 	sts	0x03A4, r18
    1f48:	08 95       	ret

00001f4a <vTaskSuspend>:
/*-----------------------------------------------------------*/

#if ( INCLUDE_vTaskSuspend == 1 )

	void vTaskSuspend( TaskHandle_t xTaskToSuspend )
	{
    1f4a:	0f 93       	push	r16
    1f4c:	1f 93       	push	r17
    1f4e:	cf 93       	push	r28
    1f50:	df 93       	push	r29
	TCB_t *pxTCB;

		taskENTER_CRITICAL();
    1f52:	0f b6       	in	r0, 0x3f	; 63
    1f54:	f8 94       	cli
    1f56:	0f 92       	push	r0
		{
			/* If null is passed in here then it is the running task that is
			being suspended. */
			pxTCB = prvGetTCBFromHandle( xTaskToSuspend );
    1f58:	00 97       	sbiw	r24, 0x00	; 0
    1f5a:	29 f4       	brne	.+10     	; 0x1f66 <vTaskSuspend+0x1c>
    1f5c:	00 91 9b 03 	lds	r16, 0x039B
    1f60:	10 91 9c 03 	lds	r17, 0x039C
    1f64:	01 c0       	rjmp	.+2      	; 0x1f68 <vTaskSuspend+0x1e>
    1f66:	8c 01       	movw	r16, r24

			traceTASK_SUSPEND( pxTCB );

			/* Remove task from the ready/delayed list and place in the
			suspended list. */
			if( uxListRemove( &( pxTCB->xStateListItem ) ) == ( UBaseType_t ) 0 )
    1f68:	e8 01       	movw	r28, r16
    1f6a:	22 96       	adiw	r28, 0x02	; 2
    1f6c:	ce 01       	movw	r24, r28
    1f6e:	0e 94 42 04 	call	0x884	; 0x884 <uxListRemove>
			{
				mtCOVERAGE_TEST_MARKER();
			}

			/* Is the task waiting on an event also? */
			if( listLIST_ITEM_CONTAINER( &( pxTCB->xEventListItem ) ) != NULL )
    1f72:	f8 01       	movw	r30, r16
    1f74:	84 89       	ldd	r24, Z+20	; 0x14
    1f76:	95 89       	ldd	r25, Z+21	; 0x15
    1f78:	00 97       	sbiw	r24, 0x00	; 0
    1f7a:	21 f0       	breq	.+8      	; 0x1f84 <vTaskSuspend+0x3a>
			{
				( void ) uxListRemove( &( pxTCB->xEventListItem ) );
    1f7c:	c8 01       	movw	r24, r16
    1f7e:	0c 96       	adiw	r24, 0x0c	; 12
    1f80:	0e 94 42 04 	call	0x884	; 0x884 <uxListRemove>
			else
			{
				mtCOVERAGE_TEST_MARKER();
			}

			vListInsertEnd( &xSuspendedTaskList, &( pxTCB->xStateListItem ) );
    1f84:	8f ef       	ldi	r24, 0xFF	; 255
    1f86:	93 e0       	ldi	r25, 0x03	; 3
    1f88:	be 01       	movw	r22, r28
    1f8a:	0e 94 f1 03 	call	0x7e2	; 0x7e2 <vListInsertEnd>
		}
		taskEXIT_CRITICAL();
    1f8e:	0f 90       	pop	r0
    1f90:	0f be       	out	0x3f, r0	; 63

		if( xSchedulerRunning != pdFALSE )
    1f92:	80 91 a3 03 	lds	r24, 0x03A3
    1f96:	88 23       	and	r24, r24
    1f98:	39 f0       	breq	.+14     	; 0x1fa8 <vTaskSuspend+0x5e>
		{
			/* Reset the next expected unblock time in case it referred to the
			task that is now in the Suspended state. */
			taskENTER_CRITICAL();
    1f9a:	0f b6       	in	r0, 0x3f	; 63
    1f9c:	f8 94       	cli
    1f9e:	0f 92       	push	r0
			{
				prvResetNextTaskUnblockTime();
    1fa0:	0e 94 2c 0a 	call	0x1458	; 0x1458 <prvResetNextTaskUnblockTime>
			}
			taskEXIT_CRITICAL();
    1fa4:	0f 90       	pop	r0
    1fa6:	0f be       	out	0x3f, r0	; 63
		else
		{
			mtCOVERAGE_TEST_MARKER();
		}

		if( pxTCB == pxCurrentTCB )
    1fa8:	80 91 9b 03 	lds	r24, 0x039B
    1fac:	90 91 9c 03 	lds	r25, 0x039C
    1fb0:	08 17       	cp	r16, r24
    1fb2:	19 07       	cpc	r17, r25
    1fb4:	a1 f4       	brne	.+40     	; 0x1fde <vTaskSuspend+0x94>
		{
			if( xSchedulerRunning != pdFALSE )
    1fb6:	80 91 a3 03 	lds	r24, 0x03A3
    1fba:	88 23       	and	r24, r24
    1fbc:	19 f0       	breq	.+6      	; 0x1fc4 <vTaskSuspend+0x7a>
			{
				/* The current task has just been suspended. */
				configASSERT( uxSchedulerSuspended == 0 );
				portYIELD_WITHIN_API();
    1fbe:	0e 94 30 05 	call	0xa60	; 0xa60 <vPortYield>
    1fc2:	0d c0       	rjmp	.+26     	; 0x1fde <vTaskSuspend+0x94>
			else
			{
				/* The scheduler is not running, but the task that was pointed
				to by pxCurrentTCB has just been suspended and pxCurrentTCB
				must be adjusted to point to a different task. */
				if( listCURRENT_LIST_LENGTH( &xSuspendedTaskList ) == uxCurrentNumberOfTasks )
    1fc4:	80 91 a7 03 	lds	r24, 0x03A7
    1fc8:	90 91 ff 03 	lds	r25, 0x03FF
    1fcc:	98 17       	cp	r25, r24
    1fce:	29 f4       	brne	.+10     	; 0x1fda <vTaskSuspend+0x90>
				{
					/* No other tasks are ready, so set pxCurrentTCB back to
					NULL so when the next task is created pxCurrentTCB will
					be set to point to it no matter what its relative priority
					is. */
					pxCurrentTCB = NULL;
    1fd0:	10 92 9c 03 	sts	0x039C, r1
    1fd4:	10 92 9b 03 	sts	0x039B, r1
    1fd8:	02 c0       	rjmp	.+4      	; 0x1fde <vTaskSuspend+0x94>
				}
				else
				{
					vTaskSwitchContext();
    1fda:	0e 94 49 0f 	call	0x1e92	; 0x1e92 <vTaskSwitchContext>
		}
		else
		{
			mtCOVERAGE_TEST_MARKER();
		}
	}
    1fde:	df 91       	pop	r29
    1fe0:	cf 91       	pop	r28
    1fe2:	1f 91       	pop	r17
    1fe4:	0f 91       	pop	r16
    1fe6:	08 95       	ret

00001fe8 <vTaskPlaceOnEventList>:
	}
}
/*-----------------------------------------------------------*/

void vTaskPlaceOnEventList( List_t * const pxEventList, const TickType_t xTicksToWait )
{
    1fe8:	cf 93       	push	r28
    1fea:	df 93       	push	r29
    1fec:	eb 01       	movw	r28, r22

	/* Place the event list item of the TCB in the appropriate event list.
	This is placed in the list in priority order so the highest priority task
	is the first to be woken by the event.  The queue that contains the event
	list is locked, preventing simultaneous access from interrupts. */
	vListInsert( pxEventList, &( pxCurrentTCB->xEventListItem ) );
    1fee:	60 91 9b 03 	lds	r22, 0x039B
    1ff2:	70 91 9c 03 	lds	r23, 0x039C
    1ff6:	64 5f       	subi	r22, 0xF4	; 244
    1ff8:	7f 4f       	sbci	r23, 0xFF	; 255
    1ffa:	0e 94 10 04 	call	0x820	; 0x820 <vListInsert>

	prvAddCurrentTaskToDelayedList( xTicksToWait, pdTRUE );
    1ffe:	ce 01       	movw	r24, r28
    2000:	61 e0       	ldi	r22, 0x01	; 1
    2002:	0e 94 4b 0a 	call	0x1496	; 0x1496 <prvAddCurrentTaskToDelayedList>
}
    2006:	df 91       	pop	r29
    2008:	cf 91       	pop	r28
    200a:	08 95       	ret

0000200c <vTaskPlaceOnUnorderedEventList>:
/*-----------------------------------------------------------*/

void vTaskPlaceOnUnorderedEventList( List_t * pxEventList, const TickType_t xItemValue, const TickType_t xTicksToWait )
{
    200c:	cf 93       	push	r28
    200e:	df 93       	push	r29
    2010:	ea 01       	movw	r28, r20
	configASSERT( uxSchedulerSuspended != 0 );

	/* Store the item value in the event list item.  It is safe to access the
	event list item here as interrupts won't access the event list item of a
	task that is not in the Blocked state. */
	listSET_LIST_ITEM_VALUE( &( pxCurrentTCB->xEventListItem ), xItemValue | taskEVENT_LIST_ITEM_VALUE_IN_USE );
    2012:	e0 91 9b 03 	lds	r30, 0x039B
    2016:	f0 91 9c 03 	lds	r31, 0x039C
    201a:	70 68       	ori	r23, 0x80	; 128
    201c:	75 87       	std	Z+13, r23	; 0x0d
    201e:	64 87       	std	Z+12, r22	; 0x0c
	/* Place the event list item of the TCB at the end of the appropriate event
	list.  It is safe to access the event list here because it is part of an
	event group implementation - and interrupts don't access event groups
	directly (instead they access them indirectly by pending function calls to
	the task level). */
	vListInsertEnd( pxEventList, &( pxCurrentTCB->xEventListItem ) );
    2020:	60 91 9b 03 	lds	r22, 0x039B
    2024:	70 91 9c 03 	lds	r23, 0x039C
    2028:	64 5f       	subi	r22, 0xF4	; 244
    202a:	7f 4f       	sbci	r23, 0xFF	; 255
    202c:	0e 94 f1 03 	call	0x7e2	; 0x7e2 <vListInsertEnd>

	prvAddCurrentTaskToDelayedList( xTicksToWait, pdTRUE );
    2030:	ce 01       	movw	r24, r28
    2032:	61 e0       	ldi	r22, 0x01	; 1
    2034:	0e 94 4b 0a 	call	0x1496	; 0x1496 <prvAddCurrentTaskToDelayedList>
}
    2038:	df 91       	pop	r29
    203a:	cf 91       	pop	r28
    203c:	08 95       	ret

0000203e <xTaskRemoveFromEventList>:

#endif /* configUSE_TIMERS */
/*-----------------------------------------------------------*/

BaseType_t xTaskRemoveFromEventList( const List_t * const pxEventList )
{
    203e:	0f 93       	push	r16
    2040:	1f 93       	push	r17
    2042:	cf 93       	push	r28
    2044:	df 93       	push	r29
	get called - the lock count on the queue will get modified instead.  This
	means exclusive access to the event list is guaranteed here.

	This function assumes that a check has already been made to ensure that
	pxEventList is not empty. */
	pxUnblockedTCB = ( TCB_t * ) listGET_OWNER_OF_HEAD_ENTRY( pxEventList );
    2046:	dc 01       	movw	r26, r24
    2048:	15 96       	adiw	r26, 0x05	; 5
    204a:	ed 91       	ld	r30, X+
    204c:	fc 91       	ld	r31, X
    204e:	16 97       	sbiw	r26, 0x06	; 6
    2050:	06 81       	ldd	r16, Z+6	; 0x06
    2052:	17 81       	ldd	r17, Z+7	; 0x07
	configASSERT( pxUnblockedTCB );
	( void ) uxListRemove( &( pxUnblockedTCB->xEventListItem ) );
    2054:	e8 01       	movw	r28, r16
    2056:	2c 96       	adiw	r28, 0x0c	; 12
    2058:	ce 01       	movw	r24, r28
    205a:	0e 94 42 04 	call	0x884	; 0x884 <uxListRemove>

	if( uxSchedulerSuspended == ( UBaseType_t ) pdFALSE )
    205e:	80 91 9d 03 	lds	r24, 0x039D
    2062:	88 23       	and	r24, r24
    2064:	e9 f4       	brne	.+58     	; 0x20a0 <xTaskRemoveFromEventList+0x62>
	{
		( void ) uxListRemove( &( pxUnblockedTCB->xStateListItem ) );
    2066:	e8 01       	movw	r28, r16
    2068:	22 96       	adiw	r28, 0x02	; 2
    206a:	ce 01       	movw	r24, r28
    206c:	0e 94 42 04 	call	0x884	; 0x884 <uxListRemove>
		prvAddTaskToReadyList( pxUnblockedTCB );
    2070:	f8 01       	movw	r30, r16
    2072:	86 89       	ldd	r24, Z+22	; 0x16
    2074:	90 91 a4 03 	lds	r25, 0x03A4
    2078:	98 17       	cp	r25, r24
    207a:	10 f4       	brcc	.+4      	; 0x2080 <xTaskRemoveFromEventList+0x42>
    207c:	80 93 a4 03 	sts	0x03A4, r24
    2080:	90 e0       	ldi	r25, 0x00	; 0
    2082:	9c 01       	movw	r18, r24
    2084:	22 0f       	add	r18, r18
    2086:	33 1f       	adc	r19, r19
    2088:	22 0f       	add	r18, r18
    208a:	33 1f       	adc	r19, r19
    208c:	22 0f       	add	r18, r18
    208e:	33 1f       	adc	r19, r19
    2090:	82 0f       	add	r24, r18
    2092:	93 1f       	adc	r25, r19
    2094:	82 55       	subi	r24, 0x52	; 82
    2096:	9c 4f       	sbci	r25, 0xFC	; 252
    2098:	be 01       	movw	r22, r28
    209a:	0e 94 f1 03 	call	0x7e2	; 0x7e2 <vListInsertEnd>
    209e:	05 c0       	rjmp	.+10     	; 0x20aa <xTaskRemoveFromEventList+0x6c>
	}
	else
	{
		/* The delayed and ready lists cannot be accessed, so hold this task
		pending until the scheduler is resumed. */
		vListInsertEnd( &( xPendingReadyList ), &( pxUnblockedTCB->xEventListItem ) );
    20a0:	8d ee       	ldi	r24, 0xED	; 237
    20a2:	93 e0       	ldi	r25, 0x03	; 3
    20a4:	be 01       	movw	r22, r28
    20a6:	0e 94 f1 03 	call	0x7e2	; 0x7e2 <vListInsertEnd>
	}

	if( pxUnblockedTCB->uxPriority > pxCurrentTCB->uxPriority )
    20aa:	e0 91 9b 03 	lds	r30, 0x039B
    20ae:	f0 91 9c 03 	lds	r31, 0x039C
    20b2:	d8 01       	movw	r26, r16
    20b4:	56 96       	adiw	r26, 0x16	; 22
    20b6:	9c 91       	ld	r25, X
    20b8:	56 97       	sbiw	r26, 0x16	; 22
    20ba:	86 89       	ldd	r24, Z+22	; 0x16
    20bc:	89 17       	cp	r24, r25
    20be:	20 f4       	brcc	.+8      	; 0x20c8 <xTaskRemoveFromEventList+0x8a>
		it should force a context switch now. */
		xReturn = pdTRUE;

		/* Mark that a yield is pending in case the user is not using the
		"xHigherPriorityTaskWoken" parameter to an ISR safe FreeRTOS function. */
		xYieldPending = pdTRUE;
    20c0:	81 e0       	ldi	r24, 0x01	; 1
    20c2:	80 93 a1 03 	sts	0x03A1, r24
    20c6:	01 c0       	rjmp	.+2      	; 0x20ca <xTaskRemoveFromEventList+0x8c>
	}
	else
	{
		xReturn = pdFALSE;
    20c8:	80 e0       	ldi	r24, 0x00	; 0
		prvResetNextTaskUnblockTime();
	}
	#endif

	return xReturn;
}
    20ca:	df 91       	pop	r29
    20cc:	cf 91       	pop	r28
    20ce:	1f 91       	pop	r17
    20d0:	0f 91       	pop	r16
    20d2:	08 95       	ret

000020d4 <xTaskRemoveFromUnorderedEventList>:
/*-----------------------------------------------------------*/

BaseType_t xTaskRemoveFromUnorderedEventList( ListItem_t * pxEventListItem, const TickType_t xItemValue )
{
    20d4:	0f 93       	push	r16
    20d6:	1f 93       	push	r17
    20d8:	cf 93       	push	r28
    20da:	df 93       	push	r29
	/* THIS FUNCTION MUST BE CALLED WITH THE SCHEDULER SUSPENDED.  It is used by
	the event flags implementation. */
	configASSERT( uxSchedulerSuspended != pdFALSE );

	/* Store the new item value in the event list. */
	listSET_LIST_ITEM_VALUE( pxEventListItem, xItemValue | taskEVENT_LIST_ITEM_VALUE_IN_USE );
    20dc:	70 68       	ori	r23, 0x80	; 128
    20de:	fc 01       	movw	r30, r24
    20e0:	71 83       	std	Z+1, r23	; 0x01
    20e2:	60 83       	st	Z, r22

	/* Remove the event list form the event flag.  Interrupts do not access
	event flags. */
	pxUnblockedTCB = ( TCB_t * ) listGET_LIST_ITEM_OWNER( pxEventListItem );
    20e4:	c6 81       	ldd	r28, Z+6	; 0x06
    20e6:	d7 81       	ldd	r29, Z+7	; 0x07
	configASSERT( pxUnblockedTCB );
	( void ) uxListRemove( pxEventListItem );
    20e8:	0e 94 42 04 	call	0x884	; 0x884 <uxListRemove>

	/* Remove the task from the delayed list and add it to the ready list.  The
	scheduler is suspended so interrupts will not be accessing the ready
	lists. */
	( void ) uxListRemove( &( pxUnblockedTCB->xStateListItem ) );
    20ec:	8e 01       	movw	r16, r28
    20ee:	0e 5f       	subi	r16, 0xFE	; 254
    20f0:	1f 4f       	sbci	r17, 0xFF	; 255
    20f2:	c8 01       	movw	r24, r16
    20f4:	0e 94 42 04 	call	0x884	; 0x884 <uxListRemove>
	prvAddTaskToReadyList( pxUnblockedTCB );
    20f8:	8e 89       	ldd	r24, Y+22	; 0x16
    20fa:	90 91 a4 03 	lds	r25, 0x03A4
    20fe:	98 17       	cp	r25, r24
    2100:	10 f4       	brcc	.+4      	; 0x2106 <xTaskRemoveFromUnorderedEventList+0x32>
    2102:	80 93 a4 03 	sts	0x03A4, r24
    2106:	90 e0       	ldi	r25, 0x00	; 0
    2108:	9c 01       	movw	r18, r24
    210a:	22 0f       	add	r18, r18
    210c:	33 1f       	adc	r19, r19
    210e:	22 0f       	add	r18, r18
    2110:	33 1f       	adc	r19, r19
    2112:	22 0f       	add	r18, r18
    2114:	33 1f       	adc	r19, r19
    2116:	82 0f       	add	r24, r18
    2118:	93 1f       	adc	r25, r19
    211a:	82 55       	subi	r24, 0x52	; 82
    211c:	9c 4f       	sbci	r25, 0xFC	; 252
    211e:	b8 01       	movw	r22, r16
    2120:	0e 94 f1 03 	call	0x7e2	; 0x7e2 <vListInsertEnd>

	if( pxUnblockedTCB->uxPriority > pxCurrentTCB->uxPriority )
    2124:	e0 91 9b 03 	lds	r30, 0x039B
    2128:	f0 91 9c 03 	lds	r31, 0x039C
    212c:	9e 89       	ldd	r25, Y+22	; 0x16
    212e:	86 89       	ldd	r24, Z+22	; 0x16
    2130:	89 17       	cp	r24, r25
    2132:	20 f4       	brcc	.+8      	; 0x213c <xTaskRemoveFromUnorderedEventList+0x68>
		switch now. */
		xReturn = pdTRUE;

		/* Mark that a yield is pending in case the user is not using the
		"xHigherPriorityTaskWoken" parameter to an ISR safe FreeRTOS function. */
		xYieldPending = pdTRUE;
    2134:	81 e0       	ldi	r24, 0x01	; 1
    2136:	80 93 a1 03 	sts	0x03A1, r24
    213a:	01 c0       	rjmp	.+2      	; 0x213e <xTaskRemoveFromUnorderedEventList+0x6a>
	}
	else
	{
		xReturn = pdFALSE;
    213c:	80 e0       	ldi	r24, 0x00	; 0
	}

	return xReturn;
}
    213e:	df 91       	pop	r29
    2140:	cf 91       	pop	r28
    2142:	1f 91       	pop	r17
    2144:	0f 91       	pop	r16
    2146:	08 95       	ret

00002148 <vTaskSetTimeOutState>:
/*-----------------------------------------------------------*/

void vTaskSetTimeOutState( TimeOut_t * const pxTimeOut )
{
    2148:	fc 01       	movw	r30, r24
	configASSERT( pxTimeOut );
	pxTimeOut->xOverflowCount = xNumOfOverflows;
    214a:	80 91 a0 03 	lds	r24, 0x03A0
    214e:	80 83       	st	Z, r24
	pxTimeOut->xTimeOnEntering = xTickCount;
    2150:	80 91 a5 03 	lds	r24, 0x03A5
    2154:	90 91 a6 03 	lds	r25, 0x03A6
    2158:	92 83       	std	Z+2, r25	; 0x02
    215a:	81 83       	std	Z+1, r24	; 0x01
}
    215c:	08 95       	ret

0000215e <xTaskCheckForTimeOut>:
/*-----------------------------------------------------------*/

BaseType_t xTaskCheckForTimeOut( TimeOut_t * const pxTimeOut, TickType_t * const pxTicksToWait )
{
    215e:	fc 01       	movw	r30, r24
    2160:	db 01       	movw	r26, r22
BaseType_t xReturn;

	configASSERT( pxTimeOut );
	configASSERT( pxTicksToWait );

	taskENTER_CRITICAL();
    2162:	0f b6       	in	r0, 0x3f	; 63
    2164:	f8 94       	cli
    2166:	0f 92       	push	r0
	{
		/* Minor optimisation.  The tick count cannot change in this block. */
		const TickType_t xConstTickCount = xTickCount;
    2168:	60 91 a5 03 	lds	r22, 0x03A5
    216c:	70 91 a6 03 	lds	r23, 0x03A6
			}
			else
		#endif

		#if ( INCLUDE_vTaskSuspend == 1 )
			if( *pxTicksToWait == portMAX_DELAY )
    2170:	4d 91       	ld	r20, X+
    2172:	5c 91       	ld	r21, X
    2174:	11 97       	sbiw	r26, 0x01	; 1
    2176:	8f ef       	ldi	r24, 0xFF	; 255
    2178:	4f 3f       	cpi	r20, 0xFF	; 255
    217a:	58 07       	cpc	r21, r24
    217c:	e9 f0       	breq	.+58     	; 0x21b8 <xTaskCheckForTimeOut+0x5a>
				xReturn = pdFALSE;
			}
			else
		#endif

		if( ( xNumOfOverflows != pxTimeOut->xOverflowCount ) && ( xConstTickCount >= pxTimeOut->xTimeOnEntering ) ) /*lint !e525 Indentation preferred as is to make code within pre-processor directives clearer. */
    217e:	80 91 a0 03 	lds	r24, 0x03A0
    2182:	90 81       	ld	r25, Z
    2184:	98 17       	cp	r25, r24
    2186:	29 f0       	breq	.+10     	; 0x2192 <xTaskCheckForTimeOut+0x34>
    2188:	81 81       	ldd	r24, Z+1	; 0x01
    218a:	92 81       	ldd	r25, Z+2	; 0x02
    218c:	68 17       	cp	r22, r24
    218e:	79 07       	cpc	r23, r25
    2190:	a8 f4       	brcc	.+42     	; 0x21bc <xTaskCheckForTimeOut+0x5e>
			vTaskSetTimeOut() was called.  It must have wrapped all the way
			around and gone past again. This passed since vTaskSetTimeout()
			was called. */
			xReturn = pdTRUE;
		}
		else if( ( ( TickType_t ) ( xConstTickCount - pxTimeOut->xTimeOnEntering ) ) < *pxTicksToWait ) /*lint !e961 Explicit casting is only redundant with some compilers, whereas others require it to prevent integer conversion errors. */
    2192:	81 81       	ldd	r24, Z+1	; 0x01
    2194:	92 81       	ldd	r25, Z+2	; 0x02
    2196:	9b 01       	movw	r18, r22
    2198:	28 1b       	sub	r18, r24
    219a:	39 0b       	sbc	r19, r25
    219c:	24 17       	cp	r18, r20
    219e:	35 07       	cpc	r19, r21
    21a0:	78 f4       	brcc	.+30     	; 0x21c0 <xTaskCheckForTimeOut+0x62>
		{
			/* Not a genuine timeout. Adjust parameters for time remaining. */
			*pxTicksToWait -= ( xConstTickCount - pxTimeOut->xTimeOnEntering );
    21a2:	86 1b       	sub	r24, r22
    21a4:	97 0b       	sbc	r25, r23
    21a6:	84 0f       	add	r24, r20
    21a8:	95 1f       	adc	r25, r21
    21aa:	8d 93       	st	X+, r24
    21ac:	9c 93       	st	X, r25
			vTaskSetTimeOutState( pxTimeOut );
    21ae:	cf 01       	movw	r24, r30
    21b0:	0e 94 a4 10 	call	0x2148	; 0x2148 <vTaskSetTimeOutState>
			xReturn = pdFALSE;
    21b4:	80 e0       	ldi	r24, 0x00	; 0
    21b6:	05 c0       	rjmp	.+10     	; 0x21c2 <xTaskCheckForTimeOut+0x64>
			if( *pxTicksToWait == portMAX_DELAY )
			{
				/* If INCLUDE_vTaskSuspend is set to 1 and the block time
				specified is the maximum block time then the task should block
				indefinitely, and therefore never time out. */
				xReturn = pdFALSE;
    21b8:	80 e0       	ldi	r24, 0x00	; 0
    21ba:	03 c0       	rjmp	.+6      	; 0x21c2 <xTaskCheckForTimeOut+0x64>
			/* The tick count is greater than the time at which
			vTaskSetTimeout() was called, but has also overflowed since
			vTaskSetTimeOut() was called.  It must have wrapped all the way
			around and gone past again. This passed since vTaskSetTimeout()
			was called. */
			xReturn = pdTRUE;
    21bc:	81 e0       	ldi	r24, 0x01	; 1
    21be:	01 c0       	rjmp	.+2      	; 0x21c2 <xTaskCheckForTimeOut+0x64>
			vTaskSetTimeOutState( pxTimeOut );
			xReturn = pdFALSE;
		}
		else
		{
			xReturn = pdTRUE;
    21c0:	81 e0       	ldi	r24, 0x01	; 1
		}
	}
	taskEXIT_CRITICAL();
    21c2:	0f 90       	pop	r0
    21c4:	0f be       	out	0x3f, r0	; 63

	return xReturn;
}
    21c6:	08 95       	ret

000021c8 <vTaskMissedYield>:
/*-----------------------------------------------------------*/

void vTaskMissedYield( void )
{
	xYieldPending = pdTRUE;
    21c8:	81 e0       	ldi	r24, 0x01	; 1
    21ca:	80 93 a1 03 	sts	0x03A1, r24
}
    21ce:	08 95       	ret

000021d0 <xTaskGetCurrentTaskHandle>:
	TaskHandle_t xReturn;

		/* A critical section is not required as this is not called from
		an interrupt and the current TCB will always be the same for any
		individual execution thread. */
		xReturn = pxCurrentTCB;
    21d0:	80 91 9b 03 	lds	r24, 0x039B
    21d4:	90 91 9c 03 	lds	r25, 0x039C

		return xReturn;
	}
    21d8:	08 95       	ret

000021da <vTaskPriorityInherit>:
/*-----------------------------------------------------------*/

#if ( configUSE_MUTEXES == 1 )

	void vTaskPriorityInherit( TaskHandle_t const pxMutexHolder )
	{
    21da:	0f 93       	push	r16
    21dc:	1f 93       	push	r17
    21de:	cf 93       	push	r28
    21e0:	df 93       	push	r29
    21e2:	ec 01       	movw	r28, r24
	TCB_t * const pxTCB = ( TCB_t * ) pxMutexHolder;

		/* If the mutex was given back by an interrupt while the queue was
		locked then the mutex holder might now be NULL. */
		if( pxMutexHolder != NULL )
    21e4:	00 97       	sbiw	r24, 0x00	; 0
    21e6:	09 f4       	brne	.+2      	; 0x21ea <vTaskPriorityInherit+0x10>
    21e8:	51 c0       	rjmp	.+162    	; 0x228c <vTaskPriorityInherit+0xb2>
		{
			/* If the holder of the mutex has a priority below the priority of
			the task attempting to obtain the mutex then it will temporarily
			inherit the priority of the task attempting to obtain the mutex. */
			if( pxTCB->uxPriority < pxCurrentTCB->uxPriority )
    21ea:	8e 89       	ldd	r24, Y+22	; 0x16
    21ec:	e0 91 9b 03 	lds	r30, 0x039B
    21f0:	f0 91 9c 03 	lds	r31, 0x039C
    21f4:	96 89       	ldd	r25, Z+22	; 0x16
    21f6:	89 17       	cp	r24, r25
    21f8:	08 f0       	brcs	.+2      	; 0x21fc <vTaskPriorityInherit+0x22>
    21fa:	48 c0       	rjmp	.+144    	; 0x228c <vTaskPriorityInherit+0xb2>
			{
				/* Adjust the mutex holder state to account for its new
				priority.  Only reset the event list item value if the value is
				not	being used for anything else. */
				if( ( listGET_LIST_ITEM_VALUE( &( pxTCB->xEventListItem ) ) & taskEVENT_LIST_ITEM_VALUE_IN_USE ) == 0UL )
    21fc:	2c 85       	ldd	r18, Y+12	; 0x0c
    21fe:	3d 85       	ldd	r19, Y+13	; 0x0d
    2200:	33 23       	and	r19, r19
    2202:	5c f0       	brlt	.+22     	; 0x221a <vTaskPriorityInherit+0x40>
				{
					listSET_LIST_ITEM_VALUE( &( pxTCB->xEventListItem ), ( TickType_t ) configMAX_PRIORITIES - ( TickType_t ) pxCurrentTCB->uxPriority ); /*lint !e961 MISRA exception as the casts are only redundant for some ports. */
    2204:	e0 91 9b 03 	lds	r30, 0x039B
    2208:	f0 91 9c 03 	lds	r31, 0x039C
    220c:	96 89       	ldd	r25, Z+22	; 0x16
    220e:	25 e0       	ldi	r18, 0x05	; 5
    2210:	30 e0       	ldi	r19, 0x00	; 0
    2212:	29 1b       	sub	r18, r25
    2214:	31 09       	sbc	r19, r1
    2216:	3d 87       	std	Y+13, r19	; 0x0d
    2218:	2c 87       	std	Y+12, r18	; 0x0c
					mtCOVERAGE_TEST_MARKER();
				}

				/* If the task being modified is in the ready state it will need
				to be moved into a new list. */
				if( listIS_CONTAINED_WITHIN( &( pxReadyTasksLists[ pxTCB->uxPriority ] ), &( pxTCB->xStateListItem ) ) != pdFALSE )
    221a:	90 e0       	ldi	r25, 0x00	; 0
    221c:	9c 01       	movw	r18, r24
    221e:	22 0f       	add	r18, r18
    2220:	33 1f       	adc	r19, r19
    2222:	22 0f       	add	r18, r18
    2224:	33 1f       	adc	r19, r19
    2226:	22 0f       	add	r18, r18
    2228:	33 1f       	adc	r19, r19
    222a:	82 0f       	add	r24, r18
    222c:	93 1f       	adc	r25, r19
    222e:	82 55       	subi	r24, 0x52	; 82
    2230:	9c 4f       	sbci	r25, 0xFC	; 252
    2232:	2a 85       	ldd	r18, Y+10	; 0x0a
    2234:	3b 85       	ldd	r19, Y+11	; 0x0b
    2236:	28 17       	cp	r18, r24
    2238:	39 07       	cpc	r19, r25
    223a:	11 f5       	brne	.+68     	; 0x2280 <vTaskPriorityInherit+0xa6>
				{
					if( uxListRemove( &( pxTCB->xStateListItem ) ) == ( UBaseType_t ) 0 )
    223c:	8e 01       	movw	r16, r28
    223e:	0e 5f       	subi	r16, 0xFE	; 254
    2240:	1f 4f       	sbci	r17, 0xFF	; 255
    2242:	c8 01       	movw	r24, r16
    2244:	0e 94 42 04 	call	0x884	; 0x884 <uxListRemove>
					{
						mtCOVERAGE_TEST_MARKER();
					}

					/* Inherit the priority before being moved into the new list. */
					pxTCB->uxPriority = pxCurrentTCB->uxPriority;
    2248:	e0 91 9b 03 	lds	r30, 0x039B
    224c:	f0 91 9c 03 	lds	r31, 0x039C
    2250:	86 89       	ldd	r24, Z+22	; 0x16
    2252:	8e 8b       	std	Y+22, r24	; 0x16
					prvAddTaskToReadyList( pxTCB );
    2254:	90 91 a4 03 	lds	r25, 0x03A4
    2258:	98 17       	cp	r25, r24
    225a:	10 f4       	brcc	.+4      	; 0x2260 <vTaskPriorityInherit+0x86>
    225c:	80 93 a4 03 	sts	0x03A4, r24
    2260:	90 e0       	ldi	r25, 0x00	; 0
    2262:	9c 01       	movw	r18, r24
    2264:	22 0f       	add	r18, r18
    2266:	33 1f       	adc	r19, r19
    2268:	22 0f       	add	r18, r18
    226a:	33 1f       	adc	r19, r19
    226c:	22 0f       	add	r18, r18
    226e:	33 1f       	adc	r19, r19
    2270:	82 0f       	add	r24, r18
    2272:	93 1f       	adc	r25, r19
    2274:	82 55       	subi	r24, 0x52	; 82
    2276:	9c 4f       	sbci	r25, 0xFC	; 252
    2278:	b8 01       	movw	r22, r16
    227a:	0e 94 f1 03 	call	0x7e2	; 0x7e2 <vListInsertEnd>
    227e:	06 c0       	rjmp	.+12     	; 0x228c <vTaskPriorityInherit+0xb2>
				}
				else
				{
					/* Just inherit the priority. */
					pxTCB->uxPriority = pxCurrentTCB->uxPriority;
    2280:	e0 91 9b 03 	lds	r30, 0x039B
    2284:	f0 91 9c 03 	lds	r31, 0x039C
    2288:	86 89       	ldd	r24, Z+22	; 0x16
    228a:	8e 8b       	std	Y+22, r24	; 0x16
		}
		else
		{
			mtCOVERAGE_TEST_MARKER();
		}
	}
    228c:	df 91       	pop	r29
    228e:	cf 91       	pop	r28
    2290:	1f 91       	pop	r17
    2292:	0f 91       	pop	r16
    2294:	08 95       	ret

00002296 <xTaskPriorityDisinherit>:
/*-----------------------------------------------------------*/

#if ( configUSE_MUTEXES == 1 )

	BaseType_t xTaskPriorityDisinherit( TaskHandle_t const pxMutexHolder )
	{
    2296:	0f 93       	push	r16
    2298:	1f 93       	push	r17
    229a:	cf 93       	push	r28
    229c:	df 93       	push	r29
    229e:	ec 01       	movw	r28, r24
	TCB_t * const pxTCB = ( TCB_t * ) pxMutexHolder;
	BaseType_t xReturn = pdFALSE;

		if( pxMutexHolder != NULL )
    22a0:	00 97       	sbiw	r24, 0x00	; 0
    22a2:	81 f1       	breq	.+96     	; 0x2304 <xTaskPriorityDisinherit+0x6e>
			interrupt, and if a mutex is given by the holding task then it must
			be the running state task. */
			configASSERT( pxTCB == pxCurrentTCB );

			configASSERT( pxTCB->uxMutexesHeld );
			( pxTCB->uxMutexesHeld )--;
    22a4:	8c a1       	lds	r24, 0x4c
    22a6:	81 50       	subi	r24, 0x01	; 1
    22a8:	8c a3       	lds	r24, 0x5c

			/* Has the holder of the mutex inherited the priority of another
			task? */
			if( pxTCB->uxPriority != pxTCB->uxBasePriority )
    22aa:	2e 89       	ldd	r18, Y+22	; 0x16
    22ac:	9b a1       	lds	r25, 0x4b
    22ae:	29 17       	cp	r18, r25
    22b0:	59 f1       	breq	.+86     	; 0x2308 <xTaskPriorityDisinherit+0x72>
			{
				/* Only disinherit if no other mutexes are held. */
				if( pxTCB->uxMutexesHeld == ( UBaseType_t ) 0 )
    22b2:	88 23       	and	r24, r24
    22b4:	59 f5       	brne	.+86     	; 0x230c <xTaskPriorityDisinherit+0x76>
					/* A task can only have an inherited priority if it holds
					the mutex.  If the mutex is held by a task then it cannot be
					given from an interrupt, and if a mutex is given by the
					holding	task then it must be the running state task.  Remove
					the	holding task from the ready	list. */
					if( uxListRemove( &( pxTCB->xStateListItem ) ) == ( UBaseType_t ) 0 )
    22b6:	8e 01       	movw	r16, r28
    22b8:	0e 5f       	subi	r16, 0xFE	; 254
    22ba:	1f 4f       	sbci	r17, 0xFF	; 255
    22bc:	c8 01       	movw	r24, r16
    22be:	0e 94 42 04 	call	0x884	; 0x884 <uxListRemove>
					}

					/* Disinherit the priority before adding the task into the
					new	ready list. */
					traceTASK_PRIORITY_DISINHERIT( pxTCB, pxTCB->uxBasePriority );
					pxTCB->uxPriority = pxTCB->uxBasePriority;
    22c2:	4b a1       	lds	r20, 0x4b
    22c4:	4e 8b       	std	Y+22, r20	; 0x16

					/* Reset the event list item value.  It cannot be in use for
					any other purpose if this task is running, and it must be
					running to give back the mutex. */
					listSET_LIST_ITEM_VALUE( &( pxTCB->xEventListItem ), ( TickType_t ) configMAX_PRIORITIES - ( TickType_t ) pxTCB->uxPriority ); /*lint !e961 MISRA exception as the casts are only redundant for some ports. */
    22c6:	24 2f       	mov	r18, r20
    22c8:	30 e0       	ldi	r19, 0x00	; 0
    22ca:	85 e0       	ldi	r24, 0x05	; 5
    22cc:	90 e0       	ldi	r25, 0x00	; 0
    22ce:	82 1b       	sub	r24, r18
    22d0:	93 0b       	sbc	r25, r19
    22d2:	9d 87       	std	Y+13, r25	; 0x0d
    22d4:	8c 87       	std	Y+12, r24	; 0x0c
					prvAddTaskToReadyList( pxTCB );
    22d6:	80 91 a4 03 	lds	r24, 0x03A4
    22da:	84 17       	cp	r24, r20
    22dc:	10 f4       	brcc	.+4      	; 0x22e2 <xTaskPriorityDisinherit+0x4c>
    22de:	40 93 a4 03 	sts	0x03A4, r20
    22e2:	c9 01       	movw	r24, r18
    22e4:	88 0f       	add	r24, r24
    22e6:	99 1f       	adc	r25, r25
    22e8:	88 0f       	add	r24, r24
    22ea:	99 1f       	adc	r25, r25
    22ec:	88 0f       	add	r24, r24
    22ee:	99 1f       	adc	r25, r25
    22f0:	28 0f       	add	r18, r24
    22f2:	39 1f       	adc	r19, r25
    22f4:	c9 01       	movw	r24, r18
    22f6:	82 55       	subi	r24, 0x52	; 82
    22f8:	9c 4f       	sbci	r25, 0xFC	; 252
    22fa:	b8 01       	movw	r22, r16
    22fc:	0e 94 f1 03 	call	0x7e2	; 0x7e2 <vListInsertEnd>
					in an order different to that in which they were taken.
					If a context switch did not occur when the first mutex was
					returned, even if a task was waiting on it, then a context
					switch should occur when the last mutex is returned whether
					a task is waiting on it or not. */
					xReturn = pdTRUE;
    2300:	81 e0       	ldi	r24, 0x01	; 1
    2302:	05 c0       	rjmp	.+10     	; 0x230e <xTaskPriorityDisinherit+0x78>
#if ( configUSE_MUTEXES == 1 )

	BaseType_t xTaskPriorityDisinherit( TaskHandle_t const pxMutexHolder )
	{
	TCB_t * const pxTCB = ( TCB_t * ) pxMutexHolder;
	BaseType_t xReturn = pdFALSE;
    2304:	80 e0       	ldi	r24, 0x00	; 0
    2306:	03 c0       	rjmp	.+6      	; 0x230e <xTaskPriorityDisinherit+0x78>
    2308:	80 e0       	ldi	r24, 0x00	; 0
    230a:	01 c0       	rjmp	.+2      	; 0x230e <xTaskPriorityDisinherit+0x78>
    230c:	80 e0       	ldi	r24, 0x00	; 0
		{
			mtCOVERAGE_TEST_MARKER();
		}

		return xReturn;
	}
    230e:	df 91       	pop	r29
    2310:	cf 91       	pop	r28
    2312:	1f 91       	pop	r17
    2314:	0f 91       	pop	r16
    2316:	08 95       	ret

00002318 <uxTaskResetEventItemValue>:

TickType_t uxTaskResetEventItemValue( void )
{
TickType_t uxReturn;

	uxReturn = listGET_LIST_ITEM_VALUE( &( pxCurrentTCB->xEventListItem ) );
    2318:	e0 91 9b 03 	lds	r30, 0x039B
    231c:	f0 91 9c 03 	lds	r31, 0x039C
    2320:	84 85       	ldd	r24, Z+12	; 0x0c
    2322:	95 85       	ldd	r25, Z+13	; 0x0d

	/* Reset the event list item to its normal value - so it can be used with
	queues and semaphores. */
	listSET_LIST_ITEM_VALUE( &( pxCurrentTCB->xEventListItem ), ( ( TickType_t ) configMAX_PRIORITIES - ( TickType_t ) pxCurrentTCB->uxPriority ) ); /*lint !e961 MISRA exception as the casts are only redundant for some ports. */
    2324:	e0 91 9b 03 	lds	r30, 0x039B
    2328:	f0 91 9c 03 	lds	r31, 0x039C
    232c:	a0 91 9b 03 	lds	r26, 0x039B
    2330:	b0 91 9c 03 	lds	r27, 0x039C
    2334:	56 96       	adiw	r26, 0x16	; 22
    2336:	4c 91       	ld	r20, X
    2338:	56 97       	sbiw	r26, 0x16	; 22
    233a:	25 e0       	ldi	r18, 0x05	; 5
    233c:	30 e0       	ldi	r19, 0x00	; 0
    233e:	24 1b       	sub	r18, r20
    2340:	31 09       	sbc	r19, r1
    2342:	35 87       	std	Z+13, r19	; 0x0d
    2344:	24 87       	std	Z+12, r18	; 0x0c

	return uxReturn;
}
    2346:	08 95       	ret

00002348 <pvTaskIncrementMutexHeldCount>:

	void *pvTaskIncrementMutexHeldCount( void )
	{
		/* If xSemaphoreCreateMutex() is called before any tasks have been created
		then pxCurrentTCB will be NULL. */
		if( pxCurrentTCB != NULL )
    2348:	80 91 9b 03 	lds	r24, 0x039B
    234c:	90 91 9c 03 	lds	r25, 0x039C
    2350:	00 97       	sbiw	r24, 0x00	; 0
    2352:	39 f0       	breq	.+14     	; 0x2362 <pvTaskIncrementMutexHeldCount+0x1a>
		{
			( pxCurrentTCB->uxMutexesHeld )++;
    2354:	e0 91 9b 03 	lds	r30, 0x039B
    2358:	f0 91 9c 03 	lds	r31, 0x039C
    235c:	84 a1       	lds	r24, 0x44
    235e:	8f 5f       	subi	r24, 0xFF	; 255
    2360:	84 a3       	lds	r24, 0x54
		}

		return pxCurrentTCB;
    2362:	80 91 9b 03 	lds	r24, 0x039B
    2366:	90 91 9c 03 	lds	r25, 0x039C
	}
    236a:	08 95       	ret

0000236c <ulTaskNotifyTake>:
/*-----------------------------------------------------------*/

#if( configUSE_TASK_NOTIFICATIONS == 1 )

	uint32_t ulTaskNotifyTake( BaseType_t xClearCountOnExit, TickType_t xTicksToWait )
	{
    236c:	0f 93       	push	r16
    236e:	1f 93       	push	r17
    2370:	cf 93       	push	r28
    2372:	c8 2f       	mov	r28, r24
	uint32_t ulReturn;

		taskENTER_CRITICAL();
    2374:	0f b6       	in	r0, 0x3f	; 63
    2376:	f8 94       	cli
    2378:	0f 92       	push	r0
		{
			/* Only block if the notification count is not already non-zero. */
			if( pxCurrentTCB->ulNotifiedValue == 0UL )
    237a:	e0 91 9b 03 	lds	r30, 0x039B
    237e:	f0 91 9c 03 	lds	r31, 0x039C
    2382:	85 a1       	lds	r24, 0x45
    2384:	96 a1       	lds	r25, 0x46
    2386:	a7 a1       	lds	r26, 0x47
    2388:	b0 a5       	lds	r27, 0x60
    238a:	00 97       	sbiw	r24, 0x00	; 0
    238c:	a1 05       	cpc	r26, r1
    238e:	b1 05       	cpc	r27, r1
    2390:	79 f4       	brne	.+30     	; 0x23b0 <ulTaskNotifyTake+0x44>
			{
				/* Mark this task as waiting for a notification. */
				pxCurrentTCB->ucNotifyState = taskWAITING_NOTIFICATION;
    2392:	e0 91 9b 03 	lds	r30, 0x039B
    2396:	f0 91 9c 03 	lds	r31, 0x039C
    239a:	81 e0       	ldi	r24, 0x01	; 1
    239c:	81 a7       	lds	r24, 0x71

				if( xTicksToWait > ( TickType_t ) 0 )
    239e:	61 15       	cp	r22, r1
    23a0:	71 05       	cpc	r23, r1
    23a2:	31 f0       	breq	.+12     	; 0x23b0 <ulTaskNotifyTake+0x44>
				{
					prvAddCurrentTaskToDelayedList( xTicksToWait, pdTRUE );
    23a4:	cb 01       	movw	r24, r22
    23a6:	61 e0       	ldi	r22, 0x01	; 1
    23a8:	0e 94 4b 0a 	call	0x1496	; 0x1496 <prvAddCurrentTaskToDelayedList>

					/* All ports are written to allow a yield in a critical
					section (some will yield immediately, others wait until the
					critical section exits) - but it is not something that
					application code should ever do. */
					portYIELD_WITHIN_API();
    23ac:	0e 94 30 05 	call	0xa60	; 0xa60 <vPortYield>
			else
			{
				mtCOVERAGE_TEST_MARKER();
			}
		}
		taskEXIT_CRITICAL();
    23b0:	0f 90       	pop	r0
    23b2:	0f be       	out	0x3f, r0	; 63

		taskENTER_CRITICAL();
    23b4:	0f b6       	in	r0, 0x3f	; 63
    23b6:	f8 94       	cli
    23b8:	0f 92       	push	r0
		{
			traceTASK_NOTIFY_TAKE();
			ulReturn = pxCurrentTCB->ulNotifiedValue;
    23ba:	e0 91 9b 03 	lds	r30, 0x039B
    23be:	f0 91 9c 03 	lds	r31, 0x039C
    23c2:	05 a1       	lds	r16, 0x45
    23c4:	16 a1       	lds	r17, 0x46
    23c6:	27 a1       	lds	r18, 0x47
    23c8:	30 a5       	lds	r19, 0x60

			if( ulReturn != 0UL )
    23ca:	01 15       	cp	r16, r1
    23cc:	11 05       	cpc	r17, r1
    23ce:	21 05       	cpc	r18, r1
    23d0:	31 05       	cpc	r19, r1
    23d2:	c1 f0       	breq	.+48     	; 0x2404 <ulTaskNotifyTake+0x98>
			{
				if( xClearCountOnExit != pdFALSE )
    23d4:	cc 23       	and	r28, r28
    23d6:	49 f0       	breq	.+18     	; 0x23ea <ulTaskNotifyTake+0x7e>
				{
					pxCurrentTCB->ulNotifiedValue = 0UL;
    23d8:	e0 91 9b 03 	lds	r30, 0x039B
    23dc:	f0 91 9c 03 	lds	r31, 0x039C
    23e0:	15 a2       	lds	r17, 0x95
    23e2:	16 a2       	lds	r17, 0x96
    23e4:	17 a2       	lds	r17, 0x97
    23e6:	10 a6       	lds	r17, 0xb0
    23e8:	0d c0       	rjmp	.+26     	; 0x2404 <ulTaskNotifyTake+0x98>
				}
				else
				{
					pxCurrentTCB->ulNotifiedValue = ulReturn - 1;
    23ea:	e0 91 9b 03 	lds	r30, 0x039B
    23ee:	f0 91 9c 03 	lds	r31, 0x039C
    23f2:	d9 01       	movw	r26, r18
    23f4:	c8 01       	movw	r24, r16
    23f6:	01 97       	sbiw	r24, 0x01	; 1
    23f8:	a1 09       	sbc	r26, r1
    23fa:	b1 09       	sbc	r27, r1
    23fc:	85 a3       	lds	r24, 0x55
    23fe:	96 a3       	lds	r25, 0x56
    2400:	a7 a3       	lds	r26, 0x57
    2402:	b0 a7       	lds	r27, 0x70
			else
			{
				mtCOVERAGE_TEST_MARKER();
			}

			pxCurrentTCB->ucNotifyState = taskNOT_WAITING_NOTIFICATION;
    2404:	e0 91 9b 03 	lds	r30, 0x039B
    2408:	f0 91 9c 03 	lds	r31, 0x039C
    240c:	11 a6       	lds	r17, 0xb1
		}
		taskEXIT_CRITICAL();
    240e:	0f 90       	pop	r0
    2410:	0f be       	out	0x3f, r0	; 63

		return ulReturn;
	}
    2412:	60 2f       	mov	r22, r16
    2414:	71 2f       	mov	r23, r17
    2416:	82 2f       	mov	r24, r18
    2418:	93 2f       	mov	r25, r19
    241a:	cf 91       	pop	r28
    241c:	1f 91       	pop	r17
    241e:	0f 91       	pop	r16
    2420:	08 95       	ret

00002422 <xTaskNotifyWait>:
/*-----------------------------------------------------------*/

#if( configUSE_TASK_NOTIFICATIONS == 1 )

	BaseType_t xTaskNotifyWait( uint32_t ulBitsToClearOnEntry, uint32_t ulBitsToClearOnExit, uint32_t *pulNotificationValue, TickType_t xTicksToWait )
	{
    2422:	8f 92       	push	r8
    2424:	9f 92       	push	r9
    2426:	af 92       	push	r10
    2428:	bf 92       	push	r11
    242a:	ef 92       	push	r14
    242c:	ff 92       	push	r15
    242e:	0f 93       	push	r16
    2430:	1f 93       	push	r17
    2432:	dc 01       	movw	r26, r24
    2434:	cb 01       	movw	r24, r22
    2436:	49 01       	movw	r8, r18
    2438:	5a 01       	movw	r10, r20
	BaseType_t xReturn;

		taskENTER_CRITICAL();
    243a:	0f b6       	in	r0, 0x3f	; 63
    243c:	f8 94       	cli
    243e:	0f 92       	push	r0
		{
			/* Only block if a notification is not already pending. */
			if( pxCurrentTCB->ucNotifyState != taskNOTIFICATION_RECEIVED )
    2440:	e0 91 9b 03 	lds	r30, 0x039B
    2444:	f0 91 9c 03 	lds	r31, 0x039C
    2448:	21 a5       	lds	r18, 0x61
    244a:	22 30       	cpi	r18, 0x02	; 2
    244c:	19 f1       	breq	.+70     	; 0x2494 <xTaskNotifyWait+0x72>
			{
				/* Clear bits in the task's notification value as bits may get
				set	by the notifying task or interrupt.  This can be used to
				clear the value to zero. */
				pxCurrentTCB->ulNotifiedValue &= ~ulBitsToClearOnEntry;
    244e:	e0 91 9b 03 	lds	r30, 0x039B
    2452:	f0 91 9c 03 	lds	r31, 0x039C
    2456:	45 a1       	lds	r20, 0x45
    2458:	56 a1       	lds	r21, 0x46
    245a:	67 a1       	lds	r22, 0x47
    245c:	70 a5       	lds	r23, 0x60
    245e:	80 95       	com	r24
    2460:	90 95       	com	r25
    2462:	a0 95       	com	r26
    2464:	b0 95       	com	r27
    2466:	84 23       	and	r24, r20
    2468:	95 23       	and	r25, r21
    246a:	a6 23       	and	r26, r22
    246c:	b7 23       	and	r27, r23
    246e:	85 a3       	lds	r24, 0x55
    2470:	96 a3       	lds	r25, 0x56
    2472:	a7 a3       	lds	r26, 0x57
    2474:	b0 a7       	lds	r27, 0x70

				/* Mark this task as waiting for a notification. */
				pxCurrentTCB->ucNotifyState = taskWAITING_NOTIFICATION;
    2476:	e0 91 9b 03 	lds	r30, 0x039B
    247a:	f0 91 9c 03 	lds	r31, 0x039C
    247e:	81 e0       	ldi	r24, 0x01	; 1
    2480:	81 a7       	lds	r24, 0x71

				if( xTicksToWait > ( TickType_t ) 0 )
    2482:	e1 14       	cp	r14, r1
    2484:	f1 04       	cpc	r15, r1
    2486:	31 f0       	breq	.+12     	; 0x2494 <xTaskNotifyWait+0x72>
				{
					prvAddCurrentTaskToDelayedList( xTicksToWait, pdTRUE );
    2488:	c7 01       	movw	r24, r14
    248a:	61 e0       	ldi	r22, 0x01	; 1
    248c:	0e 94 4b 0a 	call	0x1496	; 0x1496 <prvAddCurrentTaskToDelayedList>

					/* All ports are written to allow a yield in a critical
					section (some will yield immediately, others wait until the
					critical section exits) - but it is not something that
					application code should ever do. */
					portYIELD_WITHIN_API();
    2490:	0e 94 30 05 	call	0xa60	; 0xa60 <vPortYield>
			else
			{
				mtCOVERAGE_TEST_MARKER();
			}
		}
		taskEXIT_CRITICAL();
    2494:	0f 90       	pop	r0
    2496:	0f be       	out	0x3f, r0	; 63

		taskENTER_CRITICAL();
    2498:	0f b6       	in	r0, 0x3f	; 63
    249a:	f8 94       	cli
    249c:	0f 92       	push	r0
		{
			traceTASK_NOTIFY_WAIT();

			if( pulNotificationValue != NULL )
    249e:	01 15       	cp	r16, r1
    24a0:	11 05       	cpc	r17, r1
    24a2:	69 f0       	breq	.+26     	; 0x24be <xTaskNotifyWait+0x9c>
			{
				/* Output the current notification value, which may or may not
				have changed. */
				*pulNotificationValue = pxCurrentTCB->ulNotifiedValue;
    24a4:	e0 91 9b 03 	lds	r30, 0x039B
    24a8:	f0 91 9c 03 	lds	r31, 0x039C
    24ac:	85 a1       	lds	r24, 0x45
    24ae:	96 a1       	lds	r25, 0x46
    24b0:	a7 a1       	lds	r26, 0x47
    24b2:	b0 a5       	lds	r27, 0x60
    24b4:	f8 01       	movw	r30, r16
    24b6:	80 83       	st	Z, r24
    24b8:	91 83       	std	Z+1, r25	; 0x01
    24ba:	a2 83       	std	Z+2, r26	; 0x02
    24bc:	b3 83       	std	Z+3, r27	; 0x03

			/* If ucNotifyValue is set then either the task never entered the
			blocked state (because a notification was already pending) or the
			task unblocked because of a notification.  Otherwise the task
			unblocked because of a timeout. */
			if( pxCurrentTCB->ucNotifyState == taskWAITING_NOTIFICATION )
    24be:	e0 91 9b 03 	lds	r30, 0x039B
    24c2:	f0 91 9c 03 	lds	r31, 0x039C
    24c6:	81 a5       	lds	r24, 0x61
    24c8:	81 30       	cpi	r24, 0x01	; 1
    24ca:	b1 f0       	breq	.+44     	; 0x24f8 <xTaskNotifyWait+0xd6>
			}
			else
			{
				/* A notification was already pending or a notification was
				received while the task was waiting. */
				pxCurrentTCB->ulNotifiedValue &= ~ulBitsToClearOnExit;
    24cc:	e0 91 9b 03 	lds	r30, 0x039B
    24d0:	f0 91 9c 03 	lds	r31, 0x039C
    24d4:	85 a1       	lds	r24, 0x45
    24d6:	96 a1       	lds	r25, 0x46
    24d8:	a7 a1       	lds	r26, 0x47
    24da:	b0 a5       	lds	r27, 0x60
    24dc:	80 94       	com	r8
    24de:	90 94       	com	r9
    24e0:	a0 94       	com	r10
    24e2:	b0 94       	com	r11
    24e4:	88 22       	and	r8, r24
    24e6:	99 22       	and	r9, r25
    24e8:	aa 22       	and	r10, r26
    24ea:	bb 22       	and	r11, r27
    24ec:	85 a2       	lds	r24, 0x95
    24ee:	96 a2       	lds	r25, 0x96
    24f0:	a7 a2       	lds	r26, 0x97
    24f2:	b0 a6       	lds	r27, 0xb0
				xReturn = pdTRUE;
    24f4:	81 e0       	ldi	r24, 0x01	; 1
    24f6:	01 c0       	rjmp	.+2      	; 0x24fa <xTaskNotifyWait+0xd8>
			task unblocked because of a notification.  Otherwise the task
			unblocked because of a timeout. */
			if( pxCurrentTCB->ucNotifyState == taskWAITING_NOTIFICATION )
			{
				/* A notification was not received. */
				xReturn = pdFALSE;
    24f8:	80 e0       	ldi	r24, 0x00	; 0
				received while the task was waiting. */
				pxCurrentTCB->ulNotifiedValue &= ~ulBitsToClearOnExit;
				xReturn = pdTRUE;
			}

			pxCurrentTCB->ucNotifyState = taskNOT_WAITING_NOTIFICATION;
    24fa:	e0 91 9b 03 	lds	r30, 0x039B
    24fe:	f0 91 9c 03 	lds	r31, 0x039C
    2502:	11 a6       	lds	r17, 0xb1
		}
		taskEXIT_CRITICAL();
    2504:	0f 90       	pop	r0
    2506:	0f be       	out	0x3f, r0	; 63

		return xReturn;
	}
    2508:	1f 91       	pop	r17
    250a:	0f 91       	pop	r16
    250c:	ff 90       	pop	r15
    250e:	ef 90       	pop	r14
    2510:	bf 90       	pop	r11
    2512:	af 90       	pop	r10
    2514:	9f 90       	pop	r9
    2516:	8f 90       	pop	r8
    2518:	08 95       	ret

0000251a <xTaskGenericNotify>:
/*-----------------------------------------------------------*/

#if( configUSE_TASK_NOTIFICATIONS == 1 )

	BaseType_t xTaskGenericNotify( TaskHandle_t xTaskToNotify, uint32_t ulValue, eNotifyAction eAction, uint32_t *pulPreviousNotificationValue )
	{
    251a:	0f 93       	push	r16
    251c:	1f 93       	push	r17
    251e:	cf 93       	push	r28
    2520:	df 93       	push	r29
    2522:	ec 01       	movw	r28, r24
	uint8_t ucOriginalNotifyState;

		configASSERT( xTaskToNotify );
		pxTCB = ( TCB_t * ) xTaskToNotify;

		taskENTER_CRITICAL();
    2524:	0f b6       	in	r0, 0x3f	; 63
    2526:	f8 94       	cli
    2528:	0f 92       	push	r0
		{
			if( pulPreviousNotificationValue != NULL )
    252a:	01 15       	cp	r16, r1
    252c:	11 05       	cpc	r17, r1
    252e:	49 f0       	breq	.+18     	; 0x2542 <xTaskGenericNotify+0x28>
			{
				*pulPreviousNotificationValue = pxTCB->ulNotifiedValue;
    2530:	8d a1       	lds	r24, 0x4d
    2532:	9e a1       	lds	r25, 0x4e
    2534:	af a1       	lds	r26, 0x4f
    2536:	b8 a5       	lds	r27, 0x68
    2538:	f8 01       	movw	r30, r16
    253a:	80 83       	st	Z, r24
    253c:	91 83       	std	Z+1, r25	; 0x01
    253e:	a2 83       	std	Z+2, r26	; 0x02
    2540:	b3 83       	std	Z+3, r27	; 0x03
			}

			ucOriginalNotifyState = pxTCB->ucNotifyState;
    2542:	39 a5       	lds	r19, 0x69

			pxTCB->ucNotifyState = taskNOTIFICATION_RECEIVED;
    2544:	82 e0       	ldi	r24, 0x02	; 2
    2546:	89 a7       	lds	r24, 0x79

			switch( eAction )
    2548:	22 30       	cpi	r18, 0x02	; 2
    254a:	b9 f0       	breq	.+46     	; 0x257a <xTaskGenericNotify+0x60>
    254c:	23 30       	cpi	r18, 0x03	; 3
    254e:	18 f4       	brcc	.+6      	; 0x2556 <xTaskGenericNotify+0x3c>
    2550:	21 30       	cpi	r18, 0x01	; 1
    2552:	51 f5       	brne	.+84     	; 0x25a8 <xTaskGenericNotify+0x8e>
    2554:	05 c0       	rjmp	.+10     	; 0x2560 <xTaskGenericNotify+0x46>
    2556:	23 30       	cpi	r18, 0x03	; 3
    2558:	e1 f0       	breq	.+56     	; 0x2592 <xTaskGenericNotify+0x78>
    255a:	24 30       	cpi	r18, 0x04	; 4
    255c:	29 f5       	brne	.+74     	; 0x25a8 <xTaskGenericNotify+0x8e>
    255e:	1e c0       	rjmp	.+60     	; 0x259c <xTaskGenericNotify+0x82>
			{
				case eSetBits	:
					pxTCB->ulNotifiedValue |= ulValue;
    2560:	8d a1       	lds	r24, 0x4d
    2562:	9e a1       	lds	r25, 0x4e
    2564:	af a1       	lds	r26, 0x4f
    2566:	b8 a5       	lds	r27, 0x68
    2568:	48 2b       	or	r20, r24
    256a:	59 2b       	or	r21, r25
    256c:	6a 2b       	or	r22, r26
    256e:	7b 2b       	or	r23, r27
    2570:	4d a3       	lds	r20, 0x5d
    2572:	5e a3       	lds	r21, 0x5e
    2574:	6f a3       	lds	r22, 0x5f
    2576:	78 a7       	lds	r23, 0x78
					break;
    2578:	17 c0       	rjmp	.+46     	; 0x25a8 <xTaskGenericNotify+0x8e>

				case eIncrement	:
					( pxTCB->ulNotifiedValue )++;
    257a:	8d a1       	lds	r24, 0x4d
    257c:	9e a1       	lds	r25, 0x4e
    257e:	af a1       	lds	r26, 0x4f
    2580:	b8 a5       	lds	r27, 0x68
    2582:	01 96       	adiw	r24, 0x01	; 1
    2584:	a1 1d       	adc	r26, r1
    2586:	b1 1d       	adc	r27, r1
    2588:	8d a3       	lds	r24, 0x5d
    258a:	9e a3       	lds	r25, 0x5e
    258c:	af a3       	lds	r26, 0x5f
    258e:	b8 a7       	lds	r27, 0x78
					break;
    2590:	0b c0       	rjmp	.+22     	; 0x25a8 <xTaskGenericNotify+0x8e>

				case eSetValueWithOverwrite	:
					pxTCB->ulNotifiedValue = ulValue;
    2592:	4d a3       	lds	r20, 0x5d
    2594:	5e a3       	lds	r21, 0x5e
    2596:	6f a3       	lds	r22, 0x5f
    2598:	78 a7       	lds	r23, 0x78
					break;
    259a:	06 c0       	rjmp	.+12     	; 0x25a8 <xTaskGenericNotify+0x8e>

				case eSetValueWithoutOverwrite :
					if( ucOriginalNotifyState != taskNOTIFICATION_RECEIVED )
    259c:	32 30       	cpi	r19, 0x02	; 2
    259e:	71 f1       	breq	.+92     	; 0x25fc <xTaskGenericNotify+0xe2>
					{
						pxTCB->ulNotifiedValue = ulValue;
    25a0:	4d a3       	lds	r20, 0x5d
    25a2:	5e a3       	lds	r21, 0x5e
    25a4:	6f a3       	lds	r22, 0x5f
    25a6:	78 a7       	lds	r23, 0x78

			traceTASK_NOTIFY();

			/* If the task is in the blocked state specifically to wait for a
			notification then unblock it now. */
			if( ucOriginalNotifyState == taskWAITING_NOTIFICATION )
    25a8:	31 30       	cpi	r19, 0x01	; 1
    25aa:	51 f5       	brne	.+84     	; 0x2600 <xTaskGenericNotify+0xe6>
			{
				( void ) uxListRemove( &( pxTCB->xStateListItem ) );
    25ac:	8e 01       	movw	r16, r28
    25ae:	0e 5f       	subi	r16, 0xFE	; 254
    25b0:	1f 4f       	sbci	r17, 0xFF	; 255
    25b2:	c8 01       	movw	r24, r16
    25b4:	0e 94 42 04 	call	0x884	; 0x884 <uxListRemove>
				prvAddTaskToReadyList( pxTCB );
    25b8:	8e 89       	ldd	r24, Y+22	; 0x16
    25ba:	90 91 a4 03 	lds	r25, 0x03A4
    25be:	98 17       	cp	r25, r24
    25c0:	10 f4       	brcc	.+4      	; 0x25c6 <xTaskGenericNotify+0xac>
    25c2:	80 93 a4 03 	sts	0x03A4, r24
    25c6:	90 e0       	ldi	r25, 0x00	; 0
    25c8:	9c 01       	movw	r18, r24
    25ca:	22 0f       	add	r18, r18
    25cc:	33 1f       	adc	r19, r19
    25ce:	22 0f       	add	r18, r18
    25d0:	33 1f       	adc	r19, r19
    25d2:	22 0f       	add	r18, r18
    25d4:	33 1f       	adc	r19, r19
    25d6:	82 0f       	add	r24, r18
    25d8:	93 1f       	adc	r25, r19
    25da:	82 55       	subi	r24, 0x52	; 82
    25dc:	9c 4f       	sbci	r25, 0xFC	; 252
    25de:	b8 01       	movw	r22, r16
    25e0:	0e 94 f1 03 	call	0x7e2	; 0x7e2 <vListInsertEnd>
					earliest possible time. */
					prvResetNextTaskUnblockTime();
				}
				#endif

				if( pxTCB->uxPriority > pxCurrentTCB->uxPriority )
    25e4:	e0 91 9b 03 	lds	r30, 0x039B
    25e8:	f0 91 9c 03 	lds	r31, 0x039C
    25ec:	9e 89       	ldd	r25, Y+22	; 0x16
    25ee:	86 89       	ldd	r24, Z+22	; 0x16
    25f0:	89 17       	cp	r24, r25
    25f2:	40 f4       	brcc	.+16     	; 0x2604 <xTaskGenericNotify+0xea>
				{
					/* The notified task has a priority above the currently
					executing task so a yield is required. */
					taskYIELD_IF_USING_PREEMPTION();
    25f4:	0e 94 30 05 	call	0xa60	; 0xa60 <vPortYield>
    25f8:	81 e0       	ldi	r24, 0x01	; 1
    25fa:	05 c0       	rjmp	.+10     	; 0x2606 <xTaskGenericNotify+0xec>
						pxTCB->ulNotifiedValue = ulValue;
					}
					else
					{
						/* The value could not be written to the task. */
						xReturn = pdFAIL;
    25fc:	80 e0       	ldi	r24, 0x00	; 0
    25fe:	03 c0       	rjmp	.+6      	; 0x2606 <xTaskGenericNotify+0xec>

			traceTASK_NOTIFY();

			/* If the task is in the blocked state specifically to wait for a
			notification then unblock it now. */
			if( ucOriginalNotifyState == taskWAITING_NOTIFICATION )
    2600:	81 e0       	ldi	r24, 0x01	; 1
    2602:	01 c0       	rjmp	.+2      	; 0x2606 <xTaskGenericNotify+0xec>
					earliest possible time. */
					prvResetNextTaskUnblockTime();
				}
				#endif

				if( pxTCB->uxPriority > pxCurrentTCB->uxPriority )
    2604:	81 e0       	ldi	r24, 0x01	; 1
			else
			{
				mtCOVERAGE_TEST_MARKER();
			}
		}
		taskEXIT_CRITICAL();
    2606:	0f 90       	pop	r0
    2608:	0f be       	out	0x3f, r0	; 63

		return xReturn;
	}
    260a:	df 91       	pop	r29
    260c:	cf 91       	pop	r28
    260e:	1f 91       	pop	r17
    2610:	0f 91       	pop	r16
    2612:	08 95       	ret

00002614 <xTaskGenericNotifyFromISR>:
/*-----------------------------------------------------------*/

#if( configUSE_TASK_NOTIFICATIONS == 1 )

	BaseType_t xTaskGenericNotifyFromISR( TaskHandle_t xTaskToNotify, uint32_t ulValue, eNotifyAction eAction, uint32_t *pulPreviousNotificationValue, BaseType_t *pxHigherPriorityTaskWoken )
	{
    2614:	ef 92       	push	r14
    2616:	ff 92       	push	r15
    2618:	0f 93       	push	r16
    261a:	1f 93       	push	r17
    261c:	cf 93       	push	r28
    261e:	df 93       	push	r29
    2620:	ec 01       	movw	r28, r24

		pxTCB = ( TCB_t * ) xTaskToNotify;

		uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
		{
			if( pulPreviousNotificationValue != NULL )
    2622:	01 15       	cp	r16, r1
    2624:	11 05       	cpc	r17, r1
    2626:	49 f0       	breq	.+18     	; 0x263a <xTaskGenericNotifyFromISR+0x26>
			{
				*pulPreviousNotificationValue = pxTCB->ulNotifiedValue;
    2628:	8d a1       	lds	r24, 0x4d
    262a:	9e a1       	lds	r25, 0x4e
    262c:	af a1       	lds	r26, 0x4f
    262e:	b8 a5       	lds	r27, 0x68
    2630:	f8 01       	movw	r30, r16
    2632:	80 83       	st	Z, r24
    2634:	91 83       	std	Z+1, r25	; 0x01
    2636:	a2 83       	std	Z+2, r26	; 0x02
    2638:	b3 83       	std	Z+3, r27	; 0x03
			}

			ucOriginalNotifyState = pxTCB->ucNotifyState;
    263a:	39 a5       	lds	r19, 0x69
			pxTCB->ucNotifyState = taskNOTIFICATION_RECEIVED;
    263c:	82 e0       	ldi	r24, 0x02	; 2
    263e:	89 a7       	lds	r24, 0x79

			switch( eAction )
    2640:	22 30       	cpi	r18, 0x02	; 2
    2642:	b9 f0       	breq	.+46     	; 0x2672 <xTaskGenericNotifyFromISR+0x5e>
    2644:	23 30       	cpi	r18, 0x03	; 3
    2646:	18 f4       	brcc	.+6      	; 0x264e <xTaskGenericNotifyFromISR+0x3a>
    2648:	21 30       	cpi	r18, 0x01	; 1
    264a:	59 f5       	brne	.+86     	; 0x26a2 <xTaskGenericNotifyFromISR+0x8e>
    264c:	05 c0       	rjmp	.+10     	; 0x2658 <xTaskGenericNotifyFromISR+0x44>
    264e:	23 30       	cpi	r18, 0x03	; 3
    2650:	e1 f0       	breq	.+56     	; 0x268a <xTaskGenericNotifyFromISR+0x76>
    2652:	24 30       	cpi	r18, 0x04	; 4
    2654:	31 f5       	brne	.+76     	; 0x26a2 <xTaskGenericNotifyFromISR+0x8e>
    2656:	1e c0       	rjmp	.+60     	; 0x2694 <xTaskGenericNotifyFromISR+0x80>
			{
				case eSetBits	:
					pxTCB->ulNotifiedValue |= ulValue;
    2658:	8d a1       	lds	r24, 0x4d
    265a:	9e a1       	lds	r25, 0x4e
    265c:	af a1       	lds	r26, 0x4f
    265e:	b8 a5       	lds	r27, 0x68
    2660:	84 2b       	or	r24, r20
    2662:	95 2b       	or	r25, r21
    2664:	a6 2b       	or	r26, r22
    2666:	b7 2b       	or	r27, r23
    2668:	8d a3       	lds	r24, 0x5d
    266a:	9e a3       	lds	r25, 0x5e
    266c:	af a3       	lds	r26, 0x5f
    266e:	b8 a7       	lds	r27, 0x78
					break;
    2670:	18 c0       	rjmp	.+48     	; 0x26a2 <xTaskGenericNotifyFromISR+0x8e>

				case eIncrement	:
					( pxTCB->ulNotifiedValue )++;
    2672:	8d a1       	lds	r24, 0x4d
    2674:	9e a1       	lds	r25, 0x4e
    2676:	af a1       	lds	r26, 0x4f
    2678:	b8 a5       	lds	r27, 0x68
    267a:	01 96       	adiw	r24, 0x01	; 1
    267c:	a1 1d       	adc	r26, r1
    267e:	b1 1d       	adc	r27, r1
    2680:	8d a3       	lds	r24, 0x5d
    2682:	9e a3       	lds	r25, 0x5e
    2684:	af a3       	lds	r26, 0x5f
    2686:	b8 a7       	lds	r27, 0x78
					break;
    2688:	0c c0       	rjmp	.+24     	; 0x26a2 <xTaskGenericNotifyFromISR+0x8e>

				case eSetValueWithOverwrite	:
					pxTCB->ulNotifiedValue = ulValue;
    268a:	4d a3       	lds	r20, 0x5d
    268c:	5e a3       	lds	r21, 0x5e
    268e:	6f a3       	lds	r22, 0x5f
    2690:	78 a7       	lds	r23, 0x78
					break;
    2692:	07 c0       	rjmp	.+14     	; 0x26a2 <xTaskGenericNotifyFromISR+0x8e>

				case eSetValueWithoutOverwrite :
					if( ucOriginalNotifyState != taskNOTIFICATION_RECEIVED )
    2694:	32 30       	cpi	r19, 0x02	; 2
    2696:	09 f4       	brne	.+2      	; 0x269a <xTaskGenericNotifyFromISR+0x86>
    2698:	41 c0       	rjmp	.+130    	; 0x271c <xTaskGenericNotifyFromISR+0x108>
					{
						pxTCB->ulNotifiedValue = ulValue;
    269a:	4d a3       	lds	r20, 0x5d
    269c:	5e a3       	lds	r21, 0x5e
    269e:	6f a3       	lds	r22, 0x5f
    26a0:	78 a7       	lds	r23, 0x78

			traceTASK_NOTIFY_FROM_ISR();

			/* If the task is in the blocked state specifically to wait for a
			notification then unblock it now. */
			if( ucOriginalNotifyState == taskWAITING_NOTIFICATION )
    26a2:	31 30       	cpi	r19, 0x01	; 1
    26a4:	e9 f5       	brne	.+122    	; 0x2720 <xTaskGenericNotifyFromISR+0x10c>
			{
				/* The task should not have been on an event list. */
				configASSERT( listLIST_ITEM_CONTAINER( &( pxTCB->xEventListItem ) ) == NULL );

				if( uxSchedulerSuspended == ( UBaseType_t ) pdFALSE )
    26a6:	80 91 9d 03 	lds	r24, 0x039D
    26aa:	88 23       	and	r24, r24
    26ac:	e9 f4       	brne	.+58     	; 0x26e8 <xTaskGenericNotifyFromISR+0xd4>
				{
					( void ) uxListRemove( &( pxTCB->xStateListItem ) );
    26ae:	8e 01       	movw	r16, r28
    26b0:	0e 5f       	subi	r16, 0xFE	; 254
    26b2:	1f 4f       	sbci	r17, 0xFF	; 255
    26b4:	c8 01       	movw	r24, r16
    26b6:	0e 94 42 04 	call	0x884	; 0x884 <uxListRemove>
					prvAddTaskToReadyList( pxTCB );
    26ba:	8e 89       	ldd	r24, Y+22	; 0x16
    26bc:	90 91 a4 03 	lds	r25, 0x03A4
    26c0:	98 17       	cp	r25, r24
    26c2:	10 f4       	brcc	.+4      	; 0x26c8 <xTaskGenericNotifyFromISR+0xb4>
    26c4:	80 93 a4 03 	sts	0x03A4, r24
    26c8:	90 e0       	ldi	r25, 0x00	; 0
    26ca:	9c 01       	movw	r18, r24
    26cc:	22 0f       	add	r18, r18
    26ce:	33 1f       	adc	r19, r19
    26d0:	22 0f       	add	r18, r18
    26d2:	33 1f       	adc	r19, r19
    26d4:	22 0f       	add	r18, r18
    26d6:	33 1f       	adc	r19, r19
    26d8:	82 0f       	add	r24, r18
    26da:	93 1f       	adc	r25, r19
    26dc:	82 55       	subi	r24, 0x52	; 82
    26de:	9c 4f       	sbci	r25, 0xFC	; 252
    26e0:	b8 01       	movw	r22, r16
    26e2:	0e 94 f1 03 	call	0x7e2	; 0x7e2 <vListInsertEnd>
    26e6:	07 c0       	rjmp	.+14     	; 0x26f6 <xTaskGenericNotifyFromISR+0xe2>
				}
				else
				{
					/* The delayed and ready lists cannot be accessed, so hold
					this task pending until the scheduler is resumed. */
					vListInsertEnd( &( xPendingReadyList ), &( pxTCB->xEventListItem ) );
    26e8:	be 01       	movw	r22, r28
    26ea:	64 5f       	subi	r22, 0xF4	; 244
    26ec:	7f 4f       	sbci	r23, 0xFF	; 255
    26ee:	8d ee       	ldi	r24, 0xED	; 237
    26f0:	93 e0       	ldi	r25, 0x03	; 3
    26f2:	0e 94 f1 03 	call	0x7e2	; 0x7e2 <vListInsertEnd>
				}

				if( pxTCB->uxPriority > pxCurrentTCB->uxPriority )
    26f6:	e0 91 9b 03 	lds	r30, 0x039B
    26fa:	f0 91 9c 03 	lds	r31, 0x039C
    26fe:	9e 89       	ldd	r25, Y+22	; 0x16
    2700:	86 89       	ldd	r24, Z+22	; 0x16
    2702:	89 17       	cp	r24, r25
    2704:	78 f4       	brcc	.+30     	; 0x2724 <xTaskGenericNotifyFromISR+0x110>
				{
					/* The notified task has a priority above the currently
					executing task so a yield is required. */
					if( pxHigherPriorityTaskWoken != NULL )
    2706:	e1 14       	cp	r14, r1
    2708:	f1 04       	cpc	r15, r1
    270a:	21 f0       	breq	.+8      	; 0x2714 <xTaskGenericNotifyFromISR+0x100>
					{
						*pxHigherPriorityTaskWoken = pdTRUE;
    270c:	81 e0       	ldi	r24, 0x01	; 1
    270e:	f7 01       	movw	r30, r14
    2710:	80 83       	st	Z, r24
    2712:	09 c0       	rjmp	.+18     	; 0x2726 <xTaskGenericNotifyFromISR+0x112>
					else
					{
						/* Mark that a yield is pending in case the user is not
						using the "xHigherPriorityTaskWoken" parameter to an ISR
						safe FreeRTOS function. */
						xYieldPending = pdTRUE;
    2714:	81 e0       	ldi	r24, 0x01	; 1
    2716:	80 93 a1 03 	sts	0x03A1, r24
    271a:	05 c0       	rjmp	.+10     	; 0x2726 <xTaskGenericNotifyFromISR+0x112>
						pxTCB->ulNotifiedValue = ulValue;
					}
					else
					{
						/* The value could not be written to the task. */
						xReturn = pdFAIL;
    271c:	80 e0       	ldi	r24, 0x00	; 0
    271e:	03 c0       	rjmp	.+6      	; 0x2726 <xTaskGenericNotifyFromISR+0x112>

			traceTASK_NOTIFY_FROM_ISR();

			/* If the task is in the blocked state specifically to wait for a
			notification then unblock it now. */
			if( ucOriginalNotifyState == taskWAITING_NOTIFICATION )
    2720:	81 e0       	ldi	r24, 0x01	; 1
    2722:	01 c0       	rjmp	.+2      	; 0x2726 <xTaskGenericNotifyFromISR+0x112>
					/* The delayed and ready lists cannot be accessed, so hold
					this task pending until the scheduler is resumed. */
					vListInsertEnd( &( xPendingReadyList ), &( pxTCB->xEventListItem ) );
				}

				if( pxTCB->uxPriority > pxCurrentTCB->uxPriority )
    2724:	81 e0       	ldi	r24, 0x01	; 1
			}
		}
		portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );

		return xReturn;
	}
    2726:	df 91       	pop	r29
    2728:	cf 91       	pop	r28
    272a:	1f 91       	pop	r17
    272c:	0f 91       	pop	r16
    272e:	ff 90       	pop	r15
    2730:	ef 90       	pop	r14
    2732:	08 95       	ret

00002734 <vTaskNotifyGiveFromISR>:
/*-----------------------------------------------------------*/

#if( configUSE_TASK_NOTIFICATIONS == 1 )

	void vTaskNotifyGiveFromISR( TaskHandle_t xTaskToNotify, BaseType_t *pxHigherPriorityTaskWoken )
	{
    2734:	ef 92       	push	r14
    2736:	ff 92       	push	r15
    2738:	0f 93       	push	r16
    273a:	1f 93       	push	r17
    273c:	cf 93       	push	r28
    273e:	df 93       	push	r29
    2740:	ec 01       	movw	r28, r24
    2742:	8b 01       	movw	r16, r22

		pxTCB = ( TCB_t * ) xTaskToNotify;

		uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
		{
			ucOriginalNotifyState = pxTCB->ucNotifyState;
    2744:	29 a5       	lds	r18, 0x69
			pxTCB->ucNotifyState = taskNOTIFICATION_RECEIVED;
    2746:	82 e0       	ldi	r24, 0x02	; 2
    2748:	89 a7       	lds	r24, 0x79

			/* 'Giving' is equivalent to incrementing a count in a counting
			semaphore. */
			( pxTCB->ulNotifiedValue )++;
    274a:	8d a1       	lds	r24, 0x4d
    274c:	9e a1       	lds	r25, 0x4e
    274e:	af a1       	lds	r26, 0x4f
    2750:	b8 a5       	lds	r27, 0x68
    2752:	01 96       	adiw	r24, 0x01	; 1
    2754:	a1 1d       	adc	r26, r1
    2756:	b1 1d       	adc	r27, r1
    2758:	8d a3       	lds	r24, 0x5d
    275a:	9e a3       	lds	r25, 0x5e
    275c:	af a3       	lds	r26, 0x5f
    275e:	b8 a7       	lds	r27, 0x78

			traceTASK_NOTIFY_GIVE_FROM_ISR();

			/* If the task is in the blocked state specifically to wait for a
			notification then unblock it now. */
			if( ucOriginalNotifyState == taskWAITING_NOTIFICATION )
    2760:	21 30       	cpi	r18, 0x01	; 1
    2762:	e9 f5       	brne	.+122    	; 0x27de <vTaskNotifyGiveFromISR+0xaa>
			{
				/* The task should not have been on an event list. */
				configASSERT( listLIST_ITEM_CONTAINER( &( pxTCB->xEventListItem ) ) == NULL );

				if( uxSchedulerSuspended == ( UBaseType_t ) pdFALSE )
    2764:	80 91 9d 03 	lds	r24, 0x039D
    2768:	88 23       	and	r24, r24
    276a:	01 f5       	brne	.+64     	; 0x27ac <vTaskNotifyGiveFromISR+0x78>
				{
					( void ) uxListRemove( &( pxTCB->xStateListItem ) );
    276c:	ee 24       	eor	r14, r14
    276e:	ff 24       	eor	r15, r15
    2770:	68 94       	set
    2772:	e1 f8       	bld	r14, 1
    2774:	ec 0e       	add	r14, r28
    2776:	fd 1e       	adc	r15, r29
    2778:	c7 01       	movw	r24, r14
    277a:	0e 94 42 04 	call	0x884	; 0x884 <uxListRemove>
					prvAddTaskToReadyList( pxTCB );
    277e:	8e 89       	ldd	r24, Y+22	; 0x16
    2780:	90 91 a4 03 	lds	r25, 0x03A4
    2784:	98 17       	cp	r25, r24
    2786:	10 f4       	brcc	.+4      	; 0x278c <vTaskNotifyGiveFromISR+0x58>
    2788:	80 93 a4 03 	sts	0x03A4, r24
    278c:	90 e0       	ldi	r25, 0x00	; 0
    278e:	9c 01       	movw	r18, r24
    2790:	22 0f       	add	r18, r18
    2792:	33 1f       	adc	r19, r19
    2794:	22 0f       	add	r18, r18
    2796:	33 1f       	adc	r19, r19
    2798:	22 0f       	add	r18, r18
    279a:	33 1f       	adc	r19, r19
    279c:	82 0f       	add	r24, r18
    279e:	93 1f       	adc	r25, r19
    27a0:	82 55       	subi	r24, 0x52	; 82
    27a2:	9c 4f       	sbci	r25, 0xFC	; 252
    27a4:	b7 01       	movw	r22, r14
    27a6:	0e 94 f1 03 	call	0x7e2	; 0x7e2 <vListInsertEnd>
    27aa:	07 c0       	rjmp	.+14     	; 0x27ba <vTaskNotifyGiveFromISR+0x86>
				}
				else
				{
					/* The delayed and ready lists cannot be accessed, so hold
					this task pending until the scheduler is resumed. */
					vListInsertEnd( &( xPendingReadyList ), &( pxTCB->xEventListItem ) );
    27ac:	be 01       	movw	r22, r28
    27ae:	64 5f       	subi	r22, 0xF4	; 244
    27b0:	7f 4f       	sbci	r23, 0xFF	; 255
    27b2:	8d ee       	ldi	r24, 0xED	; 237
    27b4:	93 e0       	ldi	r25, 0x03	; 3
    27b6:	0e 94 f1 03 	call	0x7e2	; 0x7e2 <vListInsertEnd>
				}

				if( pxTCB->uxPriority > pxCurrentTCB->uxPriority )
    27ba:	e0 91 9b 03 	lds	r30, 0x039B
    27be:	f0 91 9c 03 	lds	r31, 0x039C
    27c2:	9e 89       	ldd	r25, Y+22	; 0x16
    27c4:	86 89       	ldd	r24, Z+22	; 0x16
    27c6:	89 17       	cp	r24, r25
    27c8:	50 f4       	brcc	.+20     	; 0x27de <vTaskNotifyGiveFromISR+0xaa>
				{
					/* The notified task has a priority above the currently
					executing task so a yield is required. */
					if( pxHigherPriorityTaskWoken != NULL )
    27ca:	01 15       	cp	r16, r1
    27cc:	11 05       	cpc	r17, r1
    27ce:	21 f0       	breq	.+8      	; 0x27d8 <vTaskNotifyGiveFromISR+0xa4>
					{
						*pxHigherPriorityTaskWoken = pdTRUE;
    27d0:	81 e0       	ldi	r24, 0x01	; 1
    27d2:	f8 01       	movw	r30, r16
    27d4:	80 83       	st	Z, r24
    27d6:	03 c0       	rjmp	.+6      	; 0x27de <vTaskNotifyGiveFromISR+0xaa>
					else
					{
						/* Mark that a yield is pending in case the user is not
						using the "xHigherPriorityTaskWoken" parameter in an ISR
						safe FreeRTOS function. */
						xYieldPending = pdTRUE;
    27d8:	81 e0       	ldi	r24, 0x01	; 1
    27da:	80 93 a1 03 	sts	0x03A1, r24
					mtCOVERAGE_TEST_MARKER();
				}
			}
		}
		portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );
	}
    27de:	df 91       	pop	r29
    27e0:	cf 91       	pop	r28
    27e2:	1f 91       	pop	r17
    27e4:	0f 91       	pop	r16
    27e6:	ff 90       	pop	r15
    27e8:	ef 90       	pop	r14
    27ea:	08 95       	ret

000027ec <xTaskNotifyStateClear>:
	TCB_t *pxTCB;
	BaseType_t xReturn;

		/* If null is passed in here then it is the calling task that is having
		its notification state cleared. */
		pxTCB = prvGetTCBFromHandle( xTask );
    27ec:	00 97       	sbiw	r24, 0x00	; 0
    27ee:	29 f4       	brne	.+10     	; 0x27fa <xTaskNotifyStateClear+0xe>
    27f0:	e0 91 9b 03 	lds	r30, 0x039B
    27f4:	f0 91 9c 03 	lds	r31, 0x039C
    27f8:	01 c0       	rjmp	.+2      	; 0x27fc <xTaskNotifyStateClear+0x10>
    27fa:	fc 01       	movw	r30, r24

		taskENTER_CRITICAL();
    27fc:	0f b6       	in	r0, 0x3f	; 63
    27fe:	f8 94       	cli
    2800:	0f 92       	push	r0
		{
			if( pxTCB->ucNotifyState == taskNOTIFICATION_RECEIVED )
    2802:	81 a5       	lds	r24, 0x61
    2804:	82 30       	cpi	r24, 0x02	; 2
    2806:	19 f4       	brne	.+6      	; 0x280e <xTaskNotifyStateClear+0x22>
			{
				pxTCB->ucNotifyState = taskNOT_WAITING_NOTIFICATION;
    2808:	11 a6       	lds	r17, 0xb1
				xReturn = pdPASS;
    280a:	81 e0       	ldi	r24, 0x01	; 1
    280c:	01 c0       	rjmp	.+2      	; 0x2810 <xTaskNotifyStateClear+0x24>
			}
			else
			{
				xReturn = pdFAIL;
    280e:	80 e0       	ldi	r24, 0x00	; 0
			}
		}
		taskEXIT_CRITICAL();
    2810:	0f 90       	pop	r0
    2812:	0f be       	out	0x3f, r0	; 63

		return xReturn;
	}
    2814:	08 95       	ret

00002816 <memcpy>:
    2816:	fb 01       	movw	r30, r22
    2818:	dc 01       	movw	r26, r24
    281a:	02 c0       	rjmp	.+4      	; 0x2820 <memcpy+0xa>
    281c:	01 90       	ld	r0, Z+
    281e:	0d 92       	st	X+, r0
    2820:	41 50       	subi	r20, 0x01	; 1
    2822:	50 40       	sbci	r21, 0x00	; 0
    2824:	d8 f7       	brcc	.-10     	; 0x281c <memcpy+0x6>
    2826:	08 95       	ret

00002828 <_exit>:
    2828:	f8 94       	cli

0000282a <__stop_program>:
    282a:	ff cf       	rjmp	.-2      	; 0x282a <__stop_program>
